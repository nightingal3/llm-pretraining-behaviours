import argparse
import json
import pandas as pd
from typing import List, Tuple
from tqdm import tqdm
from langdetect import detect
from langdetect.lang_detect_exception import LangDetectException
from openai import OpenAI
import os
import pycld2 as cld2
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns

client = OpenAI()


def detect_language(text: str) -> str:
    """Detect the language of the text using CLD2."""
    try:
        # isReliable, textBytesFound, details
        _, _, details = cld2.detect(text[:10000])  # Limit text length for performance
        return details[0][1]  # Return the most likely language
    except Exception:
        return "unknown"


def extract_top_category(classification: str) -> Tuple[str, str]:
    top_categories = {
        "web": ["social_media", "news", "blogs", "forums", "shopping"],
        "books": ["literary", "fiction", "nonfiction", "textbooks"],
        "reference": ["encyclopedic", "dictionaries"],
        "academic": ["sciences", "humanities"],
        "code": ["source_code", "documentation"],
        "media": ["podcasts", "subtitles"],
        "patent": [],
        "specific_datasets": [],
        "incoherent": [],
        "unknown": [],
    }

    # Create a reverse mapping from subcategories to top categories
    subcategory_to_top = {
        sub: top for top, subs in top_categories.items() for sub in subs
    }

    classification_lower = classification.lower()

    for top_category in top_categories.keys():
        if top_category in classification_lower:
            return top_category, classification

    for word in classification_lower.split():
        if word in subcategory_to_top:
            return subcategory_to_top[word], classification

    for subcategory, top_category in subcategory_to_top.items():
        if subcategory in classification_lower:
            return top_category, classification

    return "unknown", classification

def classify_incoherent(document):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": """You are a system tasked with classifying documents. First, determine if this document is relatively coherent. These documents are generated by language models, so they may not make sense. Classify a document as incoherent ONLY if it shows extreme repetition, code mixes in a way that does not make sense (such as different languages referencing entirely different subjects), or if it is mostly gibberish. Don't worry about logic errors or factual inconsistencies. If multiple documents are mixed into one, classify it as incoherent. Respond ONLY with "incoherent" if the document is incoherent, otherwise respond with "not_incoherent"."""
        },
        {
            "role": "user",
            "content": f"Please classify the document as incoherent or not_incoherent.\nDocument: {document}"
            }],
        temperature=0,
        max_tokens=10,
    )
    return response.choices[0].message.content

def classify_code(document):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": """Determine if this document contains programming code. Look for:
1. Programming language keywords (def, class, import, etc)
2. Code blocks (marked with backticks, indentation patterns)
3. Stack Overflow-style Q&A about programming
4. File extensions (.py, .js, etc)
5. Documentation about code/config files

Respond ONLY with:
- "code" if ANY of these are present
- "not_code" otherwise"""
        },
        {
            "role": "user",
            "content": f"Please classify the document as code or not_code.\nDocument: {document}"
        }],
        temperature=0,
        max_tokens=10,
    )
    return response.choices[0].message.content

def classify_web(document):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": """For documents WITHOUT programming code, determine if this is web content. Web content includes news articles, social media and online forums, blog posts, shopping websites, and other general websites. This includes a wide variety of content, and anything that looks like it may be a web article at all should be included. Look for:
1. URLs or hyperlinks
2. Social media formatting (@mentions, #hashtags)
3. "Click here" or UI elements
4. Comment threads or forum posts
5. Shopping/e-commerce language
6. Bylines or author names
7. Descriptions of products or product features

Respond ONLY with:
- "web" if ANY of these are present
- "not_web" otherwise"""
        }, 
        {
            "role": "user",
            "content": f"Please classify the document as web or not_web.\nDocument: {document}"
        }],
        temperature=0,
        max_tokens=10,
    )
    return response.choices[0].message.content

def classify_academic(document):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": """For documents WITHOUT programming code, determine if this is academic or patent-related content. Academic content consists of research papers and snippets of research in both sciences and humanities, as well as patent applications. Student essays or assignments should also be included in this category. Look for:
1. Citations or references 
2. Latex formatting such as equations or tables
3. Formal academic language, not aimed at educating a general audience
4. Technical jargon or domain-specific terminology
5. Patent numbers or legal language (but not court documents, only patents)

Do NOT classify as academic if the document:
- Only uses occasional technical terms
- Is a popular science article or description of a scientific study, rather than the study itself
- Is educational but aimed at a general audience

Respond ONLY with:
- "academic" if ANY of these are present
- "not_academic" otherwise"""
        },
        {
            "role": "user",
            "content": f"Please classify the document as academic or not_academic.\nDocument: {document}"
            }],
        temperature=0,
        max_tokens=10,
    )
    return response.choices[0].message.content

def classify_remaining(document):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": """For documents WITHOUT programming code, determine if this is a book, reference material (including media content), or a specific dataset. Books include literary works, fiction, and narrative nonfiction. Reference material includes wikipedia, dictionaries, textbooks and textbook like content, and encyclopedias. Please note that reference should also include instruction or human preference datasets for language model training. Media content includes podcasts, subtitles, and other media-related text. Specific datasets are unique and not covered by the other categories, such as biomedical datasets or molecules, chess PGNs or specific data formats not covered by any other category. Look for:
            
            For the books category:
            1. Chapter headings or book titles
            2. Fictional character names or dialogue
            3. For literary nonfiction, look for a more narrative and less didactic tone
            4. Extended narrative prose or dialogue
            Do NOT classify as books if the document:
            - Only has a single dialogue snippet
            - Could be a web article
            - Is primarily informational or educational (use reference instead)

            For the reference category:
            1. Definitions or explanations of terms
            2. Encyclopedic formatting
            3. Textbook-like language
            4. Explanations or examples meant to educate a reader
            5. Chat formatting like 'User:/Assistant:' or similar tokens
            6. Court documents or legal language (NOT patents)
            7. Wikipedia headers such as 'references' or 'external links'

            For the media category (should be classified as reference):
            1. Audio or video timestamps
            2. Subtitles or captions

            For the specific datasets category:
            1. Unique names or identifiers
            2. Dataset-specific formatting
            3. Data or metadata descriptions

            If this seems to be a web document (social media, news, blogs, forums, shopping), you can also back off to the 'web' category.

            Respond ONLY with:
            - "books" if the document is a book
            - "reference" if the document is reference material
            - "specific_datasets" if the document is a specific dataset
            - "web" if the document is web content
            - "unknown" if none of these are present
            """
        }, 
        {
            "role": "user",
            "content": f"Please classify the document as books, reference, media, specific_datasets, or unknown.\nDocument: {document}"
            }],
        temperature=0,
        max_tokens=10,
    )
    return response.choices[0].message.content

def read_samples(file_path: str, text_field: str = "text") -> List[str]:
    """Read all text samples from a file (supports JSONL format)."""
    if file_path.endswith(".jsonl"):
        import jsonlines
        with jsonlines.open(file_path) as reader:
            if text_field == "resps":
                return [record["resps"][0][0] for record in reader]
            return [record[text_field] for record in reader]
    else:
        raise ValueError(f"Unsupported file format: {file_path}")


def classify_multistep(document: str) -> str:
    """Classify the document using a multi-step approach."""
    # Classify incoherent documents
    incoherent = classify_incoherent(document)
    if incoherent == "incoherent":
        return "incoherent"

    # Classify programming code
    code = classify_code(document)
    if code == "code":
        return "code"

    # Classify web content
    web = classify_web(document)
    if web == "web":
        return "web"

    # Classify academic content
    academic = classify_academic(document)
    if academic == "academic":
        return "academic"

    # Classify remaining categories
    return classify_remaining(document)

def evaluate_predictions(true_labels: List[str], pred_labels: List[str], output_dir: str):
    """Generate evaluation metrics and visualizations, focusing on precision for classifiable categories.
    Treats 'unknown' and 'incoherent' as the same category and excludes them from scoring.
    """
    # Normalize labels - treat unknown and incoherent as the same
    norm_true = ['unknown' if l in ['unknown', 'incoherent'] else l for l in true_labels]
    norm_pred = ['unknown' if l in ['unknown', 'incoherent'] else l for l in pred_labels]
    
    # Filter out unknown/incoherent from both predictions and true labels
    known_mask = [(pred != "unknown" and true != "unknown") 
                 for pred, true in zip(norm_pred, norm_true)]
    filtered_true = [norm_true[i] for i in range(len(norm_true)) if known_mask[i]]
    filtered_pred = [norm_pred[i] for i in range(len(norm_pred)) if known_mask[i]]
    
    # Calculate how many samples we're keeping
    total_samples = len(true_labels)
    kept_samples = len(filtered_true)
    print(f"\nKept {kept_samples}/{total_samples} samples ({(kept_samples/total_samples)*100:.1f}%)")
    
    # Get unique categories excluding unknown/incoherent
    categories = sorted(list(set(filtered_true) | set(filtered_pred)))
    if 'unknown' in categories:
        categories.remove('unknown')
    if 'incoherent' in categories:
        categories.remove('incoherent')
    
    # Generate classification report only for known categories
    report = classification_report(filtered_true, filtered_pred, labels=categories)
    print("\nClassification Report (excluding unknown/incoherent):")
    print(report)
    
    # Calculate and display precision for each category
    print("\nPrecision by category:")
    for category in categories:
        true_positives = sum(1 for i in range(len(filtered_pred)) 
                           if filtered_pred[i] == category and filtered_true[i] == category)
        predicted_as_category = sum(1 for pred in filtered_pred if pred == category)
        if predicted_as_category > 0:
            precision = true_positives / predicted_as_category
            support = sum(1 for true in filtered_true if true == category)
            print(f"{category:>15}: {precision:.2f} (support: {support})")
    
    # Save detailed report
    with open(os.path.join(output_dir, "classification_report.txt"), "w") as f:
        f.write("Classification Report (excluding unknown/incoherent):\n")
        f.write(report)
        f.write("\n\nPrecision by category:\n")
        for category in categories:
            true_positives = sum(1 for i in range(len(filtered_pred)) 
                               if filtered_pred[i] == category and filtered_true[i] == category)
            predicted_as_category = sum(1 for pred in filtered_pred if pred == category)
            if predicted_as_category > 0:
                precision = true_positives / predicted_as_category
                support = sum(1 for true in filtered_true if true == category)
                f.write(f"{category:>15}: {precision:.2f} (support: {support})\n")
    
    # Generate and plot confusion matrix for known categories
    cm = confusion_matrix(filtered_true, filtered_pred, labels=categories)
    
    plt.figure(figsize=(12, 10))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)
    disp.plot(cmap='Blues', values_format='d')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "confusion_matrix.png"))
    plt.close()
    
    # Save confusion matrix as CSV for easier analysis
    cm_df = pd.DataFrame(cm, index=categories, columns=categories)
    cm_df.to_csv(os.path.join(output_dir, "confusion_matrix.csv"))

def process_file(input_file: str, output_file: str, resp_format: bool = False, limit: int = None, test_column: str = None):
    """Process the input file to generate domain distribution and save results."""
    print(f"Reading data from {input_file}...")
    
    # Read samples
    try:
        if input_file.endswith('.jsonl'):
            samples = read_samples(input_file, text_field = "resps" if resp_format else "text")
            df = pd.DataFrame({"text": samples})
            if limit:
                df = df.head(limit)
        elif input_file.endswith('.csv'):
            df = pd.read_csv(input_file)
            if limit:
                df = df.head(limit)
    except Exception as e:
        print(f"Error reading file: {e}")
        return

    results = []
    print("Classifying documents...")
    for text in tqdm(df['text'], desc="Processing documents"):
        if not isinstance(text, str) or len(text) < 50:  # skip if text is too short
            results.append({
                "language": "unknown",
                "prediction_raw": "too_short",
                "prediction": "incoherent"
            })
            continue
            
        language = detect_language(text)
        prediction = classify_multistep(text)  # Using the multistep classifier
        results.append({
            "language": language,
            "prediction": prediction,
        })

    # Add results to original dataframe
    for col in ['language', 'prediction']:
        df[col] = [r[col] for r in results]

    # Calculate and display domain distribution
    print("\nDomain Distribution:")
    domain_counts = df["prediction"].value_counts()
    total = len(df)
    for domain, count in domain_counts.items():
        percentage = (count / total) * 100
        print(f"{domain}: {count} ({percentage:.1f}%)")

    # If test column is provided, evaluate predictions
    if test_column and test_column in df.columns:
        print("\nEvaluating predictions...")
        # Filter out rows where test column is empty/null
        mask = df[test_column].notna()
        if mask.sum() > 0:
            true_labels = df[mask][test_column].tolist()
            pred_labels = df[mask]['prediction'].tolist()
            
            output_dir = os.path.dirname(output_file)
            evaluate_predictions(true_labels, pred_labels, output_dir)
        else:
            print(f"Warning: No valid test labels found in column '{test_column}'")

    # Save results to output file
    print(f"Saving results to {output_file}...")
    output_dir = os.path.dirname(output_file)
    os.makedirs(output_dir, exist_ok=True)
    df.to_csv(output_file, index=False)
    if test_column:
        misclassifications = df[df['prediction'] != df[test_column]]
        misclassifications.to_csv(os.path.join(output_dir, "misclassifications.csv"), index=False)
    print("Done.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate domain distribution for a file.")
    parser.add_argument("--input", type=str, help="Path to the input file (JSONL or CSV format).")
    parser.add_argument("--output", type=str, help="Path to the output file (CSV format).")
    parser.add_argument("--resps_format", action="store_true", help="Use 'resps' field for input data.")
    parser.add_argument("--limit", type=int, help="Limit the number of samples to process.")
    parser.add_argument("--test_column", type=str, help="Name of column containing test labels")

    args = parser.parse_args()
    process_file(args.input, args.output, args.resps_format, args.limit, args.test_column)