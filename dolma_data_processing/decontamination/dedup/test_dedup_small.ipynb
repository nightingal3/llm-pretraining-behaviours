{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file tests the deduplication code from EleutherAI's `janitor.py` file on small section(s) of Dolma to estimate how long full deduplication would take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run ``janitor.py`` with C++ on Linux:\n",
    "1. At ``lm-evaluation-harness/scripts/clean_training_data``, run ``c++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) janitor_util.cpp -o janitor_util$(python3-config --extension-suffix)``\n",
    "2. Rename the resulting ``.so`` file to ``janitor_util.so``\n",
    "3. Tell Python the location of ``janitor_util.so`` when it looks for ``janitor_util``: ```sys.path.append(harness_dir + \"/scripts/clean_training_data\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchen5/.local/lib/python3.9/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "/home/mchen5/.local/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mchen5/.local/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mchen5/.local/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "import pyarrow\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "harness_dir = str(Path(\"__file__\").resolve().parents[3] / \"lm-evaluation-harness\")\n",
    "sys.path.append(harness_dir)\n",
    "\n",
    "sys.path.append(harness_dir + \"/scripts/clean_training_data\")\n",
    "from lm_eval.decontamination.janitor import Janitor\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '256'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '128'\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tasks_txt_files/arithmetic.txt\", \"r\") as file:\n",
    "    arithmetic: str = file.read() # 339K\n",
    "with open(\"./contaminant.txt\", \"r\") as file:\n",
    "    contaminant: str = file.read() # 3.4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw: pyarrow.lib.Table = pq.read_table(\"/data/tir/projects/tir7/user_data/mchen5/dolma_100B/c4/part_1.arrow\")\n",
    "data_raw_size = sys.getsizeof(data_raw)\n",
    "print(f\"Size of data_raw: {sys.getsizeof(data_raw)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data_mini: 112133501 bytes\n"
     ]
    }
   ],
   "source": [
    "data_mini: pyarrow.lib.Table = pq.read_table(\"data_mini.arrow\")\n",
    "data_mini_size = sys.getsizeof(data_mini)\n",
    "print(f\"Size of data_mini: {sys.getsizeof(data_mini)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09c6eceb562caeba5b94489087fb1e8d</td>\n",
       "      <td>b'TAMPA, Fla., Nov. 03, 2016 (GLOBE NEWSWIRE) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7378e5a823604985555d1d9267827368</td>\n",
       "      <td>b'It was brimming with midges. Everywhere, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43088e9ab3bdb2236fc493594b99f72f</td>\n",
       "      <td>b'We encourage all our employees to be ambitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14b802b07c5b0685470f5c87fc60e394</td>\n",
       "      <td>b'The first road assignment is coming this wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>954f973826676c5a9421c0286f964bd3</td>\n",
       "      <td>b\"Course to upgrade skills for experienced Hr ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  09c6eceb562caeba5b94489087fb1e8d   \n",
       "1  7378e5a823604985555d1d9267827368   \n",
       "2  43088e9ab3bdb2236fc493594b99f72f   \n",
       "3  14b802b07c5b0685470f5c87fc60e394   \n",
       "4  954f973826676c5a9421c0286f964bd3   \n",
       "\n",
       "                                                text  \n",
       "0  b'TAMPA, Fla., Nov. 03, 2016 (GLOBE NEWSWIRE) ...  \n",
       "1  b'It was brimming with midges. Everywhere, the...  \n",
       "2  b'We encourage all our employees to be ambitio...  \n",
       "3  b'The first road assignment is coming this wee...  \n",
       "4  b\"Course to upgrade skills for experienced Hr ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = data_mini.to_pandas()\n",
    "df[\"text\"] = df[\"text\"].str.encode(\"utf-8\", errors=\"ignore\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decontaminate(contaminant: str, df: pd.DataFrame) -> (Janitor, pd.DataFrame):\n",
    "    janitor = Janitor()\n",
    "    result = copy.deepcopy(df)\n",
    "    result[\"num_contaminated\"] = 0\n",
    "\n",
    "    registration_time = datetime.timedelta(hours=0)\n",
    "    pre_register = datetime.datetime.now()\n",
    "    print(\"Registering contaminant\")\n",
    "    janitor.register_contaminant(contaminant)\n",
    "    registration_time += datetime.datetime.now() - pre_register\n",
    "    print(f\"Registered in {str(registration_time)}\")\n",
    "    \n",
    "    print(\"Decontaminating\")\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        (cleaned, num_contaminated) = janitor.clean_cpp(str(row[\"text\"]))\n",
    "        result.iloc[index][\"num_contaminated\"] = num_contaminated\n",
    "        if num_contaminated != 0:\n",
    "            result.iloc[index][\"text\"] = \"\".join(cleaned)\n",
    "        \n",
    "    return (janitor, result)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def test_decontaminate(contaminant: str, output_filename: str):\n",
    "    print(f\"Contaminant size {len(contaminant)}\")\n",
    "    janitor = Janitor(delete_chars=\"\")\n",
    "\n",
    "    registration_time = datetime.timedelta(hours=0)\n",
    "    pre_register = datetime.datetime.now()\n",
    "    print(\"Registering contaminant\")\n",
    "    janitor.register_contaminant(contaminant)\n",
    "    registration_time += datetime.datetime.now() - pre_register\n",
    "    print(f\"Registered in {str(registration_time)}\")\n",
    "\n",
    "    decontamination_time = datetime.timedelta(hours=0)\n",
    "    pre_decontaminate = datetime.datetime.now()\n",
    "    print(\"Decontaminating\")\n",
    "    # NOTE: Running clean_cpp throws unicodedecode error; maybe sort this out later\n",
    "    result = janitor.clean_python(data_string)\n",
    "    \n",
    "    decontamination_time += datetime.datetime.now() - pre_decontaminate\n",
    "    print(f\"Decontaminated in {str(decontamination_time)}\")\n",
    "\n",
    "    print(f\"Total time: {str(registration_time + decontamination_time)}\")\n",
    "    return janitor\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering contaminant\n",
      "Registered in 0:00:00.132472\n",
      "Decontaminating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/tmp/ipykernel_3968827/1521561067.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.iloc[index][\"num_contaminated\"] = num_contaminated\n",
      "/tmp/ipykernel_3968827/1521561067.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.iloc[index][\"text\"] = \"\".join(cleaned)\n",
      "100%|██████████| 50000/50000 [00:24<00:00, 2024.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(arithmetic_janitor, df_dedup) = test_decontaminate(arithmetic, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contaminant size 3518772866\n",
      "Registering contaminant\n",
      "Registered in 0:03:56.102353\n",
      "Decontaminating\n",
      "Decontaminated in 0:00:10.991375\n",
      "Total time: 0:04:07.093728\n"
     ]
    }
   ],
   "source": [
    "scrolls_janitor = test_decontaminate(scrolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For estimating runtimes:\n",
    "| Folder | # of arrow files |\n",
    "|--------|-------|\n",
    "| c4 | 4213499 |\n",
    "| common-crawl | 510983 |\n",
    "| gutenberg-books | 1178 |\n",
    "| peS2o | 20803 |\n",
    "| stack-code | 103818 |\n",
    "| wiki-en-simple | 2785999 |\n",
    "| dolma_100B (total) | 7636280 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing results:\n",
    "- Deduplicating full part 1 of c4 against arithmetic (C++):\n",
    "    - 512G RAM (43 G used), 1 GPU, 4 CPUs (169% efficiency) - 15 mins 40 sec\n",
    "- Deduplicating 1/10 of part 1 of c4 against arithmetic (Python):\n",
    "    - 512G RAM (43 G used), 1 GPU, 4 CPUs (169% efficiency) - 1 min 35 sec\n",
    "- Deduplicating full part 2 of c4 against arithemtic (C++):\n",
    "    - 512G RAM (26 G used), 1 GPU, 16 CPUs (14% efficiency) - 16 min 16 sec\n",
    "- Deduplicating parts 5 - 12 of c4 against arithmetic (C++):\n",
    "    - 512G RAM (43 G used), 1 GPU, 16 CPUs (66% efficiency) - 140 min\n",
    "        - Average 17.5 min per part\n",
    "\n",
    "To do:\n",
    "- Multithread(?) by splitting data into chunks and deduplicating each chunk in parallel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "towerllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
