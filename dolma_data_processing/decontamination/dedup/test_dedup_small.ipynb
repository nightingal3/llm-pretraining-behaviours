{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file tests the deduplication code from EleutherAI's `janitor.py` file on small section(s) of Dolma to estimate how long full deduplication would take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run ``janitor.py`` with C++ on Linux:\n",
    "1. At ``lm-evaluation-harness/scripts/clean_training_data``, run ``c++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) janitor_util.cpp -o janitor_util$(python3-config --extension-suffix)``\n",
    "2. Rename the resulting ``.so`` file to ``janitor_util.so``\n",
    "3. Tell Python the location of ``janitor_util.so`` when it looks for ``janitor_util``: ```sys.path.append(harness_dir + \"/scripts/clean_training_data\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchen5/.local/lib/python3.9/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "/home/mchen5/.local/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mchen5/.local/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "import pyarrow\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "harness_dir = str(Path(\"__file__\").resolve().parents[3] / \"lm-evaluation-harness\")\n",
    "sys.path.append(harness_dir)\n",
    "\n",
    "sys.path.append(harness_dir + \"/scripts/clean_training_data\")\n",
    "from lm_eval.decontamination.janitor import Janitor\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '256'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '128'\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./tasks_txt_files/arithmetic.txt\", \"r\") as file:\n",
    "#     arithmetic: str = file.read() # 339K\n",
    "# with open(\"./contaminant.txt\", \"r\") as file:\n",
    "#     contaminant: str = file.read() # 3.4G\n",
    "# contaminant = contaminant.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contaminant_mini = contaminant[:20000].encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "# with open(\"./contaminant_mini.txt\", \"w\") as file:\n",
    "#     file.write(contaminant_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./contaminant_mini.txt\", \"r\") as file:\n",
    "    contaminant_mini: str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data_mini: 112133501 bytes\n"
     ]
    }
   ],
   "source": [
    "data_mini: pyarrow.lib.Table = pq.read_table(\"data_mini.arrow\")\n",
    "data_mini_size = sys.getsizeof(data_mini)\n",
    "print(f\"Size of data_mini: {sys.getsizeof(data_mini)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09c6eceb562caeba5b94489087fb1e8d</td>\n",
       "      <td>TAMPA, Fla., Nov. 03, 2016 (GLOBE NEWSWIRE) --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7378e5a823604985555d1d9267827368</td>\n",
       "      <td>It was brimming with midges. Everywhere, these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43088e9ab3bdb2236fc493594b99f72f</td>\n",
       "      <td>We encourage all our employees to be ambitious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14b802b07c5b0685470f5c87fc60e394</td>\n",
       "      <td>The first road assignment is coming this weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>954f973826676c5a9421c0286f964bd3</td>\n",
       "      <td>Course to upgrade skills for experienced Hr pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  09c6eceb562caeba5b94489087fb1e8d   \n",
       "1  7378e5a823604985555d1d9267827368   \n",
       "2  43088e9ab3bdb2236fc493594b99f72f   \n",
       "3  14b802b07c5b0685470f5c87fc60e394   \n",
       "4  954f973826676c5a9421c0286f964bd3   \n",
       "\n",
       "                                                text  \n",
       "0  TAMPA, Fla., Nov. 03, 2016 (GLOBE NEWSWIRE) --...  \n",
       "1  It was brimming with midges. Everywhere, these...  \n",
       "2  We encourage all our employees to be ambitious...  \n",
       "3  The first road assignment is coming this weeke...  \n",
       "4  Course to upgrade skills for experienced Hr pr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = data_mini.to_pandas()\n",
    "df[\"text\"] = df[\"text\"].str.encode(\"utf-8\", errors=\"ignore\").str.decode(\"utf-8\", errors=\"ignore\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontaminate(contaminant: str, df: pd.DataFrame) -> (Janitor, pd.DataFrame):\n",
    "    janitor = Janitor()\n",
    "    result = copy.deepcopy(df)\n",
    "    result[\"num_contaminated\"] = 0\n",
    "\n",
    "    print(\"Registering contaminant\")\n",
    "    pre_register = datetime.datetime.now()\n",
    "    janitor.register_contaminant(contaminant)\n",
    "    print(f\"Registered in {str(datetime.datetime.now() - pre_register)}\")\n",
    "    \n",
    "    print(\"Decontaminating\")\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # TODO: Why is there a UnicodeDecodeError????\n",
    "        (cleaned, num_contaminated) = janitor.clean_cpp(row[\"text\"].encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\"))\n",
    "        result.iloc[index][\"num_contaminated\"] = num_contaminated\n",
    "        if num_contaminated != 0:\n",
    "            result.iloc[index][\"text\"] = \"\".join(cleaned)\n",
    "        \n",
    "    return (janitor, result)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def test_decontaminate(contaminant: str, output_filename: str):\n",
    "    print(f\"Contaminant size {len(contaminant)}\")\n",
    "    janitor = Janitor(delete_chars=\"\")\n",
    "\n",
    "    registration_time = datetime.timedelta(hours=0)\n",
    "    pre_register = datetime.datetime.now()\n",
    "    print(\"Registering contaminant\")\n",
    "    janitor.register_contaminant(contaminant)\n",
    "    registration_time += datetime.datetime.now() - pre_register\n",
    "    print(f\"Registered in {str(registration_time)}\")\n",
    "\n",
    "    decontamination_time = datetime.timedelta(hours=0)\n",
    "    pre_decontaminate = datetime.datetime.now()\n",
    "    print(\"Decontaminating\")\n",
    "    # NOTE: Running clean_cpp throws unicodedecode error; maybe sort this out later\n",
    "    result = janitor.clean_python(data_string)\n",
    "    \n",
    "    decontamination_time += datetime.datetime.now() - pre_decontaminate\n",
    "    print(f\"Decontaminated in {str(decontamination_time)}\")\n",
    "\n",
    "    print(f\"Total time: {str(registration_time + decontamination_time)}\")\n",
    "    return janitor\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering contaminant\n",
      "Registered in 0:00:00.001266\n",
      "Decontaminating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe2 in position 86: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (janitor, df_dedup) \u001b[38;5;241m=\u001b[39m \u001b[43mdecontaminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontaminant_mini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mdecontaminate\u001b[0;34m(contaminant, df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecontaminating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# NOTE: Not sure how to fix the utf-8 decoding error\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     (cleaned, num_contaminated) \u001b[38;5;241m=\u001b[39m \u001b[43mjanitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_cpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     result\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_contaminated\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_contaminated\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_contaminated \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/data/tir/projects/tir7/user_data/mchen5/llm-pretraining-behaviours/lm-evaluation-harness/lm_eval/decontamination/janitor.py:207\u001b[0m, in \u001b[0;36mJanitor.clean_cpp\u001b[0;34m(self, dirty_string)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_cpp\u001b[39m(\u001b[38;5;28mself\u001b[39m, dirty_string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    204\u001b[0m     dirty_string_utf_8 \u001b[38;5;241m=\u001b[39m dirty_string\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     )\n\u001b[0;32m--> 207\u001b[0m     contamination_indices \u001b[38;5;241m=\u001b[39m \u001b[43mjanitor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_ngram_with_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirty_string_utf_8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngram_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_chunks(dirty_string, contamination_indices),\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mlen\u001b[39m(contamination_indices),\n\u001b[1;32m    215\u001b[0m     )\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe2 in position 86: unexpected end of data"
     ]
    }
   ],
   "source": [
    "(janitor, df_dedup) = decontaminate(contaminant_mini, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_dedup to a new arrow file\n",
    "def pandas_to_arrow(df: pd.DataFrame, output_file: str):\n",
    "    schema = pyarrow.Schema.from_pandas(df, preserve_index=False)\n",
    "    table = pyarrow.Table.from_pandas(df, preserve_index=False)\n",
    "    \n",
    "    writer = pyarrow.ipc.new_file(output_file, schema)\n",
    "    writer.write(table)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_write = datetime.datetime.now()\n",
    "pandas_to_arrow(df_dedup)\n",
    "print(f\"Finished writing in {datetime.datetime.now() - pre_write}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing results:\n",
    "- Deduplicating full part 1 of c4 against arithmetic (C++):\n",
    "    - 512G RAM (43 G used), 1 GPU, 4 CPUs (169% efficiency) - 15 mins 40 sec\n",
    "- Deduplicating 1/10 of part 1 of c4 against arithmetic (Python):\n",
    "    - 512G RAM (43 G used), 1 GPU, 4 CPUs (169% efficiency) - 1 min 35 sec\n",
    "- Deduplicating full part 2 of c4 against arithemtic (C++):\n",
    "    - 512G RAM (26 G used), 1 GPU, 16 CPUs (14% efficiency) - 16 min 16 sec\n",
    "- Deduplicating parts 5 - 12 of c4 against arithmetic (C++):\n",
    "    - 512G RAM (43 G used), 1 GPU, 16 CPUs (66% efficiency) - 140 min\n",
    "        - Average 17.5 min per part\n",
    "\n",
    "To do:\n",
    "- Multithread(?) by splitting data into chunks and deduplicating each chunk in parallel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "towerllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
