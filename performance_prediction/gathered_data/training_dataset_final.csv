id,total_summary:total_size_tokens_billions,pretraining_summary:total_size_tokens_billions,pretraining_summary:percentage_web,pretraining_summary:percentage_code,pretraining_summary:percentage_books,pretraining_summary:percentage_encyclopedic,pretraining_summary:percentage_english,sft_summary:total_size_tokens_billions,pretraining_summary:percentage_academic
meta-llama/Meta-Llama-3-8B,0.0,,,,,,,,
mistralai/Mistral-7B-v0.1,0.0,,,,,,,,
01-ai/Yi-34B,3120.0,3120.0,0.8083,0.0853,0.0269,0.0109,,,
playdev7/theseed-v0.3,0.0,,,,,,,,
meta-llama/Llama-2-13b-hf,0.0,,,,,,,,
tiiuae/falcon-7b,1500.0,1500.0,0.82,0.03,0.07,,0.97,,
NousResearch/Nous-Hermes-2-Yi-34B,0.0,,,,,,,,
jb723/LLaMA2-en-ko-7B-model,2000.0,2000.0,,0.0838,,,0.897,,
CohereForAI/c4ai-command-r-v01,0.0,,,,,,,,
openai-community/gpt2,0.0,,,,,,,,
EleutherAI/pythia-6.9b,288.0,288.0,,,,,,,
CohereForAI/c4ai-command-r-plus,0.0,,,,,,,,
allenai/tulu-2-70b,1999.0,2000.0,,0.0838,,,0.897,-1.0,
allenai/OLMo-7B,2673.9,2673.9,0.82,0.1343,0.002,0.0014,1.0,,
TinyLlama/TinyLlama-1.1B-Chat-v1.0,950.0,950.0,,,,,,,
jisukim8873/falcon-7B-case-0,1500.0,1500.0,0.82,0.03,0.07,,0.97,,
huggyllama/llama-7b,1250.0,1250.0,0.82,0.065,0.045,0.045,,,
AbacusResearch/Jallabi-34B,3120.0,3120.0,0.8083,0.0853,0.0269,0.0109,,,
Qwen/Qwen-7B,3000.0,3000.0,,,,,,,
mistralai/Mixtral-8x7B-v0.1,0.0,,,,,,,,
kevin009/flyingllama-v2,0.0,,,,,,,,
meta-llama/Llama-2-7b,2000.0,2000.0,,0.0838,,,0.897,,
meta-llama/Meta-Llama-3-70B,0.0,,,,,,,,
mistral-community/Mixtral-8x22B-v0.1,0.0,,,,,,,,
allenai/tulu-2-dpo-70b,2000.0,2000.0,,0.0838,,,0.897,,
kevin009/babyllama-v0.6,950.0,950.0,,,,,,,
meta-llama/Llama-2-70b-chat-hf,2000.0,2000.0,,0.0838,,,0.897,,
jb723/cross_lingual_epoch2,2000.0,2000.0,,0.0838,,,0.897,,
openlm-research/open_llama_7b,1200.0,1200.0,0.8942,0.0492,0.0217,0.02,,,0.0233
meta-llama/Llama-2-70b-hf,2000.0,2000.0,,0.0838,,,0.897,,
Monero/WizardLM-13b-OpenAssistant-Uncensored,0.0,,,,,,,,
