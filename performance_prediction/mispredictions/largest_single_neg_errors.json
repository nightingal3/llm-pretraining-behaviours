[
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-astronomy_5-shot_acc",
    -0.4811711876015913
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-sociology_5-shot_acc",
    -0.4778464095509468
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_biology_5-shot_acc",
    -0.4521769852407515
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-college_biology_5-shot_acc",
    -0.4328165650367737
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_computer_science_5-shot_acc",
    -0.42466144323349
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-logical_fallacies_5-shot_acc",
    -0.4208297663671108
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-nutrition_5-shot_acc",
    -0.4110205989647535
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-moral_disputes_5-shot_acc",
    -0.4105763214861038
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-prehistory_5-shot_acc",
    -0.4078968564669291
  ],
  [
    "Qwen/Qwen-7B",
    "gsm8k_5-shot_acc",
    -0.4078655887234156
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-college_medicine_5-shot_acc",
    -0.4072842031200497
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_government_and_politics_5-shot_acc",
    -0.4064335035536573
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "gsm8k_5-shot_acc",
    -0.3953530069234428
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-business_ethics_5-shot_acc",
    -0.3950857591629028
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_geography_5-shot_acc",
    -0.387526633161487
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_psychology_5-shot_acc",
    -0.3783005927680829
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_macroeconomics_5-shot_acc",
    -0.3762648299718514
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-clinical_knowledge_5-shot_acc",
    -0.3757751307397519
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-jurisprudence_5-shot_acc",
    -0.3746371037430234
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-conceptual_physics_5-shot_acc",
    -0.3710731715598004
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-philosophy_5-shot_acc",
    -0.3679295569370797
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-security_studies_5-shot_acc",
    -0.3667932147882422
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-human_sexuality_5-shot_acc",
    -0.3664334853186862
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-professional_psychology_5-shot_acc",
    -0.3590035352831572
  ],
  [
    "Qwen/Qwen-7B",
    "hendrycksTest-sociology_5-shot_acc",
    -0.3586111535776907
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_chemistry_5-shot_acc",
    -0.355683167579726
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-management_5-shot_acc",
    -0.3537594479264565
  ],
  [
    "meta-llama/Meta-Llama-3-8B-Instruct",
    "gsm8k_5-shot_acc",
    -0.3514847329749222
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_world_history_5-shot_acc",
    -0.3449190751912724
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-us_foreign_policy_5-shot_acc",
    -0.3444514894485473
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-electrical_engineering_5-shot_acc",
    -0.3361754855205272
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-marketing_5-shot_acc",
    -0.3357233965498769
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-world_religions_5-shot_acc",
    -0.3321545727071705
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-miscellaneous_5-shot_acc",
    -0.3220834766311208
  ],
  [
    "01-ai/Yi-34B",
    "hendrycksTest-astronomy_5-shot_acc",
    -0.3133806994086817
  ],
  [
    "Qwen/Qwen-7B",
    "hendrycksTest-jurisprudence_5-shot_acc",
    -0.3130791728143338
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-high_school_us_history_5-shot_acc",
    -0.3068712774445028
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-college_computer_science_5-shot_acc",
    -0.305625479221344
  ],
  [
    "01-ai/Yi-34B",
    "hendrycksTest-electrical_engineering_5-shot_acc",
    -0.3042188465595246
  ],
  [
    "Qwen/Qwen-7B",
    "hendrycksTest-management_5-shot_acc",
    -0.3032935785437093
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-public_relations_5-shot_acc",
    -0.3017537935213609
  ],
  [
    "meta-llama/Meta-Llama-3-70B",
    "hendrycksTest-formal_logic_5-shot_acc",
    -0.299347856688121
  ],
  [
    "Qwen/Qwen-7B",
    "hendrycksTest-high_school_government_and_politics_5-shot_acc",
    -0.2973258847399697
  ]
]