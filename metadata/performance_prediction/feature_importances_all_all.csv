,0
sequence_length,0.3598347
total_params,0.22713171
dimension,0.12316255
mlp_ratio,0.10535707
biases_none,0.06669925
attention_variant_full,0.04292593
batch_instances,0.03155799
layer_norm_type_rmsnorm,0.010897843
total_summary:total_size_tokens_billions,0.008534336
attention_variant_gqa,0.0057218797
num_heads,0.0036902206
pretraining_summary:total_size_tokens_billions,0.0031945165
pretraining_summary:percentage_code,0.0030684047
biases_attn_only,0.0029125765
activation_swiglu,0.0019911546
pretraining_summary:percentage_english,0.0019178748
pretraining_summary:percentage_web,0.00072924834
activation_silu,0.00030661852
pretraining_summary:percentage_encyclopedic,0.00030089833
block_type_sequential,4.3828746e-05
activation_gelu,2.1447173e-05
sft_summary:total_size_tokens_billions,0.0
block_type_parallel,0.0
weight_tying_-1,0.0
positional_embeddings_rotary,0.0
positional_embeddings_rope,0.0
positional_embeddings_-1,0.0
batch_tokens,0.0
layer_norm_type_parametric,0.0
layer_norm_type_-1,0.0
biases_ln_only,0.0
block_type_-1,0.0
deep_key,0.0
pretraining_summary:percentage_academic,0.0
biases_-1,0.0
attention_variant_mqa,0.0
pretraining_summary:percentage_books,0.0
attention_variant_-1,0.0
activation_-1,0.0
weight_tying_FALSE,0.0
