{
    "model_name": "bigscience/bloom-1b7",
    "last_updated": "2024-12-19 13:38:14.414566",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.007326007326007326,
                "exact_match_stderr": 0.0036529080893830334,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.004592422502870264,
                "exact_match_stderr": 0.0022922488477038036,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.001851851851851852,
                "exact_match_stderr": 0.0018518518518518487,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.0022148394241417496,
                "exact_match_stderr": 0.0015652595934070718,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_geometry": {
                "exact_match": 0.0020876826722338203,
                "exact_match_stderr": 0.0020876826722338276,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.004219409282700422,
                "exact_match_stderr": 0.002980417365102052,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "minerva_math_algebra": {
                "exact_match": 0.0016849199663016006,
                "exact_match_stderr": 0.001190915943716835,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_3da": {
                "acc": 0.001,
                "acc_stderr": 0.0007069298939339458,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_3ds": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000116,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_4da": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000151,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_2ds": {
                "acc": 0.0125,
                "acc_stderr": 0.00248494717876267,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_5da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_1dc": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_4ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_2dm": {
                "acc": 0.0215,
                "acc_stderr": 0.0032440926417928273,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "arithmetic_2da": {
                "acc": 0.007,
                "acc_stderr": 0.0018647355360237557,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "gsm8k_cot": {
                "exact_match": 0.019711902956785442,
                "exact_match_stderr": 0.0038289829787357126,
                "timestamp": "2024-06-14T16-54-37.517980"
            },
            "gsm8k": {
                "exact_match": 0.002274450341167551,
                "exact_match_stderr": 0.0013121578148674335,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "anli_r2": {
                "brier_score": 1.0330875069706043,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "anli_r3": {
                "brier_score": 0.9725282585009661,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "anli_r1": {
                "brier_score": 1.060858355860431,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_eu": {
                "brier_score": 0.7072047602264854,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_vi": {
                "brier_score": 0.7456517590436983,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_ru": {
                "brier_score": 0.8780666443369725,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_zh": {
                "brier_score": 1.0595421588854064,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_tr": {
                "brier_score": 1.0231158229219457,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_fr": {
                "brier_score": 0.7775316951866434,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_en": {
                "brier_score": 0.6711576322549884,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_ur": {
                "brier_score": 0.923647671686833,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_ar": {
                "brier_score": 1.1627421056647778,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_de": {
                "brier_score": 0.8945053213391374,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_hi": {
                "brier_score": 0.7454041920812018,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_es": {
                "brier_score": 0.8212945296045504,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_bg": {
                "brier_score": 0.9352486767969873,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_sw": {
                "brier_score": 1.033987465428587,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_el": {
                "brier_score": 0.9576070804353392,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "xnli_th": {
                "brier_score": 1.311056215973815,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "logiqa2": {
                "brier_score": 1.1991580009166556,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "mathqa": {
                "brier_score": 0.9845015446410308,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T17-00-03.907320"
            },
            "lambada_standard": {
                "perplexity": 16.696442854077176,
                "perplexity_stderr": 0.5544057536741888,
                "acc": 0.4449835047545119,
                "acc_stderr": 0.006923679791679091,
                "timestamp": "2024-06-14T17-01-04.888098"
            },
            "lambada_openai": {
                "perplexity": 12.585182126996132,
                "perplexity_stderr": 0.40089107426896314,
                "acc": 0.4622549970890743,
                "acc_stderr": 0.0069461006470815665,
                "timestamp": "2024-06-14T17-01-04.888098"
            },
            "mmlu_world_religions": {
                "acc": 0.2982456140350877,
                "acc_stderr": 0.03508771929824565,
                "brier_score": 0.7542430156573607,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_formal_logic": {
                "acc": 0.14285714285714285,
                "acc_stderr": 0.031298431857438094,
                "brier_score": 0.798740683570427,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_prehistory": {
                "acc": 0.2839506172839506,
                "acc_stderr": 0.02508947852376513,
                "brier_score": 0.7590573428880001,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.23687150837988827,
                "acc_stderr": 0.014219570788103987,
                "brier_score": 0.760565800135267,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.26582278481012656,
                "acc_stderr": 0.028756799629658346,
                "brier_score": 0.7655519522477238,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_moral_disputes": {
                "acc": 0.30057803468208094,
                "acc_stderr": 0.024685316867257803,
                "brier_score": 0.7566306701713452,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_professional_law": {
                "acc": 0.2653194263363755,
                "acc_stderr": 0.011276198843958871,
                "brier_score": 0.763543464923393,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.2883435582822086,
                "acc_stderr": 0.035590395316173425,
                "brier_score": 0.7541555610476428,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.25,
                "acc_stderr": 0.03039153369274154,
                "brier_score": 0.7769130551084145,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_philosophy": {
                "acc": 0.2508038585209003,
                "acc_stderr": 0.02461977195669716,
                "brier_score": 0.781006843058891,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_jurisprudence": {
                "acc": 0.25925925925925924,
                "acc_stderr": 0.04236511258094633,
                "brier_score": 0.7708865794629522,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_international_law": {
                "acc": 0.35537190082644626,
                "acc_stderr": 0.0436923632657398,
                "brier_score": 0.7234428693278497,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.26666666666666666,
                "acc_stderr": 0.03453131801885415,
                "brier_score": 0.7755857983182882,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.24352331606217617,
                "acc_stderr": 0.030975436386845436,
                "brier_score": 0.7869607311121265,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.21428571428571427,
                "acc_stderr": 0.026653531596715473,
                "brier_score": 0.792844202748864,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_geography": {
                "acc": 0.24242424242424243,
                "acc_stderr": 0.030532892233932036,
                "brier_score": 0.758184696530688,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.22752293577981653,
                "acc_stderr": 0.017974463578776502,
                "brier_score": 0.7763696246652465,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_public_relations": {
                "acc": 0.21818181818181817,
                "acc_stderr": 0.03955932861795833,
                "brier_score": 0.7678053749290249,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.7840269984992296,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_sociology": {
                "acc": 0.263681592039801,
                "acc_stderr": 0.031157150869355568,
                "brier_score": 0.7852952947920849,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.22564102564102564,
                "acc_stderr": 0.02119363252514854,
                "brier_score": 0.7935731623921292,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_security_studies": {
                "acc": 0.2,
                "acc_stderr": 0.025607375986579153,
                "brier_score": 0.8063760510247837,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_professional_psychology": {
                "acc": 0.26633986928104575,
                "acc_stderr": 0.017883188134667195,
                "brier_score": 0.7657508919797539,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_human_sexuality": {
                "acc": 0.2595419847328244,
                "acc_stderr": 0.03844876139785271,
                "brier_score": 0.7665013825604922,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_econometrics": {
                "acc": 0.2543859649122807,
                "acc_stderr": 0.040969851398436695,
                "brier_score": 0.766316971646447,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_miscellaneous": {
                "acc": 0.2784163473818646,
                "acc_stderr": 0.016028295188992462,
                "brier_score": 0.7594185589263097,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_marketing": {
                "acc": 0.2863247863247863,
                "acc_stderr": 0.02961432369045665,
                "brier_score": 0.7569178236298468,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_management": {
                "acc": 0.24271844660194175,
                "acc_stderr": 0.042450224863844935,
                "brier_score": 0.8133530185364424,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_nutrition": {
                "acc": 0.24836601307189543,
                "acc_stderr": 0.02473998135511359,
                "brier_score": 0.78442135518889,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_medical_genetics": {
                "acc": 0.24,
                "acc_stderr": 0.042923469599092816,
                "brier_score": 0.7523798314128147,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_human_aging": {
                "acc": 0.19282511210762332,
                "acc_stderr": 0.026478240960489365,
                "brier_score": 0.7772495068884132,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_professional_medicine": {
                "acc": 0.16176470588235295,
                "acc_stderr": 0.022368672562886754,
                "brier_score": 0.808249444559704,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_medicine": {
                "acc": 0.24277456647398843,
                "acc_stderr": 0.0326926380614177,
                "brier_score": 0.7880406191469156,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_business_ethics": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.771045014592912,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.23773584905660378,
                "acc_stderr": 0.02619980880756193,
                "brier_score": 0.7870920404089861,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_global_facts": {
                "acc": 0.33,
                "acc_stderr": 0.047258156262526045,
                "brier_score": 0.7574532104546047,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_virology": {
                "acc": 0.25903614457831325,
                "acc_stderr": 0.03410646614071856,
                "brier_score": 0.7710796189243675,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_professional_accounting": {
                "acc": 0.24468085106382978,
                "acc_stderr": 0.02564555362226673,
                "brier_score": 0.7762138964007215,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_physics": {
                "acc": 0.22549019607843138,
                "acc_stderr": 0.041583075330832865,
                "brier_score": 0.8187186665326814,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2847682119205298,
                "acc_stderr": 0.03684881521389023,
                "brier_score": 0.7560166622001294,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_biology": {
                "acc": 0.23870967741935484,
                "acc_stderr": 0.024251071262208834,
                "brier_score": 0.7669627733915457,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_biology": {
                "acc": 0.2569444444444444,
                "acc_stderr": 0.03653946969442099,
                "brier_score": 0.76589617503354,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_anatomy": {
                "acc": 0.3333333333333333,
                "acc_stderr": 0.04072314811876837,
                "brier_score": 0.7545449490443557,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_chemistry": {
                "acc": 0.2,
                "acc_stderr": 0.04020151261036845,
                "brier_score": 0.7983463688517936,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_computer_security": {
                "acc": 0.2,
                "acc_stderr": 0.04020151261036845,
                "brier_score": 0.7738297058247153,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_computer_science": {
                "acc": 0.32,
                "acc_stderr": 0.04688261722621503,
                "brier_score": 0.7458884425655282,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_astronomy": {
                "acc": 0.29605263157894735,
                "acc_stderr": 0.03715062154998905,
                "brier_score": 0.752107495455209,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_college_mathematics": {
                "acc": 0.29,
                "acc_stderr": 0.045604802157206845,
                "brier_score": 0.7524346393147284,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.20425531914893616,
                "acc_stderr": 0.02635515841334941,
                "brier_score": 0.7891426254381969,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.7721622244111885,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.33,
                "acc_stderr": 0.04725815626252604,
                "brier_score": 0.7375773903853942,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_machine_learning": {
                "acc": 0.1875,
                "acc_stderr": 0.0370468111477387,
                "brier_score": 0.7739719958530921,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.30049261083743845,
                "acc_stderr": 0.03225799476233486,
                "brier_score": 0.7645420958708635,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.27314814814814814,
                "acc_stderr": 0.030388051301678116,
                "brier_score": 0.7466109237770758,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.2566137566137566,
                "acc_stderr": 0.022494510767503154,
                "brier_score": 0.7884536895302897,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.2689655172413793,
                "acc_stderr": 0.03695183311650232,
                "brier_score": 0.7678659005899077,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.28888888888888886,
                "acc_stderr": 0.027634907264178544,
                "brier_score": 0.7685854680890092,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-41-35.899405"
            },
            "arc_challenge": {
                "acc": 0.2627986348122867,
                "acc_stderr": 0.012862523175351331,
                "acc_norm": 0.2977815699658703,
                "acc_norm_stderr": 0.013363080107244487,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "hellaswag": {
                "acc": 0.37621987651862177,
                "acc_stderr": 0.004834461997944859,
                "acc_norm": 0.4794861581358295,
                "acc_norm_stderr": 0.004985580065946455,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "truthfulqa_mc2": {
                "acc": 0.4132695309257005,
                "acc_stderr": 0.014434938787204109,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "truthfulqa_gen": {
                "bleu_max": 6.25057775012128,
                "bleu_max_stderr": 0.3528698043271998,
                "bleu_acc": 0.24724602203182375,
                "bleu_acc_stderr": 0.015102404797359654,
                "bleu_diff": -0.4783944349233914,
                "bleu_diff_stderr": 0.29103233082588886,
                "rouge1_max": 18.178185223654555,
                "rouge1_max_stderr": 0.7404994679390557,
                "rouge1_acc": 0.2521419828641371,
                "rouge1_acc_stderr": 0.01520152224629999,
                "rouge1_diff": -1.0202739853119616,
                "rouge1_diff_stderr": 0.4615520291209216,
                "rouge2_max": 10.60641799597891,
                "rouge2_max_stderr": 0.5882439588833563,
                "rouge2_acc": 0.18727050183598531,
                "rouge2_acc_stderr": 0.013657229868067033,
                "rouge2_diff": -1.1219916084328412,
                "rouge2_diff_stderr": 0.4934334962891775,
                "rougeL_max": 17.075940690862858,
                "rougeL_max_stderr": 0.7066741788370577,
                "rougeL_acc": 0.25091799265605874,
                "rougeL_acc_stderr": 0.015176985027707682,
                "rougeL_diff": -0.81444520512165,
                "rougeL_diff_stderr": 0.45367739492458453,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "truthfulqa_mc1": {
                "acc": 0.24479804161566707,
                "acc_stderr": 0.015051869486714997,
                "timestamp": "2024-11-21T08-38-18.699254"
            },
            "winogrande": {
                "acc": 0.5445935280189423,
                "acc_stderr": 0.013996485037729775,
                "timestamp": "2024-11-21T08-38-18.699254"
            }
        }
    }
}