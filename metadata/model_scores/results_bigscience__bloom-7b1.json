{
    "model_name": "bigscience/bloom-7b1",
    "last_updated": "2024-12-19 13:38:18.341415",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.003663003663003663,
                "exact_match_stderr": 0.002587757368193454,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.001148105625717566,
                "exact_match_stderr": 0.0011481056257175725,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.003703703703703704,
                "exact_match_stderr": 0.0026164834572311967,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.0022148394241417496,
                "exact_match_stderr": 0.001565259593407063,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_geometry": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.004219409282700422,
                "exact_match_stderr": 0.002980417365102053,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "minerva_math_algebra": {
                "exact_match": 0.005897219882055603,
                "exact_match_stderr": 0.0022232943288310806,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_3da": {
                "acc": 0.002,
                "acc_stderr": 0.0009992493430694982,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_3ds": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000116,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_4da": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000151,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_2ds": {
                "acc": 0.0135,
                "acc_stderr": 0.0025811249685073444,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_5da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_1dc": {
                "acc": 0.024,
                "acc_stderr": 0.0034231358327511544,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_4ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_2dm": {
                "acc": 0.0315,
                "acc_stderr": 0.003906597720891821,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "arithmetic_2da": {
                "acc": 0.0185,
                "acc_stderr": 0.0030138707185866863,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "gsm8k_cot": {
                "exact_match": 0.021986353297952996,
                "exact_match_stderr": 0.004039162758110064,
                "timestamp": "2024-06-14T07-37-07.236381"
            },
            "gsm8k": {
                "exact_match": 0.024260803639120546,
                "exact_match_stderr": 0.004238007900001381,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "anli_r2": {
                "brier_score": 0.9456261005824846,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "anli_r3": {
                "brier_score": 0.9124531167930634,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "anli_r1": {
                "brier_score": 0.982579018108182,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_eu": {
                "brier_score": 0.7070982982123462,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_vi": {
                "brier_score": 0.7579336684566961,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_ru": {
                "brier_score": 0.7718940275749611,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_zh": {
                "brier_score": 1.1474241210913452,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_tr": {
                "brier_score": 0.8440682891485775,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_fr": {
                "brier_score": 0.7413355596902762,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_en": {
                "brier_score": 0.6356461345686089,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_ur": {
                "brier_score": 0.9251624347491019,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_ar": {
                "brier_score": 1.120036997482241,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_de": {
                "brier_score": 0.892294512080338,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_hi": {
                "brier_score": 0.7053726297546287,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_es": {
                "brier_score": 0.7988409860889734,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_bg": {
                "brier_score": 0.9255423577067828,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_sw": {
                "brier_score": 0.9813718635919855,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_el": {
                "brier_score": 0.9271262855069101,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "xnli_th": {
                "brier_score": 1.032461389997439,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "logiqa2": {
                "brier_score": 1.1331202068301027,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "mathqa": {
                "brier_score": 0.9772026799355674,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-14T07-45-44.940388"
            },
            "lambada_standard": {
                "perplexity": 7.352795006135428,
                "perplexity_stderr": 0.202079419708096,
                "acc": 0.581797011449641,
                "acc_stderr": 0.006872130244051415,
                "timestamp": "2024-06-14T07-47-06.594201"
            },
            "lambada_openai": {
                "perplexity": 6.619167022578283,
                "perplexity_stderr": 0.17610608259142468,
                "acc": 0.5761692218125364,
                "acc_stderr": 0.006884673454916903,
                "timestamp": "2024-06-14T07-47-06.594201"
            },
            "mmlu_world_religions": {
                "acc": 0.2807017543859649,
                "acc_stderr": 0.03446296217088427,
                "brier_score": 0.7547868709568236,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_formal_logic": {
                "acc": 0.29365079365079366,
                "acc_stderr": 0.040735243221471255,
                "brier_score": 0.7542957646039679,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_prehistory": {
                "acc": 0.2191358024691358,
                "acc_stderr": 0.023016705640262185,
                "brier_score": 0.7523443552886664,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.25139664804469275,
                "acc_stderr": 0.014508979453553977,
                "brier_score": 0.7510528990492207,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.21518987341772153,
                "acc_stderr": 0.02675082699467617,
                "brier_score": 0.7615802570185577,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_moral_disputes": {
                "acc": 0.23699421965317918,
                "acc_stderr": 0.022894082489925992,
                "brier_score": 0.7534295148857957,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_professional_law": {
                "acc": 0.28878748370273793,
                "acc_stderr": 0.011574914757219962,
                "brier_score": 0.7503956948481256,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.22085889570552147,
                "acc_stderr": 0.03259177392742177,
                "brier_score": 0.7566267051940508,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.21568627450980393,
                "acc_stderr": 0.028867431449849313,
                "brier_score": 0.7640591185075365,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_philosophy": {
                "acc": 0.26366559485530544,
                "acc_stderr": 0.02502553850053234,
                "brier_score": 0.7499865265122302,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_jurisprudence": {
                "acc": 0.1574074074074074,
                "acc_stderr": 0.035207039905179635,
                "brier_score": 0.764194816756646,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_international_law": {
                "acc": 0.38016528925619836,
                "acc_stderr": 0.04431324501968432,
                "brier_score": 0.7308189036868278,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.18787878787878787,
                "acc_stderr": 0.03050193405942914,
                "brier_score": 0.7642456313854691,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.3005181347150259,
                "acc_stderr": 0.03308818594415751,
                "brier_score": 0.740565281777382,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.2647058823529412,
                "acc_stderr": 0.02865749128507198,
                "brier_score": 0.7482446000796693,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_geography": {
                "acc": 0.3484848484848485,
                "acc_stderr": 0.033948539651564025,
                "brier_score": 0.7405135376552053,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.29908256880733947,
                "acc_stderr": 0.01963041728541517,
                "brier_score": 0.7443715431074973,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_public_relations": {
                "acc": 0.2636363636363636,
                "acc_stderr": 0.04220224692971987,
                "brier_score": 0.7532888263064784,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.7489981620742795,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_sociology": {
                "acc": 0.24875621890547264,
                "acc_stderr": 0.030567675938916718,
                "brier_score": 0.7505873310310913,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.31794871794871793,
                "acc_stderr": 0.02361088430892786,
                "brier_score": 0.7411049977825732,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_security_studies": {
                "acc": 0.2857142857142857,
                "acc_stderr": 0.02892058322067561,
                "brier_score": 0.7442189649442519,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_professional_psychology": {
                "acc": 0.24836601307189543,
                "acc_stderr": 0.017479487001364764,
                "brier_score": 0.7563644232783947,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_human_sexuality": {
                "acc": 0.2748091603053435,
                "acc_stderr": 0.03915345408847836,
                "brier_score": 0.7568870604049708,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_econometrics": {
                "acc": 0.23684210526315788,
                "acc_stderr": 0.039994238792813344,
                "brier_score": 0.7618061547279509,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_miscellaneous": {
                "acc": 0.24776500638569604,
                "acc_stderr": 0.015438083080568963,
                "brier_score": 0.7551437519659098,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_marketing": {
                "acc": 0.2863247863247863,
                "acc_stderr": 0.02961432369045666,
                "brier_score": 0.7505136324296918,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_management": {
                "acc": 0.30097087378640774,
                "acc_stderr": 0.0454160944650395,
                "brier_score": 0.7481389336784959,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_nutrition": {
                "acc": 0.3104575163398693,
                "acc_stderr": 0.02649303322514589,
                "brier_score": 0.7431157926009903,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_medical_genetics": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.7492520817638646,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_human_aging": {
                "acc": 0.19282511210762332,
                "acc_stderr": 0.026478240960489365,
                "brier_score": 0.7669465589527058,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_professional_medicine": {
                "acc": 0.3014705882352941,
                "acc_stderr": 0.027875982114273168,
                "brier_score": 0.747362125363743,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_medicine": {
                "acc": 0.2658959537572254,
                "acc_stderr": 0.03368762932259431,
                "brier_score": 0.7503399941846938,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_business_ethics": {
                "acc": 0.26,
                "acc_stderr": 0.04408440022768081,
                "brier_score": 0.7570753162485974,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.27169811320754716,
                "acc_stderr": 0.02737770662467071,
                "brier_score": 0.7442302549814358,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_global_facts": {
                "acc": 0.24,
                "acc_stderr": 0.042923469599092816,
                "brier_score": 0.7605468395990248,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_virology": {
                "acc": 0.20481927710843373,
                "acc_stderr": 0.031417842916639245,
                "brier_score": 0.7681776042810181,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_professional_accounting": {
                "acc": 0.24822695035460993,
                "acc_stderr": 0.025770015644290382,
                "brier_score": 0.7516006983355339,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_physics": {
                "acc": 0.22549019607843138,
                "acc_stderr": 0.041583075330832865,
                "brier_score": 0.7919065334892137,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2980132450331126,
                "acc_stderr": 0.03734535676787198,
                "brier_score": 0.7490773527348867,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_biology": {
                "acc": 0.3,
                "acc_stderr": 0.026069362295335123,
                "brier_score": 0.7506773910715951,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_biology": {
                "acc": 0.2916666666666667,
                "acc_stderr": 0.03800968060554859,
                "brier_score": 0.749773570282803,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_anatomy": {
                "acc": 0.25925925925925924,
                "acc_stderr": 0.03785714465066654,
                "brier_score": 0.7563532132714177,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_chemistry": {
                "acc": 0.33,
                "acc_stderr": 0.047258156262526045,
                "brier_score": 0.7495173234527738,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_computer_security": {
                "acc": 0.23,
                "acc_stderr": 0.04229525846816507,
                "brier_score": 0.7597888572881607,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_computer_science": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.7601643308711965,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_astronomy": {
                "acc": 0.29605263157894735,
                "acc_stderr": 0.03715062154998906,
                "brier_score": 0.7480539257491657,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_college_mathematics": {
                "acc": 0.29,
                "acc_stderr": 0.04560480215720684,
                "brier_score": 0.7361561560209223,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.32340425531914896,
                "acc_stderr": 0.030579442773610337,
                "brier_score": 0.7451312536249421,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.23,
                "acc_stderr": 0.04229525846816506,
                "brier_score": 0.7581665860489692,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.28,
                "acc_stderr": 0.04512608598542127,
                "brier_score": 0.7500153040904679,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_machine_learning": {
                "acc": 0.3125,
                "acc_stderr": 0.043994650575715215,
                "brier_score": 0.7577083286356877,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.24630541871921183,
                "acc_stderr": 0.030315099285617722,
                "brier_score": 0.7470868809070461,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.26851851851851855,
                "acc_stderr": 0.03022522616001239,
                "brier_score": 0.7523433337900371,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.02141168439369419,
                "brier_score": 0.7615287575912638,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.2620689655172414,
                "acc_stderr": 0.036646663372252565,
                "brier_score": 0.7500765841791096,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.24074074074074073,
                "acc_stderr": 0.026067159222275798,
                "brier_score": 0.7641323203116751,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T17-54-06.552984"
            },
            "arc_challenge": {
                "acc": 0.36945392491467577,
                "acc_stderr": 0.014104578366491894,
                "acc_norm": 0.3984641638225256,
                "acc_norm_stderr": 0.014306946052735563,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "hellaswag": {
                "acc": 0.46415056761601275,
                "acc_stderr": 0.004976939333240076,
                "acc_norm": 0.6211909978092014,
                "acc_norm_stderr": 0.004840990593494687,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "truthfulqa_mc2": {
                "acc": 0.3889181333038942,
                "acc_stderr": 0.014016257357529404,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "truthfulqa_gen": {
                "bleu_max": 6.2009331295626025,
                "bleu_max_stderr": 0.40016089959474577,
                "bleu_acc": 0.1481028151774786,
                "bleu_acc_stderr": 0.012434552750319277,
                "bleu_diff": -2.008955984058176,
                "bleu_diff_stderr": 0.36533772424088057,
                "rouge1_max": 15.973477335995934,
                "rouge1_max_stderr": 0.7756937195072751,
                "rouge1_acc": 0.1481028151774786,
                "rouge1_acc_stderr": 0.012434552750319294,
                "rouge1_diff": -3.5047573052504597,
                "rouge1_diff_stderr": 0.4764981051843214,
                "rouge2_max": 9.298241101337537,
                "rouge2_max_stderr": 0.6208670674741479,
                "rouge2_acc": 0.08935128518971848,
                "rouge2_acc_stderr": 0.009985751676755862,
                "rouge2_diff": -3.8860340582661594,
                "rouge2_diff_stderr": 0.5670349584056208,
                "rougeL_max": 15.125543867609249,
                "rougeL_max_stderr": 0.7432106357285632,
                "rougeL_acc": 0.14320685434516525,
                "rougeL_acc_stderr": 0.012262381258730764,
                "rougeL_diff": -3.509115227685031,
                "rougeL_diff_stderr": 0.48390180734803606,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "truthfulqa_mc1": {
                "acc": 0.22399020807833536,
                "acc_stderr": 0.014594964329474205,
                "timestamp": "2024-11-18T13-06-35.949978"
            },
            "winogrande": {
                "acc": 0.6432517758484609,
                "acc_stderr": 0.013463393958028726,
                "timestamp": "2024-11-18T13-06-35.949978"
            }
        }
    }
}