{
    "model_name": "frank098/Wizard-Vicuna-13B-juniper",
    "last_updated": "2023-09-17",
    "results": {
        "harness": {
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.5332764505119454,
                    "acc_stderr": 0.014578995859605811,
                    "acc_norm": 0.5588737201365188,
                    "acc_norm_stderr": 0.014509747749064663,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.5999800836486756,
                    "acc_stderr": 0.004889007921214695,
                    "acc_norm": 0.797450707030472,
                    "acc_norm_stderr": 0.004010779679661523,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.34,
                    "acc_stderr": 0.04760952285695235,
                    "acc_norm": 0.34,
                    "acc_norm_stderr": 0.04760952285695235,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.4666666666666667,
                    "acc_stderr": 0.043097329010363554,
                    "acc_norm": 0.4666666666666667,
                    "acc_norm_stderr": 0.043097329010363554,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.5,
                    "acc_stderr": 0.04068942293855797,
                    "acc_norm": 0.5,
                    "acc_norm_stderr": 0.04068942293855797,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.5,
                    "acc_stderr": 0.050251890762960605,
                    "acc_norm": 0.5,
                    "acc_norm_stderr": 0.050251890762960605,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.4037735849056604,
                    "acc_stderr": 0.03019761160019795,
                    "acc_norm": 0.4037735849056604,
                    "acc_norm_stderr": 0.03019761160019795,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.4305555555555556,
                    "acc_stderr": 0.04140685639111502,
                    "acc_norm": 0.4305555555555556,
                    "acc_norm_stderr": 0.04140685639111502,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.22,
                    "acc_stderr": 0.041633319989322695,
                    "acc_norm": 0.22,
                    "acc_norm_stderr": 0.041633319989322695,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.34,
                    "acc_stderr": 0.04760952285695235,
                    "acc_norm": 0.34,
                    "acc_norm_stderr": 0.04760952285695235,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.04688261722621504,
                    "acc_norm": 0.32,
                    "acc_norm_stderr": 0.04688261722621504,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.3872832369942196,
                    "acc_stderr": 0.037143259063020656,
                    "acc_norm": 0.3872832369942196,
                    "acc_norm_stderr": 0.037143259063020656,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.21568627450980393,
                    "acc_stderr": 0.04092563958237656,
                    "acc_norm": 0.21568627450980393,
                    "acc_norm_stderr": 0.04092563958237656,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.68,
                    "acc_stderr": 0.04688261722621505,
                    "acc_norm": 0.68,
                    "acc_norm_stderr": 0.04688261722621505,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.40425531914893614,
                    "acc_stderr": 0.03208115750788684,
                    "acc_norm": 0.40425531914893614,
                    "acc_norm_stderr": 0.03208115750788684,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.2719298245614035,
                    "acc_stderr": 0.04185774424022056,
                    "acc_norm": 0.2719298245614035,
                    "acc_norm_stderr": 0.04185774424022056,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.36551724137931035,
                    "acc_stderr": 0.04013124195424385,
                    "acc_norm": 0.36551724137931035,
                    "acc_norm_stderr": 0.04013124195424385,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.26455026455026454,
                    "acc_stderr": 0.022717467897708624,
                    "acc_norm": 0.26455026455026454,
                    "acc_norm_stderr": 0.022717467897708624,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.29365079365079366,
                    "acc_stderr": 0.04073524322147124,
                    "acc_norm": 0.29365079365079366,
                    "acc_norm_stderr": 0.04073524322147124,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.47096774193548385,
                    "acc_stderr": 0.028396016402760998,
                    "acc_norm": 0.47096774193548385,
                    "acc_norm_stderr": 0.028396016402760998,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.2561576354679803,
                    "acc_stderr": 0.0307127300709826,
                    "acc_norm": 0.2561576354679803,
                    "acc_norm_stderr": 0.0307127300709826,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.49,
                    "acc_stderr": 0.05024183937956912,
                    "acc_norm": 0.49,
                    "acc_norm_stderr": 0.05024183937956912,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.5575757575757576,
                    "acc_stderr": 0.03878372113711274,
                    "acc_norm": 0.5575757575757576,
                    "acc_norm_stderr": 0.03878372113711274,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.4696969696969697,
                    "acc_stderr": 0.03555804051763929,
                    "acc_norm": 0.4696969696969697,
                    "acc_norm_stderr": 0.03555804051763929,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.6321243523316062,
                    "acc_stderr": 0.03480175668466037,
                    "acc_norm": 0.6321243523316062,
                    "acc_norm_stderr": 0.03480175668466037,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.4230769230769231,
                    "acc_stderr": 0.02504919787604235,
                    "acc_norm": 0.4230769230769231,
                    "acc_norm_stderr": 0.02504919787604235,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.26296296296296295,
                    "acc_stderr": 0.026842057873833706,
                    "acc_norm": 0.26296296296296295,
                    "acc_norm_stderr": 0.026842057873833706,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.3949579831932773,
                    "acc_stderr": 0.031753678460966245,
                    "acc_norm": 0.3949579831932773,
                    "acc_norm_stderr": 0.031753678460966245,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.26490066225165565,
                    "acc_stderr": 0.036030385453603826,
                    "acc_norm": 0.26490066225165565,
                    "acc_norm_stderr": 0.036030385453603826,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.5944954128440367,
                    "acc_stderr": 0.021050997991896834,
                    "acc_norm": 0.5944954128440367,
                    "acc_norm_stderr": 0.021050997991896834,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.24537037037037038,
                    "acc_stderr": 0.029346665094372934,
                    "acc_norm": 0.24537037037037038,
                    "acc_norm_stderr": 0.029346665094372934,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.6323529411764706,
                    "acc_stderr": 0.03384132045674119,
                    "acc_norm": 0.6323529411764706,
                    "acc_norm_stderr": 0.03384132045674119,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.6497890295358649,
                    "acc_stderr": 0.031052391937584346,
                    "acc_norm": 0.6497890295358649,
                    "acc_norm_stderr": 0.031052391937584346,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.5560538116591929,
                    "acc_stderr": 0.03334625674242728,
                    "acc_norm": 0.5560538116591929,
                    "acc_norm_stderr": 0.03334625674242728,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.48854961832061067,
                    "acc_stderr": 0.043841400240780176,
                    "acc_norm": 0.48854961832061067,
                    "acc_norm_stderr": 0.043841400240780176,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.6115702479338843,
                    "acc_stderr": 0.04449270350068383,
                    "acc_norm": 0.6115702479338843,
                    "acc_norm_stderr": 0.04449270350068383,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.4722222222222222,
                    "acc_stderr": 0.04826217294139894,
                    "acc_norm": 0.4722222222222222,
                    "acc_norm_stderr": 0.04826217294139894,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.49079754601226994,
                    "acc_stderr": 0.03927705600787443,
                    "acc_norm": 0.49079754601226994,
                    "acc_norm_stderr": 0.03927705600787443,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.3482142857142857,
                    "acc_stderr": 0.045218299028335865,
                    "acc_norm": 0.3482142857142857,
                    "acc_norm_stderr": 0.045218299028335865,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.5533980582524272,
                    "acc_stderr": 0.04922424153458933,
                    "acc_norm": 0.5533980582524272,
                    "acc_norm_stderr": 0.04922424153458933,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.6837606837606838,
                    "acc_stderr": 0.030463656747340268,
                    "acc_norm": 0.6837606837606838,
                    "acc_norm_stderr": 0.030463656747340268,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.49,
                    "acc_stderr": 0.05024183937956911,
                    "acc_norm": 0.49,
                    "acc_norm_stderr": 0.05024183937956911,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.6590038314176245,
                    "acc_stderr": 0.016951781383223313,
                    "acc_norm": 0.6590038314176245,
                    "acc_norm_stderr": 0.016951781383223313,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.4624277456647399,
                    "acc_stderr": 0.026842985519615375,
                    "acc_norm": 0.4624277456647399,
                    "acc_norm_stderr": 0.026842985519615375,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.23798882681564246,
                    "acc_stderr": 0.014242630070574915,
                    "acc_norm": 0.23798882681564246,
                    "acc_norm_stderr": 0.014242630070574915,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.4803921568627451,
                    "acc_stderr": 0.028607893699576066,
                    "acc_norm": 0.4803921568627451,
                    "acc_norm_stderr": 0.028607893699576066,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.4565916398713826,
                    "acc_stderr": 0.028290869054197598,
                    "acc_norm": 0.4565916398713826,
                    "acc_norm_stderr": 0.028290869054197598,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.5123456790123457,
                    "acc_stderr": 0.027812262269327242,
                    "acc_norm": 0.5123456790123457,
                    "acc_norm_stderr": 0.027812262269327242,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.32269503546099293,
                    "acc_stderr": 0.027889139300534785,
                    "acc_norm": 0.32269503546099293,
                    "acc_norm_stderr": 0.027889139300534785,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.3748370273794003,
                    "acc_stderr": 0.012363652467551929,
                    "acc_norm": 0.3748370273794003,
                    "acc_norm_stderr": 0.012363652467551929,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.47794117647058826,
                    "acc_stderr": 0.030343264224213528,
                    "acc_norm": 0.47794117647058826,
                    "acc_norm_stderr": 0.030343264224213528,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.4477124183006536,
                    "acc_stderr": 0.02011692534742242,
                    "acc_norm": 0.4477124183006536,
                    "acc_norm_stderr": 0.02011692534742242,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.5909090909090909,
                    "acc_stderr": 0.04709306978661896,
                    "acc_norm": 0.5909090909090909,
                    "acc_norm_stderr": 0.04709306978661896,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.5469387755102041,
                    "acc_stderr": 0.03186785930004129,
                    "acc_norm": 0.5469387755102041,
                    "acc_norm_stderr": 0.03186785930004129,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.6218905472636815,
                    "acc_stderr": 0.034288678487786564,
                    "acc_norm": 0.6218905472636815,
                    "acc_norm_stderr": 0.034288678487786564,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.68,
                    "acc_stderr": 0.046882617226215034,
                    "acc_norm": 0.68,
                    "acc_norm_stderr": 0.046882617226215034,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.3855421686746988,
                    "acc_stderr": 0.037891344246115496,
                    "acc_norm": 0.3855421686746988,
                    "acc_norm_stderr": 0.037891344246115496,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.6432748538011696,
                    "acc_stderr": 0.03674013002860954,
                    "acc_norm": 0.6432748538011696,
                    "acc_norm_stderr": 0.03674013002860954,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.39167686658506734,
                    "mc1_stderr": 0.017087795881769632,
                    "mc2": 0.5471532512276316,
                    "mc2_stderr": 0.01556326289744955,
                    "timestamp": "2023-08-21T16-00-50.313415"
                }
            },
            "drop": {
                "3-shot": {
                    "em": 0.0025167785234899327,
                    "em_stderr": 0.0005131152834514818,
                    "f1": 0.06578020134228216,
                    "f1_stderr": 0.0014299327364359015,
                    "timestamp": "2023-09-17T07-24-44.144750"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.07278241091736164,
                    "acc_stderr": 0.007155604761167476,
                    "timestamp": "2023-09-17T07-24-44.144750"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7269139700078927,
                    "acc_stderr": 0.012522020105869456,
                    "timestamp": "2023-09-17T07-24-44.144750"
                }
            }
        }
    }
}