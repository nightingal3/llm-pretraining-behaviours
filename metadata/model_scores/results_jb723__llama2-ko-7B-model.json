{
    "model_name": "jb723/llama2-ko-7B-model",
    "last_updated": "2023-10-28",
    "results": {
        "harness": {
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.5349829351535836,
                    "acc_stderr": 0.014575583922019674,
                    "acc_norm": 0.5631399317406144,
                    "acc_norm_stderr": 0.014494421584256532,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.6158135829516033,
                    "acc_stderr": 0.004854082479916911,
                    "acc_norm": 0.7950607448715395,
                    "acc_norm_stderr": 0.004028322654852745,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.31,
                    "acc_stderr": 0.04648231987117316,
                    "acc_norm": 0.31,
                    "acc_norm_stderr": 0.04648231987117316,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.45925925925925926,
                    "acc_stderr": 0.04304979692464242,
                    "acc_norm": 0.45925925925925926,
                    "acc_norm_stderr": 0.04304979692464242,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.4605263157894737,
                    "acc_stderr": 0.04056242252249034,
                    "acc_norm": 0.4605263157894737,
                    "acc_norm_stderr": 0.04056242252249034,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.45,
                    "acc_stderr": 0.05,
                    "acc_norm": 0.45,
                    "acc_norm_stderr": 0.05,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.45660377358490567,
                    "acc_stderr": 0.030656748696739438,
                    "acc_norm": 0.45660377358490567,
                    "acc_norm_stderr": 0.030656748696739438,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.4375,
                    "acc_stderr": 0.04148415739394154,
                    "acc_norm": 0.4375,
                    "acc_norm_stderr": 0.04148415739394154,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.36,
                    "acc_stderr": 0.04824181513244218,
                    "acc_norm": 0.36,
                    "acc_norm_stderr": 0.04824181513244218,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.04725815626252604,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.04725815626252604,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.37,
                    "acc_stderr": 0.04852365870939098,
                    "acc_norm": 0.37,
                    "acc_norm_stderr": 0.04852365870939098,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.4046242774566474,
                    "acc_stderr": 0.03742461193887248,
                    "acc_norm": 0.4046242774566474,
                    "acc_norm_stderr": 0.03742461193887248,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.14705882352941177,
                    "acc_stderr": 0.035240689515674495,
                    "acc_norm": 0.14705882352941177,
                    "acc_norm_stderr": 0.035240689515674495,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.52,
                    "acc_stderr": 0.05021167315686779,
                    "acc_norm": 0.52,
                    "acc_norm_stderr": 0.05021167315686779,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.4127659574468085,
                    "acc_stderr": 0.03218471141400351,
                    "acc_norm": 0.4127659574468085,
                    "acc_norm_stderr": 0.03218471141400351,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.32456140350877194,
                    "acc_stderr": 0.04404556157374767,
                    "acc_norm": 0.32456140350877194,
                    "acc_norm_stderr": 0.04404556157374767,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.4482758620689655,
                    "acc_stderr": 0.04144311810878151,
                    "acc_norm": 0.4482758620689655,
                    "acc_norm_stderr": 0.04144311810878151,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.31746031746031744,
                    "acc_stderr": 0.023973861998992072,
                    "acc_norm": 0.31746031746031744,
                    "acc_norm_stderr": 0.023973861998992072,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.23809523809523808,
                    "acc_stderr": 0.03809523809523812,
                    "acc_norm": 0.23809523809523808,
                    "acc_norm_stderr": 0.03809523809523812,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.39,
                    "acc_stderr": 0.04902071300001974,
                    "acc_norm": 0.39,
                    "acc_norm_stderr": 0.04902071300001974,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.4935483870967742,
                    "acc_stderr": 0.02844163823354051,
                    "acc_norm": 0.4935483870967742,
                    "acc_norm_stderr": 0.02844163823354051,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.33004926108374383,
                    "acc_stderr": 0.033085304262282574,
                    "acc_norm": 0.33004926108374383,
                    "acc_norm_stderr": 0.033085304262282574,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.41,
                    "acc_stderr": 0.04943110704237102,
                    "acc_norm": 0.41,
                    "acc_norm_stderr": 0.04943110704237102,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.5878787878787879,
                    "acc_stderr": 0.03843566993588717,
                    "acc_norm": 0.5878787878787879,
                    "acc_norm_stderr": 0.03843566993588717,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.5757575757575758,
                    "acc_stderr": 0.035212249088415845,
                    "acc_norm": 0.5757575757575758,
                    "acc_norm_stderr": 0.035212249088415845,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.689119170984456,
                    "acc_stderr": 0.033403619062765864,
                    "acc_norm": 0.689119170984456,
                    "acc_norm_stderr": 0.033403619062765864,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.4461538461538462,
                    "acc_stderr": 0.02520357177302833,
                    "acc_norm": 0.4461538461538462,
                    "acc_norm_stderr": 0.02520357177302833,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.25925925925925924,
                    "acc_stderr": 0.026719240783712173,
                    "acc_norm": 0.25925925925925924,
                    "acc_norm_stderr": 0.026719240783712173,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.40756302521008403,
                    "acc_stderr": 0.03191863374478466,
                    "acc_norm": 0.40756302521008403,
                    "acc_norm_stderr": 0.03191863374478466,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.31788079470198677,
                    "acc_stderr": 0.03802039760107903,
                    "acc_norm": 0.31788079470198677,
                    "acc_norm_stderr": 0.03802039760107903,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.6146788990825688,
                    "acc_stderr": 0.02086585085279412,
                    "acc_norm": 0.6146788990825688,
                    "acc_norm_stderr": 0.02086585085279412,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.28703703703703703,
                    "acc_stderr": 0.030851992993257017,
                    "acc_norm": 0.28703703703703703,
                    "acc_norm_stderr": 0.030851992993257017,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.5833333333333334,
                    "acc_stderr": 0.03460228327239171,
                    "acc_norm": 0.5833333333333334,
                    "acc_norm_stderr": 0.03460228327239171,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.6666666666666666,
                    "acc_stderr": 0.030685820596610795,
                    "acc_norm": 0.6666666666666666,
                    "acc_norm_stderr": 0.030685820596610795,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.5246636771300448,
                    "acc_stderr": 0.03351695167652628,
                    "acc_norm": 0.5246636771300448,
                    "acc_norm_stderr": 0.03351695167652628,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.5343511450381679,
                    "acc_stderr": 0.04374928560599738,
                    "acc_norm": 0.5343511450381679,
                    "acc_norm_stderr": 0.04374928560599738,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.6446280991735537,
                    "acc_stderr": 0.0436923632657398,
                    "acc_norm": 0.6446280991735537,
                    "acc_norm_stderr": 0.0436923632657398,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.5,
                    "acc_stderr": 0.04833682445228318,
                    "acc_norm": 0.5,
                    "acc_norm_stderr": 0.04833682445228318,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.44785276073619634,
                    "acc_stderr": 0.03906947479456602,
                    "acc_norm": 0.44785276073619634,
                    "acc_norm_stderr": 0.03906947479456602,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.29464285714285715,
                    "acc_stderr": 0.043270409325787296,
                    "acc_norm": 0.29464285714285715,
                    "acc_norm_stderr": 0.043270409325787296,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.5631067961165048,
                    "acc_stderr": 0.04911147107365777,
                    "acc_norm": 0.5631067961165048,
                    "acc_norm_stderr": 0.04911147107365777,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.6752136752136753,
                    "acc_stderr": 0.030679022765498828,
                    "acc_norm": 0.6752136752136753,
                    "acc_norm_stderr": 0.030679022765498828,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.53,
                    "acc_stderr": 0.05016135580465919,
                    "acc_norm": 0.53,
                    "acc_norm_stderr": 0.05016135580465919,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.6577266922094508,
                    "acc_stderr": 0.016967031766413624,
                    "acc_norm": 0.6577266922094508,
                    "acc_norm_stderr": 0.016967031766413624,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.5202312138728323,
                    "acc_stderr": 0.026897049996382868,
                    "acc_norm": 0.5202312138728323,
                    "acc_norm_stderr": 0.026897049996382868,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.23798882681564246,
                    "acc_stderr": 0.014242630070574915,
                    "acc_norm": 0.23798882681564246,
                    "acc_norm_stderr": 0.014242630070574915,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.477124183006536,
                    "acc_stderr": 0.028599936776089782,
                    "acc_norm": 0.477124183006536,
                    "acc_norm_stderr": 0.028599936776089782,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.5562700964630225,
                    "acc_stderr": 0.028217683556652315,
                    "acc_norm": 0.5562700964630225,
                    "acc_norm_stderr": 0.028217683556652315,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.5216049382716049,
                    "acc_stderr": 0.027794760105008736,
                    "acc_norm": 0.5216049382716049,
                    "acc_norm_stderr": 0.027794760105008736,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.3475177304964539,
                    "acc_stderr": 0.02840662780959095,
                    "acc_norm": 0.3475177304964539,
                    "acc_norm_stderr": 0.02840662780959095,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.35528031290743156,
                    "acc_stderr": 0.012223623364044037,
                    "acc_norm": 0.35528031290743156,
                    "acc_norm_stderr": 0.012223623364044037,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.4411764705882353,
                    "acc_stderr": 0.03016191193076711,
                    "acc_norm": 0.4411764705882353,
                    "acc_norm_stderr": 0.03016191193076711,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.4526143790849673,
                    "acc_stderr": 0.020136790918492523,
                    "acc_norm": 0.4526143790849673,
                    "acc_norm_stderr": 0.020136790918492523,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.5272727272727272,
                    "acc_stderr": 0.04782001791380061,
                    "acc_norm": 0.5272727272727272,
                    "acc_norm_stderr": 0.04782001791380061,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.4326530612244898,
                    "acc_stderr": 0.031717528240626645,
                    "acc_norm": 0.4326530612244898,
                    "acc_norm_stderr": 0.031717528240626645,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.572139303482587,
                    "acc_stderr": 0.03498541988407795,
                    "acc_norm": 0.572139303482587,
                    "acc_norm_stderr": 0.03498541988407795,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.63,
                    "acc_stderr": 0.04852365870939099,
                    "acc_norm": 0.63,
                    "acc_norm_stderr": 0.04852365870939099,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.42168674698795183,
                    "acc_stderr": 0.03844453181770917,
                    "acc_norm": 0.42168674698795183,
                    "acc_norm_stderr": 0.03844453181770917,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.6842105263157895,
                    "acc_stderr": 0.03565079670708311,
                    "acc_norm": 0.6842105263157895,
                    "acc_norm_stderr": 0.03565079670708311,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.28151774785801714,
                    "mc1_stderr": 0.015744027248256045,
                    "mc2": 0.4097811489004275,
                    "mc2_stderr": 0.015552291335837638,
                    "timestamp": "2023-09-22T03-46-09.444345"
                }
            },
            "drop": {
                "3-shot": {
                    "em": 0.23427013422818793,
                    "em_stderr": 0.004337464243138509,
                    "f1": 0.3152516778523505,
                    "f1_stderr": 0.004353725712557671,
                    "timestamp": "2023-10-28T09-35-48.028758"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.02577710386656558,
                    "acc_stderr": 0.0043650429536218095,
                    "timestamp": "2023-10-28T09-35-48.028758"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7205998421468035,
                    "acc_stderr": 0.012610826539404667,
                    "timestamp": "2023-10-28T09-35-48.028758"
                }
            }
        }
    }
}