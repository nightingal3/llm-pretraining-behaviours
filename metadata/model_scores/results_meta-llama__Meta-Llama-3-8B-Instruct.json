{
    "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "last_updated": "2024-12-04 11:23:53.204834",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "5-shot": {
                    "acc": 0.11172161172161173,
                    "acc_stderr": 0.013494130099732618,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_prealgebra": {
                "5-shot": {
                    "acc": 0.4764638346727899,
                    "acc_stderr": 0.016932796474939078,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_num_theory": {
                "5-shot": {
                    "acc": 0.2037037037037037,
                    "acc_stderr": 0.017347720963761987,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_intermediate_algebra": {
                "5-shot": {
                    "acc": 0.12070874861572536,
                    "acc_stderr": 0.010847570493593098,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_geometry": {
                "5-shot": {
                    "acc": 0.19624217118997914,
                    "acc_stderr": 0.018165394328850663,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_counting_and_prob": {
                "5-shot": {
                    "acc": 0.24472573839662448,
                    "acc_stderr": 0.019767948269352843,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "minerva_math_algebra": {
                "5-shot": {
                    "acc": 0.37826453243470937,
                    "acc_stderr": 0.014081803764022903,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "fld_default": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "fld_star": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_3da": {
                "5-shot": {
                    "acc": 0.9995,
                    "acc_stderr": 0.0005000000000000156,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_3ds": {
                "5-shot": {
                    "acc": 0.8855,
                    "acc_stderr": 0.007121814032784058,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_4da": {
                "5-shot": {
                    "acc": 0.8945,
                    "acc_stderr": 0.006870842687736334,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_2ds": {
                "5-shot": {
                    "acc": 0.997,
                    "acc_stderr": 0.0012232122154647094,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_5ds": {
                "5-shot": {
                    "acc": 0.7225,
                    "acc_stderr": 0.010014840164064459,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_5da": {
                "5-shot": {
                    "acc": 0.795,
                    "acc_stderr": 0.009029300312431016,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_1dc": {
                "5-shot": {
                    "acc": 0.7925,
                    "acc_stderr": 0.009069895616998728,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_4ds": {
                "5-shot": {
                    "acc": 0.8155,
                    "acc_stderr": 0.008675684915577362,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_2dm": {
                "5-shot": {
                    "acc": 0.67,
                    "acc_stderr": 0.010516905564438917,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "arithmetic_2da": {
                "5-shot": {
                    "acc": 1.0,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "gsm8k_cot": {
                "5-shot": {
                    "acc": 0.775587566338135,
                    "acc_stderr": 0.011491617756630552,
                    "timestamp": "2024-06-12T07-08-32.563552"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.755117513267627,
                    "acc_stderr": 0.011844819027863667,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "anli_r2": {
                "0-shot": {
                    "brier_score": 0.7985456079098852,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "anli_r3": {
                "0-shot": {
                    "brier_score": 0.8097953259921752,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "anli_r1": {
                "0-shot": {
                    "brier_score": 0.7717221698804513,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_eu": {
                "0-shot": {
                    "brier_score": 0.8196432026111591,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_vi": {
                "0-shot": {
                    "brier_score": 0.7618000692371746,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_ru": {
                "0-shot": {
                    "brier_score": 0.8013434537191864,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_zh": {
                "0-shot": {
                    "brier_score": 0.9930200253772428,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_tr": {
                "0-shot": {
                    "brier_score": 0.8615816405837291,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_fr": {
                "0-shot": {
                    "brier_score": 0.6960972021301648,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_en": {
                "0-shot": {
                    "brier_score": 0.6514935237404581,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_ur": {
                "0-shot": {
                    "brier_score": 1.2113932574417665,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_ar": {
                "0-shot": {
                    "brier_score": 1.2690322872660167,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_de": {
                "0-shot": {
                    "brier_score": 0.8339566525731148,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_hi": {
                "0-shot": {
                    "brier_score": 0.8549027587669167,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_es": {
                "0-shot": {
                    "brier_score": 0.8028087096573583,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_bg": {
                "0-shot": {
                    "brier_score": 0.8658614845860327,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_sw": {
                "0-shot": {
                    "brier_score": 1.0179283740266234,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_el": {
                "0-shot": {
                    "brier_score": 0.8840107296653167,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "xnli_th": {
                "0-shot": {
                    "brier_score": 0.8332666686094854,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "logiqa2": {
                "0-shot": {
                    "brier_score": 0.9980174455769029,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "mathqa": {
                "5-shot": {
                    "brier_score": 0.8366526946512588,
                    "timestamp": "2024-06-12T07-17-27.857323"
                }
            },
            "lambada_standard": {
                "0-shot": {
                    "perplexity": 4.010364094889167,
                    "perplexity_stderr": 0.10269598682376097,
                    "acc": 0.6501067339413934,
                    "acc_stderr": 0.0066446513367465045,
                    "timestamp": "2024-06-12T07-18-51.438784"
                }
            },
            "lambada_openai": {
                "0-shot": {
                    "perplexity": 3.104536403718183,
                    "perplexity_stderr": 0.07662347070866664,
                    "acc": 0.7189986415680186,
                    "acc_stderr": 0.006262248789164311,
                    "timestamp": "2024-06-12T07-18-51.438784"
                }
            },
            "mmlu_world_religions": {
                "0-shot": {
                    "acc": 0.783625730994152,
                    "acc_stderr": 0.031581495393387324,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_formal_logic": {
                "0-shot": {
                    "acc": 0.49206349206349204,
                    "acc_stderr": 0.044715725362943486,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_prehistory": {
                "0-shot": {
                    "acc": 0.7407407407407407,
                    "acc_stderr": 0.02438366553103545,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_moral_scenarios": {
                "0-shot": {
                    "acc": 0.4346368715083799,
                    "acc_stderr": 0.01657899743549672,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_world_history": {
                "0-shot": {
                    "acc": 0.8438818565400844,
                    "acc_stderr": 0.023627159460318684,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_moral_disputes": {
                "0-shot": {
                    "acc": 0.7456647398843931,
                    "acc_stderr": 0.023445826276545546,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_professional_law": {
                "0-shot": {
                    "acc": 0.4784876140808344,
                    "acc_stderr": 0.01275841094103892,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_logical_fallacies": {
                "0-shot": {
                    "acc": 0.7668711656441718,
                    "acc_stderr": 0.0332201579577674,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_us_history": {
                "0-shot": {
                    "acc": 0.8529411764705882,
                    "acc_stderr": 0.024857478080250465,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_philosophy": {
                "0-shot": {
                    "acc": 0.7202572347266881,
                    "acc_stderr": 0.0254942593506949,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_jurisprudence": {
                "0-shot": {
                    "acc": 0.7777777777777778,
                    "acc_stderr": 0.0401910747255735,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_international_law": {
                "0-shot": {
                    "acc": 0.8181818181818182,
                    "acc_stderr": 0.03520893951097653,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_european_history": {
                "0-shot": {
                    "acc": 0.7515151515151515,
                    "acc_stderr": 0.03374402644139405,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_government_and_politics": {
                "0-shot": {
                    "acc": 0.9119170984455959,
                    "acc_stderr": 0.02045374660160103,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_microeconomics": {
                "0-shot": {
                    "acc": 0.7647058823529411,
                    "acc_stderr": 0.027553614467863818,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_geography": {
                "0-shot": {
                    "acc": 0.8434343434343434,
                    "acc_stderr": 0.025890520358141454,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_psychology": {
                "0-shot": {
                    "acc": 0.8311926605504587,
                    "acc_stderr": 0.01606005626853035,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_public_relations": {
                "0-shot": {
                    "acc": 0.6363636363636364,
                    "acc_stderr": 0.046075820907199756,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_us_foreign_policy": {
                "0-shot": {
                    "acc": 0.85,
                    "acc_stderr": 0.0358870281282637,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_sociology": {
                "0-shot": {
                    "acc": 0.8706467661691543,
                    "acc_stderr": 0.023729830881018515,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_macroeconomics": {
                "0-shot": {
                    "acc": 0.658974358974359,
                    "acc_stderr": 0.024035489676335065,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_security_studies": {
                "0-shot": {
                    "acc": 0.7428571428571429,
                    "acc_stderr": 0.02797982353874455,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_professional_psychology": {
                "0-shot": {
                    "acc": 0.7091503267973857,
                    "acc_stderr": 0.018373116915903973,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_human_sexuality": {
                "0-shot": {
                    "acc": 0.7786259541984732,
                    "acc_stderr": 0.03641297081313729,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_econometrics": {
                "0-shot": {
                    "acc": 0.6140350877192983,
                    "acc_stderr": 0.045796394220704334,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_miscellaneous": {
                "0-shot": {
                    "acc": 0.7994891443167306,
                    "acc_stderr": 0.014317653708594212,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_marketing": {
                "0-shot": {
                    "acc": 0.905982905982906,
                    "acc_stderr": 0.019119892798924974,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_management": {
                "0-shot": {
                    "acc": 0.7766990291262136,
                    "acc_stderr": 0.04123553189891431,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_nutrition": {
                "0-shot": {
                    "acc": 0.7516339869281046,
                    "acc_stderr": 0.024739981355113592,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_medical_genetics": {
                "0-shot": {
                    "acc": 0.8,
                    "acc_stderr": 0.04020151261036846,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_human_aging": {
                "0-shot": {
                    "acc": 0.7309417040358744,
                    "acc_stderr": 0.029763779406874972,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_professional_medicine": {
                "0-shot": {
                    "acc": 0.7242647058823529,
                    "acc_stderr": 0.027146271936625166,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_medicine": {
                "0-shot": {
                    "acc": 0.6416184971098265,
                    "acc_stderr": 0.0365634365335316,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_business_ethics": {
                "0-shot": {
                    "acc": 0.69,
                    "acc_stderr": 0.04648231987117316,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_clinical_knowledge": {
                "0-shot": {
                    "acc": 0.7471698113207547,
                    "acc_stderr": 0.026749899771241224,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_global_facts": {
                "0-shot": {
                    "acc": 0.4,
                    "acc_stderr": 0.049236596391733084,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_virology": {
                "0-shot": {
                    "acc": 0.5060240963855421,
                    "acc_stderr": 0.03892212195333045,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_professional_accounting": {
                "0-shot": {
                    "acc": 0.5390070921985816,
                    "acc_stderr": 0.029736592526424438,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_physics": {
                "0-shot": {
                    "acc": 0.5098039215686274,
                    "acc_stderr": 0.04974229460422817,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_physics": {
                "0-shot": {
                    "acc": 0.44370860927152317,
                    "acc_stderr": 0.04056527902281732,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_biology": {
                "0-shot": {
                    "acc": 0.7806451612903226,
                    "acc_stderr": 0.023540799358723302,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_biology": {
                "0-shot": {
                    "acc": 0.7916666666666666,
                    "acc_stderr": 0.03396116205845334,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_anatomy": {
                "0-shot": {
                    "acc": 0.6370370370370371,
                    "acc_stderr": 0.041539484047424,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_chemistry": {
                "0-shot": {
                    "acc": 0.47,
                    "acc_stderr": 0.05016135580465919,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_computer_security": {
                "0-shot": {
                    "acc": 0.77,
                    "acc_stderr": 0.042295258468165065,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_computer_science": {
                "0-shot": {
                    "acc": 0.58,
                    "acc_stderr": 0.049604496374885836,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_astronomy": {
                "0-shot": {
                    "acc": 0.6973684210526315,
                    "acc_stderr": 0.03738520676119667,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_college_mathematics": {
                "0-shot": {
                    "acc": 0.38,
                    "acc_stderr": 0.04878317312145633,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_conceptual_physics": {
                "0-shot": {
                    "acc": 0.6042553191489362,
                    "acc_stderr": 0.031967586978353627,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_abstract_algebra": {
                "0-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.046882617226215034,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_computer_science": {
                "0-shot": {
                    "acc": 0.75,
                    "acc_stderr": 0.04351941398892446,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_machine_learning": {
                "0-shot": {
                    "acc": 0.5446428571428571,
                    "acc_stderr": 0.04726835553719097,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_chemistry": {
                "0-shot": {
                    "acc": 0.5024630541871922,
                    "acc_stderr": 0.03517945038691063,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_statistics": {
                "0-shot": {
                    "acc": 0.5370370370370371,
                    "acc_stderr": 0.03400603625538271,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_elementary_mathematics": {
                "0-shot": {
                    "acc": 0.4470899470899471,
                    "acc_stderr": 0.025606723995777025,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_electrical_engineering": {
                "0-shot": {
                    "acc": 0.6275862068965518,
                    "acc_stderr": 0.04028731532947559,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "mmlu_high_school_mathematics": {
                "0-shot": {
                    "acc": 0.3925925925925926,
                    "acc_stderr": 0.02977384701253297,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "arc_challenge": {
                "25-shot": {
                    "acc": 0.5767918088737202,
                    "acc_stderr": 0.014438036220848025,
                    "acc_norm": 0.6186006825938567,
                    "acc_norm_stderr": 0.01419438908668527,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.5898227444732125,
                    "acc_stderr": 0.004908604732082822,
                    "acc_norm": 0.7898824935271859,
                    "acc_norm_stderr": 0.004065592811695992,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "truthfulqa_mc2": {
                "0-shot": {
                    "acc": 0.5165834108450839,
                    "acc_stderr": 0.015188480530101718,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "truthfulqa_gen": {
                "0-shot": {
                    "bleu_max": 20.38284601416647,
                    "bleu_max_stderr": 0.7259585799496531,
                    "bleu_acc": 0.4749082007343941,
                    "bleu_acc_stderr": 0.017481446804104003,
                    "bleu_diff": -0.39825979672746564,
                    "bleu_diff_stderr": 0.6399548657857169,
                    "rouge1_max": 43.70636561691526,
                    "rouge1_max_stderr": 0.8683149503828073,
                    "rouge1_acc": 0.4969400244798042,
                    "rouge1_acc_stderr": 0.017503173260960625,
                    "rouge1_diff": -0.267087450778999,
                    "rouge1_diff_stderr": 0.8748649880343018,
                    "rouge2_max": 27.583822895276878,
                    "rouge2_max_stderr": 0.9560493672304742,
                    "rouge2_acc": 0.36474908200734396,
                    "rouge2_acc_stderr": 0.016850961061720113,
                    "rouge2_diff": -1.7302074043155247,
                    "rouge2_diff_stderr": 0.928098862686909,
                    "rougeL_max": 40.83179541506895,
                    "rougeL_max_stderr": 0.8672456167019427,
                    "rougeL_acc": 0.4847001223990208,
                    "rougeL_acc_stderr": 0.017495304473187902,
                    "rougeL_diff": -0.6070224090190008,
                    "rougeL_diff_stderr": 0.8794043276943261,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "truthfulqa_mc1": {
                "0-shot": {
                    "acc": 0.36474908200734396,
                    "acc_stderr": 0.016850961061720116,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7561168113654302,
                    "acc_stderr": 0.01206892327890818,
                    "timestamp": "2024-11-22T19-05-59.919138"
                }
            }
        }
    }
}