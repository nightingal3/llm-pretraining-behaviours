{
    "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "last_updated": "2024-12-19 13:39:16.941147",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.11172161172161173,
                "exact_match_stderr": 0.013494130099732618,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.4764638346727899,
                "exact_match_stderr": 0.016932796474939078,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.2037037037037037,
                "exact_match_stderr": 0.017347720963761987,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.12070874861572536,
                "exact_match_stderr": 0.010847570493593098,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_geometry": {
                "exact_match": 0.19624217118997914,
                "exact_match_stderr": 0.018165394328850663,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.24472573839662448,
                "exact_match_stderr": 0.019767948269352843,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "minerva_math_algebra": {
                "exact_match": 0.37826453243470937,
                "exact_match_stderr": 0.014081803764022903,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_3da": {
                "acc": 0.9995,
                "acc_stderr": 0.0005000000000000156,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_3ds": {
                "acc": 0.8855,
                "acc_stderr": 0.007121814032784058,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_4da": {
                "acc": 0.8945,
                "acc_stderr": 0.006870842687736334,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_2ds": {
                "acc": 0.997,
                "acc_stderr": 0.0012232122154647094,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_5ds": {
                "acc": 0.7225,
                "acc_stderr": 0.010014840164064459,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_5da": {
                "acc": 0.795,
                "acc_stderr": 0.009029300312431016,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_1dc": {
                "acc": 0.7925,
                "acc_stderr": 0.009069895616998728,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_4ds": {
                "acc": 0.8155,
                "acc_stderr": 0.008675684915577362,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_2dm": {
                "acc": 0.67,
                "acc_stderr": 0.010516905564438917,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "arithmetic_2da": {
                "acc": 1.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "gsm8k_cot": {
                "exact_match": 0.775587566338135,
                "exact_match_stderr": 0.011491617756630552,
                "timestamp": "2024-06-12T07-08-32.563552"
            },
            "gsm8k": {
                "exact_match": 0.755117513267627,
                "exact_match_stderr": 0.011844819027863667,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "anli_r2": {
                "brier_score": 0.7985456079098852,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "anli_r3": {
                "brier_score": 0.8097953259921752,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "anli_r1": {
                "brier_score": 0.7717221698804513,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_eu": {
                "brier_score": 0.8196432026111591,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_vi": {
                "brier_score": 0.7618000692371746,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_ru": {
                "brier_score": 0.8013434537191864,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_zh": {
                "brier_score": 0.9930200253772428,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_tr": {
                "brier_score": 0.8615816405837291,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_fr": {
                "brier_score": 0.6960972021301648,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_en": {
                "brier_score": 0.6514935237404581,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_ur": {
                "brier_score": 1.2113932574417665,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_ar": {
                "brier_score": 1.2690322872660167,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_de": {
                "brier_score": 0.8339566525731148,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_hi": {
                "brier_score": 0.8549027587669167,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_es": {
                "brier_score": 0.8028087096573583,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_bg": {
                "brier_score": 0.8658614845860327,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_sw": {
                "brier_score": 1.0179283740266234,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_el": {
                "brier_score": 0.8840107296653167,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "xnli_th": {
                "brier_score": 0.8332666686094854,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "logiqa2": {
                "brier_score": 0.9980174455769029,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "mathqa": {
                "brier_score": 0.8366526946512588,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-12T07-17-27.857323"
            },
            "lambada_standard": {
                "perplexity": 4.010364094889167,
                "perplexity_stderr": 0.10269598682376097,
                "acc": 0.6501067339413934,
                "acc_stderr": 0.0066446513367465045,
                "timestamp": "2024-06-12T07-18-51.438784"
            },
            "lambada_openai": {
                "perplexity": 3.104536403718183,
                "perplexity_stderr": 0.07662347070866664,
                "acc": 0.7189986415680186,
                "acc_stderr": 0.006262248789164311,
                "timestamp": "2024-06-12T07-18-51.438784"
            },
            "mmlu_world_religions": {
                "acc": 0.7777777777777778,
                "acc_stderr": 0.03188578017686398,
                "brier_score": 0.3376258192694194,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_formal_logic": {
                "acc": 0.5238095238095238,
                "acc_stderr": 0.04467062628403273,
                "brier_score": 0.6980274551083973,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_prehistory": {
                "acc": 0.7283950617283951,
                "acc_stderr": 0.02474862449053738,
                "brier_score": 0.39291690430528736,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.3407821229050279,
                "acc_stderr": 0.01585200244986209,
                "brier_score": 0.8668016282305296,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.8354430379746836,
                "acc_stderr": 0.024135736240566943,
                "brier_score": 0.2441529748394776,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_moral_disputes": {
                "acc": 0.6907514450867052,
                "acc_stderr": 0.024883140570071755,
                "brier_score": 0.4533446390696797,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_professional_law": {
                "acc": 0.49022164276401564,
                "acc_stderr": 0.01276779378772933,
                "brier_score": 0.7291735128410968,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.7607361963190185,
                "acc_stderr": 0.03351953879521271,
                "brier_score": 0.34506175696101216,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.8186274509803921,
                "acc_stderr": 0.027044621719474072,
                "brier_score": 0.2588802540945586,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_philosophy": {
                "acc": 0.7202572347266881,
                "acc_stderr": 0.0254942593506949,
                "brier_score": 0.4062055829570173,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_jurisprudence": {
                "acc": 0.7592592592592593,
                "acc_stderr": 0.041331194402438376,
                "brier_score": 0.3270627816811494,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_international_law": {
                "acc": 0.7603305785123967,
                "acc_stderr": 0.038968789850704164,
                "brier_score": 0.3526125001130658,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.7454545454545455,
                "acc_stderr": 0.03401506715249039,
                "brier_score": 0.40408127337296396,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.8756476683937824,
                "acc_stderr": 0.023814477086593563,
                "brier_score": 0.20414191906912876,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.7184873949579832,
                "acc_stderr": 0.029213549414372167,
                "brier_score": 0.40663777837532783,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_geography": {
                "acc": 0.7777777777777778,
                "acc_stderr": 0.02962022787479047,
                "brier_score": 0.30299606961532244,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.8238532110091743,
                "acc_stderr": 0.01633288239343138,
                "brier_score": 0.2711728027147795,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_public_relations": {
                "acc": 0.6727272727272727,
                "acc_stderr": 0.0449429086625209,
                "brier_score": 0.4659728330390492,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.84,
                "acc_stderr": 0.03684529491774709,
                "brier_score": 0.22274870775036582,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_sociology": {
                "acc": 0.8557213930348259,
                "acc_stderr": 0.024845753212306046,
                "brier_score": 0.23113090531934954,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.6461538461538462,
                "acc_stderr": 0.02424378399406216,
                "brier_score": 0.49839898594912685,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_security_studies": {
                "acc": 0.7306122448979592,
                "acc_stderr": 0.02840125202902294,
                "brier_score": 0.379967944540605,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_professional_psychology": {
                "acc": 0.6715686274509803,
                "acc_stderr": 0.018999707383162666,
                "brier_score": 0.48283691821628216,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_human_sexuality": {
                "acc": 0.7633587786259542,
                "acc_stderr": 0.03727673575596915,
                "brier_score": 0.3548332095368855,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_econometrics": {
                "acc": 0.5350877192982456,
                "acc_stderr": 0.046920083813689104,
                "brier_score": 0.677082317785518,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_miscellaneous": {
                "acc": 0.8058748403575989,
                "acc_stderr": 0.01414397027665757,
                "brier_score": 0.2832781046612229,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_marketing": {
                "acc": 0.8931623931623932,
                "acc_stderr": 0.02023714900899092,
                "brier_score": 0.16389074991554042,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_management": {
                "acc": 0.8252427184466019,
                "acc_stderr": 0.037601780060266196,
                "brier_score": 0.2718740815792001,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_nutrition": {
                "acc": 0.7320261437908496,
                "acc_stderr": 0.025360603796242557,
                "brier_score": 0.3897167590755755,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_medical_genetics": {
                "acc": 0.81,
                "acc_stderr": 0.03942772444036623,
                "brier_score": 0.307411346256468,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_human_aging": {
                "acc": 0.6771300448430493,
                "acc_stderr": 0.031381476375754995,
                "brier_score": 0.468792528284544,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_professional_medicine": {
                "acc": 0.75,
                "acc_stderr": 0.026303648393696036,
                "brier_score": 0.40109802460691063,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_medicine": {
                "acc": 0.630057803468208,
                "acc_stderr": 0.0368122963339432,
                "brier_score": 0.5050045005099414,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_business_ethics": {
                "acc": 0.65,
                "acc_stderr": 0.047937248544110196,
                "brier_score": 0.4819277244337173,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.7169811320754716,
                "acc_stderr": 0.027724236492700918,
                "brier_score": 0.3907958149135372,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_global_facts": {
                "acc": 0.38,
                "acc_stderr": 0.048783173121456316,
                "brier_score": 0.7258617716168976,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_virology": {
                "acc": 0.5120481927710844,
                "acc_stderr": 0.038913644958358175,
                "brier_score": 0.8143739339624022,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_professional_accounting": {
                "acc": 0.549645390070922,
                "acc_stderr": 0.02968010556502904,
                "brier_score": 0.6166727913872267,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_physics": {
                "acc": 0.5,
                "acc_stderr": 0.04975185951049946,
                "brier_score": 0.669272266134827,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_physics": {
                "acc": 0.4304635761589404,
                "acc_stderr": 0.04042809961395634,
                "brier_score": 0.7136826066672557,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_biology": {
                "acc": 0.7645161290322581,
                "acc_stderr": 0.024137632429337703,
                "brier_score": 0.36284198711840915,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_biology": {
                "acc": 0.75,
                "acc_stderr": 0.03621034121889507,
                "brier_score": 0.3503528186466499,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_anatomy": {
                "acc": 0.6370370370370371,
                "acc_stderr": 0.04153948404742399,
                "brier_score": 0.5389026229745647,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_chemistry": {
                "acc": 0.42,
                "acc_stderr": 0.049604496374885836,
                "brier_score": 0.7118320327181862,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_computer_security": {
                "acc": 0.77,
                "acc_stderr": 0.04229525846816506,
                "brier_score": 0.37266458073179076,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_computer_science": {
                "acc": 0.51,
                "acc_stderr": 0.05024183937956911,
                "brier_score": 0.6364190283622218,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_astronomy": {
                "acc": 0.6842105263157895,
                "acc_stderr": 0.03782728980865469,
                "brier_score": 0.4362631512301302,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_college_mathematics": {
                "acc": 0.33,
                "acc_stderr": 0.04725815626252604,
                "brier_score": 0.7951255964154708,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.5361702127659574,
                "acc_stderr": 0.032600385118357715,
                "brier_score": 0.6263913485195526,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.7972656381802152,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.69,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.4321421643505633,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_machine_learning": {
                "acc": 0.48214285714285715,
                "acc_stderr": 0.047427623612430116,
                "brier_score": 0.6323848144772048,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.4630541871921182,
                "acc_stderr": 0.035083705204426656,
                "brier_score": 0.7004761750941393,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.5185185185185185,
                "acc_stderr": 0.03407632093854052,
                "brier_score": 0.6747863159719197,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.455026455026455,
                "acc_stderr": 0.025646928361049398,
                "brier_score": 0.7064055129748947,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.6275862068965518,
                "acc_stderr": 0.04028731532947558,
                "brier_score": 0.5380762418986331,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.3888888888888889,
                "acc_stderr": 0.029723278961476668,
                "brier_score": 0.7657337575523382,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T20-07-57.894580"
            },
            "arc_challenge": {
                "acc": 0.5767918088737202,
                "acc_stderr": 0.014438036220848025,
                "acc_norm": 0.6186006825938567,
                "acc_norm_stderr": 0.01419438908668527,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "hellaswag": {
                "acc": 0.5898227444732125,
                "acc_stderr": 0.004908604732082822,
                "acc_norm": 0.7898824935271859,
                "acc_norm_stderr": 0.004065592811695992,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "truthfulqa_mc2": {
                "acc": 0.5165834108450839,
                "acc_stderr": 0.015188480530101718,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "truthfulqa_gen": {
                "bleu_max": 20.38284601416647,
                "bleu_max_stderr": 0.7259585799496531,
                "bleu_acc": 0.4749082007343941,
                "bleu_acc_stderr": 0.017481446804104003,
                "bleu_diff": -0.39825979672746564,
                "bleu_diff_stderr": 0.6399548657857169,
                "rouge1_max": 43.70636561691526,
                "rouge1_max_stderr": 0.8683149503828073,
                "rouge1_acc": 0.4969400244798042,
                "rouge1_acc_stderr": 0.017503173260960625,
                "rouge1_diff": -0.267087450778999,
                "rouge1_diff_stderr": 0.8748649880343018,
                "rouge2_max": 27.583822895276878,
                "rouge2_max_stderr": 0.9560493672304742,
                "rouge2_acc": 0.36474908200734396,
                "rouge2_acc_stderr": 0.016850961061720113,
                "rouge2_diff": -1.7302074043155247,
                "rouge2_diff_stderr": 0.928098862686909,
                "rougeL_max": 40.83179541506895,
                "rougeL_max_stderr": 0.8672456167019427,
                "rougeL_acc": 0.4847001223990208,
                "rougeL_acc_stderr": 0.017495304473187902,
                "rougeL_diff": -0.6070224090190008,
                "rougeL_diff_stderr": 0.8794043276943261,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "truthfulqa_mc1": {
                "acc": 0.36474908200734396,
                "acc_stderr": 0.016850961061720116,
                "timestamp": "2024-11-22T19-05-59.919138"
            },
            "winogrande": {
                "acc": 0.7561168113654302,
                "acc_stderr": 0.01206892327890818,
                "timestamp": "2024-11-22T19-05-59.919138"
            }
        }
    }
}