{
    "model_name": "cerebras/Cerebras-GPT-1.3B",
    "last_updated": "2024-12-19 13:39:39.590011",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.009157509157509158,
                "exact_match_stderr": 0.004080306065048968,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.012629161882893225,
                "exact_match_stderr": 0.0037858882182630017,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.012962962962962963,
                "exact_match_stderr": 0.004872192984581503,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.015503875968992248,
                "exact_match_stderr": 0.004113617238360454,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_geometry": {
                "exact_match": 0.006263048016701462,
                "exact_match_stderr": 0.003608399732887888,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.010548523206751054,
                "exact_match_stderr": 0.004697453735376145,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "minerva_math_algebra": {
                "exact_match": 0.009267059814658803,
                "exact_match_stderr": 0.0027823191184887844,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_3da": {
                "acc": 0.001,
                "acc_stderr": 0.0007069298939339458,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_3ds": {
                "acc": 0.0015,
                "acc_stderr": 0.0008655920660521539,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_4da": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000151,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_2ds": {
                "acc": 0.013,
                "acc_stderr": 0.0025335171905233197,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_5da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_1dc": {
                "acc": 0.0275,
                "acc_stderr": 0.0036576719757437743,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_4ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_2dm": {
                "acc": 0.022,
                "acc_stderr": 0.0032807593162018913,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "arithmetic_2da": {
                "acc": 0.007,
                "acc_stderr": 0.0018647355360237512,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "gsm8k_cot": {
                "exact_match": 0.014404852160727824,
                "exact_match_stderr": 0.003282055917136958,
                "timestamp": "2024-06-11T18-28-01.677806"
            },
            "gsm8k": {
                "exact_match": 0.02122820318423048,
                "exact_match_stderr": 0.003970449129848635,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "anli_r2": {
                "brier_score": 0.8160206698968121,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "anli_r3": {
                "brier_score": 0.7564486854420894,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "anli_r1": {
                "brier_score": 0.8453036236123399,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_eu": {
                "brier_score": 1.203122941977538,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_vi": {
                "brier_score": 0.9581888474081791,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_ru": {
                "brier_score": 0.8555274102354892,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_zh": {
                "brier_score": 0.9525134852831153,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_tr": {
                "brier_score": 0.8488424294763287,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_fr": {
                "brier_score": 0.9004072134991292,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_en": {
                "brier_score": 0.676735865099788,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_ur": {
                "brier_score": 1.119118044439167,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_ar": {
                "brier_score": 1.0334678129216435,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_de": {
                "brier_score": 0.8840107844662859,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_hi": {
                "brier_score": 0.9489724257727796,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_es": {
                "brier_score": 0.9940572286363858,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_bg": {
                "brier_score": 0.7972760255131902,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_sw": {
                "brier_score": 0.9917977124323483,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_el": {
                "brier_score": 1.2932784189714346,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "xnli_th": {
                "brier_score": 0.7809459010580413,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "logiqa2": {
                "brier_score": 1.2019264190394812,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "mathqa": {
                "brier_score": 0.9930432217011608,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-11T18-38-40.786526"
            },
            "lambada_standard": {
                "perplexity": 30.331273764614334,
                "perplexity_stderr": 1.0890794817806768,
                "acc": 0.3584319813700757,
                "acc_stderr": 0.006680928173680374,
                "timestamp": "2024-06-11T18-40-02.959579"
            },
            "lambada_openai": {
                "perplexity": 14.11714896411139,
                "perplexity_stderr": 0.4545475556587265,
                "acc": 0.4614787502425771,
                "acc_stderr": 0.006945273445805861,
                "timestamp": "2024-06-11T18-40-02.959579"
            },
            "mmlu_world_religions": {
                "acc": 0.32748538011695905,
                "acc_stderr": 0.03599335771456027,
                "brier_score": 0.8937719714888455,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_formal_logic": {
                "acc": 0.2698412698412698,
                "acc_stderr": 0.03970158273235172,
                "brier_score": 0.8046229494807222,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_prehistory": {
                "acc": 0.21296296296296297,
                "acc_stderr": 0.022779719088733396,
                "brier_score": 0.9238815756889868,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.24134078212290502,
                "acc_stderr": 0.014310999547961455,
                "brier_score": 0.7654012206749515,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.2742616033755274,
                "acc_stderr": 0.029041333510598042,
                "brier_score": 0.8953044137931278,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_moral_disputes": {
                "acc": 0.24855491329479767,
                "acc_stderr": 0.023267528432100174,
                "brier_score": 0.9076762471398718,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_professional_law": {
                "acc": 0.24445893089960888,
                "acc_stderr": 0.010976425013113909,
                "brier_score": 0.9081932458376115,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.22699386503067484,
                "acc_stderr": 0.03291099578615768,
                "brier_score": 0.9047494006062847,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.25,
                "acc_stderr": 0.03039153369274154,
                "brier_score": 0.8896682536103456,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_philosophy": {
                "acc": 0.1864951768488746,
                "acc_stderr": 0.02212243977248077,
                "brier_score": 0.9950397047163916,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_jurisprudence": {
                "acc": 0.25,
                "acc_stderr": 0.04186091791394607,
                "brier_score": 0.9152850991695487,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_international_law": {
                "acc": 0.2396694214876033,
                "acc_stderr": 0.03896878985070417,
                "brier_score": 1.0013452528417237,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.21212121212121213,
                "acc_stderr": 0.03192271569548301,
                "brier_score": 0.8834985641364104,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.20207253886010362,
                "acc_stderr": 0.02897908979429673,
                "brier_score": 0.97165754636985,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.21008403361344538,
                "acc_stderr": 0.026461398717471874,
                "brier_score": 0.934970235522194,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_geography": {
                "acc": 0.17676767676767677,
                "acc_stderr": 0.027178752639044915,
                "brier_score": 0.9866251603319629,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.1908256880733945,
                "acc_stderr": 0.01684767640009109,
                "brier_score": 0.9465549801953812,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_public_relations": {
                "acc": 0.20909090909090908,
                "acc_stderr": 0.03895091015724137,
                "brier_score": 0.9756479393225346,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.27,
                "acc_stderr": 0.0446196043338474,
                "brier_score": 0.8913658520374631,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_sociology": {
                "acc": 0.24378109452736318,
                "acc_stderr": 0.030360490154014652,
                "brier_score": 0.9723441679448906,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.2,
                "acc_stderr": 0.020280805062535726,
                "brier_score": 0.9225384105640989,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_security_studies": {
                "acc": 0.18775510204081633,
                "acc_stderr": 0.02500025603954622,
                "brier_score": 0.9870533074312139,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_professional_psychology": {
                "acc": 0.25163398692810457,
                "acc_stderr": 0.01755581809132225,
                "brier_score": 0.8988898696397957,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_human_sexuality": {
                "acc": 0.2595419847328244,
                "acc_stderr": 0.03844876139785271,
                "brier_score": 0.8984801627491069,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_econometrics": {
                "acc": 0.23684210526315788,
                "acc_stderr": 0.039994238792813386,
                "brier_score": 0.9009249067332376,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_miscellaneous": {
                "acc": 0.23754789272030652,
                "acc_stderr": 0.015218733046150195,
                "brier_score": 0.9171301184162767,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_marketing": {
                "acc": 0.2905982905982906,
                "acc_stderr": 0.029745048572674057,
                "brier_score": 0.8904287868983547,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_management": {
                "acc": 0.18446601941747573,
                "acc_stderr": 0.03840423627288276,
                "brier_score": 1.0585623359693057,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_nutrition": {
                "acc": 0.22875816993464052,
                "acc_stderr": 0.024051029739912258,
                "brier_score": 0.9635607731453667,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_medical_genetics": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.8623705842444132,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_human_aging": {
                "acc": 0.31390134529147984,
                "acc_stderr": 0.03114679648297246,
                "brier_score": 0.8158083435782157,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_professional_medicine": {
                "acc": 0.1875,
                "acc_stderr": 0.023709788253811766,
                "brier_score": 1.0112612383958777,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_medicine": {
                "acc": 0.20809248554913296,
                "acc_stderr": 0.030952890217749884,
                "brier_score": 0.9331850115461513,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_business_ethics": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.853814068235312,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.21509433962264152,
                "acc_stderr": 0.025288394502891377,
                "brier_score": 1.0002391981534213,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_global_facts": {
                "acc": 0.18,
                "acc_stderr": 0.038612291966536955,
                "brier_score": 0.9287312274934277,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_virology": {
                "acc": 0.28313253012048195,
                "acc_stderr": 0.03507295431370518,
                "brier_score": 0.8980442362410103,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_professional_accounting": {
                "acc": 0.22695035460992907,
                "acc_stderr": 0.024987106365642973,
                "brier_score": 0.886959008863655,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_physics": {
                "acc": 0.21568627450980393,
                "acc_stderr": 0.040925639582376556,
                "brier_score": 0.8534210516503284,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2052980132450331,
                "acc_stderr": 0.032979866484738336,
                "brier_score": 0.8619739918680707,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_biology": {
                "acc": 0.1774193548387097,
                "acc_stderr": 0.021732540689329265,
                "brier_score": 0.9335354805317831,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_biology": {
                "acc": 0.25,
                "acc_stderr": 0.03621034121889507,
                "brier_score": 0.891799674376725,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_anatomy": {
                "acc": 0.18518518518518517,
                "acc_stderr": 0.03355677216313142,
                "brier_score": 1.0232390398107596,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_chemistry": {
                "acc": 0.19,
                "acc_stderr": 0.03942772444036623,
                "brier_score": 0.8849749719428637,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_computer_security": {
                "acc": 0.28,
                "acc_stderr": 0.045126085985421276,
                "brier_score": 0.8346834446161736,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_computer_science": {
                "acc": 0.22,
                "acc_stderr": 0.041633319989322695,
                "brier_score": 0.8582590301713728,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_astronomy": {
                "acc": 0.17105263157894737,
                "acc_stderr": 0.030643607071677098,
                "brier_score": 0.8904045198086842,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_college_mathematics": {
                "acc": 0.22,
                "acc_stderr": 0.041633319989322695,
                "brier_score": 0.8630935255597413,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.2680851063829787,
                "acc_stderr": 0.028957342788342347,
                "brier_score": 0.8508397492714637,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.22,
                "acc_stderr": 0.04163331998932269,
                "brier_score": 0.8737331790827914,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.8761422947323227,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_machine_learning": {
                "acc": 0.32142857142857145,
                "acc_stderr": 0.04432804055291519,
                "brier_score": 0.8139880556182322,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.15270935960591134,
                "acc_stderr": 0.025308904539380627,
                "brier_score": 0.9375182997733705,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.16203703703703703,
                "acc_stderr": 0.02513045365226846,
                "brier_score": 0.923847541062819,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.20899470899470898,
                "acc_stderr": 0.020940481565334835,
                "brier_score": 0.8580255403499754,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.2413793103448276,
                "acc_stderr": 0.03565998174135302,
                "brier_score": 0.866950272038678,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.21851851851851853,
                "acc_stderr": 0.02519575225182379,
                "brier_score": 0.8407321696951865,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-52-10.280607"
            },
            "arc_challenge": {
                "acc": 0.24744027303754265,
                "acc_stderr": 0.01261035266329267,
                "acc_norm": 0.2738907849829352,
                "acc_norm_stderr": 0.013032004972989503,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "hellaswag": {
                "acc": 0.32433778131846247,
                "acc_stderr": 0.004671701705567258,
                "acc_norm": 0.38946425014937264,
                "acc_norm_stderr": 0.004866322258335968,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "truthfulqa_mc2": {
                "acc": 0.4270182875007654,
                "acc_stderr": 0.014896443872403905,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "truthfulqa_gen": {
                "bleu_max": 15.75896364576763,
                "bleu_max_stderr": 0.5364357683647447,
                "bleu_acc": 0.3598531211750306,
                "bleu_acc_stderr": 0.016801860466677174,
                "bleu_diff": -3.3445863219845346,
                "bleu_diff_stderr": 0.5222101463879798,
                "rouge1_max": 36.903769503650345,
                "rouge1_max_stderr": 0.7998635375855746,
                "rouge1_acc": 0.2913096695226438,
                "rouge1_acc_stderr": 0.01590598704818482,
                "rouge1_diff": -6.460703210665295,
                "rouge1_diff_stderr": 0.7328034463145772,
                "rouge2_max": 19.326584406586324,
                "rouge2_max_stderr": 0.8077506474590068,
                "rouge2_acc": 0.18237454100367198,
                "rouge2_acc_stderr": 0.013518055636187212,
                "rouge2_diff": -6.646991226024485,
                "rouge2_diff_stderr": 0.7429900455011789,
                "rougeL_max": 33.790056148847405,
                "rougeL_max_stderr": 0.78334334845043,
                "rougeL_acc": 0.28518971848225216,
                "rougeL_acc_stderr": 0.015805827874454892,
                "rougeL_diff": -6.286118787315412,
                "rougeL_diff_stderr": 0.7141317626988594,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "truthfulqa_mc1": {
                "acc": 0.24479804161566707,
                "acc_stderr": 0.015051869486714997,
                "timestamp": "2024-11-21T01-52-17.626746"
            },
            "winogrande": {
                "acc": 0.5248618784530387,
                "acc_stderr": 0.01403510288362775,
                "timestamp": "2024-11-21T01-52-17.626746"
            }
        }
    }
}