{
    "model_name": "Salesforce/codegen-350M-multi",
    "last_updated": "2024-12-19 13:39:13.209588",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.01098901098901099,
                "exact_match_stderr": 0.004465618427331418,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.01951779563719862,
                "exact_match_stderr": 0.004690029935284569,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.005555555555555556,
                "exact_match_stderr": 0.00320154512732093,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.012181616832779624,
                "exact_match_stderr": 0.0036524791938863663,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_geometry": {
                "exact_match": 0.0020876826722338203,
                "exact_match_stderr": 0.0020876826722338333,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.008438818565400843,
                "exact_match_stderr": 0.004206007207713054,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "minerva_math_algebra": {
                "exact_match": 0.014321819713563605,
                "exact_match_stderr": 0.003450041570937017,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_3da": {
                "acc": 0.0015,
                "acc_stderr": 0.0008655920660521454,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_3ds": {
                "acc": 0.001,
                "acc_stderr": 0.0007069298939339515,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_4da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_2ds": {
                "acc": 0.0015,
                "acc_stderr": 0.0008655920660521503,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_5da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_1dc": {
                "acc": 0.029,
                "acc_stderr": 0.0037532044004605115,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_4ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_2dm": {
                "acc": 0.016,
                "acc_stderr": 0.002806410156941532,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "arithmetic_2da": {
                "acc": 0.004,
                "acc_stderr": 0.0014117352790977004,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "gsm8k_cot": {
                "exact_match": 0.022744503411675512,
                "exact_match_stderr": 0.004106620637749713,
                "timestamp": "2024-06-13T18-16-04.607115"
            },
            "gsm8k": {
                "exact_match": 0.02047005307050796,
                "exact_match_stderr": 0.003900413385915717,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "anli_r2": {
                "brier_score": 0.985719346196084,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "anli_r3": {
                "brier_score": 0.9732009467249916,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "anli_r1": {
                "brier_score": 0.9985649407847307,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_eu": {
                "brier_score": 1.2461840807929438,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_vi": {
                "brier_score": 1.1678074729947867,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_ru": {
                "brier_score": 0.9554534962904667,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_zh": {
                "brier_score": 1.0339034216345016,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_tr": {
                "brier_score": 1.255509308223099,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_fr": {
                "brier_score": 1.2357496951451048,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_en": {
                "brier_score": 0.8204070568367904,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_ur": {
                "brier_score": 1.2449382078214195,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_ar": {
                "brier_score": 1.026144943391084,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_de": {
                "brier_score": 0.9722273139773239,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_hi": {
                "brier_score": 1.0013653907261761,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_es": {
                "brier_score": 1.1864389653417817,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_bg": {
                "brier_score": 0.9590675242887678,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_sw": {
                "brier_score": 1.087228705558193,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_el": {
                "brier_score": 1.107009491211521,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "xnli_th": {
                "brier_score": 1.0205217980811283,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "logiqa2": {
                "brier_score": 1.1839026222831999,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "mathqa": {
                "brier_score": 1.0109975167317484,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T18-21-36.595519"
            },
            "lambada_standard": {
                "perplexity": 929.8432444456479,
                "perplexity_stderr": 44.08843957528335,
                "acc": 0.12012419949543955,
                "acc_stderr": 0.004529372226920103,
                "timestamp": "2024-06-13T18-22-36.360059"
            },
            "lambada_openai": {
                "perplexity": 1118.2514080440103,
                "perplexity_stderr": 58.16346545779122,
                "acc": 0.12652823597904134,
                "acc_stderr": 0.004631591355662349,
                "timestamp": "2024-06-13T18-22-36.360059"
            },
            "mmlu_world_religions": {
                "acc": 0.3157894736842105,
                "acc_stderr": 0.03565079670708313,
                "brier_score": 0.9076127637219964,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_formal_logic": {
                "acc": 0.2619047619047619,
                "acc_stderr": 0.03932537680392872,
                "brier_score": 0.8460958087423824,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_prehistory": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.023132376234543325,
                "brier_score": 0.987859802666584,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.2446927374301676,
                "acc_stderr": 0.01437816988409841,
                "brier_score": 0.7630963566676106,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.26582278481012656,
                "acc_stderr": 0.028756799629658335,
                "brier_score": 0.9634761184938231,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_moral_disputes": {
                "acc": 0.24566473988439305,
                "acc_stderr": 0.02317629820399201,
                "brier_score": 0.9605339536210215,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_professional_law": {
                "acc": 0.2438070404172099,
                "acc_stderr": 0.010966507972178475,
                "brier_score": 0.8748290864284843,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.22085889570552147,
                "acc_stderr": 0.032591773927421776,
                "brier_score": 1.044997786061394,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.2549019607843137,
                "acc_stderr": 0.030587591351604246,
                "brier_score": 0.9482436683910561,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_philosophy": {
                "acc": 0.1864951768488746,
                "acc_stderr": 0.02212243977248077,
                "brier_score": 1.0453732068606783,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_jurisprudence": {
                "acc": 0.26851851851851855,
                "acc_stderr": 0.04284467968052192,
                "brier_score": 0.9867169959007726,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_international_law": {
                "acc": 0.2396694214876033,
                "acc_stderr": 0.03896878985070417,
                "brier_score": 1.0114064863859569,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.20606060606060606,
                "acc_stderr": 0.0315841532404771,
                "brier_score": 0.9819375183718658,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.19689119170984457,
                "acc_stderr": 0.02869787397186069,
                "brier_score": 1.016578117624572,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.20168067226890757,
                "acc_stderr": 0.026064313406304527,
                "brier_score": 1.0361993540193473,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_geography": {
                "acc": 0.1717171717171717,
                "acc_stderr": 0.026869716187429917,
                "brier_score": 1.0463816816619436,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.1908256880733945,
                "acc_stderr": 0.01684767640009109,
                "brier_score": 1.108188168555968,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_public_relations": {
                "acc": 0.21818181818181817,
                "acc_stderr": 0.03955932861795833,
                "brier_score": 1.07147508063318,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.28,
                "acc_stderr": 0.045126085985421276,
                "brier_score": 0.8866703263248481,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_sociology": {
                "acc": 0.24378109452736318,
                "acc_stderr": 0.030360490154014652,
                "brier_score": 1.0909873671496528,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.2076923076923077,
                "acc_stderr": 0.02056753956724679,
                "brier_score": 0.9714959985838358,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_security_studies": {
                "acc": 0.19591836734693877,
                "acc_stderr": 0.025409301953225678,
                "brier_score": 1.035349559854223,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_professional_psychology": {
                "acc": 0.24836601307189543,
                "acc_stderr": 0.017479487001364764,
                "brier_score": 1.0612778969181413,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_human_sexuality": {
                "acc": 0.25190839694656486,
                "acc_stderr": 0.038073871163060866,
                "brier_score": 1.0156352887399498,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_econometrics": {
                "acc": 0.23684210526315788,
                "acc_stderr": 0.03999423879281338,
                "brier_score": 0.9444932309114732,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_miscellaneous": {
                "acc": 0.23627075351213284,
                "acc_stderr": 0.01519047371703751,
                "brier_score": 0.9882763883266693,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_marketing": {
                "acc": 0.2905982905982906,
                "acc_stderr": 0.029745048572674057,
                "brier_score": 1.0379668720217567,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_management": {
                "acc": 0.17475728155339806,
                "acc_stderr": 0.03760178006026621,
                "brier_score": 1.14546352508103,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_nutrition": {
                "acc": 0.21895424836601307,
                "acc_stderr": 0.02367908986180772,
                "brier_score": 1.0325525503748743,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_medical_genetics": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.9153923451609859,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_human_aging": {
                "acc": 0.31390134529147984,
                "acc_stderr": 0.03114679648297246,
                "brier_score": 0.9091966675496221,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_professional_medicine": {
                "acc": 0.18382352941176472,
                "acc_stderr": 0.02352924218519311,
                "brier_score": 1.041393277404226,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_medicine": {
                "acc": 0.20809248554913296,
                "acc_stderr": 0.030952890217749884,
                "brier_score": 1.035016973705624,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_business_ethics": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.949501669515644,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.22264150943396227,
                "acc_stderr": 0.025604233470899088,
                "brier_score": 1.0155779930799764,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_global_facts": {
                "acc": 0.18,
                "acc_stderr": 0.03861229196653697,
                "brier_score": 0.9658862144878719,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_virology": {
                "acc": 0.28313253012048195,
                "acc_stderr": 0.03507295431370518,
                "brier_score": 0.9147287745722621,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_professional_accounting": {
                "acc": 0.23049645390070922,
                "acc_stderr": 0.025123739226872405,
                "brier_score": 0.972198891754218,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_physics": {
                "acc": 0.21568627450980393,
                "acc_stderr": 0.040925639582376556,
                "brier_score": 0.958858133650472,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2119205298013245,
                "acc_stderr": 0.03336767086567978,
                "brier_score": 0.9895118534031518,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_biology": {
                "acc": 0.18064516129032257,
                "acc_stderr": 0.021886178567172558,
                "brier_score": 1.0620215312594377,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_biology": {
                "acc": 0.2569444444444444,
                "acc_stderr": 0.03653946969442099,
                "brier_score": 0.9572646773476323,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_anatomy": {
                "acc": 0.1925925925925926,
                "acc_stderr": 0.03406542058502653,
                "brier_score": 1.0196718677574592,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_chemistry": {
                "acc": 0.19,
                "acc_stderr": 0.03942772444036623,
                "brier_score": 0.9834123630567483,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_computer_security": {
                "acc": 0.28,
                "acc_stderr": 0.045126085985421276,
                "brier_score": 0.9511809132462804,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_computer_science": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.971996928215002,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_astronomy": {
                "acc": 0.17105263157894737,
                "acc_stderr": 0.03064360707167709,
                "brier_score": 1.0437098022366331,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_college_mathematics": {
                "acc": 0.21,
                "acc_stderr": 0.040936018074033256,
                "brier_score": 0.966038248892535,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.26382978723404255,
                "acc_stderr": 0.02880998985410298,
                "brier_score": 0.9290328394695287,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.21,
                "acc_stderr": 0.040936018074033256,
                "brier_score": 1.038614939773198,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.23,
                "acc_stderr": 0.04229525846816506,
                "brier_score": 0.9759436161616507,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_machine_learning": {
                "acc": 0.33035714285714285,
                "acc_stderr": 0.04464285714285712,
                "brier_score": 0.8620202101436615,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.1724137931034483,
                "acc_stderr": 0.02657767218303657,
                "brier_score": 1.0588217991363558,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.1388888888888889,
                "acc_stderr": 0.02358544736890012,
                "brier_score": 1.0655089115094414,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.021411684393694175,
                "brier_score": 0.9576128764995636,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.25517241379310346,
                "acc_stderr": 0.03632984052707842,
                "brier_score": 0.9581270488425577,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.21481481481481482,
                "acc_stderr": 0.025040443877000683,
                "brier_score": 1.0486529075001332,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-58-20.110786"
            },
            "arc_challenge": {
                "acc": 0.17320819112627986,
                "acc_stderr": 0.011058694183280328,
                "acc_norm": 0.21928327645051193,
                "acc_norm_stderr": 0.012091245787615716,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "hellaswag": {
                "acc": 0.27454690300736906,
                "acc_stderr": 0.004453735900947804,
                "acc_norm": 0.29356701852220674,
                "acc_norm_stderr": 0.0045446519760401006,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "truthfulqa_mc2": {
                "acc": 0.46878684418952904,
                "acc_stderr": 0.015919757808354366,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "truthfulqa_gen": {
                "bleu_max": 14.843134516314572,
                "bleu_max_stderr": 0.5728559782867888,
                "bleu_acc": 0.2864137086903305,
                "bleu_acc_stderr": 0.01582614243950239,
                "bleu_diff": -2.2717050031248,
                "bleu_diff_stderr": 0.43331168281195936,
                "rouge1_max": 35.03124298423832,
                "rouge1_max_stderr": 0.7866389432856384,
                "rouge1_acc": 0.28886168910648713,
                "rouge1_acc_stderr": 0.015866346401384315,
                "rouge1_diff": -4.893306750479266,
                "rouge1_diff_stderr": 0.5725461641851453,
                "rouge2_max": 19.758755174632952,
                "rouge2_max_stderr": 0.79627641363227,
                "rouge2_acc": 0.20685434516523868,
                "rouge2_acc_stderr": 0.014179591496728337,
                "rouge2_diff": -4.2748721462575014,
                "rouge2_diff_stderr": 0.5919097348223242,
                "rougeL_max": 32.14833428429696,
                "rougeL_max_stderr": 0.7758150933271327,
                "rougeL_acc": 0.2668298653610771,
                "rougeL_acc_stderr": 0.015483691939237277,
                "rougeL_diff": -4.921493483348142,
                "rougeL_diff_stderr": 0.5510430423849421,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "truthfulqa_mc1": {
                "acc": 0.27539779681762544,
                "acc_stderr": 0.01563813566777552,
                "timestamp": "2024-11-21T23-05-09.706261"
            },
            "winogrande": {
                "acc": 0.516179952644041,
                "acc_stderr": 0.0140451261309786,
                "timestamp": "2024-11-21T23-05-09.706261"
            }
        }
    }
}