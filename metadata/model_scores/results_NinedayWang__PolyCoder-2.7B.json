{
    "model_name": "NinedayWang__PolyCoder-2.7B",
    "last_updated": "2024-12-04 11:22:36.527352",
    "results": {
        "harness": {
            "mmlu_world_religions": {
                "acc": 0.3157894736842105,
                "acc_stderr": 0.03565079670708312,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_formal_logic": {
                "acc": 0.18253968253968253,
                "acc_stderr": 0.03455071019102147,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_prehistory": {
                "acc": 0.2191358024691358,
                "acc_stderr": 0.023016705640262196,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.24804469273743016,
                "acc_stderr": 0.014444157808261436,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.2742616033755274,
                "acc_stderr": 0.02904133351059802,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_moral_disputes": {
                "acc": 0.23699421965317918,
                "acc_stderr": 0.02289408248992599,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_professional_law": {
                "acc": 0.24771838331160365,
                "acc_stderr": 0.011025499291443737,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.27607361963190186,
                "acc_stderr": 0.0351238528370505,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.2647058823529412,
                "acc_stderr": 0.03096451792692341,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_philosophy": {
                "acc": 0.26366559485530544,
                "acc_stderr": 0.02502553850053234,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_jurisprudence": {
                "acc": 0.21296296296296297,
                "acc_stderr": 0.03957835471980978,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_international_law": {
                "acc": 0.3140495867768595,
                "acc_stderr": 0.04236964753041019,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.2606060606060606,
                "acc_stderr": 0.03427743175816524,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.31088082901554404,
                "acc_stderr": 0.03340361906276585,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.23529411764705882,
                "acc_stderr": 0.027553614467863804,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_geography": {
                "acc": 0.2727272727272727,
                "acc_stderr": 0.03173071239071724,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.20733944954128442,
                "acc_stderr": 0.017381415563608674,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_public_relations": {
                "acc": 0.22727272727272727,
                "acc_stderr": 0.04013964554072773,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.24,
                "acc_stderr": 0.042923469599092816,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_sociology": {
                "acc": 0.22388059701492538,
                "acc_stderr": 0.029475250236017193,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.34615384615384615,
                "acc_stderr": 0.024121125416941183,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_security_studies": {
                "acc": 0.1836734693877551,
                "acc_stderr": 0.024789071332007643,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_professional_psychology": {
                "acc": 0.24509803921568626,
                "acc_stderr": 0.017401816711427657,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_human_sexuality": {
                "acc": 0.2595419847328244,
                "acc_stderr": 0.03844876139785271,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_econometrics": {
                "acc": 0.23684210526315788,
                "acc_stderr": 0.03999423879281335,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_miscellaneous": {
                "acc": 0.25287356321839083,
                "acc_stderr": 0.015543377313719681,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_marketing": {
                "acc": 0.1794871794871795,
                "acc_stderr": 0.02514093595033545,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_management": {
                "acc": 0.13592233009708737,
                "acc_stderr": 0.033932957297610145,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_nutrition": {
                "acc": 0.23529411764705882,
                "acc_stderr": 0.024288619466046105,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_medical_genetics": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_human_aging": {
                "acc": 0.31390134529147984,
                "acc_stderr": 0.031146796482972465,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_professional_medicine": {
                "acc": 0.4411764705882353,
                "acc_stderr": 0.0301619119307671,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_medicine": {
                "acc": 0.23121387283236994,
                "acc_stderr": 0.032147373020294696,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_business_ethics": {
                "acc": 0.22,
                "acc_stderr": 0.041633319989322695,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.2641509433962264,
                "acc_stderr": 0.027134291628741702,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_global_facts": {
                "acc": 0.18,
                "acc_stderr": 0.038612291966536955,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_virology": {
                "acc": 0.1746987951807229,
                "acc_stderr": 0.029560326211256822,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_professional_accounting": {
                "acc": 0.26595744680851063,
                "acc_stderr": 0.026358065698880592,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_physics": {
                "acc": 0.21568627450980393,
                "acc_stderr": 0.040925639582376556,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2781456953642384,
                "acc_stderr": 0.03658603262763743,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_biology": {
                "acc": 0.3032258064516129,
                "acc_stderr": 0.02614868593067175,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_biology": {
                "acc": 0.2569444444444444,
                "acc_stderr": 0.03653946969442099,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_anatomy": {
                "acc": 0.3333333333333333,
                "acc_stderr": 0.04072314811876837,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_chemistry": {
                "acc": 0.19,
                "acc_stderr": 0.039427724440366234,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_computer_security": {
                "acc": 0.28,
                "acc_stderr": 0.04512608598542127,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_computer_science": {
                "acc": 0.34,
                "acc_stderr": 0.04760952285695236,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_astronomy": {
                "acc": 0.19078947368421054,
                "acc_stderr": 0.031975658210325,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_college_mathematics": {
                "acc": 0.27,
                "acc_stderr": 0.044619604333847394,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.2170212765957447,
                "acc_stderr": 0.02694748312149622,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.24,
                "acc_stderr": 0.04292346959909283,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.3,
                "acc_stderr": 0.04605661864718381,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_machine_learning": {
                "acc": 0.25892857142857145,
                "acc_stderr": 0.04157751539865629,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.270935960591133,
                "acc_stderr": 0.031270907132976984,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.38425925925925924,
                "acc_stderr": 0.03317354514310742,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.021411684393694196,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.22758620689655173,
                "acc_stderr": 0.03493950380131184,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.25555555555555554,
                "acc_stderr": 0.02659393910184407,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "arc_challenge": {
                "acc": 0.181740614334471,
                "acc_stderr": 0.011269198948880236,
                "acc_norm": 0.21928327645051193,
                "acc_norm_stderr": 0.012091245787615713,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "hellaswag": {
                "acc": 0.2773351921927903,
                "acc_stderr": 0.004467684132772418,
                "acc_norm": 0.2975502887870942,
                "acc_norm_stderr": 0.004562462665505278,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "truthfulqa_mc2": {
                "acc": 0.4900198282743296,
                "acc_stderr": 0.015924776108438145,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "truthfulqa_gen": {
                "bleu_max": 19.109929609778494,
                "bleu_max_stderr": 0.6347291486261849,
                "bleu_acc": 0.2913096695226438,
                "bleu_acc_stderr": 0.015905987048184824,
                "bleu_diff": -2.73808807451127,
                "bleu_diff_stderr": 0.4927649447592839,
                "rouge1_max": 43.64910481680449,
                "rouge1_max_stderr": 0.7663193889003078,
                "rouge1_acc": 0.2974296205630355,
                "rouge1_acc_stderr": 0.01600265148736098,
                "rouge1_diff": -5.224813168517498,
                "rouge1_diff_stderr": 0.5828636449526232,
                "rouge2_max": 27.07899530604482,
                "rouge2_max_stderr": 0.8474168667870206,
                "rouge2_acc": 0.24724602203182375,
                "rouge2_acc_stderr": 0.015102404797359652,
                "rouge2_diff": -4.815471980544821,
                "rouge2_diff_stderr": 0.6322835005066595,
                "rougeL_max": 40.60861307441461,
                "rougeL_max_stderr": 0.765726782060013,
                "rougeL_acc": 0.2802937576499388,
                "rougeL_acc_stderr": 0.015723139524608777,
                "rougeL_diff": -4.909635032740114,
                "rougeL_diff_stderr": 0.5671337300796637,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "truthfulqa_mc1": {
                "acc": 0.2876376988984088,
                "acc_stderr": 0.015846315101394805,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "winogrande": {
                "acc": 0.5209155485398579,
                "acc_stderr": 0.014040185494212942,
                "timestamp": "2024-11-22T00-21-02.759683"
            },
            "gsm8k": {
                "exact_match": 0.02122820318423048,
                "exact_match_stderr": 0.003970449129848635,
                "timestamp": "2024-11-22T00-21-02.759683"
            }
        }
    }
}