{
    "model_name": "EleutherAI/gpt-j-6b",
    "last_updated": "2024-12-19 13:42:20.535804",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.018315018315018316,
                "exact_match_stderr": 0.005743696731653661,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.04477611940298507,
                "exact_match_stderr": 0.007011584710623335,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.022222222222222223,
                "exact_match_stderr": 0.0063492063492063145,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.023255813953488372,
                "exact_match_stderr": 0.0050182572516275815,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_geometry": {
                "exact_match": 0.022964509394572025,
                "exact_match_stderr": 0.006851249878769254,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.029535864978902954,
                "exact_match_stderr": 0.007784559126948299,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "minerva_math_algebra": {
                "exact_match": 0.02358887952822241,
                "exact_match_stderr": 0.004406843931023534,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_3da": {
                "acc": 0.087,
                "acc_stderr": 0.006303599581496389,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_3ds": {
                "acc": 0.0465,
                "acc_stderr": 0.004709561018023942,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_4da": {
                "acc": 0.007,
                "acc_stderr": 0.0018647355360237453,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_2ds": {
                "acc": 0.2175,
                "acc_stderr": 0.009227103810100017,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_5da": {
                "acc": 0.0005,
                "acc_stderr": 0.0005000000000000127,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_1dc": {
                "acc": 0.089,
                "acc_stderr": 0.006368656050529475,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_4ds": {
                "acc": 0.0055,
                "acc_stderr": 0.0016541593398342208,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_2dm": {
                "acc": 0.1395,
                "acc_stderr": 0.007749187050909062,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "arithmetic_2da": {
                "acc": 0.24,
                "acc_stderr": 0.009552257472001268,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "gsm8k_cot": {
                "exact_match": 0.03335860500379075,
                "exact_match_stderr": 0.004946282649173773,
                "timestamp": "2024-06-13T16-47-03.193840"
            },
            "gsm8k": {
                "exact_match": 0.03639120545868082,
                "exact_match_stderr": 0.005158113489231192,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "anli_r2": {
                "brier_score": 0.7625067534704538,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "anli_r3": {
                "brier_score": 0.7268456375297242,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "anli_r1": {
                "brier_score": 0.7767404198801905,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_eu": {
                "brier_score": 0.840514896839387,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_vi": {
                "brier_score": 0.758218907162874,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_ru": {
                "brier_score": 0.7743489919871677,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_zh": {
                "brier_score": 0.9538503257434168,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_tr": {
                "brier_score": 0.8753439505463679,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_fr": {
                "brier_score": 0.7600564801060831,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_en": {
                "brier_score": 0.631686417358844,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_ur": {
                "brier_score": 0.9619292774250547,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_ar": {
                "brier_score": 1.1116475345057533,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_de": {
                "brier_score": 0.8152549958871562,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_hi": {
                "brier_score": 0.7460150666217235,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_es": {
                "brier_score": 0.7914512101723771,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_bg": {
                "brier_score": 0.7416509603093395,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_sw": {
                "brier_score": 0.8512933047395764,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_el": {
                "brier_score": 1.089738388519557,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "xnli_th": {
                "brier_score": 0.828907727940754,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "logiqa2": {
                "brier_score": 1.1310390010190252,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "mathqa": {
                "brier_score": 0.9512998262714331,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-13T17-23-39.734007"
            },
            "lambada_standard": {
                "perplexity": 5.680920517213677,
                "perplexity_stderr": 0.13320913025647432,
                "acc": 0.6136231321560256,
                "acc_stderr": 0.006783729046949487,
                "timestamp": "2024-06-13T17-26-24.151637"
            },
            "lambada_openai": {
                "perplexity": 4.1024027240281375,
                "perplexity_stderr": 0.08833542272706026,
                "acc": 0.6830972249175238,
                "acc_stderr": 0.00648210937056637,
                "timestamp": "2024-06-13T17-26-24.151637"
            },
            "mmlu_world_religions": {
                "acc": 0.3157894736842105,
                "acc_stderr": 0.03565079670708311,
                "brier_score": 0.7374101068019413,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_formal_logic": {
                "acc": 0.25396825396825395,
                "acc_stderr": 0.03893259610604674,
                "brier_score": 0.7611818191664562,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_prehistory": {
                "acc": 0.3148148148148148,
                "acc_stderr": 0.02584224870090217,
                "brier_score": 0.7444675213456617,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.2424581005586592,
                "acc_stderr": 0.014333522059217887,
                "brier_score": 0.7653061951507586,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.26582278481012656,
                "acc_stderr": 0.028756799629658332,
                "brier_score": 0.7500397365242264,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_moral_disputes": {
                "acc": 0.28901734104046245,
                "acc_stderr": 0.02440517393578323,
                "brier_score": 0.7481647628004192,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_professional_law": {
                "acc": 0.26010430247718386,
                "acc_stderr": 0.011204382887823834,
                "brier_score": 0.7520231732408674,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.2147239263803681,
                "acc_stderr": 0.03226219377286774,
                "brier_score": 0.7640208655687383,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.24019607843137256,
                "acc_stderr": 0.02998373305591361,
                "brier_score": 0.7541644655494616,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_philosophy": {
                "acc": 0.24437299035369775,
                "acc_stderr": 0.024406162094668907,
                "brier_score": 0.7488388338331259,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_jurisprudence": {
                "acc": 0.28703703703703703,
                "acc_stderr": 0.043733130409147614,
                "brier_score": 0.7477899989019611,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_international_law": {
                "acc": 0.24793388429752067,
                "acc_stderr": 0.039418975265163025,
                "brier_score": 0.7521289705486953,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.19393939393939394,
                "acc_stderr": 0.030874145136562114,
                "brier_score": 0.7651629152934769,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.25906735751295334,
                "acc_stderr": 0.031618779179354094,
                "brier_score": 0.7461302893750941,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.3277310924369748,
                "acc_stderr": 0.03048991141767323,
                "brier_score": 0.7383799741012769,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_geography": {
                "acc": 0.21717171717171718,
                "acc_stderr": 0.02937661648494563,
                "brier_score": 0.7626662681118054,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.23669724770642203,
                "acc_stderr": 0.01822407811729908,
                "brier_score": 0.7602229296110636,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_public_relations": {
                "acc": 0.2727272727272727,
                "acc_stderr": 0.04265792110940588,
                "brier_score": 0.7399827596672014,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.38,
                "acc_stderr": 0.048783173121456316,
                "brier_score": 0.731017853803002,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_sociology": {
                "acc": 0.2835820895522388,
                "acc_stderr": 0.03187187537919796,
                "brier_score": 0.7487866256318877,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.2923076923076923,
                "acc_stderr": 0.023060438380857744,
                "brier_score": 0.7432336631802331,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_security_studies": {
                "acc": 0.32653061224489793,
                "acc_stderr": 0.030021056238440296,
                "brier_score": 0.7326057170381776,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_professional_psychology": {
                "acc": 0.2581699346405229,
                "acc_stderr": 0.017704531653250075,
                "brier_score": 0.7533792173986266,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_human_sexuality": {
                "acc": 0.2900763358778626,
                "acc_stderr": 0.03980066246467766,
                "brier_score": 0.7356382300150744,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_econometrics": {
                "acc": 0.20175438596491227,
                "acc_stderr": 0.037752050135836386,
                "brier_score": 0.7629119690975171,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_miscellaneous": {
                "acc": 0.28607918263090676,
                "acc_stderr": 0.016160871405127543,
                "brier_score": 0.7480858931743369,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_marketing": {
                "acc": 0.2905982905982906,
                "acc_stderr": 0.029745048572674054,
                "brier_score": 0.74792602280863,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_management": {
                "acc": 0.23300970873786409,
                "acc_stderr": 0.04185832598928315,
                "brier_score": 0.7458389327916556,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_nutrition": {
                "acc": 0.3202614379084967,
                "acc_stderr": 0.02671611838015684,
                "brier_score": 0.739306232085926,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_medical_genetics": {
                "acc": 0.34,
                "acc_stderr": 0.04760952285695235,
                "brier_score": 0.7314187897221344,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_human_aging": {
                "acc": 0.38565022421524664,
                "acc_stderr": 0.03266842214289201,
                "brier_score": 0.7342953572667033,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_professional_medicine": {
                "acc": 0.20955882352941177,
                "acc_stderr": 0.024723110407677083,
                "brier_score": 0.8002697306213429,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_medicine": {
                "acc": 0.2254335260115607,
                "acc_stderr": 0.03186209851641144,
                "brier_score": 0.7592946121995308,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_business_ethics": {
                "acc": 0.32,
                "acc_stderr": 0.046882617226215034,
                "brier_score": 0.7491275586376847,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.24150943396226415,
                "acc_stderr": 0.026341480371118355,
                "brier_score": 0.7553629314392128,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_global_facts": {
                "acc": 0.36,
                "acc_stderr": 0.048241815132442176,
                "brier_score": 0.7304686187312108,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_virology": {
                "acc": 0.3433734939759036,
                "acc_stderr": 0.03696584317010601,
                "brier_score": 0.7374895776286096,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_professional_accounting": {
                "acc": 0.28368794326241137,
                "acc_stderr": 0.02689170942834396,
                "brier_score": 0.7505336664138332,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_physics": {
                "acc": 0.18627450980392157,
                "acc_stderr": 0.03873958714149353,
                "brier_score": 0.7800486202461536,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_physics": {
                "acc": 0.2119205298013245,
                "acc_stderr": 0.03336767086567977,
                "brier_score": 0.7503552732060065,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_biology": {
                "acc": 0.25483870967741934,
                "acc_stderr": 0.02479011845933221,
                "brier_score": 0.7596491887421389,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_biology": {
                "acc": 0.22916666666666666,
                "acc_stderr": 0.035146974678623884,
                "brier_score": 0.7588401240333378,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_anatomy": {
                "acc": 0.24444444444444444,
                "acc_stderr": 0.037125378336148665,
                "brier_score": 0.7514346773938658,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_chemistry": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.7555281959150324,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_computer_security": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.7391551892716636,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_computer_science": {
                "acc": 0.27,
                "acc_stderr": 0.0446196043338474,
                "brier_score": 0.7604929068028424,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_astronomy": {
                "acc": 0.2894736842105263,
                "acc_stderr": 0.03690677986137283,
                "brier_score": 0.7449180437327387,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_college_mathematics": {
                "acc": 0.3,
                "acc_stderr": 0.046056618647183814,
                "brier_score": 0.754253155280133,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.30638297872340425,
                "acc_stderr": 0.03013590647851756,
                "brier_score": 0.7425276218862534,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.29,
                "acc_stderr": 0.04560480215720683,
                "brier_score": 0.755635744034552,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.22,
                "acc_stderr": 0.0416333199893227,
                "brier_score": 0.7494321719105557,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_machine_learning": {
                "acc": 0.32142857142857145,
                "acc_stderr": 0.0443280405529152,
                "brier_score": 0.7430945873962429,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.270935960591133,
                "acc_stderr": 0.031270907132976984,
                "brier_score": 0.753668782444299,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.19444444444444445,
                "acc_stderr": 0.026991454502036726,
                "brier_score": 0.7804393461721738,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.2619047619047619,
                "acc_stderr": 0.022644212615525218,
                "brier_score": 0.7590777292193703,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.3448275862068966,
                "acc_stderr": 0.039609335494512087,
                "brier_score": 0.7334444866577424,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.25925925925925924,
                "acc_stderr": 0.02671924078371217,
                "brier_score": 0.757412220897825,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-46-36.775995"
            },
            "arc_challenge": {
                "acc": 0.36177474402730375,
                "acc_stderr": 0.014041957945038076,
                "acc_norm": 0.4087030716723549,
                "acc_norm_stderr": 0.014365750345427008,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "hellaswag": {
                "acc": 0.49611631149173474,
                "acc_stderr": 0.004989630887066199,
                "acc_norm": 0.6761601274646485,
                "acc_norm_stderr": 0.004669834130977053,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "truthfulqa_mc2": {
                "acc": 0.35957103209275876,
                "acc_stderr": 0.013461019906422903,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "truthfulqa_gen": {
                "bleu_max": 22.80807652676079,
                "bleu_max_stderr": 0.729394081143316,
                "bleu_acc": 0.2998776009791922,
                "bleu_acc_stderr": 0.01604035296671363,
                "bleu_diff": -7.044836167856834,
                "bleu_diff_stderr": 0.7649652886092126,
                "rouge1_max": 46.0394772961559,
                "rouge1_max_stderr": 0.8908991054603245,
                "rouge1_acc": 0.2558139534883721,
                "rouge1_acc_stderr": 0.01527417621928336,
                "rouge1_diff": -10.481586263318324,
                "rouge1_diff_stderr": 0.9003692764067813,
                "rouge2_max": 29.614709663039555,
                "rouge2_max_stderr": 0.9851662196235105,
                "rouge2_acc": 0.20318237454100369,
                "rouge2_acc_stderr": 0.014085666526340879,
                "rouge2_diff": -11.404292789473761,
                "rouge2_diff_stderr": 1.0230238475013214,
                "rougeL_max": 43.38528981216948,
                "rougeL_max_stderr": 0.8926391261722091,
                "rougeL_acc": 0.24357405140758873,
                "rougeL_acc_stderr": 0.01502635482491078,
                "rougeL_diff": -10.689938323819645,
                "rougeL_diff_stderr": 0.9132036865292477,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "truthfulqa_mc1": {
                "acc": 0.20195838433292534,
                "acc_stderr": 0.014053957441512346,
                "timestamp": "2024-11-22T19-43-59.503231"
            },
            "winogrande": {
                "acc": 0.6479873717442778,
                "acc_stderr": 0.013422874824929718,
                "timestamp": "2024-11-22T19-43-59.503231"
            }
        }
    }
}