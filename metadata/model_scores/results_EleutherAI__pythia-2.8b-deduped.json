{
    "model_name": "EleutherAI/pythia-2.8b-deduped",
    "last_updated": "2023-07-19",
    "results": {
        "harness": {
            "drop": {
                "3-shot": {
                    "acc": 0.0012583892617449664,
                    "acc_stderr": 0.00036305608931190916,
                    "f1": 0.0446549916107384,
                    "f1_stderr": 0.0011620582208289672,
                    "timestamp": "2023-10-22T02-23-42.600907"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.008339651250947688,
                    "acc_stderr": 0.002504942226860519,
                    "timestamp": "2023-10-22T02-23-42.600907"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.6022099447513812,
                    "acc_stderr": 0.013755743513749023,
                    "timestamp": "2023-10-22T02-23-42.600907"
                }
            },
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.32593856655290104,
                    "acc_stderr": 0.013697432466693244,
                    "acc_norm": 0.3626279863481229,
                    "acc_norm_stderr": 0.014049106564955014,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.45160326628161723,
                    "acc_stderr": 0.004966351835028203,
                    "acc_norm": 0.6065524795857399,
                    "acc_norm_stderr": 0.004875162699121662,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.27,
                    "acc_stderr": 0.044619604333847415,
                    "acc_norm": 0.27,
                    "acc_norm_stderr": 0.044619604333847415,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.2962962962962963,
                    "acc_stderr": 0.03944624162501117,
                    "acc_norm": 0.2962962962962963,
                    "acc_norm_stderr": 0.03944624162501117,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.20394736842105263,
                    "acc_stderr": 0.03279000406310051,
                    "acc_norm": 0.20394736842105263,
                    "acc_norm_stderr": 0.03279000406310051,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.22,
                    "acc_stderr": 0.04163331998932269,
                    "acc_norm": 0.22,
                    "acc_norm_stderr": 0.04163331998932269,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.2679245283018868,
                    "acc_stderr": 0.027257260322494845,
                    "acc_norm": 0.2679245283018868,
                    "acc_norm_stderr": 0.027257260322494845,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.2361111111111111,
                    "acc_stderr": 0.03551446610810826,
                    "acc_norm": 0.2361111111111111,
                    "acc_norm_stderr": 0.03551446610810826,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.24,
                    "acc_stderr": 0.042923469599092816,
                    "acc_norm": 0.24,
                    "acc_norm_stderr": 0.042923469599092816,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.23699421965317918,
                    "acc_stderr": 0.03242414757483099,
                    "acc_norm": 0.23699421965317918,
                    "acc_norm_stderr": 0.03242414757483099,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.14705882352941177,
                    "acc_stderr": 0.035240689515674474,
                    "acc_norm": 0.14705882352941177,
                    "acc_norm_stderr": 0.035240689515674474,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.28,
                    "acc_stderr": 0.04512608598542128,
                    "acc_norm": 0.28,
                    "acc_norm_stderr": 0.04512608598542128,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.28085106382978725,
                    "acc_stderr": 0.02937917046412483,
                    "acc_norm": 0.28085106382978725,
                    "acc_norm_stderr": 0.02937917046412483,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.21929824561403508,
                    "acc_stderr": 0.038924311065187546,
                    "acc_norm": 0.21929824561403508,
                    "acc_norm_stderr": 0.038924311065187546,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.27586206896551724,
                    "acc_stderr": 0.037245636197746325,
                    "acc_norm": 0.27586206896551724,
                    "acc_norm_stderr": 0.037245636197746325,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.26455026455026454,
                    "acc_stderr": 0.022717467897708614,
                    "acc_norm": 0.26455026455026454,
                    "acc_norm_stderr": 0.022717467897708614,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.2222222222222222,
                    "acc_stderr": 0.037184890068181146,
                    "acc_norm": 0.2222222222222222,
                    "acc_norm_stderr": 0.037184890068181146,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.047258156262526045,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.047258156262526045,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.24838709677419354,
                    "acc_stderr": 0.024580028921481,
                    "acc_norm": 0.24838709677419354,
                    "acc_norm_stderr": 0.024580028921481,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.2315270935960591,
                    "acc_stderr": 0.02967833314144444,
                    "acc_norm": 0.2315270935960591,
                    "acc_norm_stderr": 0.02967833314144444,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.23,
                    "acc_stderr": 0.04229525846816506,
                    "acc_norm": 0.23,
                    "acc_norm_stderr": 0.04229525846816506,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.28484848484848485,
                    "acc_stderr": 0.035243908445117836,
                    "acc_norm": 0.28484848484848485,
                    "acc_norm_stderr": 0.035243908445117836,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.2777777777777778,
                    "acc_stderr": 0.03191178226713548,
                    "acc_norm": 0.2777777777777778,
                    "acc_norm_stderr": 0.03191178226713548,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.2694300518134715,
                    "acc_stderr": 0.032018671228777947,
                    "acc_norm": 0.2694300518134715,
                    "acc_norm_stderr": 0.032018671228777947,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.32051282051282054,
                    "acc_stderr": 0.023661296393964273,
                    "acc_norm": 0.32051282051282054,
                    "acc_norm_stderr": 0.023661296393964273,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.26296296296296295,
                    "acc_stderr": 0.02684205787383371,
                    "acc_norm": 0.26296296296296295,
                    "acc_norm_stderr": 0.02684205787383371,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.24789915966386555,
                    "acc_stderr": 0.028047967224176892,
                    "acc_norm": 0.24789915966386555,
                    "acc_norm_stderr": 0.028047967224176892,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.31788079470198677,
                    "acc_stderr": 0.038020397601079024,
                    "acc_norm": 0.31788079470198677,
                    "acc_norm_stderr": 0.038020397601079024,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.23302752293577983,
                    "acc_stderr": 0.018125669180861503,
                    "acc_norm": 0.23302752293577983,
                    "acc_norm_stderr": 0.018125669180861503,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.44907407407407407,
                    "acc_stderr": 0.03392238405321617,
                    "acc_norm": 0.44907407407407407,
                    "acc_norm_stderr": 0.03392238405321617,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.21568627450980393,
                    "acc_stderr": 0.028867431449849316,
                    "acc_norm": 0.21568627450980393,
                    "acc_norm_stderr": 0.028867431449849316,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.2320675105485232,
                    "acc_stderr": 0.02747974455080852,
                    "acc_norm": 0.2320675105485232,
                    "acc_norm_stderr": 0.02747974455080852,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.34977578475336324,
                    "acc_stderr": 0.03200736719484503,
                    "acc_norm": 0.34977578475336324,
                    "acc_norm_stderr": 0.03200736719484503,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.22900763358778625,
                    "acc_stderr": 0.036853466317118506,
                    "acc_norm": 0.22900763358778625,
                    "acc_norm_stderr": 0.036853466317118506,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.34710743801652894,
                    "acc_stderr": 0.04345724570292534,
                    "acc_norm": 0.34710743801652894,
                    "acc_norm_stderr": 0.04345724570292534,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.23148148148148148,
                    "acc_stderr": 0.04077494709252627,
                    "acc_norm": 0.23148148148148148,
                    "acc_norm_stderr": 0.04077494709252627,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.26993865030674846,
                    "acc_stderr": 0.034878251684978906,
                    "acc_norm": 0.26993865030674846,
                    "acc_norm_stderr": 0.034878251684978906,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.26785714285714285,
                    "acc_stderr": 0.04203277291467763,
                    "acc_norm": 0.26785714285714285,
                    "acc_norm_stderr": 0.04203277291467763,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.23300970873786409,
                    "acc_stderr": 0.041858325989283136,
                    "acc_norm": 0.23300970873786409,
                    "acc_norm_stderr": 0.041858325989283136,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.24358974358974358,
                    "acc_stderr": 0.02812096650391439,
                    "acc_norm": 0.24358974358974358,
                    "acc_norm_stderr": 0.02812096650391439,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.24,
                    "acc_stderr": 0.04292346959909282,
                    "acc_norm": 0.24,
                    "acc_norm_stderr": 0.04292346959909282,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.280970625798212,
                    "acc_stderr": 0.016073127851221246,
                    "acc_norm": 0.280970625798212,
                    "acc_norm_stderr": 0.016073127851221246,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.2861271676300578,
                    "acc_stderr": 0.02433214677913413,
                    "acc_norm": 0.2861271676300578,
                    "acc_norm_stderr": 0.02433214677913413,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.22569832402234638,
                    "acc_stderr": 0.013981395058455054,
                    "acc_norm": 0.22569832402234638,
                    "acc_norm_stderr": 0.013981395058455054,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.2647058823529412,
                    "acc_stderr": 0.025261691219729494,
                    "acc_norm": 0.2647058823529412,
                    "acc_norm_stderr": 0.025261691219729494,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.2765273311897106,
                    "acc_stderr": 0.02540383297817962,
                    "acc_norm": 0.2765273311897106,
                    "acc_norm_stderr": 0.02540383297817962,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.2777777777777778,
                    "acc_stderr": 0.024922001168886338,
                    "acc_norm": 0.2777777777777778,
                    "acc_norm_stderr": 0.024922001168886338,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.2553191489361702,
                    "acc_stderr": 0.02601199293090202,
                    "acc_norm": 0.2553191489361702,
                    "acc_norm_stderr": 0.02601199293090202,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.258148631029987,
                    "acc_stderr": 0.011176923719313394,
                    "acc_norm": 0.258148631029987,
                    "acc_norm_stderr": 0.011176923719313394,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.4338235294117647,
                    "acc_stderr": 0.030105636570016647,
                    "acc_norm": 0.4338235294117647,
                    "acc_norm_stderr": 0.030105636570016647,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.27450980392156865,
                    "acc_stderr": 0.018054027458815198,
                    "acc_norm": 0.27450980392156865,
                    "acc_norm_stderr": 0.018054027458815198,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.35454545454545455,
                    "acc_stderr": 0.04582004841505417,
                    "acc_norm": 0.35454545454545455,
                    "acc_norm_stderr": 0.04582004841505417,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.19591836734693877,
                    "acc_stderr": 0.02540930195322568,
                    "acc_norm": 0.19591836734693877,
                    "acc_norm_stderr": 0.02540930195322568,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.2537313432835821,
                    "acc_stderr": 0.03076944496729602,
                    "acc_norm": 0.2537313432835821,
                    "acc_norm_stderr": 0.03076944496729602,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.2,
                    "acc_stderr": 0.040201512610368445,
                    "acc_norm": 0.2,
                    "acc_norm_stderr": 0.040201512610368445,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.3072289156626506,
                    "acc_stderr": 0.035915667978246635,
                    "acc_norm": 0.3072289156626506,
                    "acc_norm_stderr": 0.035915667978246635,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.2982456140350877,
                    "acc_stderr": 0.03508771929824565,
                    "acc_norm": 0.2982456140350877,
                    "acc_norm_stderr": 0.03508771929824565,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.2141982864137087,
                    "mc1_stderr": 0.014362148155690466,
                    "mc2": 0.3555978234501585,
                    "mc2_stderr": 0.01359490561334657,
                    "timestamp": "2023-07-19T17-26-01.712520"
                }
            }
        }
    }
}