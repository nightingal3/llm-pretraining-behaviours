{
    "model_name": "google__gemma-2-9b",
    "last_updated": "2024-12-04 11:23:42.690792",
    "results": {
        "harness": {
            "mmlu_world_religions": {
                "acc": 0.8654970760233918,
                "acc_stderr": 0.026168221344662294,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_formal_logic": {
                "acc": 0.49206349206349204,
                "acc_stderr": 0.044715725362943486,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_prehistory": {
                "acc": 0.808641975308642,
                "acc_stderr": 0.021887704613396168,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.35083798882681566,
                "acc_stderr": 0.015961036675230973,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.8649789029535865,
                "acc_stderr": 0.022245776632003694,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_moral_disputes": {
                "acc": 0.7832369942196532,
                "acc_stderr": 0.02218347766841285,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_professional_law": {
                "acc": 0.5449804432855281,
                "acc_stderr": 0.012718456618701785,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.8466257668711656,
                "acc_stderr": 0.0283116014414386,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.8970588235294118,
                "acc_stderr": 0.021328337570804365,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_philosophy": {
                "acc": 0.7717041800643086,
                "acc_stderr": 0.023839303311398212,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_jurisprudence": {
                "acc": 0.8240740740740741,
                "acc_stderr": 0.036809181416738786,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_international_law": {
                "acc": 0.8429752066115702,
                "acc_stderr": 0.03321244842547128,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.793939393939394,
                "acc_stderr": 0.031584153240477086,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.9533678756476683,
                "acc_stderr": 0.015216761819262585,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.8361344537815126,
                "acc_stderr": 0.02404405494044048,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_geography": {
                "acc": 0.8888888888888888,
                "acc_stderr": 0.02239078763821678,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.908256880733945,
                "acc_stderr": 0.012376323409137122,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_public_relations": {
                "acc": 0.7181818181818181,
                "acc_stderr": 0.043091187099464585,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.91,
                "acc_stderr": 0.028762349126466108,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_sociology": {
                "acc": 0.8706467661691543,
                "acc_stderr": 0.023729830881018515,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.782051282051282,
                "acc_stderr": 0.02093244577446318,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_security_studies": {
                "acc": 0.7551020408163265,
                "acc_stderr": 0.027529637440174927,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_professional_psychology": {
                "acc": 0.7908496732026143,
                "acc_stderr": 0.016453399332279323,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_human_sexuality": {
                "acc": 0.816793893129771,
                "acc_stderr": 0.033927709264947335,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_econometrics": {
                "acc": 0.5789473684210527,
                "acc_stderr": 0.04644602091222318,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_miscellaneous": {
                "acc": 0.8454661558109834,
                "acc_stderr": 0.012925773495095966,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_marketing": {
                "acc": 0.9230769230769231,
                "acc_stderr": 0.017456987872436183,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_management": {
                "acc": 0.8640776699029126,
                "acc_stderr": 0.0339329572976101,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_nutrition": {
                "acc": 0.761437908496732,
                "acc_stderr": 0.02440439492808787,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_medical_genetics": {
                "acc": 0.84,
                "acc_stderr": 0.03684529491774709,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_human_aging": {
                "acc": 0.7982062780269058,
                "acc_stderr": 0.026936111912802263,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_professional_medicine": {
                "acc": 0.7867647058823529,
                "acc_stderr": 0.024880971512294275,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_medicine": {
                "acc": 0.7167630057803468,
                "acc_stderr": 0.03435568056047873,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_business_ethics": {
                "acc": 0.74,
                "acc_stderr": 0.0440844002276808,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.7660377358490567,
                "acc_stderr": 0.02605529690115292,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_global_facts": {
                "acc": 0.5,
                "acc_stderr": 0.050251890762960605,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_virology": {
                "acc": 0.536144578313253,
                "acc_stderr": 0.038823108508905954,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_professional_accounting": {
                "acc": 0.5177304964539007,
                "acc_stderr": 0.02980873964223777,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_physics": {
                "acc": 0.5294117647058824,
                "acc_stderr": 0.04966570903978529,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_physics": {
                "acc": 0.4966887417218543,
                "acc_stderr": 0.04082393379449654,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_biology": {
                "acc": 0.8870967741935484,
                "acc_stderr": 0.018003603325863645,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_biology": {
                "acc": 0.8888888888888888,
                "acc_stderr": 0.026280550932848094,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_anatomy": {
                "acc": 0.7407407407407407,
                "acc_stderr": 0.037857144650666544,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_chemistry": {
                "acc": 0.5,
                "acc_stderr": 0.050251890762960605,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_computer_security": {
                "acc": 0.78,
                "acc_stderr": 0.04163331998932263,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_computer_science": {
                "acc": 0.52,
                "acc_stderr": 0.050211673156867795,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_astronomy": {
                "acc": 0.8092105263157895,
                "acc_stderr": 0.031975658210325,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_college_mathematics": {
                "acc": 0.44,
                "acc_stderr": 0.049888765156985884,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.7531914893617021,
                "acc_stderr": 0.028185441301234102,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.41,
                "acc_stderr": 0.049431107042371025,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.74,
                "acc_stderr": 0.04408440022768078,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_machine_learning": {
                "acc": 0.5267857142857143,
                "acc_stderr": 0.047389751192741546,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.6748768472906403,
                "acc_stderr": 0.032957975663112704,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.6481481481481481,
                "acc_stderr": 0.032568505702936464,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.5634920634920635,
                "acc_stderr": 0.025542846817400502,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.7103448275862069,
                "acc_stderr": 0.03780019230438014,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.45555555555555555,
                "acc_stderr": 0.03036486250482443,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "arc_challenge": {
                "acc": 0.643344709897611,
                "acc_stderr": 0.013998056902620197,
                "acc_norm": 0.681740614334471,
                "acc_norm_stderr": 0.013611993916971455,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "hellaswag": {
                "acc": 0.635929097789285,
                "acc_stderr": 0.004801852881329775,
                "acc_norm": 0.8253335988846843,
                "acc_norm_stderr": 0.0037890554870031357,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "truthfulqa_mc2": {
                "acc": 0.4553219595410078,
                "acc_stderr": 0.014210628836236725,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "truthfulqa_gen": {
                "bleu_max": 33.48367702247776,
                "bleu_max_stderr": 0.8625505675030039,
                "bleu_acc": 0.43084455324357407,
                "bleu_acc_stderr": 0.017335272475332366,
                "bleu_diff": -0.19870857289763738,
                "bleu_diff_stderr": 1.0675737646404135,
                "rouge1_max": 59.115576049843746,
                "rouge1_max_stderr": 0.9001849627161471,
                "rouge1_acc": 0.41982864137086906,
                "rouge1_acc_stderr": 0.01727703030177577,
                "rouge1_diff": 0.3244784775406543,
                "rouge1_diff_stderr": 1.280521042715171,
                "rouge2_max": 44.49834625015418,
                "rouge2_max_stderr": 1.106551965177841,
                "rouge2_acc": 0.37454100367197063,
                "rouge2_acc_stderr": 0.01694353512840533,
                "rouge2_diff": -1.3262594872227933,
                "rouge2_diff_stderr": 1.471263187794327,
                "rougeL_max": 56.491514242375466,
                "rougeL_max_stderr": 0.9276044446810214,
                "rougeL_acc": 0.40514075887392903,
                "rougeL_acc_stderr": 0.017185611727753375,
                "rougeL_diff": -0.06522153220084319,
                "rougeL_diff_stderr": 1.2948177926334004,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "truthfulqa_mc1": {
                "acc": 0.3011015911872705,
                "acc_stderr": 0.016058999026100612,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "winogrande": {
                "acc": 0.7876874506708761,
                "acc_stderr": 0.011493384687249787,
                "timestamp": "2024-11-26T08-26-54.817297"
            },
            "gsm8k": {
                "exact_match": 0.6747536012130402,
                "exact_match_stderr": 0.012903904752543926,
                "timestamp": "2024-11-26T08-26-54.817297"
            }
        }
    }
}