{
    "model_name": "Qwen__Qwen2.5-32B",
    "last_updated": "2024-12-04 11:25:05.203085",
    "results": {
        "harness": {
            "mmlu_world_religions": {
                "acc": 0.9064327485380117,
                "acc_stderr": 0.02233599323116327,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_formal_logic": {
                "acc": 0.7222222222222222,
                "acc_stderr": 0.040061680838488774,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_prehistory": {
                "acc": 0.9135802469135802,
                "acc_stderr": 0.015634305710693557,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.7541899441340782,
                "acc_stderr": 0.014400296429225613,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.9240506329113924,
                "acc_stderr": 0.0172446332510657,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_moral_disputes": {
                "acc": 0.8439306358381503,
                "acc_stderr": 0.019539014685374036,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_professional_law": {
                "acc": 0.6492829204693612,
                "acc_stderr": 0.012187773370741518,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.8895705521472392,
                "acc_stderr": 0.024624937788941315,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.9362745098039216,
                "acc_stderr": 0.01714392165552496,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_philosophy": {
                "acc": 0.8778135048231511,
                "acc_stderr": 0.018600811252967916,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_jurisprudence": {
                "acc": 0.8425925925925926,
                "acc_stderr": 0.03520703990517965,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_international_law": {
                "acc": 0.9338842975206612,
                "acc_stderr": 0.022683403691723322,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.8787878787878788,
                "acc_stderr": 0.025485498373343223,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.9740932642487047,
                "acc_stderr": 0.011464523356953162,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.9453781512605042,
                "acc_stderr": 0.014760864893498496,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_geography": {
                "acc": 0.9444444444444444,
                "acc_stderr": 0.016319950700767395,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.9339449541284404,
                "acc_stderr": 0.010649131487858935,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_public_relations": {
                "acc": 0.7636363636363637,
                "acc_stderr": 0.04069306319721377,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.96,
                "acc_stderr": 0.019694638556693223,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_sociology": {
                "acc": 0.9104477611940298,
                "acc_stderr": 0.02019067053502794,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.8769230769230769,
                "acc_stderr": 0.016656903282068206,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_security_studies": {
                "acc": 0.8489795918367347,
                "acc_stderr": 0.022923004094736858,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_professional_psychology": {
                "acc": 0.8709150326797386,
                "acc_stderr": 0.01356454163404412,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_human_sexuality": {
                "acc": 0.9236641221374046,
                "acc_stderr": 0.023288939536173784,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_econometrics": {
                "acc": 0.7807017543859649,
                "acc_stderr": 0.038924311065187546,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_miscellaneous": {
                "acc": 0.9195402298850575,
                "acc_stderr": 0.009726831316141838,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_marketing": {
                "acc": 0.9145299145299145,
                "acc_stderr": 0.018315891685625838,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_management": {
                "acc": 0.883495145631068,
                "acc_stderr": 0.03176683948640407,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_nutrition": {
                "acc": 0.869281045751634,
                "acc_stderr": 0.01930187362421529,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_medical_genetics": {
                "acc": 0.91,
                "acc_stderr": 0.028762349126466153,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_human_aging": {
                "acc": 0.8161434977578476,
                "acc_stderr": 0.02599837909235651,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_professional_medicine": {
                "acc": 0.8970588235294118,
                "acc_stderr": 0.01845951895538869,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_medicine": {
                "acc": 0.8265895953757225,
                "acc_stderr": 0.028868107874970635,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_business_ethics": {
                "acc": 0.82,
                "acc_stderr": 0.03861229196653693,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.8754716981132076,
                "acc_stderr": 0.020321376630696202,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_global_facts": {
                "acc": 0.71,
                "acc_stderr": 0.045604802157206845,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_virology": {
                "acc": 0.572289156626506,
                "acc_stderr": 0.038515976837185335,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_professional_accounting": {
                "acc": 0.6843971631205674,
                "acc_stderr": 0.027724989449509314,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_physics": {
                "acc": 0.7450980392156863,
                "acc_stderr": 0.0433643270799318,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_physics": {
                "acc": 0.7615894039735099,
                "acc_stderr": 0.0347918557259966,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_biology": {
                "acc": 0.9516129032258065,
                "acc_stderr": 0.012207189992293643,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_biology": {
                "acc": 0.9375,
                "acc_stderr": 0.02024219611347799,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_anatomy": {
                "acc": 0.7851851851851852,
                "acc_stderr": 0.03547854198560824,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_chemistry": {
                "acc": 0.62,
                "acc_stderr": 0.04878317312145632,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_computer_security": {
                "acc": 0.86,
                "acc_stderr": 0.03487350880197771,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_computer_science": {
                "acc": 0.79,
                "acc_stderr": 0.040936018074033256,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_astronomy": {
                "acc": 0.9407894736842105,
                "acc_stderr": 0.019206897196800306,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_college_mathematics": {
                "acc": 0.74,
                "acc_stderr": 0.044084400227680794,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.902127659574468,
                "acc_stderr": 0.019424777705573392,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.72,
                "acc_stderr": 0.04512608598542127,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.94,
                "acc_stderr": 0.02386832565759419,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_machine_learning": {
                "acc": 0.7946428571428571,
                "acc_stderr": 0.03834241021419073,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.7684729064039408,
                "acc_stderr": 0.029678333141444444,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.8518518518518519,
                "acc_stderr": 0.02422762927372837,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.9021164021164021,
                "acc_stderr": 0.015304374225091419,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.8206896551724138,
                "acc_stderr": 0.03196766433373187,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.6518518518518519,
                "acc_stderr": 0.029045600290616255,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "arc_challenge": {
                "acc": 0.6621160409556314,
                "acc_stderr": 0.01382204792228352,
                "acc_norm": 0.6911262798634812,
                "acc_norm_stderr": 0.013501770929344003,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "hellaswag": {
                "acc": 0.6571400119498108,
                "acc_stderr": 0.004736950810617823,
                "acc_norm": 0.8515236008763195,
                "acc_norm_stderr": 0.003548449054286016,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "truthfulqa_mc2": {
                "acc": 0.5781834572377078,
                "acc_stderr": 0.014797004312646012,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "truthfulqa_gen": {
                "bleu_max": 6.969336348202127,
                "bleu_max_stderr": 0.5870541151739272,
                "bleu_acc": 0.13096695226438188,
                "bleu_acc_stderr": 0.011810109581712577,
                "bleu_diff": 0.6563244381841533,
                "bleu_diff_stderr": 0.422393788389518,
                "rouge1_max": 14.003241923004378,
                "rouge1_max_stderr": 0.9380420509133744,
                "rouge1_acc": 0.13953488372093023,
                "rouge1_acc_stderr": 0.01213006008958147,
                "rouge1_diff": 1.0093134943305602,
                "rouge1_diff_stderr": 0.5297814254859047,
                "rouge2_max": 10.188591447651278,
                "rouge2_max_stderr": 0.7985636803484863,
                "rouge2_acc": 0.11260709914320685,
                "rouge2_acc_stderr": 0.011066130337399355,
                "rouge2_diff": 0.6138278691566204,
                "rouge2_diff_stderr": 0.608593814594194,
                "rougeL_max": 13.156036427349836,
                "rougeL_max_stderr": 0.8996246678278078,
                "rougeL_acc": 0.13953488372093023,
                "rougeL_acc_stderr": 0.01213006008958147,
                "rougeL_diff": 0.9732115915170979,
                "rougeL_diff_stderr": 0.5279186710795332,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "truthfulqa_mc1": {
                "acc": 0.40024479804161567,
                "acc_stderr": 0.01715160555574914,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "winogrande": {
                "acc": 0.8184688239936859,
                "acc_stderr": 0.01083327651500751,
                "timestamp": "2024-11-28T06-58-27.057743"
            },
            "gsm8k": {
                "exact_match": 0.8976497346474602,
                "exact_match_stderr": 0.008349110996208827,
                "timestamp": "2024-11-28T06-58-27.057743"
            }
        }
    }
}