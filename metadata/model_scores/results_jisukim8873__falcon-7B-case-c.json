{
    "model_name": "jisukim8873/falcon-7B-case-c",
    "last_updated": "2024-06-25 14:38:24.668311",
    "results": {
        "harness": {
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.454778156996587,
                    "acc_stderr": 0.014551507060836353,
                    "acc_norm": 0.4854948805460751,
                    "acc_norm_stderr": 0.014605241081370056,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.5984863572993427,
                    "acc_stderr": 0.004892026457294713,
                    "acc_norm": 0.7866958773152758,
                    "acc_norm_stderr": 0.004088034745195346,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.046882617226215034,
                    "acc_norm": 0.32,
                    "acc_norm_stderr": 0.046882617226215034,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.2814814814814815,
                    "acc_stderr": 0.03885004245800254,
                    "acc_norm": 0.2814814814814815,
                    "acc_norm_stderr": 0.03885004245800254,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.24342105263157895,
                    "acc_stderr": 0.034923496688842384,
                    "acc_norm": 0.24342105263157895,
                    "acc_norm_stderr": 0.034923496688842384,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.2,
                    "acc_stderr": 0.04020151261036845,
                    "acc_norm": 0.2,
                    "acc_norm_stderr": 0.04020151261036845,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.2981132075471698,
                    "acc_stderr": 0.028152837942493854,
                    "acc_norm": 0.2981132075471698,
                    "acc_norm_stderr": 0.028152837942493854,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.2708333333333333,
                    "acc_stderr": 0.03716177437566017,
                    "acc_norm": 0.2708333333333333,
                    "acc_norm_stderr": 0.03716177437566017,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.19,
                    "acc_stderr": 0.03942772444036624,
                    "acc_norm": 0.19,
                    "acc_norm_stderr": 0.03942772444036624,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.046882617226215034,
                    "acc_norm": 0.32,
                    "acc_norm_stderr": 0.046882617226215034,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.27,
                    "acc_stderr": 0.044619604333847394,
                    "acc_norm": 0.27,
                    "acc_norm_stderr": 0.044619604333847394,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.3179190751445087,
                    "acc_stderr": 0.03550683989165582,
                    "acc_norm": 0.3179190751445087,
                    "acc_norm_stderr": 0.03550683989165582,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.20588235294117646,
                    "acc_stderr": 0.04023382273617749,
                    "acc_norm": 0.20588235294117646,
                    "acc_norm_stderr": 0.04023382273617749,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.04725815626252605,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.04725815626252605,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.32340425531914896,
                    "acc_stderr": 0.030579442773610334,
                    "acc_norm": 0.32340425531914896,
                    "acc_norm_stderr": 0.030579442773610334,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.2719298245614035,
                    "acc_stderr": 0.04185774424022056,
                    "acc_norm": 0.2719298245614035,
                    "acc_norm_stderr": 0.04185774424022056,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.2413793103448276,
                    "acc_stderr": 0.03565998174135302,
                    "acc_norm": 0.2413793103448276,
                    "acc_norm_stderr": 0.03565998174135302,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.2698412698412698,
                    "acc_stderr": 0.02286083830923207,
                    "acc_norm": 0.2698412698412698,
                    "acc_norm_stderr": 0.02286083830923207,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.18253968253968253,
                    "acc_stderr": 0.034550710191021496,
                    "acc_norm": 0.18253968253968253,
                    "acc_norm_stderr": 0.034550710191021496,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.31290322580645163,
                    "acc_stderr": 0.02637756702864586,
                    "acc_norm": 0.31290322580645163,
                    "acc_norm_stderr": 0.02637756702864586,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.29064039408866993,
                    "acc_stderr": 0.03194740072265541,
                    "acc_norm": 0.29064039408866993,
                    "acc_norm_stderr": 0.03194740072265541,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.36,
                    "acc_stderr": 0.04824181513244218,
                    "acc_norm": 0.36,
                    "acc_norm_stderr": 0.04824181513244218,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.32727272727272727,
                    "acc_stderr": 0.03663974994391242,
                    "acc_norm": 0.32727272727272727,
                    "acc_norm_stderr": 0.03663974994391242,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.29292929292929293,
                    "acc_stderr": 0.032424979581788166,
                    "acc_norm": 0.29292929292929293,
                    "acc_norm_stderr": 0.032424979581788166,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.31088082901554404,
                    "acc_stderr": 0.03340361906276585,
                    "acc_norm": 0.31088082901554404,
                    "acc_norm_stderr": 0.03340361906276585,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.26666666666666666,
                    "acc_stderr": 0.022421273612923714,
                    "acc_norm": 0.26666666666666666,
                    "acc_norm_stderr": 0.022421273612923714,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.25925925925925924,
                    "acc_stderr": 0.026719240783712166,
                    "acc_norm": 0.25925925925925924,
                    "acc_norm_stderr": 0.026719240783712166,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.2815126050420168,
                    "acc_stderr": 0.029213549414372177,
                    "acc_norm": 0.2815126050420168,
                    "acc_norm_stderr": 0.029213549414372177,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.304635761589404,
                    "acc_stderr": 0.03757949922943342,
                    "acc_norm": 0.304635761589404,
                    "acc_norm_stderr": 0.03757949922943342,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.26788990825688075,
                    "acc_stderr": 0.018987462257978652,
                    "acc_norm": 0.26788990825688075,
                    "acc_norm_stderr": 0.018987462257978652,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.20833333333333334,
                    "acc_stderr": 0.02769691071309394,
                    "acc_norm": 0.20833333333333334,
                    "acc_norm_stderr": 0.02769691071309394,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.27450980392156865,
                    "acc_stderr": 0.0313217980308329,
                    "acc_norm": 0.27450980392156865,
                    "acc_norm_stderr": 0.0313217980308329,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.3459915611814346,
                    "acc_stderr": 0.03096481058878671,
                    "acc_norm": 0.3459915611814346,
                    "acc_norm_stderr": 0.03096481058878671,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.29596412556053814,
                    "acc_stderr": 0.030636591348699803,
                    "acc_norm": 0.29596412556053814,
                    "acc_norm_stderr": 0.030636591348699803,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.1984732824427481,
                    "acc_stderr": 0.03498149385462472,
                    "acc_norm": 0.1984732824427481,
                    "acc_norm_stderr": 0.03498149385462472,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.32231404958677684,
                    "acc_stderr": 0.042664163633521664,
                    "acc_norm": 0.32231404958677684,
                    "acc_norm_stderr": 0.042664163633521664,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.32407407407407407,
                    "acc_stderr": 0.04524596007030049,
                    "acc_norm": 0.32407407407407407,
                    "acc_norm_stderr": 0.04524596007030049,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.31901840490797545,
                    "acc_stderr": 0.03661997551073836,
                    "acc_norm": 0.31901840490797545,
                    "acc_norm_stderr": 0.03661997551073836,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.29464285714285715,
                    "acc_stderr": 0.0432704093257873,
                    "acc_norm": 0.29464285714285715,
                    "acc_norm_stderr": 0.0432704093257873,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.2524271844660194,
                    "acc_stderr": 0.04301250399690878,
                    "acc_norm": 0.2524271844660194,
                    "acc_norm_stderr": 0.04301250399690878,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.3034188034188034,
                    "acc_stderr": 0.03011821010694262,
                    "acc_norm": 0.3034188034188034,
                    "acc_norm_stderr": 0.03011821010694262,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.29,
                    "acc_stderr": 0.045604802157206824,
                    "acc_norm": 0.29,
                    "acc_norm_stderr": 0.045604802157206824,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.38058748403575987,
                    "acc_stderr": 0.017362564126075425,
                    "acc_norm": 0.38058748403575987,
                    "acc_norm_stderr": 0.017362564126075425,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.33815028901734107,
                    "acc_stderr": 0.02546977014940018,
                    "acc_norm": 0.33815028901734107,
                    "acc_norm_stderr": 0.02546977014940018,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.2569832402234637,
                    "acc_stderr": 0.01461446582196632,
                    "acc_norm": 0.2569832402234637,
                    "acc_norm_stderr": 0.01461446582196632,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.28431372549019607,
                    "acc_stderr": 0.025829163272757468,
                    "acc_norm": 0.28431372549019607,
                    "acc_norm_stderr": 0.025829163272757468,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.3536977491961415,
                    "acc_stderr": 0.027155208103200875,
                    "acc_norm": 0.3536977491961415,
                    "acc_norm_stderr": 0.027155208103200875,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.30864197530864196,
                    "acc_stderr": 0.025702640260603746,
                    "acc_norm": 0.30864197530864196,
                    "acc_norm_stderr": 0.025702640260603746,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.2553191489361702,
                    "acc_stderr": 0.026011992930902,
                    "acc_norm": 0.2553191489361702,
                    "acc_norm_stderr": 0.026011992930902,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.2737940026075619,
                    "acc_stderr": 0.0113886121679794,
                    "acc_norm": 0.2737940026075619,
                    "acc_norm_stderr": 0.0113886121679794,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.1948529411764706,
                    "acc_stderr": 0.024060599423487414,
                    "acc_norm": 0.1948529411764706,
                    "acc_norm_stderr": 0.024060599423487414,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.28594771241830064,
                    "acc_stderr": 0.01828048507295468,
                    "acc_norm": 0.28594771241830064,
                    "acc_norm_stderr": 0.01828048507295468,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.23636363636363636,
                    "acc_stderr": 0.040693063197213775,
                    "acc_norm": 0.23636363636363636,
                    "acc_norm_stderr": 0.040693063197213775,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.22448979591836735,
                    "acc_stderr": 0.026711430555538408,
                    "acc_norm": 0.22448979591836735,
                    "acc_norm_stderr": 0.026711430555538408,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.29850746268656714,
                    "acc_stderr": 0.03235743789355043,
                    "acc_norm": 0.29850746268656714,
                    "acc_norm_stderr": 0.03235743789355043,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.41,
                    "acc_stderr": 0.04943110704237102,
                    "acc_norm": 0.41,
                    "acc_norm_stderr": 0.04943110704237102,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.35542168674698793,
                    "acc_stderr": 0.03726214354322415,
                    "acc_norm": 0.35542168674698793,
                    "acc_norm_stderr": 0.03726214354322415,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.3742690058479532,
                    "acc_stderr": 0.03711601185389481,
                    "acc_norm": 0.3742690058479532,
                    "acc_norm_stderr": 0.03711601185389481,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.2668298653610771,
                    "mc1_stderr": 0.01548369193923727,
                    "mc2": 0.3826492372963991,
                    "mc2_stderr": 0.014401921891655947,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7008681925808997,
                    "acc_stderr": 0.012868639066091536,
                    "timestamp": "2024-03-07T11-30-30.635454"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.07354056103108415,
                    "acc_stderr": 0.007189835754365258,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_precalc": {
                "5-shot": {
                    "acc": 0.01282051282051282,
                    "acc_stderr": 0.004818950982487619,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_prealgebra": {
                "5-shot": {
                    "acc": 0.018369690011481057,
                    "acc_stderr": 0.004552660520674617,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_num_theory": {
                "5-shot": {
                    "acc": 0.012962962962962963,
                    "acc_stderr": 0.004872192984581488,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_intermediate_algebra": {
                "5-shot": {
                    "acc": 0.017718715393133997,
                    "acc_stderr": 0.0043926922934928924,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_geometry": {
                "5-shot": {
                    "acc": 0.012526096033402923,
                    "acc_stderr": 0.00508694138967796,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_counting_and_prob": {
                "5-shot": {
                    "acc": 0.012658227848101266,
                    "acc_stderr": 0.005140313889578845,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "minerva_math_algebra": {
                "5-shot": {
                    "acc": 0.014321819713563605,
                    "acc_stderr": 0.0034500415709370234,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "fld_default": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "fld_star": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_3da": {
                "5-shot": {
                    "acc": 0.2725,
                    "acc_stderr": 0.009958486869518226,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_3ds": {
                "5-shot": {
                    "acc": 0.468,
                    "acc_stderr": 0.011160209457602885,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_4da": {
                "5-shot": {
                    "acc": 0.029,
                    "acc_stderr": 0.0037532044004605267,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_2ds": {
                "5-shot": {
                    "acc": 0.4425,
                    "acc_stderr": 0.011108941411747607,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_5ds": {
                "5-shot": {
                    "acc": 0.0885,
                    "acc_stderr": 0.006352483925679359,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_5da": {
                "5-shot": {
                    "acc": 0.012,
                    "acc_stderr": 0.002435357362429837,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_1dc": {
                "5-shot": {
                    "acc": 0.0725,
                    "acc_stderr": 0.0057998874426297645,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_4ds": {
                "5-shot": {
                    "acc": 0.122,
                    "acc_stderr": 0.007320163413216715,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_2dm": {
                "5-shot": {
                    "acc": 0.1895,
                    "acc_stderr": 0.008765460150261466,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "arithmetic_2da": {
                "5-shot": {
                    "acc": 0.768,
                    "acc_stderr": 0.009441004516636096,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "gsm8k_cot": {
                "5-shot": {
                    "acc": 0.10765731614859743,
                    "acc_stderr": 0.008537484003023345,
                    "timestamp": "2024-06-07T12-08-31.352830"
                }
            },
            "anli_r2": {
                "0-shot": {
                    "brier_score": 0.8780178026204086,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "anli_r3": {
                "0-shot": {
                    "brier_score": 0.7901916928644884,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "anli_r1": {
                "0-shot": {
                    "brier_score": 0.9055919262241393,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_eu": {
                "0-shot": {
                    "brier_score": 1.001290310490029,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_vi": {
                "0-shot": {
                    "brier_score": 0.9798397634266888,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_ru": {
                "0-shot": {
                    "brier_score": 0.859574174744215,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_zh": {
                "0-shot": {
                    "brier_score": 0.894488082940237,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_tr": {
                "0-shot": {
                    "brier_score": 0.9948912466030565,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_fr": {
                "0-shot": {
                    "brier_score": 0.7337998938941023,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_en": {
                "0-shot": {
                    "brier_score": 0.6616939089924683,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_ur": {
                "0-shot": {
                    "brier_score": 1.3066034233367336,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_ar": {
                "0-shot": {
                    "brier_score": 1.2889195153240864,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_de": {
                "0-shot": {
                    "brier_score": 0.8343456649143227,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_hi": {
                "0-shot": {
                    "brier_score": 1.077691017146163,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_es": {
                "0-shot": {
                    "brier_score": 0.811152479987488,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_bg": {
                "0-shot": {
                    "brier_score": 0.9276588116275865,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_sw": {
                "0-shot": {
                    "brier_score": 1.0923473059839404,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_el": {
                "0-shot": {
                    "brier_score": 1.0102156151166493,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "xnli_th": {
                "0-shot": {
                    "brier_score": 0.9468478602772348,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "logiqa2": {
                "0-shot": {
                    "brier_score": 1.0599129907264795,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "mathqa": {
                "5-shot": {
                    "brier_score": 0.9539448440856261,
                    "timestamp": "2024-06-07T12-19-46.628409"
                }
            },
            "lambada_standard": {
                "0-shot": {
                    "perplexity": 4.013535326746964,
                    "perplexity_stderr": 0.08617064416280937,
                    "acc": 0.6790219289734135,
                    "acc_stderr": 0.006504166559764691,
                    "timestamp": "2024-06-07T12-21-08.837227"
                }
            },
            "lambada_openai": {
                "0-shot": {
                    "perplexity": 3.2959199182547474,
                    "perplexity_stderr": 0.06892248167777122,
                    "acc": 0.7376285658839511,
                    "acc_stderr": 0.006128994208430875,
                    "timestamp": "2024-06-07T12-21-08.837227"
                }
            }
        }
    }
}