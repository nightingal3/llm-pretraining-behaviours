{
    "model_name": "mosaicml/mpt-7b",
    "last_updated": "2023-08-22",
    "results": {
        "harness": {
            "drop": {
                "3-shot": {
                    "em": 0.0006291946308724832,
                    "em_stderr": 0.0002568002749724036,
                    "f1": 0.055483431208053824,
                    "f1_stderr": 0.0012896726370180557,
                    "timestamp": "2023-09-23T17-09-43.658606"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.0401819560272934,
                    "acc_stderr": 0.005409439736970527,
                    "timestamp": "2023-09-23T17-09-43.658606"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7213891081294396,
                    "acc_stderr": 0.012599896649493876,
                    "timestamp": "2023-09-23T17-09-43.658606"
                }
            },
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.42918088737201365,
                    "acc_stderr": 0.014464085894870653,
                    "acc_norm": 0.47696245733788395,
                    "acc_norm_stderr": 0.014595873205358269,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.5730930093606851,
                    "acc_stderr": 0.004936176784631949,
                    "acc_norm": 0.7753435570603465,
                    "acc_norm_stderr": 0.0041650291643616005,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.19,
                    "acc_stderr": 0.03942772444036624,
                    "acc_norm": 0.19,
                    "acc_norm_stderr": 0.03942772444036624,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.2222222222222222,
                    "acc_stderr": 0.035914440841969694,
                    "acc_norm": 0.2222222222222222,
                    "acc_norm_stderr": 0.035914440841969694,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.2631578947368421,
                    "acc_stderr": 0.03583496176361062,
                    "acc_norm": 0.2631578947368421,
                    "acc_norm_stderr": 0.03583496176361062,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.04725815626252604,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.04725815626252604,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.28679245283018867,
                    "acc_stderr": 0.027834912527544067,
                    "acc_norm": 0.28679245283018867,
                    "acc_norm_stderr": 0.027834912527544067,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.2847222222222222,
                    "acc_stderr": 0.03773809990686935,
                    "acc_norm": 0.2847222222222222,
                    "acc_norm_stderr": 0.03773809990686935,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.25,
                    "acc_stderr": 0.04351941398892446,
                    "acc_norm": 0.25,
                    "acc_norm_stderr": 0.04351941398892446,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.046882617226215034,
                    "acc_norm": 0.32,
                    "acc_norm_stderr": 0.046882617226215034,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.2658959537572254,
                    "acc_stderr": 0.033687629322594295,
                    "acc_norm": 0.2658959537572254,
                    "acc_norm_stderr": 0.033687629322594295,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.20588235294117646,
                    "acc_stderr": 0.04023382273617747,
                    "acc_norm": 0.20588235294117646,
                    "acc_norm_stderr": 0.04023382273617747,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.29,
                    "acc_stderr": 0.045604802157206845,
                    "acc_norm": 0.29,
                    "acc_norm_stderr": 0.045604802157206845,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.3404255319148936,
                    "acc_stderr": 0.03097669299853442,
                    "acc_norm": 0.3404255319148936,
                    "acc_norm_stderr": 0.03097669299853442,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.2894736842105263,
                    "acc_stderr": 0.04266339443159394,
                    "acc_norm": 0.2894736842105263,
                    "acc_norm_stderr": 0.04266339443159394,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.2620689655172414,
                    "acc_stderr": 0.036646663372252565,
                    "acc_norm": 0.2620689655172414,
                    "acc_norm_stderr": 0.036646663372252565,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.23809523809523808,
                    "acc_stderr": 0.021935878081184763,
                    "acc_norm": 0.23809523809523808,
                    "acc_norm_stderr": 0.021935878081184763,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.23015873015873015,
                    "acc_stderr": 0.03764950879790605,
                    "acc_norm": 0.23015873015873015,
                    "acc_norm_stderr": 0.03764950879790605,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.23,
                    "acc_stderr": 0.04229525846816505,
                    "acc_norm": 0.23,
                    "acc_norm_stderr": 0.04229525846816505,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.25161290322580643,
                    "acc_stderr": 0.024685979286239952,
                    "acc_norm": 0.25161290322580643,
                    "acc_norm_stderr": 0.024685979286239952,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.20689655172413793,
                    "acc_stderr": 0.02850137816789395,
                    "acc_norm": 0.20689655172413793,
                    "acc_norm_stderr": 0.02850137816789395,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.04725815626252606,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.04725815626252606,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.24242424242424243,
                    "acc_stderr": 0.033464098810559534,
                    "acc_norm": 0.24242424242424243,
                    "acc_norm_stderr": 0.033464098810559534,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.2222222222222222,
                    "acc_stderr": 0.02962022787479047,
                    "acc_norm": 0.2222222222222222,
                    "acc_norm_stderr": 0.02962022787479047,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.35751295336787564,
                    "acc_stderr": 0.03458816042181006,
                    "acc_norm": 0.35751295336787564,
                    "acc_norm_stderr": 0.03458816042181006,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.32051282051282054,
                    "acc_stderr": 0.02366129639396427,
                    "acc_norm": 0.32051282051282054,
                    "acc_norm_stderr": 0.02366129639396427,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.2851851851851852,
                    "acc_stderr": 0.027528599210340496,
                    "acc_norm": 0.2851851851851852,
                    "acc_norm_stderr": 0.027528599210340496,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.28991596638655465,
                    "acc_stderr": 0.029472485833136098,
                    "acc_norm": 0.28991596638655465,
                    "acc_norm_stderr": 0.029472485833136098,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.26490066225165565,
                    "acc_stderr": 0.03603038545360384,
                    "acc_norm": 0.26490066225165565,
                    "acc_norm_stderr": 0.03603038545360384,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.26055045871559634,
                    "acc_stderr": 0.018819182034850068,
                    "acc_norm": 0.26055045871559634,
                    "acc_norm_stderr": 0.018819182034850068,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.3055555555555556,
                    "acc_stderr": 0.03141554629402544,
                    "acc_norm": 0.3055555555555556,
                    "acc_norm_stderr": 0.03141554629402544,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.2549019607843137,
                    "acc_stderr": 0.030587591351604257,
                    "acc_norm": 0.2549019607843137,
                    "acc_norm_stderr": 0.030587591351604257,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.270042194092827,
                    "acc_stderr": 0.028900721906293426,
                    "acc_norm": 0.270042194092827,
                    "acc_norm_stderr": 0.028900721906293426,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.3094170403587444,
                    "acc_stderr": 0.031024411740572203,
                    "acc_norm": 0.3094170403587444,
                    "acc_norm_stderr": 0.031024411740572203,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.29770992366412213,
                    "acc_stderr": 0.04010358942462203,
                    "acc_norm": 0.29770992366412213,
                    "acc_norm_stderr": 0.04010358942462203,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.2975206611570248,
                    "acc_stderr": 0.04173349148083498,
                    "acc_norm": 0.2975206611570248,
                    "acc_norm_stderr": 0.04173349148083498,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.2962962962962963,
                    "acc_stderr": 0.044143436668549335,
                    "acc_norm": 0.2962962962962963,
                    "acc_norm_stderr": 0.044143436668549335,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.25153374233128833,
                    "acc_stderr": 0.034089978868575295,
                    "acc_norm": 0.25153374233128833,
                    "acc_norm_stderr": 0.034089978868575295,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.36607142857142855,
                    "acc_stderr": 0.0457237235873743,
                    "acc_norm": 0.36607142857142855,
                    "acc_norm_stderr": 0.0457237235873743,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.23300970873786409,
                    "acc_stderr": 0.041858325989283136,
                    "acc_norm": 0.23300970873786409,
                    "acc_norm_stderr": 0.041858325989283136,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.32051282051282054,
                    "acc_stderr": 0.03057281131029961,
                    "acc_norm": 0.32051282051282054,
                    "acc_norm_stderr": 0.03057281131029961,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.35,
                    "acc_stderr": 0.047937248544110196,
                    "acc_norm": 0.35,
                    "acc_norm_stderr": 0.047937248544110196,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.3001277139208174,
                    "acc_stderr": 0.016389249691317425,
                    "acc_norm": 0.3001277139208174,
                    "acc_norm_stderr": 0.016389249691317425,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.2630057803468208,
                    "acc_stderr": 0.023703099525258172,
                    "acc_norm": 0.2630057803468208,
                    "acc_norm_stderr": 0.023703099525258172,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.2446927374301676,
                    "acc_stderr": 0.014378169884098423,
                    "acc_norm": 0.2446927374301676,
                    "acc_norm_stderr": 0.014378169884098423,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.28104575163398693,
                    "acc_stderr": 0.025738854797818726,
                    "acc_norm": 0.28104575163398693,
                    "acc_norm_stderr": 0.025738854797818726,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.2990353697749196,
                    "acc_stderr": 0.02600330111788513,
                    "acc_norm": 0.2990353697749196,
                    "acc_norm_stderr": 0.02600330111788513,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.32098765432098764,
                    "acc_stderr": 0.025976566010862737,
                    "acc_norm": 0.32098765432098764,
                    "acc_norm_stderr": 0.025976566010862737,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.24822695035460993,
                    "acc_stderr": 0.025770015644290392,
                    "acc_norm": 0.24822695035460993,
                    "acc_norm_stderr": 0.025770015644290392,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.2607561929595828,
                    "acc_stderr": 0.011213471559602325,
                    "acc_norm": 0.2607561929595828,
                    "acc_norm_stderr": 0.011213471559602325,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.1948529411764706,
                    "acc_stderr": 0.024060599423487414,
                    "acc_norm": 0.1948529411764706,
                    "acc_norm_stderr": 0.024060599423487414,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.25980392156862747,
                    "acc_stderr": 0.017740899509177788,
                    "acc_norm": 0.25980392156862747,
                    "acc_norm_stderr": 0.017740899509177788,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.33636363636363636,
                    "acc_stderr": 0.04525393596302505,
                    "acc_norm": 0.33636363636363636,
                    "acc_norm_stderr": 0.04525393596302505,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.3020408163265306,
                    "acc_stderr": 0.029393609319879818,
                    "acc_norm": 0.3020408163265306,
                    "acc_norm_stderr": 0.029393609319879818,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.23383084577114427,
                    "acc_stderr": 0.029929415408348384,
                    "acc_norm": 0.23383084577114427,
                    "acc_norm_stderr": 0.029929415408348384,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.4,
                    "acc_stderr": 0.04923659639173309,
                    "acc_norm": 0.4,
                    "acc_norm_stderr": 0.04923659639173309,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.3493975903614458,
                    "acc_stderr": 0.03711725190740749,
                    "acc_norm": 0.3493975903614458,
                    "acc_norm_stderr": 0.03711725190740749,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.3216374269005848,
                    "acc_stderr": 0.03582529442573122,
                    "acc_norm": 0.3216374269005848,
                    "acc_norm_stderr": 0.03582529442573122,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.20563035495716034,
                    "mc1_stderr": 0.014148482219460974,
                    "mc2": 0.3354506043570123,
                    "mc2_stderr": 0.013110323313593984,
                    "timestamp": "2023-10-03T22-10-31.153532"
                }
            }
        }
    }
}