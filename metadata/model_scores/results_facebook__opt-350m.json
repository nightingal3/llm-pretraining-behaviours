{
    "model_name": "facebook/opt-350m",
    "last_updated": "2024-12-19 13:41:43.373740",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.003663003663003663,
                "exact_match_stderr": 0.0025877573681934458,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.021814006888633754,
                "exact_match_stderr": 0.00495243536887352,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.0033222591362126247,
                "exact_match_stderr": 0.0019159795218657448,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_geometry": {
                "exact_match": 0.0020876826722338203,
                "exact_match_stderr": 0.0020876826722338315,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.002109704641350211,
                "exact_match_stderr": 0.0021097046413502104,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "minerva_math_algebra": {
                "exact_match": 0.015164279696714406,
                "exact_match_stderr": 0.0035485460431325393,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_3da": {
                "acc": 0.001,
                "acc_stderr": 0.0007069298939339458,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_3ds": {
                "acc": 0.0015,
                "acc_stderr": 0.0008655920660521539,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_4da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_2ds": {
                "acc": 0.0095,
                "acc_stderr": 0.00216961485391003,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_5ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_5da": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_1dc": {
                "acc": 0.002,
                "acc_stderr": 0.0009992493430694997,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_4ds": {
                "acc": 0.0,
                "acc_stderr": 0.0,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_2dm": {
                "acc": 0.0185,
                "acc_stderr": 0.0030138707185866456,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "arithmetic_2da": {
                "acc": 0.0045,
                "acc_stderr": 0.0014969954902233223,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "gsm8k_cot": {
                "exact_match": 0.016679302501895376,
                "exact_match_stderr": 0.0035275958887224556,
                "timestamp": "2024-06-06T04-30-26.898550"
            },
            "gsm8k": {
                "exact_match": 0.01819560272934041,
                "exact_match_stderr": 0.003681611894073872,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "anli_r2": {
                "brier_score": 0.8622047830185462,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "anli_r3": {
                "brier_score": 0.8573734867626938,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "anli_r1": {
                "brier_score": 0.875763881825301,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_eu": {
                "brier_score": 1.2350745588223613,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_vi": {
                "brier_score": 1.187962184278827,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_ru": {
                "brier_score": 0.9510442144388731,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_zh": {
                "brier_score": 1.2604084317893178,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_tr": {
                "brier_score": 0.8578078728939282,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_fr": {
                "brier_score": 0.8643029753225795,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_en": {
                "brier_score": 0.7004467657014397,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_ur": {
                "brier_score": 1.294615717341209,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_ar": {
                "brier_score": 0.9077213776188938,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_de": {
                "brier_score": 0.9042343874682501,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_hi": {
                "brier_score": 1.2717666974720738,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_es": {
                "brier_score": 0.9307819515890197,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_bg": {
                "brier_score": 1.2325643903521082,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_sw": {
                "brier_score": 1.141700829535198,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_el": {
                "brier_score": 1.0571822860452535,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "xnli_th": {
                "brier_score": 1.294957782543984,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "logiqa2": {
                "brier_score": 1.1601959747659683,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "mathqa": {
                "brier_score": 1.0103387666530812,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T06-40-01.162162"
            },
            "lambada_standard": {
                "perplexity": 38.15763443103525,
                "perplexity_stderr": 1.5528711068483714,
                "acc": 0.3578497962352028,
                "acc_stderr": 0.00667852832588857,
                "timestamp": "2024-06-06T08-49-49.969484"
            },
            "lambada_openai": {
                "perplexity": 16.398847797098593,
                "perplexity_stderr": 0.555542932914263,
                "acc": 0.4513875412381137,
                "acc_stderr": 0.00693297588836862,
                "timestamp": "2024-06-06T08-49-49.969484"
            },
            "mmlu_world_religions": {
                "acc": 0.3157894736842105,
                "acc_stderr": 0.03565079670708313,
                "brier_score": 0.9970922337481368,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_formal_logic": {
                "acc": 0.2777777777777778,
                "acc_stderr": 0.04006168083848876,
                "brier_score": 0.9990126853115562,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_prehistory": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.02313237623454333,
                "brier_score": 0.938124319036566,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.2670391061452514,
                "acc_stderr": 0.014796502622562557,
                "brier_score": 0.8040521732226942,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.2911392405063291,
                "acc_stderr": 0.029571601065753374,
                "brier_score": 0.8014140166309869,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_moral_disputes": {
                "acc": 0.23699421965317918,
                "acc_stderr": 0.02289408248992599,
                "brier_score": 0.8942909106290047,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_professional_law": {
                "acc": 0.2392438070404172,
                "acc_stderr": 0.010896123652676644,
                "brier_score": 0.8333329190374003,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.2085889570552147,
                "acc_stderr": 0.03192193448934722,
                "brier_score": 0.936184462271342,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.23529411764705882,
                "acc_stderr": 0.02977177522814563,
                "brier_score": 0.8922406630766441,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_philosophy": {
                "acc": 0.20257234726688103,
                "acc_stderr": 0.022827317491059675,
                "brier_score": 0.9655163469797318,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_jurisprudence": {
                "acc": 0.25925925925925924,
                "acc_stderr": 0.042365112580946336,
                "brier_score": 0.9051404598397155,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_international_law": {
                "acc": 0.23140495867768596,
                "acc_stderr": 0.03849856098794088,
                "brier_score": 0.9717857105693258,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.23030303030303031,
                "acc_stderr": 0.0328766675860349,
                "brier_score": 0.8574131059083935,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.16580310880829016,
                "acc_stderr": 0.026839845022314415,
                "brier_score": 0.9750618207520899,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.226890756302521,
                "acc_stderr": 0.027205371538279472,
                "brier_score": 0.9519753931469569,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_geography": {
                "acc": 0.18686868686868688,
                "acc_stderr": 0.027772533334218964,
                "brier_score": 1.0463696895724388,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.1981651376146789,
                "acc_stderr": 0.017090573804217902,
                "brier_score": 0.9547817682010158,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_public_relations": {
                "acc": 0.22727272727272727,
                "acc_stderr": 0.040139645540727735,
                "brier_score": 0.935406570724006,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.27,
                "acc_stderr": 0.0446196043338474,
                "brier_score": 0.9232569027624487,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_sociology": {
                "acc": 0.22388059701492538,
                "acc_stderr": 0.029475250236017193,
                "brier_score": 0.9329688170951506,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.20512820512820512,
                "acc_stderr": 0.02047323317355198,
                "brier_score": 0.9727437139626431,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_security_studies": {
                "acc": 0.18775510204081633,
                "acc_stderr": 0.025000256039546212,
                "brier_score": 0.9654425189494698,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_professional_psychology": {
                "acc": 0.2581699346405229,
                "acc_stderr": 0.017704531653250075,
                "brier_score": 0.8587422968758852,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_human_sexuality": {
                "acc": 0.26717557251908397,
                "acc_stderr": 0.03880848301082396,
                "brier_score": 0.8835713271957959,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_econometrics": {
                "acc": 0.22807017543859648,
                "acc_stderr": 0.03947152782669415,
                "brier_score": 1.0031390195254952,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_miscellaneous": {
                "acc": 0.23371647509578544,
                "acc_stderr": 0.015133383278988846,
                "brier_score": 1.0278711513007095,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_marketing": {
                "acc": 0.28205128205128205,
                "acc_stderr": 0.02948036054954119,
                "brier_score": 0.8246799820943679,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_management": {
                "acc": 0.1941747572815534,
                "acc_stderr": 0.03916667762822585,
                "brier_score": 1.046568863939919,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_nutrition": {
                "acc": 0.20915032679738563,
                "acc_stderr": 0.023287685312334813,
                "brier_score": 0.9709268398131645,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_medical_genetics": {
                "acc": 0.35,
                "acc_stderr": 0.047937248544110196,
                "brier_score": 0.8803520332018766,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_human_aging": {
                "acc": 0.3183856502242152,
                "acc_stderr": 0.03126580522513713,
                "brier_score": 0.7888401526589168,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_professional_medicine": {
                "acc": 0.1801470588235294,
                "acc_stderr": 0.02334516361654487,
                "brier_score": 0.9400302557350523,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_medicine": {
                "acc": 0.19653179190751446,
                "acc_stderr": 0.03029957466478814,
                "brier_score": 0.9596453548624214,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_business_ethics": {
                "acc": 0.27,
                "acc_stderr": 0.044619604333847394,
                "brier_score": 0.8593432203954157,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.2037735849056604,
                "acc_stderr": 0.024790784501775416,
                "brier_score": 0.9704544573365829,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_global_facts": {
                "acc": 0.18,
                "acc_stderr": 0.038612291966536955,
                "brier_score": 1.20802224351284,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_virology": {
                "acc": 0.30120481927710846,
                "acc_stderr": 0.0357160923005348,
                "brier_score": 0.8459372985636292,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_professional_accounting": {
                "acc": 0.2375886524822695,
                "acc_stderr": 0.025389512552729903,
                "brier_score": 0.9314436226712202,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_physics": {
                "acc": 0.21568627450980393,
                "acc_stderr": 0.040925639582376556,
                "brier_score": 1.0911694886311318,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_physics": {
                "acc": 0.1986754966887417,
                "acc_stderr": 0.032578473844367746,
                "brier_score": 1.0475729127219355,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_biology": {
                "acc": 0.18387096774193548,
                "acc_stderr": 0.02203721734026784,
                "brier_score": 0.9483958221465675,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_biology": {
                "acc": 0.25,
                "acc_stderr": 0.03621034121889507,
                "brier_score": 0.8893980700028072,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_anatomy": {
                "acc": 0.2074074074074074,
                "acc_stderr": 0.03502553170678317,
                "brier_score": 0.91315436761325,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_chemistry": {
                "acc": 0.19,
                "acc_stderr": 0.03942772444036623,
                "brier_score": 1.1052586190340865,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_computer_security": {
                "acc": 0.33,
                "acc_stderr": 0.047258156262526045,
                "brier_score": 0.8464448149776044,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_computer_science": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 1.0344961178099206,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_astronomy": {
                "acc": 0.17763157894736842,
                "acc_stderr": 0.031103182383123398,
                "brier_score": 1.047975313862721,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_college_mathematics": {
                "acc": 0.21,
                "acc_stderr": 0.040936018074033256,
                "brier_score": 1.163913051137866,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.2851063829787234,
                "acc_stderr": 0.029513196625539355,
                "brier_score": 0.8870185367021838,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.21,
                "acc_stderr": 0.040936018074033256,
                "brier_score": 1.1577966267866362,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.25,
                "acc_stderr": 0.04351941398892446,
                "brier_score": 0.9710461070416393,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_machine_learning": {
                "acc": 0.3125,
                "acc_stderr": 0.043994650575715215,
                "brier_score": 0.8944828792710238,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.15763546798029557,
                "acc_stderr": 0.0256390141311724,
                "brier_score": 1.0681987273212483,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.16203703703703703,
                "acc_stderr": 0.02513045365226846,
                "brier_score": 1.103831661183318,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.20899470899470898,
                "acc_stderr": 0.020940481565334835,
                "brier_score": 1.2024783942465607,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.25517241379310346,
                "acc_stderr": 0.03632984052707842,
                "brier_score": 0.927153451586835,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.2111111111111111,
                "acc_stderr": 0.02488211685765508,
                "brier_score": 1.1781786016679823,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T19-45-02.639673"
            },
            "arc_challenge": {
                "acc": 0.20733788395904437,
                "acc_stderr": 0.011846905782971335,
                "acc_norm": 0.23976109215017063,
                "acc_norm_stderr": 0.01247630412745394,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "hellaswag": {
                "acc": 0.32304321848237405,
                "acc_stderr": 0.004666833452796162,
                "acc_norm": 0.3694483170683131,
                "acc_norm_stderr": 0.004816690123209759,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "truthfulqa_mc2": {
                "acc": 0.4101397354990324,
                "acc_stderr": 0.014705665829993402,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "truthfulqa_gen": {
                "bleu_max": 16.445503288865865,
                "bleu_max_stderr": 0.5837064468134793,
                "bleu_acc": 0.390452876376989,
                "bleu_acc_stderr": 0.017078230743431462,
                "bleu_diff": -2.0622603654652294,
                "bleu_diff_stderr": 0.549702898772285,
                "rouge1_max": 35.862459464442495,
                "rouge1_max_stderr": 0.8635314811502294,
                "rouge1_acc": 0.2839657282741738,
                "rouge1_acc_stderr": 0.015785370858396756,
                "rouge1_diff": -5.37391209618839,
                "rouge1_diff_stderr": 0.7800863393842812,
                "rouge2_max": 18.920614186005043,
                "rouge2_max_stderr": 0.8752002965989032,
                "rouge2_acc": 0.18115055079559364,
                "rouge2_acc_stderr": 0.013482697187817888,
                "rouge2_diff": -4.905442542549504,
                "rouge2_diff_stderr": 0.7931073647795669,
                "rougeL_max": 33.326011225852476,
                "rougeL_max_stderr": 0.8434189971154012,
                "rougeL_acc": 0.2962056303549572,
                "rougeL_acc_stderr": 0.015983595101811385,
                "rougeL_diff": -4.789359756965765,
                "rougeL_diff_stderr": 0.7670328005263544,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "truthfulqa_mc1": {
                "acc": 0.2350061199510404,
                "acc_stderr": 0.014843061507731606,
                "timestamp": "2024-11-22T15-23-45.050539"
            },
            "winogrande": {
                "acc": 0.5130228887134964,
                "acc_stderr": 0.014047718393997667,
                "timestamp": "2024-11-22T15-23-45.050539"
            }
        }
    }
}