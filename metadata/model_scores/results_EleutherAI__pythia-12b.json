{
    "model_name": "EleutherAI/pythia-12b",
    "last_updated": "2023-10-12",
    "results": {
        "harness": {
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.37372013651877134,
                    "acc_stderr": 0.014137708601759096,
                    "acc_norm": 0.39590443686006827,
                    "acc_norm_stderr": 0.014291228393536588,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.502688707428799,
                    "acc_stderr": 0.004989709267191016,
                    "acc_norm": 0.688209520015933,
                    "acc_norm_stderr": 0.00462278057520917,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.23,
                    "acc_stderr": 0.04229525846816505,
                    "acc_norm": 0.23,
                    "acc_norm_stderr": 0.04229525846816505,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.3333333333333333,
                    "acc_stderr": 0.04072314811876837,
                    "acc_norm": 0.3333333333333333,
                    "acc_norm_stderr": 0.04072314811876837,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.23684210526315788,
                    "acc_stderr": 0.034597776068105345,
                    "acc_norm": 0.23684210526315788,
                    "acc_norm_stderr": 0.034597776068105345,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.21,
                    "acc_stderr": 0.04093601807403326,
                    "acc_norm": 0.21,
                    "acc_norm_stderr": 0.04093601807403326,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.26037735849056604,
                    "acc_stderr": 0.027008766090708094,
                    "acc_norm": 0.26037735849056604,
                    "acc_norm_stderr": 0.027008766090708094,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.2638888888888889,
                    "acc_stderr": 0.03685651095897532,
                    "acc_norm": 0.2638888888888889,
                    "acc_norm_stderr": 0.03685651095897532,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.24,
                    "acc_stderr": 0.04292346959909282,
                    "acc_norm": 0.24,
                    "acc_norm_stderr": 0.04292346959909282,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.31,
                    "acc_stderr": 0.04648231987117316,
                    "acc_norm": 0.31,
                    "acc_norm_stderr": 0.04648231987117316,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.31,
                    "acc_stderr": 0.04648231987117316,
                    "acc_norm": 0.31,
                    "acc_norm_stderr": 0.04648231987117316,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.23121387283236994,
                    "acc_stderr": 0.0321473730202947,
                    "acc_norm": 0.23121387283236994,
                    "acc_norm_stderr": 0.0321473730202947,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.21568627450980393,
                    "acc_stderr": 0.04092563958237656,
                    "acc_norm": 0.21568627450980393,
                    "acc_norm_stderr": 0.04092563958237656,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.38,
                    "acc_stderr": 0.048783173121456316,
                    "acc_norm": 0.38,
                    "acc_norm_stderr": 0.048783173121456316,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.2297872340425532,
                    "acc_stderr": 0.027501752944412424,
                    "acc_norm": 0.2297872340425532,
                    "acc_norm_stderr": 0.027501752944412424,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.20175438596491227,
                    "acc_stderr": 0.037752050135836386,
                    "acc_norm": 0.20175438596491227,
                    "acc_norm_stderr": 0.037752050135836386,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.27586206896551724,
                    "acc_stderr": 0.037245636197746325,
                    "acc_norm": 0.27586206896551724,
                    "acc_norm_stderr": 0.037245636197746325,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.2698412698412698,
                    "acc_stderr": 0.022860838309232072,
                    "acc_norm": 0.2698412698412698,
                    "acc_norm_stderr": 0.022860838309232072,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.1984126984126984,
                    "acc_stderr": 0.03567016675276863,
                    "acc_norm": 0.1984126984126984,
                    "acc_norm_stderr": 0.03567016675276863,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.28,
                    "acc_stderr": 0.04512608598542128,
                    "acc_norm": 0.28,
                    "acc_norm_stderr": 0.04512608598542128,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.3161290322580645,
                    "acc_stderr": 0.02645087448904277,
                    "acc_norm": 0.3161290322580645,
                    "acc_norm_stderr": 0.02645087448904277,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.270935960591133,
                    "acc_stderr": 0.03127090713297698,
                    "acc_norm": 0.270935960591133,
                    "acc_norm_stderr": 0.03127090713297698,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.29,
                    "acc_stderr": 0.045604802157206845,
                    "acc_norm": 0.29,
                    "acc_norm_stderr": 0.045604802157206845,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.18181818181818182,
                    "acc_stderr": 0.03011768892950359,
                    "acc_norm": 0.18181818181818182,
                    "acc_norm_stderr": 0.03011768892950359,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.3282828282828283,
                    "acc_stderr": 0.03345678422756776,
                    "acc_norm": 0.3282828282828283,
                    "acc_norm_stderr": 0.03345678422756776,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.2849740932642487,
                    "acc_stderr": 0.03257714077709661,
                    "acc_norm": 0.2849740932642487,
                    "acc_norm_stderr": 0.03257714077709661,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.2641025641025641,
                    "acc_stderr": 0.022352193737453285,
                    "acc_norm": 0.2641025641025641,
                    "acc_norm_stderr": 0.022352193737453285,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.27037037037037037,
                    "acc_stderr": 0.02708037281514566,
                    "acc_norm": 0.27037037037037037,
                    "acc_norm_stderr": 0.02708037281514566,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.23529411764705882,
                    "acc_stderr": 0.027553614467863797,
                    "acc_norm": 0.23529411764705882,
                    "acc_norm_stderr": 0.027553614467863797,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.26490066225165565,
                    "acc_stderr": 0.03603038545360385,
                    "acc_norm": 0.26490066225165565,
                    "acc_norm_stderr": 0.03603038545360385,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.26788990825688075,
                    "acc_stderr": 0.01898746225797865,
                    "acc_norm": 0.26788990825688075,
                    "acc_norm_stderr": 0.01898746225797865,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.36574074074074076,
                    "acc_stderr": 0.03284738857647207,
                    "acc_norm": 0.36574074074074076,
                    "acc_norm_stderr": 0.03284738857647207,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.27450980392156865,
                    "acc_stderr": 0.03132179803083291,
                    "acc_norm": 0.27450980392156865,
                    "acc_norm_stderr": 0.03132179803083291,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.25316455696202533,
                    "acc_stderr": 0.0283046579430353,
                    "acc_norm": 0.25316455696202533,
                    "acc_norm_stderr": 0.0283046579430353,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.28699551569506726,
                    "acc_stderr": 0.030360379710291964,
                    "acc_norm": 0.28699551569506726,
                    "acc_norm_stderr": 0.030360379710291964,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.24427480916030533,
                    "acc_stderr": 0.03768335959728742,
                    "acc_norm": 0.24427480916030533,
                    "acc_norm_stderr": 0.03768335959728742,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.2975206611570248,
                    "acc_stderr": 0.04173349148083497,
                    "acc_norm": 0.2975206611570248,
                    "acc_norm_stderr": 0.04173349148083497,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.26851851851851855,
                    "acc_stderr": 0.04284467968052191,
                    "acc_norm": 0.26851851851851855,
                    "acc_norm_stderr": 0.04284467968052191,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.294478527607362,
                    "acc_stderr": 0.03581165790474082,
                    "acc_norm": 0.294478527607362,
                    "acc_norm_stderr": 0.03581165790474082,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.33035714285714285,
                    "acc_stderr": 0.04464285714285714,
                    "acc_norm": 0.33035714285714285,
                    "acc_norm_stderr": 0.04464285714285714,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.21359223300970873,
                    "acc_stderr": 0.04058042015646034,
                    "acc_norm": 0.21359223300970873,
                    "acc_norm_stderr": 0.04058042015646034,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.26495726495726496,
                    "acc_stderr": 0.028911208802749475,
                    "acc_norm": 0.26495726495726496,
                    "acc_norm_stderr": 0.028911208802749475,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.19,
                    "acc_stderr": 0.03942772444036623,
                    "acc_norm": 0.19,
                    "acc_norm_stderr": 0.03942772444036623,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.2541507024265645,
                    "acc_stderr": 0.015569254692045755,
                    "acc_norm": 0.2541507024265645,
                    "acc_norm_stderr": 0.015569254692045755,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.28901734104046245,
                    "acc_stderr": 0.02440517393578323,
                    "acc_norm": 0.28901734104046245,
                    "acc_norm_stderr": 0.02440517393578323,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.2424581005586592,
                    "acc_stderr": 0.014333522059217889,
                    "acc_norm": 0.2424581005586592,
                    "acc_norm_stderr": 0.014333522059217889,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.2679738562091503,
                    "acc_stderr": 0.025360603796242557,
                    "acc_norm": 0.2679738562091503,
                    "acc_norm_stderr": 0.025360603796242557,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.3022508038585209,
                    "acc_stderr": 0.02608270069539965,
                    "acc_norm": 0.3022508038585209,
                    "acc_norm_stderr": 0.02608270069539965,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.2654320987654321,
                    "acc_stderr": 0.024569223600460845,
                    "acc_norm": 0.2654320987654321,
                    "acc_norm_stderr": 0.024569223600460845,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.26595744680851063,
                    "acc_stderr": 0.02635806569888059,
                    "acc_norm": 0.26595744680851063,
                    "acc_norm_stderr": 0.02635806569888059,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.25554106910039115,
                    "acc_stderr": 0.01113985783359853,
                    "acc_norm": 0.25554106910039115,
                    "acc_norm_stderr": 0.01113985783359853,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.20220588235294118,
                    "acc_stderr": 0.02439819298665492,
                    "acc_norm": 0.20220588235294118,
                    "acc_norm_stderr": 0.02439819298665492,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.25980392156862747,
                    "acc_stderr": 0.01774089950917779,
                    "acc_norm": 0.25980392156862747,
                    "acc_norm_stderr": 0.01774089950917779,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.23636363636363636,
                    "acc_stderr": 0.040693063197213754,
                    "acc_norm": 0.23636363636363636,
                    "acc_norm_stderr": 0.040693063197213754,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.2571428571428571,
                    "acc_stderr": 0.027979823538744546,
                    "acc_norm": 0.2571428571428571,
                    "acc_norm_stderr": 0.027979823538744546,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.3034825870646766,
                    "acc_stderr": 0.032510068164586174,
                    "acc_norm": 0.3034825870646766,
                    "acc_norm_stderr": 0.032510068164586174,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.29,
                    "acc_stderr": 0.045604802157206845,
                    "acc_norm": 0.29,
                    "acc_norm_stderr": 0.045604802157206845,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.3192771084337349,
                    "acc_stderr": 0.036293353299478595,
                    "acc_norm": 0.3192771084337349,
                    "acc_norm_stderr": 0.036293353299478595,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.30409356725146197,
                    "acc_stderr": 0.03528211258245232,
                    "acc_norm": 0.30409356725146197,
                    "acc_norm_stderr": 0.03528211258245232,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.20563035495716034,
                    "mc1_stderr": 0.014148482219460969,
                    "mc2": 0.3185371350132154,
                    "mc2_stderr": 0.013103356003141161,
                    "timestamp": "2023-07-19T18-06-28.460226"
                }
            },
            "drop": {
                "3-shot": {
                    "em": 0.0006291946308724832,
                    "em_stderr": 0.0002568002749723885,
                    "f1": 0.04447986577181216,
                    "f1_stderr": 0.0010992181181045415,
                    "timestamp": "2023-10-12T13-49-53.203420"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.017437452615617893,
                    "acc_stderr": 0.003605486867998272,
                    "timestamp": "2023-10-12T13-49-53.203420"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.6416732438831886,
                    "acc_stderr": 0.013476581172567535,
                    "timestamp": "2023-10-12T13-49-53.203420"
                }
            }
        }
    }
}