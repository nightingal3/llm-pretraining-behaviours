{
    "model_name": "jb723/LLaMA2-en-ko-7B-model",
    "last_updated": "2024-12-19 13:39:03.610739",
    "results": {
        "harness": {
            "minerva_math_precalc": {
                "exact_match": 0.02564102564102564,
                "exact_match_stderr": 0.006770627800780461,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_prealgebra": {
                "exact_match": 0.06314580941446613,
                "exact_match_stderr": 0.008246100866669394,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_num_theory": {
                "exact_match": 0.044444444444444446,
                "exact_match_stderr": 0.008876511687867027,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_intermediate_algebra": {
                "exact_match": 0.04318936877076412,
                "exact_match_stderr": 0.006768589184759898,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_geometry": {
                "exact_match": 0.031315240083507306,
                "exact_match_stderr": 0.00796627249945704,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_counting_and_prob": {
                "exact_match": 0.0379746835443038,
                "exact_match_stderr": 0.008788398915918344,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "minerva_math_algebra": {
                "exact_match": 0.03622577927548441,
                "exact_match_stderr": 0.005425680006601671,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "fld_default": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "fld_star": {
                "exact_match": 0.0,
                "exact_match_stderr": 0.0,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_3da": {
                "acc": 0.812,
                "acc_stderr": 0.008738774690512815,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_3ds": {
                "acc": 0.6985,
                "acc_stderr": 0.010264090353040862,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_4da": {
                "acc": 0.445,
                "acc_stderr": 0.011115272135099212,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_2ds": {
                "acc": 0.888,
                "acc_stderr": 0.007053571892184729,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_5ds": {
                "acc": 0.1365,
                "acc_stderr": 0.0076787601003246685,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_5da": {
                "acc": 0.1975,
                "acc_stderr": 0.00890429774092991,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_1dc": {
                "acc": 0.1985,
                "acc_stderr": 0.008921248193760077,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_4ds": {
                "acc": 0.324,
                "acc_stderr": 0.010467415315716553,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_2dm": {
                "acc": 0.2485,
                "acc_stderr": 0.009665432493822849,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "arithmetic_2da": {
                "acc": 0.913,
                "acc_stderr": 0.0063035995814963814,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "gsm8k_cot": {
                "exact_match": 0.10462471569370735,
                "exact_match_stderr": 0.008430668082029294,
                "timestamp": "2024-06-06T19-14-34.984908"
            },
            "gsm8k": {
                "exact_match": 0.0803639120545868,
                "exact_match_stderr": 0.007488258573239077,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "anli_r2": {
                "brier_score": 0.7571293238745885,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "anli_r3": {
                "brier_score": 0.7917361451062274,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "anli_r1": {
                "brier_score": 0.790322608509962,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_eu": {
                "brier_score": 1.1616926264930671,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_vi": {
                "brier_score": 1.281568581631835,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_ru": {
                "brier_score": 1.0656470677761996,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_zh": {
                "brier_score": 1.2528903645729945,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_tr": {
                "brier_score": 1.1733266271961436,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_fr": {
                "brier_score": 0.9317029900667162,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_en": {
                "brier_score": 0.7583959203972753,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_ur": {
                "brier_score": 1.2177675272267834,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_ar": {
                "brier_score": 1.2410505846779556,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_de": {
                "brier_score": 1.0386205045640462,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_hi": {
                "brier_score": 1.293753345210115,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_es": {
                "brier_score": 1.1731481806637558,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_bg": {
                "brier_score": 1.2046814609921392,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_sw": {
                "brier_score": 0.9985997618380864,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_el": {
                "brier_score": 1.2034257796980916,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "xnli_th": {
                "brier_score": 1.1949904072552373,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "logiqa2": {
                "brier_score": 1.062929306890202,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "mathqa": {
                "brier_score": 0.9595240469786607,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-06-06T19-48-26.693694"
            },
            "lambada_standard": {
                "perplexity": 13.492654865070445,
                "perplexity_stderr": 0.760087072196989,
                "acc": 0.5649136425383272,
                "acc_stderr": 0.006907021966670063,
                "timestamp": "2024-06-06T19-51-27.840893"
            },
            "lambada_openai": {
                "perplexity": 5.252813024296853,
                "perplexity_stderr": 0.1956035665911124,
                "acc": 0.6510770424995148,
                "acc_stderr": 0.006640381581831476,
                "timestamp": "2024-06-06T19-51-27.840893"
            },
            "mmlu_world_religions": {
                "acc": 0.6783625730994152,
                "acc_stderr": 0.03582529442573122,
                "brier_score": 0.534748864523759,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_formal_logic": {
                "acc": 0.3253968253968254,
                "acc_stderr": 0.041905964388711366,
                "brier_score": 0.8666146302504888,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_prehistory": {
                "acc": 0.48148148148148145,
                "acc_stderr": 0.027801656212323674,
                "brier_score": 0.7871000666395396,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.23798882681564246,
                "acc_stderr": 0.014242630070574885,
                "brier_score": 0.8958739388927954,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.5907172995780591,
                "acc_stderr": 0.032007041833595914,
                "brier_score": 0.5286244391845626,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_moral_disputes": {
                "acc": 0.45664739884393063,
                "acc_stderr": 0.02681771813034892,
                "brier_score": 0.7386694527340083,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_professional_law": {
                "acc": 0.35071707953063885,
                "acc_stderr": 0.012187773370741518,
                "brier_score": 0.8635056976637175,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.50920245398773,
                "acc_stderr": 0.03927705600787443,
                "brier_score": 0.6678415022899983,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.553921568627451,
                "acc_stderr": 0.03488845451304974,
                "brier_score": 0.5595603036672312,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_philosophy": {
                "acc": 0.5176848874598071,
                "acc_stderr": 0.028380322849077138,
                "brier_score": 0.6871936008769992,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_jurisprudence": {
                "acc": 0.5185185185185185,
                "acc_stderr": 0.04830366024635331,
                "brier_score": 0.6878288469289898,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_international_law": {
                "acc": 0.5950413223140496,
                "acc_stderr": 0.04481137755942469,
                "brier_score": 0.5623984217998076,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.5636363636363636,
                "acc_stderr": 0.03872592983524754,
                "brier_score": 0.6111700359415961,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.6217616580310881,
                "acc_stderr": 0.03499807276193338,
                "brier_score": 0.5171590492344016,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.3949579831932773,
                "acc_stderr": 0.03175367846096625,
                "brier_score": 0.8008431040907894,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_geography": {
                "acc": 0.5,
                "acc_stderr": 0.035623524993954825,
                "brier_score": 0.716531768993534,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.6055045871559633,
                "acc_stderr": 0.020954642108587485,
                "brier_score": 0.5735431778963822,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_public_relations": {
                "acc": 0.4727272727272727,
                "acc_stderr": 0.04782001791380063,
                "brier_score": 0.7798231001117422,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.63,
                "acc_stderr": 0.04852365870939099,
                "brier_score": 0.5615693250727137,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_sociology": {
                "acc": 0.7164179104477612,
                "acc_stderr": 0.03187187537919798,
                "brier_score": 0.46012516626124617,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.44358974358974357,
                "acc_stderr": 0.0251891498947642,
                "brier_score": 0.7532580528185948,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_security_studies": {
                "acc": 0.5510204081632653,
                "acc_stderr": 0.03184213866687579,
                "brier_score": 0.6568185057962493,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_professional_psychology": {
                "acc": 0.43790849673202614,
                "acc_stderr": 0.020071257886886525,
                "brier_score": 0.7805813506963591,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_human_sexuality": {
                "acc": 0.5801526717557252,
                "acc_stderr": 0.04328577215262972,
                "brier_score": 0.6283695295776315,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_econometrics": {
                "acc": 0.23684210526315788,
                "acc_stderr": 0.03999423879281336,
                "brier_score": 1.040054312603874,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_miscellaneous": {
                "acc": 0.632183908045977,
                "acc_stderr": 0.017243828891846273,
                "brier_score": 0.5591275539615225,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_marketing": {
                "acc": 0.6709401709401709,
                "acc_stderr": 0.03078232157768818,
                "brier_score": 0.5298966348501603,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_management": {
                "acc": 0.6116504854368932,
                "acc_stderr": 0.04825729337356391,
                "brier_score": 0.6290326612663383,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_nutrition": {
                "acc": 0.4738562091503268,
                "acc_stderr": 0.028590752958852394,
                "brier_score": 0.7600916780576064,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_medical_genetics": {
                "acc": 0.47,
                "acc_stderr": 0.05016135580465919,
                "brier_score": 0.7919592716712658,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_human_aging": {
                "acc": 0.4170403587443946,
                "acc_stderr": 0.03309266936071721,
                "brier_score": 0.764915455584205,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_professional_medicine": {
                "acc": 0.4227941176470588,
                "acc_stderr": 0.030008562845003476,
                "brier_score": 0.7693848977296722,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_medicine": {
                "acc": 0.43352601156069365,
                "acc_stderr": 0.037786210790920545,
                "brier_score": 0.7900118197708276,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_business_ethics": {
                "acc": 0.52,
                "acc_stderr": 0.050211673156867795,
                "brier_score": 0.690535414285433,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.4830188679245283,
                "acc_stderr": 0.030755120364119905,
                "brier_score": 0.7388561021827996,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_global_facts": {
                "acc": 0.32,
                "acc_stderr": 0.046882617226215034,
                "brier_score": 0.8966340480041656,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_virology": {
                "acc": 0.4457831325301205,
                "acc_stderr": 0.03869543323472101,
                "brier_score": 0.889841462632872,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_professional_accounting": {
                "acc": 0.36879432624113473,
                "acc_stderr": 0.028782227561347257,
                "brier_score": 0.821098937892523,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_physics": {
                "acc": 0.27450980392156865,
                "acc_stderr": 0.044405219061793275,
                "brier_score": 0.9858278163501498,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_physics": {
                "acc": 0.23841059602649006,
                "acc_stderr": 0.03479185572599661,
                "brier_score": 0.9301743583498789,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_biology": {
                "acc": 0.4870967741935484,
                "acc_stderr": 0.02843453315268186,
                "brier_score": 0.7268153093495426,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_biology": {
                "acc": 0.4166666666666667,
                "acc_stderr": 0.041227287076512825,
                "brier_score": 0.807682603750939,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_anatomy": {
                "acc": 0.5111111111111111,
                "acc_stderr": 0.04318275491977976,
                "brier_score": 0.7261012587186336,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_chemistry": {
                "acc": 0.36,
                "acc_stderr": 0.04824181513244218,
                "brier_score": 0.7860073437698719,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_computer_security": {
                "acc": 0.51,
                "acc_stderr": 0.05024183937956911,
                "brier_score": 0.6798467302926896,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_computer_science": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.858095517218403,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_astronomy": {
                "acc": 0.46710526315789475,
                "acc_stderr": 0.040601270352363966,
                "brier_score": 0.7703617335441443,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_college_mathematics": {
                "acc": 0.35,
                "acc_stderr": 0.0479372485441102,
                "brier_score": 0.785867596602279,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.3446808510638298,
                "acc_stderr": 0.03106898596312215,
                "brier_score": 0.9114039342379253,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "brier_score": 0.8541042943465978,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.43,
                "acc_stderr": 0.04975698519562428,
                "brier_score": 0.7536844740552069,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_machine_learning": {
                "acc": 0.3125,
                "acc_stderr": 0.043994650575715215,
                "brier_score": 0.8672657328988382,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.3645320197044335,
                "acc_stderr": 0.03386405746062089,
                "brier_score": 0.8207565586615612,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.28703703703703703,
                "acc_stderr": 0.030851992993257013,
                "brier_score": 0.9131758303558689,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.25132275132275134,
                "acc_stderr": 0.022340482339643898,
                "brier_score": 0.9622714666506607,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.43448275862068964,
                "acc_stderr": 0.041307408795554966,
                "brier_score": 0.7647456420359826,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.2740740740740741,
                "acc_stderr": 0.027195934804085626,
                "brier_score": 0.9189945009491987,
                "brier_score_stderr": "N/A",
                "timestamp": "2024-12-15T18-29-52.764283"
            },
            "arc_challenge": {
                "acc": 0.5136518771331058,
                "acc_stderr": 0.014605943429860942,
                "acc_norm": 0.53839590443686,
                "acc_norm_stderr": 0.014568245550296365,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "hellaswag": {
                "acc": 0.6069508066122287,
                "acc_stderr": 0.004874293964843518,
                "acc_norm": 0.7893845847440749,
                "acc_norm_stderr": 0.004069123905324906,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "truthfulqa_mc2": {
                "acc": 0.4095607803946665,
                "acc_stderr": 0.015544245050976095,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "truthfulqa_gen": {
                "bleu_max": 20.89104935353322,
                "bleu_max_stderr": 0.690580917763846,
                "bleu_acc": 0.34394124847001223,
                "bleu_acc_stderr": 0.016629087514276816,
                "bleu_diff": -4.982714805919928,
                "bleu_diff_stderr": 0.6525563274154834,
                "rouge1_max": 46.0179025495015,
                "rouge1_max_stderr": 0.8157872400574628,
                "rouge1_acc": 0.34149326805385555,
                "rouge1_acc_stderr": 0.016600688619950833,
                "rouge1_diff": -7.817434391713708,
                "rouge1_diff_stderr": 0.7537330659697064,
                "rouge2_max": 30.284883181541517,
                "rouge2_max_stderr": 0.885344085472441,
                "rouge2_acc": 0.2913096695226438,
                "rouge2_acc_stderr": 0.015905987048184824,
                "rouge2_diff": -8.624090028516706,
                "rouge2_diff_stderr": 0.8953473056334376,
                "rougeL_max": 42.39510902130912,
                "rougeL_max_stderr": 0.8131112049425046,
                "rougeL_acc": 0.31334149326805383,
                "rougeL_acc_stderr": 0.016238065069059573,
                "rougeL_diff": -8.169098689998256,
                "rougeL_diff_stderr": 0.7490350953113237,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "truthfulqa_mc1": {
                "acc": 0.2876376988984088,
                "acc_stderr": 0.015846315101394795,
                "timestamp": "2024-11-15T06-50-09.288337"
            },
            "winogrande": {
                "acc": 0.7000789265982637,
                "acc_stderr": 0.012878347526636072,
                "timestamp": "2024-11-15T06-50-09.288337"
            }
        }
    }
}