{
    "model_name": "HuggingFaceTB__SmolLM-1.7B",
    "last_updated": "2024-12-04 11:25:37.408937",
    "results": {
        "harness": {
            "mmlu_world_religions": {
                "acc": 0.34502923976608185,
                "acc_stderr": 0.03645981377388807,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_formal_logic": {
                "acc": 0.2222222222222222,
                "acc_stderr": 0.037184890068181146,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_prehistory": {
                "acc": 0.3271604938271605,
                "acc_stderr": 0.026105673861409814,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_moral_scenarios": {
                "acc": 0.2446927374301676,
                "acc_stderr": 0.014378169884098424,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_world_history": {
                "acc": 0.26582278481012656,
                "acc_stderr": 0.028756799629658332,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_moral_disputes": {
                "acc": 0.3236994219653179,
                "acc_stderr": 0.02519018132760842,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_professional_law": {
                "acc": 0.2835723598435463,
                "acc_stderr": 0.011511900775968318,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_logical_fallacies": {
                "acc": 0.26380368098159507,
                "acc_stderr": 0.03462419931615624,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_us_history": {
                "acc": 0.23039215686274508,
                "acc_stderr": 0.029554292605695063,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_philosophy": {
                "acc": 0.36977491961414793,
                "acc_stderr": 0.027417996705630995,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_jurisprudence": {
                "acc": 0.3055555555555556,
                "acc_stderr": 0.044531975073749834,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_international_law": {
                "acc": 0.36363636363636365,
                "acc_stderr": 0.043913262867240704,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_european_history": {
                "acc": 0.24242424242424243,
                "acc_stderr": 0.033464098810559534,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_government_and_politics": {
                "acc": 0.27461139896373055,
                "acc_stderr": 0.032210245080411544,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_microeconomics": {
                "acc": 0.2605042016806723,
                "acc_stderr": 0.02851025151234193,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_geography": {
                "acc": 0.3484848484848485,
                "acc_stderr": 0.033948539651564025,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_psychology": {
                "acc": 0.30458715596330277,
                "acc_stderr": 0.019732299420354045,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_public_relations": {
                "acc": 0.2545454545454545,
                "acc_stderr": 0.04172343038705383,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_us_foreign_policy": {
                "acc": 0.39,
                "acc_stderr": 0.04902071300001974,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_sociology": {
                "acc": 0.2885572139303483,
                "acc_stderr": 0.0320384104021332,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_macroeconomics": {
                "acc": 0.28974358974358977,
                "acc_stderr": 0.023000628243687954,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_security_studies": {
                "acc": 0.363265306122449,
                "acc_stderr": 0.030789051139030806,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_professional_psychology": {
                "acc": 0.26633986928104575,
                "acc_stderr": 0.01788318813466721,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_human_sexuality": {
                "acc": 0.29770992366412213,
                "acc_stderr": 0.04010358942462203,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_econometrics": {
                "acc": 0.20175438596491227,
                "acc_stderr": 0.03775205013583639,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_miscellaneous": {
                "acc": 0.33205619412515963,
                "acc_stderr": 0.016841174655295717,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_marketing": {
                "acc": 0.2863247863247863,
                "acc_stderr": 0.029614323690456648,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_management": {
                "acc": 0.30097087378640774,
                "acc_stderr": 0.04541609446503948,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_nutrition": {
                "acc": 0.3333333333333333,
                "acc_stderr": 0.02699254433929723,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_medical_genetics": {
                "acc": 0.32,
                "acc_stderr": 0.04688261722621504,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_human_aging": {
                "acc": 0.33183856502242154,
                "acc_stderr": 0.031602951437766785,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_professional_medicine": {
                "acc": 0.3492647058823529,
                "acc_stderr": 0.02895975519682487,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_medicine": {
                "acc": 0.2658959537572254,
                "acc_stderr": 0.0336876293225943,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_business_ethics": {
                "acc": 0.32,
                "acc_stderr": 0.046882617226215034,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_clinical_knowledge": {
                "acc": 0.35094339622641507,
                "acc_stderr": 0.029373646253234686,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_global_facts": {
                "acc": 0.35,
                "acc_stderr": 0.0479372485441102,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_virology": {
                "acc": 0.3795180722891566,
                "acc_stderr": 0.03777798822748018,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_professional_accounting": {
                "acc": 0.24113475177304963,
                "acc_stderr": 0.02551873104953776,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_physics": {
                "acc": 0.2647058823529412,
                "acc_stderr": 0.04389869956808779,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_physics": {
                "acc": 0.271523178807947,
                "acc_stderr": 0.03631329803969653,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_biology": {
                "acc": 0.33225806451612905,
                "acc_stderr": 0.026795560848122797,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_biology": {
                "acc": 0.3541666666666667,
                "acc_stderr": 0.039994111357535424,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_anatomy": {
                "acc": 0.4148148148148148,
                "acc_stderr": 0.04256193767901407,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_chemistry": {
                "acc": 0.32,
                "acc_stderr": 0.046882617226215034,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_computer_security": {
                "acc": 0.31,
                "acc_stderr": 0.04648231987117316,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_computer_science": {
                "acc": 0.34,
                "acc_stderr": 0.04760952285695235,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_astronomy": {
                "acc": 0.3618421052631579,
                "acc_stderr": 0.03910525752849725,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_college_mathematics": {
                "acc": 0.27,
                "acc_stderr": 0.044619604333847394,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_conceptual_physics": {
                "acc": 0.28085106382978725,
                "acc_stderr": 0.02937917046412482,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_abstract_algebra": {
                "acc": 0.24,
                "acc_stderr": 0.04292346959909283,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_computer_science": {
                "acc": 0.33,
                "acc_stderr": 0.047258156262526045,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_machine_learning": {
                "acc": 0.32142857142857145,
                "acc_stderr": 0.04432804055291518,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_chemistry": {
                "acc": 0.2413793103448276,
                "acc_stderr": 0.030108330718011625,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_statistics": {
                "acc": 0.3194444444444444,
                "acc_stderr": 0.0317987634217685,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_elementary_mathematics": {
                "acc": 0.24867724867724866,
                "acc_stderr": 0.022261817692400182,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_electrical_engineering": {
                "acc": 0.2206896551724138,
                "acc_stderr": 0.0345593020192481,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "mmlu_high_school_mathematics": {
                "acc": 0.24814814814814815,
                "acc_stderr": 0.0263357394040558,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "arc_challenge": {
                "acc": 0.4616040955631399,
                "acc_stderr": 0.014568245550296358,
                "acc_norm": 0.48976109215017066,
                "acc_norm_stderr": 0.014608326906285012,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "hellaswag": {
                "acc": 0.4985062736506672,
                "acc_stderr": 0.004989759144812283,
                "acc_norm": 0.673770165305716,
                "acc_norm_stderr": 0.004678743563766636,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "truthfulqa_mc2": {
                "acc": 0.3850766766083665,
                "acc_stderr": 0.0141318041269147,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "truthfulqa_gen": {
                "bleu_max": 25.637781985326768,
                "bleu_max_stderr": 0.7862985780149876,
                "bleu_acc": 0.3243574051407589,
                "bleu_acc_stderr": 0.016387976779647935,
                "bleu_diff": -7.032993037032112,
                "bleu_diff_stderr": 0.8260513065264542,
                "rouge1_max": 50.02333005649277,
                "rouge1_max_stderr": 0.888601487283363,
                "rouge1_acc": 0.2974296205630355,
                "rouge1_acc_stderr": 0.016002651487361005,
                "rouge1_diff": -9.43923743956951,
                "rouge1_diff_stderr": 0.9261892834631157,
                "rouge2_max": 33.70014727089389,
                "rouge2_max_stderr": 1.0124553331073005,
                "rouge2_acc": 0.25458996328029376,
                "rouge2_acc_stderr": 0.015250117079156487,
                "rouge2_diff": -11.30035982468476,
                "rouge2_diff_stderr": 1.0978598755923092,
                "rougeL_max": 47.21056335206833,
                "rougeL_max_stderr": 0.8970416486465508,
                "rougeL_acc": 0.2839657282741738,
                "rougeL_acc_stderr": 0.015785370858396718,
                "rougeL_diff": -9.830444388716177,
                "rougeL_diff_stderr": 0.9254935688315172,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "truthfulqa_mc1": {
                "acc": 0.24479804161566707,
                "acc_stderr": 0.015051869486715006,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "winogrande": {
                "acc": 0.611681136543015,
                "acc_stderr": 0.013697456658457228,
                "timestamp": "2024-11-21T21-51-42.336660"
            },
            "gsm8k": {
                "exact_match": 0.052312357846853674,
                "exact_match_stderr": 0.006133057708959227,
                "timestamp": "2024-11-21T21-51-42.336660"
            }
        }
    }
}