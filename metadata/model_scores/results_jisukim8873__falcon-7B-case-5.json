{
    "model_name": "jisukim8873/falcon-7B-case-5",
    "last_updated": "2024-06-25 14:38:34.988256",
    "results": {
        "harness": {
            "arc:challenge": {
                "25-shot": {
                    "acc": 0.4462457337883959,
                    "acc_stderr": 0.014526705548539982,
                    "acc_norm": 0.48378839590443684,
                    "acc_norm_stderr": 0.014603708567414947,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hellaswag": {
                "10-shot": {
                    "acc": 0.5970922127066322,
                    "acc_stderr": 0.004894801119898607,
                    "acc_norm": 0.7851025692093209,
                    "acc_norm_stderr": 0.004099117122280895,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-abstract_algebra": {
                "5-shot": {
                    "acc": 0.34,
                    "acc_stderr": 0.04760952285695236,
                    "acc_norm": 0.34,
                    "acc_norm_stderr": 0.04760952285695236,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-anatomy": {
                "5-shot": {
                    "acc": 0.31851851851851853,
                    "acc_stderr": 0.040247784019771096,
                    "acc_norm": 0.31851851851851853,
                    "acc_norm_stderr": 0.040247784019771096,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-astronomy": {
                "5-shot": {
                    "acc": 0.23684210526315788,
                    "acc_stderr": 0.03459777606810536,
                    "acc_norm": 0.23684210526315788,
                    "acc_norm_stderr": 0.03459777606810536,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-business_ethics": {
                "5-shot": {
                    "acc": 0.19,
                    "acc_stderr": 0.039427724440366234,
                    "acc_norm": 0.19,
                    "acc_norm_stderr": 0.039427724440366234,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-clinical_knowledge": {
                "5-shot": {
                    "acc": 0.3169811320754717,
                    "acc_stderr": 0.028637235639800935,
                    "acc_norm": 0.3169811320754717,
                    "acc_norm_stderr": 0.028637235639800935,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_biology": {
                "5-shot": {
                    "acc": 0.2708333333333333,
                    "acc_stderr": 0.03716177437566017,
                    "acc_norm": 0.2708333333333333,
                    "acc_norm_stderr": 0.03716177437566017,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_chemistry": {
                "5-shot": {
                    "acc": 0.16,
                    "acc_stderr": 0.03684529491774709,
                    "acc_norm": 0.16,
                    "acc_norm_stderr": 0.03684529491774709,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_computer_science": {
                "5-shot": {
                    "acc": 0.28,
                    "acc_stderr": 0.04512608598542127,
                    "acc_norm": 0.28,
                    "acc_norm_stderr": 0.04512608598542127,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_mathematics": {
                "5-shot": {
                    "acc": 0.26,
                    "acc_stderr": 0.044084400227680794,
                    "acc_norm": 0.26,
                    "acc_norm_stderr": 0.044084400227680794,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_medicine": {
                "5-shot": {
                    "acc": 0.2832369942196532,
                    "acc_stderr": 0.034355680560478746,
                    "acc_norm": 0.2832369942196532,
                    "acc_norm_stderr": 0.034355680560478746,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-college_physics": {
                "5-shot": {
                    "acc": 0.16666666666666666,
                    "acc_stderr": 0.03708284662416545,
                    "acc_norm": 0.16666666666666666,
                    "acc_norm_stderr": 0.03708284662416545,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-computer_security": {
                "5-shot": {
                    "acc": 0.33,
                    "acc_stderr": 0.047258156262526045,
                    "acc_norm": 0.33,
                    "acc_norm_stderr": 0.047258156262526045,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-conceptual_physics": {
                "5-shot": {
                    "acc": 0.34893617021276596,
                    "acc_stderr": 0.031158522131357783,
                    "acc_norm": 0.34893617021276596,
                    "acc_norm_stderr": 0.031158522131357783,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-econometrics": {
                "5-shot": {
                    "acc": 0.24561403508771928,
                    "acc_stderr": 0.040493392977481425,
                    "acc_norm": 0.24561403508771928,
                    "acc_norm_stderr": 0.040493392977481425,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-electrical_engineering": {
                "5-shot": {
                    "acc": 0.2689655172413793,
                    "acc_stderr": 0.036951833116502325,
                    "acc_norm": 0.2689655172413793,
                    "acc_norm_stderr": 0.036951833116502325,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-elementary_mathematics": {
                "5-shot": {
                    "acc": 0.2671957671957672,
                    "acc_stderr": 0.02278967314577657,
                    "acc_norm": 0.2671957671957672,
                    "acc_norm_stderr": 0.02278967314577657,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-formal_logic": {
                "5-shot": {
                    "acc": 0.1984126984126984,
                    "acc_stderr": 0.03567016675276864,
                    "acc_norm": 0.1984126984126984,
                    "acc_norm_stderr": 0.03567016675276864,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-global_facts": {
                "5-shot": {
                    "acc": 0.32,
                    "acc_stderr": 0.046882617226215034,
                    "acc_norm": 0.32,
                    "acc_norm_stderr": 0.046882617226215034,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_biology": {
                "5-shot": {
                    "acc": 0.3419354838709677,
                    "acc_stderr": 0.02698528957655274,
                    "acc_norm": 0.3419354838709677,
                    "acc_norm_stderr": 0.02698528957655274,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_chemistry": {
                "5-shot": {
                    "acc": 0.31527093596059114,
                    "acc_stderr": 0.03269080871970187,
                    "acc_norm": 0.31527093596059114,
                    "acc_norm_stderr": 0.03269080871970187,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_computer_science": {
                "5-shot": {
                    "acc": 0.39,
                    "acc_stderr": 0.04902071300001975,
                    "acc_norm": 0.39,
                    "acc_norm_stderr": 0.04902071300001975,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_european_history": {
                "5-shot": {
                    "acc": 0.34545454545454546,
                    "acc_stderr": 0.037131580674819135,
                    "acc_norm": 0.34545454545454546,
                    "acc_norm_stderr": 0.037131580674819135,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_geography": {
                "5-shot": {
                    "acc": 0.2878787878787879,
                    "acc_stderr": 0.03225883512300993,
                    "acc_norm": 0.2878787878787879,
                    "acc_norm_stderr": 0.03225883512300993,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_government_and_politics": {
                "5-shot": {
                    "acc": 0.2849740932642487,
                    "acc_stderr": 0.03257714077709662,
                    "acc_norm": 0.2849740932642487,
                    "acc_norm_stderr": 0.03257714077709662,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_macroeconomics": {
                "5-shot": {
                    "acc": 0.26153846153846155,
                    "acc_stderr": 0.02228214120420442,
                    "acc_norm": 0.26153846153846155,
                    "acc_norm_stderr": 0.02228214120420442,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_mathematics": {
                "5-shot": {
                    "acc": 0.25555555555555554,
                    "acc_stderr": 0.02659393910184408,
                    "acc_norm": 0.25555555555555554,
                    "acc_norm_stderr": 0.02659393910184408,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_microeconomics": {
                "5-shot": {
                    "acc": 0.2857142857142857,
                    "acc_stderr": 0.02934457250063435,
                    "acc_norm": 0.2857142857142857,
                    "acc_norm_stderr": 0.02934457250063435,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_physics": {
                "5-shot": {
                    "acc": 0.271523178807947,
                    "acc_stderr": 0.03631329803969654,
                    "acc_norm": 0.271523178807947,
                    "acc_norm_stderr": 0.03631329803969654,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_psychology": {
                "5-shot": {
                    "acc": 0.30091743119266057,
                    "acc_stderr": 0.019664751366802114,
                    "acc_norm": 0.30091743119266057,
                    "acc_norm_stderr": 0.019664751366802114,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_statistics": {
                "5-shot": {
                    "acc": 0.2037037037037037,
                    "acc_stderr": 0.027467401804057986,
                    "acc_norm": 0.2037037037037037,
                    "acc_norm_stderr": 0.027467401804057986,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_us_history": {
                "5-shot": {
                    "acc": 0.29411764705882354,
                    "acc_stderr": 0.03198001660115071,
                    "acc_norm": 0.29411764705882354,
                    "acc_norm_stderr": 0.03198001660115071,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-high_school_world_history": {
                "5-shot": {
                    "acc": 0.3333333333333333,
                    "acc_stderr": 0.0306858205966108,
                    "acc_norm": 0.3333333333333333,
                    "acc_norm_stderr": 0.0306858205966108,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-human_aging": {
                "5-shot": {
                    "acc": 0.4260089686098655,
                    "acc_stderr": 0.033188332862172806,
                    "acc_norm": 0.4260089686098655,
                    "acc_norm_stderr": 0.033188332862172806,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-human_sexuality": {
                "5-shot": {
                    "acc": 0.2824427480916031,
                    "acc_stderr": 0.03948406125768361,
                    "acc_norm": 0.2824427480916031,
                    "acc_norm_stderr": 0.03948406125768361,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-international_law": {
                "5-shot": {
                    "acc": 0.36363636363636365,
                    "acc_stderr": 0.043913262867240704,
                    "acc_norm": 0.36363636363636365,
                    "acc_norm_stderr": 0.043913262867240704,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-jurisprudence": {
                "5-shot": {
                    "acc": 0.3055555555555556,
                    "acc_stderr": 0.044531975073749834,
                    "acc_norm": 0.3055555555555556,
                    "acc_norm_stderr": 0.044531975073749834,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-logical_fallacies": {
                "5-shot": {
                    "acc": 0.25153374233128833,
                    "acc_stderr": 0.03408997886857529,
                    "acc_norm": 0.25153374233128833,
                    "acc_norm_stderr": 0.03408997886857529,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-machine_learning": {
                "5-shot": {
                    "acc": 0.33035714285714285,
                    "acc_stderr": 0.04464285714285713,
                    "acc_norm": 0.33035714285714285,
                    "acc_norm_stderr": 0.04464285714285713,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-management": {
                "5-shot": {
                    "acc": 0.30097087378640774,
                    "acc_stderr": 0.045416094465039476,
                    "acc_norm": 0.30097087378640774,
                    "acc_norm_stderr": 0.045416094465039476,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-marketing": {
                "5-shot": {
                    "acc": 0.36752136752136755,
                    "acc_stderr": 0.03158539157745637,
                    "acc_norm": 0.36752136752136755,
                    "acc_norm_stderr": 0.03158539157745637,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-medical_genetics": {
                "5-shot": {
                    "acc": 0.3,
                    "acc_stderr": 0.046056618647183814,
                    "acc_norm": 0.3,
                    "acc_norm_stderr": 0.046056618647183814,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-miscellaneous": {
                "5-shot": {
                    "acc": 0.3614303959131545,
                    "acc_stderr": 0.017179601328900736,
                    "acc_norm": 0.3614303959131545,
                    "acc_norm_stderr": 0.017179601328900736,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-moral_disputes": {
                "5-shot": {
                    "acc": 0.3699421965317919,
                    "acc_stderr": 0.025992472029306383,
                    "acc_norm": 0.3699421965317919,
                    "acc_norm_stderr": 0.025992472029306383,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-moral_scenarios": {
                "5-shot": {
                    "acc": 0.24916201117318434,
                    "acc_stderr": 0.014465893829859924,
                    "acc_norm": 0.24916201117318434,
                    "acc_norm_stderr": 0.014465893829859924,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-nutrition": {
                "5-shot": {
                    "acc": 0.3104575163398693,
                    "acc_stderr": 0.02649303322514589,
                    "acc_norm": 0.3104575163398693,
                    "acc_norm_stderr": 0.02649303322514589,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-philosophy": {
                "5-shot": {
                    "acc": 0.33762057877813506,
                    "acc_stderr": 0.026858825879488558,
                    "acc_norm": 0.33762057877813506,
                    "acc_norm_stderr": 0.026858825879488558,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-prehistory": {
                "5-shot": {
                    "acc": 0.3055555555555556,
                    "acc_stderr": 0.025630824975621344,
                    "acc_norm": 0.3055555555555556,
                    "acc_norm_stderr": 0.025630824975621344,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-professional_accounting": {
                "5-shot": {
                    "acc": 0.24822695035460993,
                    "acc_stderr": 0.025770015644290392,
                    "acc_norm": 0.24822695035460993,
                    "acc_norm_stderr": 0.025770015644290392,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-professional_law": {
                "5-shot": {
                    "acc": 0.2907431551499348,
                    "acc_stderr": 0.011598062372851988,
                    "acc_norm": 0.2907431551499348,
                    "acc_norm_stderr": 0.011598062372851988,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-professional_medicine": {
                "5-shot": {
                    "acc": 0.17647058823529413,
                    "acc_stderr": 0.023157468308559356,
                    "acc_norm": 0.17647058823529413,
                    "acc_norm_stderr": 0.023157468308559356,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-professional_psychology": {
                "5-shot": {
                    "acc": 0.28921568627450983,
                    "acc_stderr": 0.018342529845275908,
                    "acc_norm": 0.28921568627450983,
                    "acc_norm_stderr": 0.018342529845275908,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-public_relations": {
                "5-shot": {
                    "acc": 0.2545454545454545,
                    "acc_stderr": 0.041723430387053825,
                    "acc_norm": 0.2545454545454545,
                    "acc_norm_stderr": 0.041723430387053825,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-security_studies": {
                "5-shot": {
                    "acc": 0.2653061224489796,
                    "acc_stderr": 0.028263889943784596,
                    "acc_norm": 0.2653061224489796,
                    "acc_norm_stderr": 0.028263889943784596,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-sociology": {
                "5-shot": {
                    "acc": 0.31343283582089554,
                    "acc_stderr": 0.03280188205348643,
                    "acc_norm": 0.31343283582089554,
                    "acc_norm_stderr": 0.03280188205348643,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-us_foreign_policy": {
                "5-shot": {
                    "acc": 0.42,
                    "acc_stderr": 0.049604496374885836,
                    "acc_norm": 0.42,
                    "acc_norm_stderr": 0.049604496374885836,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-virology": {
                "5-shot": {
                    "acc": 0.37349397590361444,
                    "acc_stderr": 0.037658451171688624,
                    "acc_norm": 0.37349397590361444,
                    "acc_norm_stderr": 0.037658451171688624,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "hendrycksTest-world_religions": {
                "5-shot": {
                    "acc": 0.3567251461988304,
                    "acc_stderr": 0.03674013002860954,
                    "acc_norm": 0.3567251461988304,
                    "acc_norm_stderr": 0.03674013002860954,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "truthfulqa:mc": {
                "0-shot": {
                    "mc1": 0.2484700122399021,
                    "mc1_stderr": 0.01512742709652069,
                    "mc2": 0.36034965375475575,
                    "mc2_stderr": 0.01417459244672947,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "winogrande": {
                "5-shot": {
                    "acc": 0.7182320441988951,
                    "acc_stderr": 0.012643326011852946,
                    "timestamp": "2024-03-04T02-58-17.035373"
                }
            },
            "gsm8k": {
                "5-shot": {
                    "acc": 0.07960576194086429,
                    "acc_stderr": 0.007455924338676244,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_precalc": {
                "5-shot": {
                    "acc": 0.007326007326007326,
                    "acc_stderr": 0.0036529080893830334,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_prealgebra": {
                "5-shot": {
                    "acc": 0.03559127439724455,
                    "acc_stderr": 0.006281201252709593,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_num_theory": {
                "5-shot": {
                    "acc": 0.018518518518518517,
                    "acc_stderr": 0.005806972807912272,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_intermediate_algebra": {
                "5-shot": {
                    "acc": 0.01107419712070875,
                    "acc_stderr": 0.0034844537978317943,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_geometry": {
                "5-shot": {
                    "acc": 0.006263048016701462,
                    "acc_stderr": 0.003608399732887869,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_counting_and_prob": {
                "5-shot": {
                    "acc": 0.008438818565400843,
                    "acc_stderr": 0.004206007207713057,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "minerva_math_algebra": {
                "5-shot": {
                    "acc": 0.011794439764111205,
                    "acc_stderr": 0.003134873065301043,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "fld_default": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "fld_star": {
                "0-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_3da": {
                "5-shot": {
                    "acc": 0.001,
                    "acc_stderr": 0.0007069298939339458,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_3ds": {
                "5-shot": {
                    "acc": 0.001,
                    "acc_stderr": 0.0007069298939339484,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_4da": {
                "5-shot": {
                    "acc": 0.0005,
                    "acc_stderr": 0.0005000000000000151,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_2ds": {
                "5-shot": {
                    "acc": 0.0125,
                    "acc_stderr": 0.00248494717876267,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_5ds": {
                "5-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_5da": {
                "5-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_1dc": {
                "5-shot": {
                    "acc": 0.0565,
                    "acc_stderr": 0.0051640302675624965,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_4ds": {
                "5-shot": {
                    "acc": 0.0,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_2dm": {
                "5-shot": {
                    "acc": 0.041,
                    "acc_stderr": 0.004435012363831016,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "arithmetic_2da": {
                "5-shot": {
                    "acc": 0.0095,
                    "acc_stderr": 0.002169614853910038,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "gsm8k_cot": {
                "5-shot": {
                    "acc": 0.10614101592115238,
                    "acc_stderr": 0.008484346948434586,
                    "timestamp": "2024-06-06T22-51-59.460568"
                }
            },
            "anli_r2": {
                "0-shot": {
                    "brier_score": 0.9513281547700652,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "anli_r3": {
                "0-shot": {
                    "brier_score": 0.8632624385858723,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "anli_r1": {
                "0-shot": {
                    "brier_score": 0.9747999915331574,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_eu": {
                "0-shot": {
                    "brier_score": 1.0516363750130937,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_vi": {
                "0-shot": {
                    "brier_score": 0.9989937908225948,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_ru": {
                "0-shot": {
                    "brier_score": 0.8313811181787544,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_zh": {
                "0-shot": {
                    "brier_score": 0.9903379657251044,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_tr": {
                "0-shot": {
                    "brier_score": 0.9686053353297328,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_fr": {
                "0-shot": {
                    "brier_score": 0.7336352662626028,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_en": {
                "0-shot": {
                    "brier_score": 0.6661677143555013,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_ur": {
                "0-shot": {
                    "brier_score": 1.2696545502356362,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_ar": {
                "0-shot": {
                    "brier_score": 1.2884254322323176,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_de": {
                "0-shot": {
                    "brier_score": 0.8278491965645761,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_hi": {
                "0-shot": {
                    "brier_score": 1.0473020786937401,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_es": {
                "0-shot": {
                    "brier_score": 0.8100639118042829,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_bg": {
                "0-shot": {
                    "brier_score": 0.9677419215546682,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_sw": {
                "0-shot": {
                    "brier_score": 1.1267158887404765,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_el": {
                "0-shot": {
                    "brier_score": 0.9376379182808555,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "xnli_th": {
                "0-shot": {
                    "brier_score": 0.9937338487237533,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "logiqa2": {
                "0-shot": {
                    "brier_score": 1.07732917197947,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "mathqa": {
                "5-shot": {
                    "brier_score": 0.9433681905807897,
                    "timestamp": "2024-06-06T23-03-17.282446"
                }
            },
            "lambada_standard": {
                "0-shot": {
                    "perplexity": 4.154513384117848,
                    "perplexity_stderr": 0.09112783779974745,
                    "acc": 0.6679604114108286,
                    "acc_stderr": 0.006561186280791164,
                    "timestamp": "2024-06-06T23-04-37.895404"
                }
            },
            "lambada_openai": {
                "0-shot": {
                    "perplexity": 3.231212255722818,
                    "perplexity_stderr": 0.06690211574319113,
                    "acc": 0.7393751212885697,
                    "acc_stderr": 0.006115788029333531,
                    "timestamp": "2024-06-06T23-04-37.895404"
                }
            }
        }
    }
}