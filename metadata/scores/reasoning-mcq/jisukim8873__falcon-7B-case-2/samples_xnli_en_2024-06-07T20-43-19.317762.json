{"doc_id": 0, "doc": {"premise": "And he said, Mama, I'm home.", "hypothesis": "He called his mom as soon as the school bus dropped him off.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Yes, He called his mom as soon as the school bus dropped him off."}, "gen_args_1": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Also, He called his mom as soon as the school bus dropped him off."}, "gen_args_2": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? No, He called his mom as soon as the school bus dropped him off."}}, "resps": [[["-97.0", "False"]], [["-99.0", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-97.0", "False"], ["-99.0", "False"], ["-98.5", "False"]], "doc_hash": "14c71f5ef25b6c09d320fb0c82ce486c67e5491825ee27a2f1e0579c589221cc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.73612472 0.09962365 0.16425163]"]}
{"doc_id": 8, "doc": {"premise": "He didn't get to go.", "hypothesis": "He wasn't allowed to go to the museum's opening.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't get to go., right? Yes, He wasn't allowed to go to the museum's opening."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't get to go., right? Also, He wasn't allowed to go to the museum's opening."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't get to go., right? No, He wasn't allowed to go to the museum's opening."}}, "resps": [[["-85.5", "False"]], [["-89.0", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-85.5", "False"], ["-89.0", "False"], ["-86.0", "False"]], "doc_hash": "ad6a73f927d335f9359e677fbce517445e03f4d4bcda61799a082b528546f140", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61097505 0.01844985 0.3705751 ]"]}
{"doc_id": 16, "doc": {"premise": "And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white.", "hypothesis": "They didn't visit the family anymore.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Yes, They didn't visit the family anymore."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Also, They didn't visit the family anymore."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? No, They didn't visit the family anymore."}}, "resps": [[["-151.0", "False"]], [["-158.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-158.0", "False"], ["-152.0", "False"]], "doc_hash": "d8e2cf9dadd36107f9a4ecfb57dc61e5db5bd10487374c7e44487a81997158b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 24, "doc": {"premise": "But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property.", "hypothesis": "His dad had never owned anything in his life.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Yes, His dad had never owned anything in his life."}, "gen_args_1": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Also, His dad had never owned anything in his life."}, "gen_args_2": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? No, His dad had never owned anything in his life."}}, "resps": [[["-156.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "26c482935019c79283c6ca7cd8baf48a25f7a3937544cfb4e236c544e90ba51d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00242826 0.01794253 0.97962921]"]}
{"doc_id": 32, "doc": {"premise": "Now that's how, uh, I stay buckled in.", "hypothesis": "That is precisely how I was fastened in.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Yes, That is precisely how I was fastened in."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Also, That is precisely how I was fastened in."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? No, That is precisely how I was fastened in."}}, "resps": [[["-112.5", "False"]], [["-121.0", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-121.0", "False"], ["-115.5", "False"]], "doc_hash": "50d9c27c087ba78387cff10b792d3e8f9e455102bd51f8e8094c9592e283e39c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52389536e-01 1.93781146e-04 4.74166829e-02]"]}
{"doc_id": 40, "doc": {"premise": "And, she didn't really understand.", "hypothesis": "Indeed, she did not comprehend.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Yes, Indeed, she did not comprehend."}, "gen_args_1": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Also, Indeed, she did not comprehend."}, "gen_args_2": {"arg_0": "", "arg_1": " And, she didn't really understand., right? No, Indeed, she did not comprehend."}}, "resps": [[["-80.5", "False"]], [["-85.5", "False"]], [["-82.5", "False"]]], "filtered_resps": [["-80.5", "False"], ["-85.5", "False"], ["-82.5", "False"]], "doc_hash": "8a85f61aea816636cbb715bbdcdf61197ea2cc9e3a4ecff5360f3505a3b8030c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 48, "doc": {"premise": "I need you to do something for me.", "hypothesis": "I don't need any help.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I need you to do something for me., right? Yes, I don't need any help."}, "gen_args_1": {"arg_0": "", "arg_1": " I need you to do something for me., right? Also, I don't need any help."}, "gen_args_2": {"arg_0": "", "arg_1": " I need you to do something for me., right? No, I don't need any help."}}, "resps": [[["-63.75", "False"]], [["-66.0", "False"]], [["-59.25", "False"]]], "filtered_resps": [["-63.75", "False"], ["-66.0", "False"], ["-59.25", "False"]], "doc_hash": "9dba382df5223cdced7c83119604a541fe510ffcf4dd872d7097affd52a714e3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01097423 0.00115668 0.98786909]"]}
{"doc_id": 56, "doc": {"premise": "It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's.", "hypothesis": "We were blessed to have Rudolph Anderson help with the U2's.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Yes, We were blessed to have Rudolph Anderson help with the U2's."}, "gen_args_1": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Also, We were blessed to have Rudolph Anderson help with the U2's."}, "gen_args_2": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? No, We were blessed to have Rudolph Anderson help with the U2's."}}, "resps": [[["-182.0", "False"]], [["-188.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-188.0", "False"], ["-184.0", "False"]], "doc_hash": "3c74cee277b78c4e2dcc248cd1b876f35bd2ea3acbc663103515b9e42078cb9a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 64, "doc": {"premise": "But all of a sudden, we was called out to look at what was flying.", "hypothesis": "We were supposed to look at what was flying.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Yes, We were supposed to look at what was flying."}, "gen_args_1": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Also, We were supposed to look at what was flying."}, "gen_args_2": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? No, We were supposed to look at what was flying."}}, "resps": [[["-109.0", "False"]], [["-116.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-116.0", "False"], ["-109.0", "False"]], "doc_hash": "699e95af991df8f93da65ae5e6cc304feee55e35e1ea5da57ca55046e0e6d97a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 72, "doc": {"premise": "That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities.", "hypothesis": "I was in Special Activities for years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Yes, I was in Special Activities for years."}, "gen_args_1": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Also, I was in Special Activities for years."}, "gen_args_2": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? No, I was in Special Activities for years."}}, "resps": [[["-138.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "6d5ef2130c3fcc5ca1f26959aacdf0f1d14e8139bbd9e8f1a6f7c21e6a395b51", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 80, "doc": {"premise": "And it makes you feel just awful.", "hypothesis": "You feel better after an hour.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Yes, You feel better after an hour."}, "gen_args_1": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Also, You feel better after an hour."}, "gen_args_2": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? No, You feel better after an hour."}}, "resps": [[["-86.0", "False"]], [["-89.0", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-86.0", "False"], ["-89.0", "False"], ["-84.5", "False"]], "doc_hash": "543477771380081d0a51341c74ff636f8d1601630743a5b004ec6cd0fd8c4d76", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.18078357 0.00900068 0.81021575]"]}
{"doc_id": 88, "doc": {"premise": "Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas.", "hypothesis": "It seemed to take forever.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Yes, It seemed to take forever."}, "gen_args_1": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Also, It seemed to take forever."}, "gen_args_2": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? No, It seemed to take forever."}}, "resps": [[["-143.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "57278b254e8b0fc19f8d404a9cd458247456380afa62b6b25efa7cf7d1f27005", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 96, "doc": {"premise": "And then once you get everything entered you can go on from there.", "hypothesis": "You can continue after you enter everything.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Yes, You can continue after you enter everything."}, "gen_args_1": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Also, You can continue after you enter everything."}, "gen_args_2": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? No, You can continue after you enter everything."}}, "resps": [[["-101.0", "False"]], [["-110.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-101.0", "False"], ["-110.0", "False"], ["-104.5", "False"]], "doc_hash": "077cfcee52d744b128633720ca5a6a76eb961bb6dfb59d6828300e90f894a2cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70571502e-01 1.19778039e-04 2.93087198e-02]"]}
{"doc_id": 104, "doc": {"premise": "They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do.", "hypothesis": "Joe died and it was really depressing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Yes, Joe died and it was really depressing."}, "gen_args_1": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Also, Joe died and it was really depressing."}, "gen_args_2": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? No, Joe died and it was really depressing."}}, "resps": [[["-175.0", "False"]], [["-174.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-174.0", "False"], ["-174.0", "False"]], "doc_hash": "884083f89c73888717d9d96fe8a311fc09ef2d8e5fbd9ed8621f5569c6008b5e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 112, "doc": {"premise": "It wasn't nothing but a desert; there was sagebrush out on the runway.", "hypothesis": "There was a lot of scrubbby foilage in the area.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Yes, There was a lot of scrubbby foilage in the area."}, "gen_args_1": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Also, There was a lot of scrubbby foilage in the area."}, "gen_args_2": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? No, There was a lot of scrubbby foilage in the area."}}, "resps": [[["-151.0", "False"]], [["-150.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-150.0", "False"], ["-148.0", "False"]], "doc_hash": "08ac983bd5100e23b3f2bd86389b935702f21c4d4303d06cf63017f80bc3fd0d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 120, "doc": {"premise": "So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing.", "hypothesis": "I did not bother to call Ramona.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Yes, I did not bother to call Ramona."}, "gen_args_1": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Also, I did not bother to call Ramona."}, "gen_args_2": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? No, I did not bother to call Ramona."}}, "resps": [[["-186.0", "False"]], [["-186.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-186.0", "False"], ["-182.0", "False"]], "doc_hash": "aea0720fcb96a38d28489895a616857972a46cf0670ccf78bc7b95b79820bc6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 128, "doc": {"premise": "Well, there's nobody there to help me.", "hypothesis": "There isn't anyone in that place to assist me.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Yes, There isn't anyone in that place to assist me."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Also, There isn't anyone in that place to assist me."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? No, There isn't anyone in that place to assist me."}}, "resps": [[["-89.0", "False"]], [["-91.0", "False"]], [["-88.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-91.0", "False"], ["-88.0", "False"]], "doc_hash": "4dfe0ed07c3cf6730274026343e24e14ab60ba33919dc6e1e60b46d213b13ff3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 136, "doc": {"premise": "That's why I didn't graduate college, but I never, I never read any of the books I was supposed to.", "hypothesis": "I finished college with honors.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Yes, I finished college with honors."}, "gen_args_1": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Also, I finished college with honors."}, "gen_args_2": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? No, I finished college with honors."}}, "resps": [[["-114.5", "False"]], [["-115.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-115.5", "False"], ["-112.5", "False"]], "doc_hash": "ae5b32938673c0a672a975a590fb5cd0f8e8dbfebe206c874db2a8588aad3843", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 144, "doc": {"premise": "The story I shall talk about today is about my father and the culture diversities he had when he moved to America.", "hypothesis": "I don't want to talk about my parents.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Yes, I don't want to talk about my parents."}, "gen_args_1": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Also, I don't want to talk about my parents."}, "gen_args_2": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? No, I don't want to talk about my parents."}}, "resps": [[["-135.0", "False"]], [["-138.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-138.0", "False"], ["-132.0", "False"]], "doc_hash": "14793ee4a1ce988921de1ed1043bd5940800e1adcbc1b8f36412dad413c9a703", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 152, "doc": {"premise": "And then I heard him leave, so I'm still finishing what I had to do.", "hypothesis": "I'm not going to bother doing this stuff.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Yes, I'm not going to bother doing this stuff."}, "gen_args_1": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Also, I'm not going to bother doing this stuff."}, "gen_args_2": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? No, I'm not going to bother doing this stuff."}}, "resps": [[["-120.0", "False"]], [["-121.5", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-121.5", "False"], ["-115.0", "False"]], "doc_hash": "0511cf257c40a8beda863a02ab20647055660f2ed5767a4b2ff747db617bb828", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00668287 0.00149115 0.99182598]"]}
{"doc_id": 160, "doc": {"premise": "And so when they told her she had to go home with this guy, she said, Go home with him?", "hypothesis": "They told her she had to sleep with the man.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Yes, They told her she had to sleep with the man."}, "gen_args_1": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Also, They told her she had to sleep with the man."}, "gen_args_2": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? No, They told her she had to sleep with the man."}}, "resps": [[["-121.0", "False"]], [["-126.5", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-126.5", "False"], ["-120.5", "False"]], "doc_hash": "9205eafedcf9869bfcb94839838f7650d9470919c3b3de5001396223f9c448d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37695905 0.00154055 0.6215004 ]"]}
{"doc_id": 168, "doc": {"premise": "Even though I don't see how he could have expected me to have it done.", "hypothesis": "I don't understand why he expected me to finish the drawing today", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Yes, I don't understand why he expected me to finish the drawing today"}, "gen_args_1": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Also, I don't understand why he expected me to finish the drawing today"}, "gen_args_2": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? No, I don't understand why he expected me to finish the drawing today"}}, "resps": [[["-117.5", "False"]], [["-118.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-117.5", "False"], ["-118.0", "False"], ["-117.5", "False"]], "doc_hash": "a857cac45f4f566478687933cf61e4a76f93516441982cf458f89ed993d47a35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.38365173 0.23269654 0.38365173]"]}
{"doc_id": 176, "doc": {"premise": "They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington.", "hypothesis": "They told me to pick up by white suitcase.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Yes, They told me to pick up by white suitcase."}, "gen_args_1": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Also, They told me to pick up by white suitcase."}, "gen_args_2": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? No, They told me to pick up by white suitcase."}}, "resps": [[["-182.0", "False"]], [["-183.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-183.0", "False"], ["-184.0", "False"]], "doc_hash": "b3b5b776adaf13210ca98d6cffbbce77161d56b76a1d003cdb78e20a94901e4b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 184, "doc": {"premise": "Is there any reason why she didn't tell you?", "hypothesis": "Why wouldn't she tell you about it?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Yes, Why wouldn't she tell you about it?"}, "gen_args_1": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Also, Why wouldn't she tell you about it?"}, "gen_args_2": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? No, Why wouldn't she tell you about it?"}}, "resps": [[["-84.5", "False"]], [["-83.0", "False"]], [["-85.5", "False"]]], "filtered_resps": [["-84.5", "False"], ["-83.0", "False"], ["-85.5", "False"]], "doc_hash": "0cc4b21591b51d69577f76326a78b16975b9e586497fabe5811edbda7e7e0644", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.17095278 0.76615721 0.06289001]"]}
{"doc_id": 192, "doc": {"premise": "We didn't know what a U2 was and nobody knew anything about a U2.", "hypothesis": "We didn't know what the heck a u2 was.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Yes, We didn't know what the heck a u2 was."}, "gen_args_1": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Also, We didn't know what the heck a u2 was."}, "gen_args_2": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? No, We didn't know what the heck a u2 was."}}, "resps": [[["-109.0", "False"]], [["-112.0", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-109.0", "False"], ["-112.0", "False"], ["-108.5", "False"]], "doc_hash": "6d813b61316983dadd2d663e306799eed768be8f4f2dde028d6853f312b364c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.3705751  0.01844985 0.61097505]"]}
{"doc_id": 200, "doc": {"premise": "So he stayed in Augusta after that?", "hypothesis": "I know he left Augusta immediately.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Yes, I know he left Augusta immediately."}, "gen_args_1": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Also, I know he left Augusta immediately."}, "gen_args_2": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? No, I know he left Augusta immediately."}}, "resps": [[["-89.0", "False"]], [["-96.5", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-96.5", "False"], ["-86.0", "False"]], "doc_hash": "870343a8387f42e58adec75af1d9fc189199d3b605364e8da8ca5d178b0f922e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74246292e-02 2.62298212e-05 9.52549141e-01]"]}
{"doc_id": 208, "doc": {"premise": "And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast.", "hypothesis": "She kept talking.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Yes, She kept talking."}, "gen_args_1": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Also, She kept talking."}, "gen_args_2": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? No, She kept talking."}}, "resps": [[["-150.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "2cd6d3d0fb446d93f661392128892d8a05a2dec51ed12f1b2e9cd55275d4c1fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 216, "doc": {"premise": "I'll call you back in about an hour, he says.", "hypothesis": "He said he would call once he got home.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Yes, He said he would call once he got home."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Also, He said he would call once he got home."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? No, He said he would call once he got home."}}, "resps": [[["-92.0", "False"]], [["-93.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-92.0", "False"], ["-93.0", "False"], ["-89.0", "False"]], "doc_hash": "1e8be0ba29f117925bb415d7f0edee912f89798614291102fa61f4006d705e8d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 224, "doc": {"premise": "I had to start training in course.", "hypothesis": "I had to start preparing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I had to start training in course., right? Yes, I had to start preparing."}, "gen_args_1": {"arg_0": "", "arg_1": " I had to start training in course., right? Also, I had to start preparing."}, "gen_args_2": {"arg_0": "", "arg_1": " I had to start training in course., right? No, I had to start preparing."}}, "resps": [[["-81.0", "False"]], [["-86.0", "False"]], [["-81.5", "False"]]], "filtered_resps": [["-81.0", "False"], ["-86.0", "False"], ["-81.5", "False"]], "doc_hash": "38b2176312d21d09e2f6cba47dbbc847f80e4d60192356f9a09c7ab242e5557d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61985958 0.00417658 0.37596384]"]}
{"doc_id": 232, "doc": {"premise": "They didn't want to stay captive.", "hypothesis": "They had been detained in relation to a recent robbery.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Yes, They had been detained in relation to a recent robbery."}, "gen_args_1": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Also, They had been detained in relation to a recent robbery."}, "gen_args_2": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? No, They had been detained in relation to a recent robbery."}}, "resps": [[["-103.5", "False"]], [["-108.0", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-103.5", "False"], ["-108.0", "False"], ["-103.5", "False"]], "doc_hash": "578e25ff1ccd8c0b21031ea837a5f206dded996542c50806423baa814d769a00", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 240, "doc": {"premise": "And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area.", "hypothesis": "They left Augusta and went to Atlanta.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Yes, They left Augusta and went to Atlanta."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Also, They left Augusta and went to Atlanta."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? No, They left Augusta and went to Atlanta."}}, "resps": [[["-205.0", "False"]], [["-208.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-208.0", "False"], ["-203.0", "False"]], "doc_hash": "99f515be8be6e3ee2fcf2991efc7d7573636b0cc7889d6a6df0c5c49afe56f7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 248, "doc": {"premise": "She's like, But you need to look here, look here, she's gives me like three different places to look in the computer.", "hypothesis": "She told me where to search.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Yes, She told me where to search."}, "gen_args_1": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Also, She told me where to search."}, "gen_args_2": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? No, She told me where to search."}}, "resps": [[["-147.0", "False"]], [["-153.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-153.0", "False"], ["-148.0", "False"]], "doc_hash": "e0d3f1885361163c4928ea33718c3f301bb7d26085ac0ae0b899568e1dd084ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 256, "doc": {"premise": "exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think", "hypothesis": "I think you need to be devoted to it to do well.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Yes, I think you need to be devoted to it to do well."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Also, I think you need to be devoted to it to do well."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? No, I think you need to be devoted to it to do well."}}, "resps": [[["-168.0", "False"]], [["-175.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-175.0", "False"], ["-166.0", "False"]], "doc_hash": "ca74340f1f85a7eae890a32b8099821bb5cb6849afffca582d4878d0e2f9a72e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19189966e-01 1.08687181e-04 8.80701347e-01]"]}
{"doc_id": 264, "doc": {"premise": "and it can go on for ten twenty years i i think this is a little ridiculous", "hypothesis": "I think it's crazy that one lawsuit can go on so many years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Yes, I think it's crazy that one lawsuit can go on so many years."}, "gen_args_1": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Also, I think it's crazy that one lawsuit can go on so many years."}, "gen_args_2": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? No, I think it's crazy that one lawsuit can go on so many years."}}, "resps": [[["-127.5", "False"]], [["-133.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-133.0", "False"], ["-130.0", "False"]], "doc_hash": "c81f57c9a25dcf3946d1a6d17b16ad8d3e37ae87ed1e470f7fea0b223c9511fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.92066469 0.00376255 0.07557276]"]}
{"doc_id": 272, "doc": {"premise": "are you saying the teachers or the parents", "hypothesis": "What are you implying about the parents and the teachers?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Yes, What are you implying about the parents and the teachers?"}, "gen_args_1": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Also, What are you implying about the parents and the teachers?"}, "gen_args_2": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? No, What are you implying about the parents and the teachers?"}}, "resps": [[["-84.0", "False"]], [["-84.0", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-84.0", "False"], ["-84.0", "False"], ["-87.0", "False"]], "doc_hash": "badc81736375a9244f945d22bb680d8c4c07d4ce311fe0fa76ef78b70b548e77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 280, "doc": {"premise": "care about how the national news affects the local area", "hypothesis": "I could care less what the national news covers with concerns about our local areas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Yes, I could care less what the national news covers with concerns about our local areas."}, "gen_args_1": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Also, I could care less what the national news covers with concerns about our local areas."}, "gen_args_2": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? No, I could care less what the national news covers with concerns about our local areas."}}, "resps": [[["-114.0", "False"]], [["-113.0", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-113.0", "False"], ["-112.5", "False"]], "doc_hash": "1a1d8bcb0d3b343aa5abd73804316c4e45f794724a5041536b49fcb90e9d5bdc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.12195165 0.33149896 0.54654939]"]}
{"doc_id": 288, "doc": {"premise": "yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed", "hypothesis": "It would be easy to find out if the corporation was financed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Yes, It would be easy to find out if the corporation was financed."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Also, It would be easy to find out if the corporation was financed."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? No, It would be easy to find out if the corporation was financed."}}, "resps": [[["-157.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "2fc8fe54401eb914087525d44ca257ff7b0ebcb5917d982ed172391eb50c1628", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 296, "doc": {"premise": "and uh i kind of kind of like the black eyed pea but i don't think it's a chain", "hypothesis": "The Black Eyed Pea is likable, I think its corporate.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Yes, The Black Eyed Pea is likable, I think its corporate."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Also, The Black Eyed Pea is likable, I think its corporate."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? No, The Black Eyed Pea is likable, I think its corporate."}}, "resps": [[["-147.0", "False"]], [["-152.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-152.0", "False"], ["-146.0", "False"]], "doc_hash": "f396df3011b33e1ff7a34bc3fb86110c11a5667de768eb46f9274d26b0e0f6e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 304, "doc": {"premise": "it's it's really bad it uh i", "hypothesis": "It is horrible.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Yes, It is horrible."}, "gen_args_1": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Also, It is horrible."}, "gen_args_2": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? No, It is horrible."}}, "resps": [[["-83.5", "False"]], [["-94.0", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-83.5", "False"], ["-94.0", "False"], ["-85.0", "False"]], "doc_hash": "e4f19ae0811cf33bd7666e9414ef7e2e16141bfe83eeb881a2d52552056e4937", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.17556070e-01 2.25125913e-05 1.82421417e-01]"]}
{"doc_id": 312, "doc": {"premise": "exactly and i was very flattered until she told me she the company she was with", "hypothesis": "I do not like the company she is with.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Yes, I do not like the company she is with."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Also, I do not like the company she is with."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? No, I do not like the company she is with."}}, "resps": [[["-120.0", "False"]], [["-121.0", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-120.0", "False"], ["-121.0", "False"], ["-118.5", "False"]], "doc_hash": "d9d6f286bcaa966e5218e08c105d8481ba4c9a8a4cebab49ac1ab6b5aba35233", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.17095278 0.06289001 0.76615721]"]}
{"doc_id": 320, "doc": {"premise": "yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was", "hypothesis": "We threw a surprise birthday for her.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Yes, We threw a surprise birthday for her."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Also, We threw a surprise birthday for her."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? No, We threw a surprise birthday for her."}}, "resps": [[["-129.0", "False"]], [["-137.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-137.0", "False"], ["-130.0", "False"]], "doc_hash": "5a41039e3353ec0bf6f0f780ebacbbcffd749a3e00b2ba0c0c3430574fcfaf0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 328, "doc": {"premise": "course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know", "hypothesis": "That might cause crime to increase.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Yes, That might cause crime to increase."}, "gen_args_1": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Also, That might cause crime to increase."}, "gen_args_2": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? No, That might cause crime to increase."}}, "resps": [[["-196.0", "False"]], [["-201.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-201.0", "False"], ["-200.0", "False"]], "doc_hash": "d09c38d4e08dec26328e7b0bd1096833279d212a00879ac4b533a408f0cff3b9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 336, "doc": {"premise": "uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news", "hypothesis": "Do you think that the local newspapers are not interested in what the citizens have to say?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Yes, Do you think that the local newspapers are not interested in what the citizens have to say?"}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Also, Do you think that the local newspapers are not interested in what the citizens have to say?"}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? No, Do you think that the local newspapers are not interested in what the citizens have to say?"}}, "resps": [[["-158.0", "False"]], [["-161.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-161.0", "False"], ["-158.0", "False"]], "doc_hash": "1ce35fe6542f25c208a8b4d1de1da25b362cd06b860ae923d2a600447aefb79a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 344, "doc": {"premise": "well why don't you start because you've had more time to think about it if you don't mind", "hypothesis": "You should go last because you don't know anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Yes, You should go last because you don't know anything."}, "gen_args_1": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Also, You should go last because you don't know anything."}, "gen_args_2": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? No, You should go last because you don't know anything."}}, "resps": [[["-116.5", "False"]], [["-121.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-121.0", "False"], ["-111.0", "False"]], "doc_hash": "2748332d90e4788d930472498064c4b41fe74576933ef81c66e93ad2ef2f0b17", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06995369e-03 4.52131015e-05 9.95884833e-01]"]}
{"doc_id": 352, "doc": {"premise": "oh um no but they do have hay horse races  at the Oaklawn tracks", "hypothesis": "There are hay horse races at the tracks at Oaklawn.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Yes, There are hay horse races at the tracks at Oaklawn."}, "gen_args_1": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Also, There are hay horse races at the tracks at Oaklawn."}, "gen_args_2": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? No, There are hay horse races at the tracks at Oaklawn."}}, "resps": [[["-141.0", "False"]], [["-150.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-150.0", "False"], ["-145.0", "False"]], "doc_hash": "d618cd76f156044deca678e67df94fc66cf8be3dc83e7d0e019b79a1f604d747", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81894794e-01 1.21175444e-04 1.79840305e-02]"]}
{"doc_id": 360, "doc": {"premise": "is it twenty percent interest", "hypothesis": "Could the interest be more than 20?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Yes, Could the interest be more than 20?"}, "gen_args_1": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Also, Could the interest be more than 20?"}, "gen_args_2": {"arg_0": "", "arg_1": " is it twenty percent interest, right? No, Could the interest be more than 20?"}}, "resps": [[["-84.0", "False"]], [["-86.5", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-84.0", "False"], ["-86.5", "False"], ["-84.5", "False"]], "doc_hash": "2a7b2bfee5cd175f7e9658672db71b809be017006f30cd55b3126425b94afe13", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 368, "doc": {"premise": "uh-huh it's funny and um i i guess i just like funny shows mostly", "hypothesis": "I may have to watch this new comedy show.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Yes, I may have to watch this new comedy show."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Also, I may have to watch this new comedy show."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? No, I may have to watch this new comedy show."}}, "resps": [[["-125.5", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-125.5", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "6164d53f47b4d3d2f697e5646fdb4f74004d1ff11f091c50dd755c8b3a10a666", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.91475073 0.01016196 0.07508731]"]}
{"doc_id": 376, "doc": {"premise": "do you do you wilderness camp", "hypothesis": "Did you go to the indoor camp?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Yes, Did you go to the indoor camp?"}, "gen_args_1": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Also, Did you go to the indoor camp?"}, "gen_args_2": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? No, Did you go to the indoor camp?"}}, "resps": [[["-91.5", "False"]], [["-92.0", "False"]], [["-91.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-92.0", "False"], ["-91.0", "False"]], "doc_hash": "e2a9c98378f58495f6e6195e63793e1e1b8ac588ab866074d6533427b65bd3bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.30719589 0.18632372 0.50648039]"]}
{"doc_id": 384, "doc": {"premise": "tag them or anything you you do it all yourself they tell you what to do but you do it all yourself", "hypothesis": "After they tell you what to do, you go ahead and do it yourself.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Yes, After they tell you what to do, you go ahead and do it yourself."}, "gen_args_1": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Also, After they tell you what to do, you go ahead and do it yourself."}, "gen_args_2": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? No, After they tell you what to do, you go ahead and do it yourself."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-134.0", "False"]], "doc_hash": "de0970a0f2375b532173154b237125192bcee986aa4e77638032ea1161a3573f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 392, "doc": {"premise": "and uh that was twenty five hundred people when i joined and uh", "hypothesis": "There is only at the most one hundred people that ever joined.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Yes, There is only at the most one hundred people that ever joined."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Also, There is only at the most one hundred people that ever joined."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? No, There is only at the most one hundred people that ever joined."}}, "resps": [[["-138.0", "False"]], [["-141.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-141.0", "False"], ["-134.0", "False"]], "doc_hash": "11bfce0842985f4dd1a8900f1be8325f5339a82ac31bf0636f997b6cd5420301", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 400, "doc": {"premise": "i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and", "hypothesis": "Anderson ran against Reagan as an independent.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Yes, Anderson ran against Reagan as an independent."}, "gen_args_1": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Also, Anderson ran against Reagan as an independent."}, "gen_args_2": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? No, Anderson ran against Reagan as an independent."}}, "resps": [[["-154.0", "False"]], [["-163.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-163.0", "False"], ["-156.0", "False"]], "doc_hash": "98f8be508ff6799415dbb9190a06238f9001d098100b1d506961b8e3d5536501", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80701347e-01 1.08687181e-04 1.19189966e-01]"]}
{"doc_id": 408, "doc": {"premise": "but they did something a little different with them", "hypothesis": "The did the same thing as everyone else.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Yes, The did the same thing as everyone else."}, "gen_args_1": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Also, The did the same thing as everyone else."}, "gen_args_2": {"arg_0": "", "arg_1": " but they did something a little different with them, right? No, The did the same thing as everyone else."}}, "resps": [[["-84.0", "False"]], [["-87.5", "False"]], [["-79.5", "False"]]], "filtered_resps": [["-84.0", "False"], ["-87.5", "False"], ["-79.5", "False"]], "doc_hash": "f2f0b75ef4521ea99493a9e55691ab6c5ac0d35b7ebcdd161bcb504f091e7f8e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.09832986e-02 3.31666880e-04 9.88685034e-01]"]}
{"doc_id": 416, "doc": {"premise": "well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture", "hypothesis": "The VCR only works for about a week and then it is broken again.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Yes, The VCR only works for about a week and then it is broken again."}, "gen_args_1": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Also, The VCR only works for about a week and then it is broken again."}, "gen_args_2": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? No, The VCR only works for about a week and then it is broken again."}}, "resps": [[["-186.0", "False"]], [["-186.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-186.0", "False"], ["-186.0", "False"]], "doc_hash": "8b24cd3e576be20d02d4861e5d969c175ec849db24f7beb4296fa2dd6a375f34", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 424, "doc": {"premise": "well oh well that's interesting do you uh did you take classes to learn how to do that", "hypothesis": "That is so lame, I am glad you dont know how to do it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Yes, That is so lame, I am glad you dont know how to do it."}, "gen_args_1": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Also, That is so lame, I am glad you dont know how to do it."}, "gen_args_2": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? No, That is so lame, I am glad you dont know how to do it."}}, "resps": [[["-145.0", "False"]], [["-148.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-148.0", "False"], ["-143.0", "False"]], "doc_hash": "1f416d7cfa1bca0a8714ac5398530c2a6e8df6e2aae7c366984e41e8f61f5231", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 432, "doc": {"premise": "yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families", "hypothesis": "Everyone takes care of their own family, no matter what.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Yes, Everyone takes care of their own family, no matter what."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Also, Everyone takes care of their own family, no matter what."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? No, Everyone takes care of their own family, no matter what."}}, "resps": [[["-206.0", "False"]], [["-210.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-210.0", "False"], ["-206.0", "False"]], "doc_hash": "452b4005c031eb0be1e7bb60ac1368539ef16c66d90a7b5b0d5342efab1230f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 440, "doc": {"premise": "okay and do they have good lasagna", "hypothesis": "Their lasagna is great because of the spicy sausage they use.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Yes, Their lasagna is great because of the spicy sausage they use."}, "gen_args_1": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Also, Their lasagna is great because of the spicy sausage they use."}, "gen_args_2": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? No, Their lasagna is great because of the spicy sausage they use."}}, "resps": [[["-98.0", "False"]], [["-104.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-98.0", "False"], ["-104.0", "False"], ["-100.5", "False"]], "doc_hash": "55d6de4af4a8bf4fb99e092f1c5e275d418caf1ff53e2b16f392ea80aef76b33", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.92202971 0.00228548 0.07568481]"]}
{"doc_id": 448, "doc": {"premise": "um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you", "hypothesis": "It's ok for parents to support their kids until they are able to do it on their own.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Yes, It's ok for parents to support their kids until they are able to do it on their own."}, "gen_args_1": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Also, It's ok for parents to support their kids until they are able to do it on their own."}, "gen_args_2": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? No, It's ok for parents to support their kids until they are able to do it on their own."}}, "resps": [[["-173.0", "False"]], [["-178.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-178.0", "False"], ["-175.0", "False"]], "doc_hash": "19b5eaa005101f3c5d0f7019e09fe2ee3ed4e2f806422a260e5b0750a8e04b06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 456, "doc": {"premise": "excuse me we pay for any you know the child care but we don't pay as much as they do off base", "hypothesis": "Childcare costs $2000 more off base.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Yes, Childcare costs $2000 more off base."}, "gen_args_1": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Also, Childcare costs $2000 more off base."}, "gen_args_2": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? No, Childcare costs $2000 more off base."}}, "resps": [[["-150.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "a3deaa738d1486d0cb194966f194eb3923f088c10e214c3c54ceb8fdac47fa4d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 464, "doc": {"premise": "yeah we have between the spouse and myself we have six", "hypothesis": "My spouse and I have six of them.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Yes, My spouse and I have six of them."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Also, My spouse and I have six of them."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? No, My spouse and I have six of them."}}, "resps": [[["-95.5", "False"]], [["-103.0", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-95.5", "False"], ["-103.0", "False"], ["-96.5", "False"]], "doc_hash": "736308254bc93c99765f7eb4eee9013f0347b46914fadb885ce436f0318f0374", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30763104e-01 4.04173651e-04 2.68832722e-01]"]}
{"doc_id": 472, "doc": {"premise": "and uh sometimes it's nice to go out and have a salad", "hypothesis": "I occasionally like to eat a vegetarian salad on the deck.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Yes, I occasionally like to eat a vegetarian salad on the deck."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Also, I occasionally like to eat a vegetarian salad on the deck."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? No, I occasionally like to eat a vegetarian salad on the deck."}}, "resps": [[["-109.0", "False"]], [["-113.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-109.0", "False"], ["-113.5", "False"], ["-113.5", "False"]], "doc_hash": "0bb0a575cd3706de5f811815567e0831d2b9fc160d714e8d81df6e92e108351e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97826492 0.01086754 0.01086754]"]}
{"doc_id": 480, "doc": {"premise": "and they just pretty much know how much they have coming in you know and they just make sure they don't buy over", "hypothesis": "They are aware of the money they have as income.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Yes, They are aware of the money they have as income."}, "gen_args_1": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Also, They are aware of the money they have as income."}, "gen_args_2": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? No, They are aware of the money they have as income."}}, "resps": [[["-141.0", "False"]], [["-146.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-146.0", "False"], ["-145.0", "False"]], "doc_hash": "ad645a4d498fb939d1cc441ccee2c35fb99fddc7be18df852492b7f1f5b47821", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 488, "doc": {"premise": "it's kind of like a soap a nighttime soap opera type thing", "hypothesis": "The show is a lot like Days of Our lives.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Yes, The show is a lot like Days of Our lives."}, "gen_args_1": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Also, The show is a lot like Days of Our lives."}, "gen_args_2": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? No, The show is a lot like Days of Our lives."}}, "resps": [[["-105.5", "False"]], [["-108.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-105.5", "False"], ["-108.5", "False"], ["-108.0", "False"]], "doc_hash": "22b29b642cd00d8b1a8af9b04c42f7d0b99891213d3472023f1b81c9cd7fb635", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.88349207 0.04398648 0.07252145]"]}
{"doc_id": 496, "doc": {"premise": "the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know", "hypothesis": "The contracts have raised lots of red flags with the lawyers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Yes, The contracts have raised lots of red flags with the lawyers."}, "gen_args_1": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Also, The contracts have raised lots of red flags with the lawyers."}, "gen_args_2": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? No, The contracts have raised lots of red flags with the lawyers."}}, "resps": [[["-229.0", "False"]], [["-232.0", "False"]], [["-234.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-232.0", "False"], ["-234.0", "False"]], "doc_hash": "90556c34644d63442d8424d03d4976543a567b8792a59fc366035c5826acf7f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.04712342 0.00637746]"]}
{"doc_id": 504, "doc": {"premise": "But I do not believe any such algorithmic tool can be complete.", "hypothesis": "The algorithm cannot decide how to make a perfect sandwich without human judgement.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Yes, The algorithm cannot decide how to make a perfect sandwich without human judgement."}, "gen_args_1": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Also, The algorithm cannot decide how to make a perfect sandwich without human judgement."}, "gen_args_2": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? No, The algorithm cannot decide how to make a perfect sandwich without human judgement."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-137.0", "False"]], "doc_hash": "a828872e5529a11af29d048e4e05cc8a8d3802d6887375e3e7b80d23246d764c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 512, "doc": {"premise": "The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory.", "hypothesis": "The right to recover slaves from free territories was not a popular right.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Yes, The right to recover slaves from free territories was not a popular right."}, "gen_args_1": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Also, The right to recover slaves from free territories was not a popular right."}, "gen_args_2": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? No, The right to recover slaves from free territories was not a popular right."}}, "resps": [[["-152.0", "False"]], [["-153.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-153.0", "False"], ["-150.0", "False"]], "doc_hash": "fec5d3c5847dd2cef98253cff0fc95402f8b84bed3b8d748691b04515441df50", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 520, "doc": {"premise": "For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?", "hypothesis": "Five year olds are concerned with what happens next.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Yes, Five year olds are concerned with what happens next."}, "gen_args_1": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Also, Five year olds are concerned with what happens next."}, "gen_args_2": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? No, Five year olds are concerned with what happens next."}}, "resps": [[["-144.0", "False"]], [["-146.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-146.0", "False"], ["-147.0", "False"]], "doc_hash": "c79044da56e6cfbf1deec9acd38ffc332bf93b60b53d4565cfcc8d13f68cb71c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 528, "doc": {"premise": "In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself.", "hypothesis": "In the final chapter, I only discuss how many licks it takes to get to the center of a Tootsie Roll Pop.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Yes, In the final chapter, I only discuss how many licks it takes to get to the center of a Tootsie Roll Pop."}, "gen_args_1": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Also, In the final chapter, I only discuss how many licks it takes to get to the center of a Tootsie Roll Pop."}, "gen_args_2": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? No, In the final chapter, I only discuss how many licks it takes to get to the center of a Tootsie Roll Pop."}}, "resps": [[["-159.0", "False"]], [["-160.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-160.0", "False"], ["-153.0", "False"]], "doc_hash": "33b139eacbb211ee5682ec6b04eb8cc284c6b2fb72dac7c46b3ae38f2a1d1d3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 536, "doc": {"premise": "No difference exists between younger and older classmates in achievement test scores.", "hypothesis": "Young and old classmates have different test results as age is a factor", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Yes, Young and old classmates have different test results as age is a factor"}, "gen_args_1": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Also, Young and old classmates have different test results as age is a factor"}, "gen_args_2": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? No, Young and old classmates have different test results as age is a factor"}}, "resps": [[["-125.0", "False"]], [["-129.0", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-129.0", "False"], ["-123.5", "False"]], "doc_hash": "7c37757dc2e3420ad317cdbbe152d3fca9fa2d237babb882e3b19bf26ef31399", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18181803 0.00333011 0.81485186]"]}
{"doc_id": 544, "doc": {"premise": "The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection.", "hypothesis": "Otitis media is incredibly rare during a child's preschool years.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Yes, Otitis media is incredibly rare during a child's preschool years."}, "gen_args_1": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Also, Otitis media is incredibly rare during a child's preschool years."}, "gen_args_2": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? No, Otitis media is incredibly rare during a child's preschool years."}}, "resps": [[["-130.0", "False"]], [["-134.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-134.0", "False"], ["-125.0", "False"]], "doc_hash": "770beda8e4acb4587fa217b763b1f79d145b541dbc3d0bc0efc37708b74518be", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 552, "doc": {"premise": "Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world.", "hypothesis": "We need labels so we can see where the organization is doing well.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Yes, We need labels so we can see where the organization is doing well."}, "gen_args_1": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Also, We need labels so we can see where the organization is doing well."}, "gen_args_2": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? No, We need labels so we can see where the organization is doing well."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-171.0", "False"]], "doc_hash": "4cb6efbf8d150f4f35450ca11679c6a6373c0659219e5322e8f719e081dac88d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 560, "doc": {"premise": "But consider bread and butter.", "hypothesis": "Think only about raisins and corn chips and nothing else.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But consider bread and butter., right? Yes, Think only about raisins and corn chips and nothing else."}, "gen_args_1": {"arg_0": "", "arg_1": " But consider bread and butter., right? Also, Think only about raisins and corn chips and nothing else."}, "gen_args_2": {"arg_0": "", "arg_1": " But consider bread and butter., right? No, Think only about raisins and corn chips and nothing else."}}, "resps": [[["-112.0", "False"]], [["-111.0", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-112.0", "False"], ["-111.0", "False"], ["-108.5", "False"]], "doc_hash": "246388efd34b4db0237c2bde490a1a2393dcce096a1d67e46a93be91cb3d909f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02714903 0.0737987  0.89905227]"]}
{"doc_id": 568, "doc": {"premise": "We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance.", "hypothesis": "The current models are brilliant but limited.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Yes, The current models are brilliant but limited."}, "gen_args_1": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Also, The current models are brilliant but limited."}, "gen_args_2": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? No, The current models are brilliant but limited."}}, "resps": [[["-215.0", "False"]], [["-221.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-221.0", "False"], ["-216.0", "False"]], "doc_hash": "6f7281c4b48761fabb225a1f998e113ab3190363d32ef8f9f670b8ead54da8f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 576, "doc": {"premise": "Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?", "hypothesis": "We always pay attention to everything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Yes, We always pay attention to everything."}, "gen_args_1": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Also, We always pay attention to everything."}, "gen_args_2": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? No, We always pay attention to everything."}}, "resps": [[["-143.0", "False"]], [["-149.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-149.0", "False"], ["-145.0", "False"]], "doc_hash": "cdac5347aae436d5ec1f814668a0626b450f82214a035ab504f40d0dc5ba5ef8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 584, "doc": {"premise": "The relationship between rights and freedom is thus turned on its head.", "hypothesis": "There is a relationship between your rights and freedom.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Yes, There is a relationship between your rights and freedom."}, "gen_args_1": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Also, There is a relationship between your rights and freedom."}, "gen_args_2": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? No, There is a relationship between your rights and freedom."}}, "resps": [[["-102.5", "False"]], [["-106.5", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.5", "False"], ["-103.5", "False"]], "doc_hash": "6f607445ccf5d170232ed0abacbbca1951db9e7d32c451018d1a0ff134a11ed8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 592, "doc": {"premise": "I begin life with an endowment of a hundred pears and a thousand apples.", "hypothesis": "I have something to eat.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Yes, I have something to eat."}, "gen_args_1": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Also, I have something to eat."}, "gen_args_2": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? No, I have something to eat."}}, "resps": [[["-112.0", "False"]], [["-115.0", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-115.0", "False"], ["-113.0", "False"]], "doc_hash": "b54b3a045ab00e8da60d59419021fe6c24ed2627b3b075c068e5c54cd28896ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 600, "doc": {"premise": "The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions.", "hypothesis": "No records remain of the traditions of the early Hispanos.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Yes, No records remain of the traditions of the early Hispanos."}, "gen_args_1": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Also, No records remain of the traditions of the early Hispanos."}, "gen_args_2": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? No, No records remain of the traditions of the early Hispanos."}}, "resps": [[["-206.0", "False"]], [["-207.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-207.0", "False"], ["-205.0", "False"]], "doc_hash": "322a4e287a0867df23befe054b36e33bc0983c0c70721a5e501ab25ebaa29c43", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 608, "doc": {"premise": "And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation.", "hypothesis": "There is no common assumption today.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Yes, There is no common assumption today."}, "gen_args_1": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Also, There is no common assumption today."}, "gen_args_2": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? No, There is no common assumption today."}}, "resps": [[["-163.0", "False"]], [["-165.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-165.0", "False"], ["-159.0", "False"]], "doc_hash": "5f3135f57facf69156a5b5c77a2d90e8fe4c87e917ee10c476c9c16e68cb929a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 616, "doc": {"premise": "While this is being done prayers are recited.", "hypothesis": "Other things happen while prayers are said.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Yes, Other things happen while prayers are said."}, "gen_args_1": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Also, Other things happen while prayers are said."}, "gen_args_2": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? No, Other things happen while prayers are said."}}, "resps": [[["-100.0", "False"]], [["-103.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-103.0", "False"], ["-100.5", "False"]], "doc_hash": "2da9ab2f25b4615b1f6fb94710a04bb7ac44863d9c151c3cb9ec128648d6146e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.6037489  0.03005889 0.36619222]"]}
{"doc_id": 624, "doc": {"premise": "During the preschool and elementary school years, thought is largely tied to the here-and-now.", "hypothesis": "Preschool and elementary aged children often dream about the future.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Yes, Preschool and elementary aged children often dream about the future."}, "gen_args_1": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Also, Preschool and elementary aged children often dream about the future."}, "gen_args_2": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? No, Preschool and elementary aged children often dream about the future."}}, "resps": [[["-127.5", "False"]], [["-130.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-130.0", "False"], ["-122.0", "False"]], "doc_hash": "e0048b889075975ad83a10eafefac1ddadee37cea9ad8bbb01911df9459c559a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06877835e-03 3.33985665e-04 9.95597236e-01]"]}
{"doc_id": 632, "doc": {"premise": "The same is true of the sense of nationhood.", "hypothesis": "This is applicable everywhere else save for the sense of nationhood.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Yes, This is applicable everywhere else save for the sense of nationhood."}, "gen_args_1": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Also, This is applicable everywhere else save for the sense of nationhood."}, "gen_args_2": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? No, This is applicable everywhere else save for the sense of nationhood."}}, "resps": [[["-112.0", "False"]], [["-116.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-116.0", "False"], ["-111.0", "False"]], "doc_hash": "3a81b1aaa26d9b6e28593c173f3891eae0e47c4589b965c0f6ad5a28dd02072e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 640, "doc": {"premise": "A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles.", "hypothesis": "Charles F. Lummis was a photographer.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Yes, Charles F. Lummis was a photographer."}, "gen_args_1": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Also, Charles F. Lummis was a photographer."}, "gen_args_2": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? No, Charles F. Lummis was a photographer."}}, "resps": [[["-171.0", "False"]], [["-176.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-176.0", "False"], ["-171.0", "False"]], "doc_hash": "04903734f997616c5bb388c8edaa8c13afa4ecacee1c27ae41359f1ef907734e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 648, "doc": {"premise": "I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game.", "hypothesis": "I could not address the natural game in this chapter.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Yes, I could not address the natural game in this chapter."}, "gen_args_1": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Also, I could not address the natural game in this chapter."}, "gen_args_2": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? No, I could not address the natural game in this chapter."}}, "resps": [[["-149.0", "False"]], [["-153.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-153.0", "False"], ["-148.0", "False"]], "doc_hash": "0f009741e754322a51362b64d4f346adb5ed4d2d7312cadddd51d8d8c37e9d58", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 656, "doc": {"premise": "If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear.", "hypothesis": "The particle-horizon problem is always there, regardless of the initial expansion model.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Yes, The particle-horizon problem is always there, regardless of the initial expansion model."}, "gen_args_1": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Also, The particle-horizon problem is always there, regardless of the initial expansion model."}, "gen_args_2": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? No, The particle-horizon problem is always there, regardless of the initial expansion model."}}, "resps": [[["-215.0", "False"]], [["-216.0", "False"]], [["-210.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-216.0", "False"], ["-210.0", "False"]], "doc_hash": "dd6beece6d6f93932e3ca7039d9ca5d231145b13bebacba3e7a51c58ca7dbb7e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 664, "doc": {"premise": "In turn, object must be on machine for minutes, then machine for minutes, and so on.", "hypothesis": "The object cannot be on the machine.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Yes, The object cannot be on the machine."}, "gen_args_1": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Also, The object cannot be on the machine."}, "gen_args_2": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? No, The object cannot be on the machine."}}, "resps": [[["-135.0", "False"]], [["-136.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-136.0", "False"], ["-132.0", "False"]], "doc_hash": "af7f834dcf0c0bf5e28b5b30df9ae716d2e3e54544544d60b3af220ca9d58a82", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 672, "doc": {"premise": "In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen.", "hypothesis": "In the poem, Joaquan lived in his car.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Yes, In the poem, Joaquan lived in his car."}, "gen_args_1": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Also, In the poem, Joaquan lived in his car."}, "gen_args_2": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? No, In the poem, Joaquan lived in his car."}}, "resps": [[["-225.0", "False"]], [["-228.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-225.0", "False"], ["-228.0", "False"], ["-224.0", "False"]], "doc_hash": "0f82db9778ac0ee13185cfedccfb4ad998f9d5b6c5af184a6dbb503d19a56981", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 680, "doc": {"premise": "Limpiar means to clean and a limpia is similar to a barrida.", "hypothesis": "The word that means to clean is Limpiar.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Yes, The word that means to clean is Limpiar."}, "gen_args_1": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Also, The word that means to clean is Limpiar."}, "gen_args_2": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? No, The word that means to clean is Limpiar."}}, "resps": [[["-123.0", "False"]], [["-126.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-126.5", "False"], ["-122.0", "False"]], "doc_hash": "06ebf05b654235e1c9e10973660f5f90950bf9b7f791256a571bf067fe5b2dba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26677486 0.0080559  0.72516924]"]}
{"doc_id": 688, "doc": {"premise": "A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions.", "hypothesis": "There are less important things in our future discussions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Yes, There are less important things in our future discussions."}, "gen_args_1": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Also, There are less important things in our future discussions."}, "gen_args_2": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? No, There are less important things in our future discussions."}}, "resps": [[["-209.0", "False"]], [["-213.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-213.0", "False"], ["-206.0", "False"]], "doc_hash": "b1710b40ce7f345fa178b6a3b21570a1e7f8ae1410db742f1e5a8e431c98f606", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 696, "doc": {"premise": "Riddles are fun and educational as well.", "hypothesis": "Riddles are boring and teach you nothing.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Yes, Riddles are boring and teach you nothing."}, "gen_args_1": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Also, Riddles are boring and teach you nothing."}, "gen_args_2": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? No, Riddles are boring and teach you nothing."}}, "resps": [[["-90.0", "False"]], [["-93.0", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-90.0", "False"], ["-93.0", "False"], ["-84.5", "False"]], "doc_hash": "f723ec7a91d0f101a7f7319eb8a036e7846131e5839fc9c1f7420453e5c137d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06931311e-03 2.02599170e-04 9.95728088e-01]"]}
{"doc_id": 704, "doc": {"premise": "Could statistical averaging be the source of order in organisms?", "hypothesis": "There is a theory that statistical averaging is the source of order in organisms.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Yes, There is a theory that statistical averaging is the source of order in organisms."}, "gen_args_1": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Also, There is a theory that statistical averaging is the source of order in organisms."}, "gen_args_2": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? No, There is a theory that statistical averaging is the source of order in organisms."}}, "resps": [[["-113.5", "False"]], [["-118.5", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-118.5", "False"], ["-118.0", "False"]], "doc_hash": "b8f3b87035865cdf63ae45262390ba4098c8be5b5d16d1e4f6823ca8d8716880", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98246599 0.0066198  0.01091421]"]}
{"doc_id": 712, "doc": {"premise": "Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers.", "hypothesis": "Gregorio Cortez is one of the folk heroes that confronted the Texas Rangers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Yes, Gregorio Cortez is one of the folk heroes that confronted the Texas Rangers."}, "gen_args_1": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Also, Gregorio Cortez is one of the folk heroes that confronted the Texas Rangers."}, "gen_args_2": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? No, Gregorio Cortez is one of the folk heroes that confronted the Texas Rangers."}}, "resps": [[["-174.0", "False"]], [["-183.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-183.0", "False"], ["-178.0", "False"]], "doc_hash": "91c937420ddaedf1b43fd84fead3826dffd89ef766f606308bfeb2719c41b0b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81894794e-01 1.21175444e-04 1.79840305e-02]"]}
{"doc_id": 720, "doc": {"premise": "15 The commander wants us to do something, and has used the language of the law to move us toward action.", "hypothesis": "If it weren't for the law, we would have disobeyed the commander.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Yes, If it weren't for the law, we would have disobeyed the commander."}, "gen_args_1": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Also, If it weren't for the law, we would have disobeyed the commander."}, "gen_args_2": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? No, If it weren't for the law, we would have disobeyed the commander."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-149.0", "False"]], "doc_hash": "5ae6a385f2c076d69a3d8b1f1d70dec96f66f0dad58e12a5bdd9343432174460", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 728, "doc": {"premise": "7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3).", "hypothesis": "There are two groups that are defined by demand variation.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Yes, There are two groups that are defined by demand variation."}, "gen_args_1": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Also, There are two groups that are defined by demand variation."}, "gen_args_2": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? No, There are two groups that are defined by demand variation."}}, "resps": [[["-191.0", "False"]], [["-192.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-192.0", "False"], ["-190.0", "False"]], "doc_hash": "287b14d66d09b1c545fe09103cd6579ad5899601711d30d24ecead32597b1f3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 736, "doc": {"premise": "La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale.", "hypothesis": "Katz only wrote about what other people did.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Yes, Katz only wrote about what other people did."}, "gen_args_1": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Also, Katz only wrote about what other people did."}, "gen_args_2": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? No, Katz only wrote about what other people did."}}, "resps": [[["-230.0", "False"]], [["-229.0", "False"]], [["-227.0", "False"]]], "filtered_resps": [["-230.0", "False"], ["-229.0", "False"], ["-227.0", "False"]], "doc_hash": "a4bfd9b9f6337cafd6a9bff3454500796679c5e967d962ed46b5d1b0ed8e56d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 744, "doc": {"premise": "What we see are details.", "hypothesis": "At this time there are no details available.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What we see are details., right? Yes, At this time there are no details available."}, "gen_args_1": {"arg_0": "", "arg_1": " What we see are details., right? Also, At this time there are no details available."}, "gen_args_2": {"arg_0": "", "arg_1": " What we see are details., right? No, At this time there are no details available."}}, "resps": [[["-88.0", "False"]], [["-90.5", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-88.0", "False"], ["-90.5", "False"], ["-87.0", "False"]], "doc_hash": "ffc7fbd84edd3798d2f3ad94b60fb15060403694d8f2ddd8e187eec90f00e301", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26313249 0.02159923 0.71526828]"]}
{"doc_id": 752, "doc": {"premise": "Jeremy Pitt answered the laugh with an oath.", "hypothesis": "Someone laughed near Jeremy Pitt.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Yes, Someone laughed near Jeremy Pitt."}, "gen_args_1": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Also, Someone laughed near Jeremy Pitt."}, "gen_args_2": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? No, Someone laughed near Jeremy Pitt."}}, "resps": [[["-122.5", "False"]], [["-128.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-128.0", "False"], ["-124.0", "False"]], "doc_hash": "c655720ee2900d91457a4a4603d836731c42372315119493d6548567b1c64570", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81485186 0.00333011 0.18181803]"]}
{"doc_id": 760, "doc": {"premise": "You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed.", "hypothesis": "He chose not to take his hands because they are tainted with a crime.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Yes, He chose not to take his hands because they are tainted with a crime."}, "gen_args_1": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Also, He chose not to take his hands because they are tainted with a crime."}, "gen_args_2": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? No, He chose not to take his hands because they are tainted with a crime."}}, "resps": [[["-224.0", "False"]], [["-228.0", "False"]], [["-223.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-228.0", "False"], ["-223.0", "False"]], "doc_hash": "b42825307d4cdf3ff4b15480338f806626e4140a436d14bcaaec9695b6e004a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 768, "doc": {"premise": "You are Lord Julian Wade, I understand,  was his truculent greeting.", "hypothesis": "Lord Julian Wade provided a warm and welcoming greeting.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Yes, Lord Julian Wade provided a warm and welcoming greeting."}, "gen_args_1": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Also, Lord Julian Wade provided a warm and welcoming greeting."}, "gen_args_2": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? No, Lord Julian Wade provided a warm and welcoming greeting."}}, "resps": [[["-156.0", "False"]], [["-162.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-162.0", "False"], ["-157.0", "False"]], "doc_hash": "8f84c7d858ec3f621072a2e8bac02668d03e558a177f374481a0fdfe12758863", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 776, "doc": {"premise": "There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him.", "hypothesis": "Port Royal has facilities for punishing criminals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Yes, Port Royal has facilities for punishing criminals."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Also, Port Royal has facilities for punishing criminals."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? No, Port Royal has facilities for punishing criminals."}}, "resps": [[["-205.0", "False"]], [["-203.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-203.0", "False"], ["-205.0", "False"]], "doc_hash": "bbd6c30ed2857cbf073c80f00888764682413f1feb5da95f11c67ca499b372e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 784, "doc": {"premise": "Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission.", "hypothesis": "Keeping him up at night was the fact that he accepted the King's commission.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Yes, Keeping him up at night was the fact that he accepted the King's commission."}, "gen_args_1": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Also, Keeping him up at night was the fact that he accepted the King's commission."}, "gen_args_2": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? No, Keeping him up at night was the fact that he accepted the King's commission."}}, "resps": [[["-168.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "e1bb3fe47818af76a45581f3cc9473c9c02e5793796389629f7ba3455afe650a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 792, "doc": {"premise": "Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure.", "hypothesis": "Her composure looked unnatural because she had a backache", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Yes, Her composure looked unnatural because she had a backache"}, "gen_args_1": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Also, Her composure looked unnatural because she had a backache"}, "gen_args_2": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? No, Her composure looked unnatural because she had a backache"}}, "resps": [[["-224.0", "False"]], [["-226.0", "False"]], [["-225.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-226.0", "False"], ["-225.0", "False"]], "doc_hash": "e5ae9984ee97c6071d70505bc3ff4c0d38e2b107360bd815eb4f0d899ba7fd6d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 800, "doc": {"premise": "Well, well, maybe he'll not find me quite so easy to grasp as he imagines.", "hypothesis": "I may not be as easy to grab as he thinks.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Yes, I may not be as easy to grab as he thinks."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Also, I may not be as easy to grab as he thinks."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? No, I may not be as easy to grab as he thinks."}}, "resps": [[["-118.0", "False"]], [["-119.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-119.0", "False"], ["-119.0", "False"]], "doc_hash": "3b9d7ac41f85975be4e1c51a2f8e6e227f5e3adabb9927e9d1e3ba6d815328a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 808, "doc": {"premise": "Thoughtfully he stroked his golden beard.", "hypothesis": "He had been growing his beard for years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Yes, He had been growing his beard for years."}, "gen_args_1": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Also, He had been growing his beard for years."}, "gen_args_2": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? No, He had been growing his beard for years."}}, "resps": [[["-98.0", "False"]], [["-102.5", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-102.5", "False"], ["-100.0", "False"]], "doc_hash": "f644a55720fc01ddb2e33171034d3bc6d4178c81944d85a0a88ad8019cf5d221", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 816, "doc": {"premise": "He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example.", "hypothesis": "He rose promptly, and proceeded to pull Lord Julian up to his feet.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Yes, He rose promptly, and proceeded to pull Lord Julian up to his feet."}, "gen_args_1": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Also, He rose promptly, and proceeded to pull Lord Julian up to his feet."}, "gen_args_2": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? No, He rose promptly, and proceeded to pull Lord Julian up to his feet."}}, "resps": [[["-175.0", "False"]], [["-183.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-183.0", "False"], ["-174.0", "False"]], "doc_hash": "a6b2d898cfdd8df5770be93ff44e1751df2288fa5dbb7e69171f309495cc748d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68917160e-01 9.02116571e-05 7.30992629e-01]"]}
{"doc_id": 824, "doc": {"premise": "Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis.", "hypothesis": "Wolverstone and Colonel Bishop were close friends.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Yes, Wolverstone and Colonel Bishop were close friends."}, "gen_args_1": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Also, Wolverstone and Colonel Bishop were close friends."}, "gen_args_2": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? No, Wolverstone and Colonel Bishop were close friends."}}, "resps": [[["-255.0", "False"]], [["-256.0", "False"]], [["-256.0", "False"]]], "filtered_resps": [["-255.0", "False"], ["-256.0", "False"], ["-256.0", "False"]], "doc_hash": "767b030051b7e4e2bc482866cc10dde5d7871335176ac185af6ff127f2bc7088", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 832, "doc": {"premise": "Your resolve delivered me from a horrible danger,  she admitted.", "hypothesis": "She had told him that resolve was what it took to keep her away from peril.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Yes, She had told him that resolve was what it took to keep her away from peril."}, "gen_args_1": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Also, She had told him that resolve was what it took to keep her away from peril."}, "gen_args_2": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? No, She had told him that resolve was what it took to keep her away from peril."}}, "resps": [[["-166.0", "False"]], [["-170.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-170.0", "False"], ["-166.0", "False"]], "doc_hash": "91d606e77fe1cd8d28a10c6db8e83a24cf8a2ffb07eac4e5d7a5abfdeedc226b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 840, "doc": {"premise": "Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully.", "hypothesis": "He had heard some exciting news.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Yes, He had heard some exciting news."}, "gen_args_1": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Also, He had heard some exciting news."}, "gen_args_2": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? No, He had heard some exciting news."}}, "resps": [[["-168.0", "False"]], [["-171.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-171.0", "False"], ["-169.0", "False"]], "doc_hash": "7a09e18b2c83ed40abf20be2e72f9c441c548127503357211973b2e6074e214c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 848, "doc": {"premise": "But Pitt, although he shared it, was prompt to obey.", "hypothesis": "Pitt quickly followed the order.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Yes, Pitt quickly followed the order."}, "gen_args_1": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Also, Pitt quickly followed the order."}, "gen_args_2": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? No, Pitt quickly followed the order."}}, "resps": [[["-117.0", "False"]], [["-124.0", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-124.0", "False"], ["-120.0", "False"]], "doc_hash": "e76f64534e1354e0d8f21bcac7b2392aeeffb73ea23cc79d6e7a4c2ede0137f0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 856, "doc": {"premise": "There's a thorn or two left on me.  And with a laugh Blood departed to his cabin.", "hypothesis": "Blood was laughing because he was joyful.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Yes, Blood was laughing because he was joyful."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Also, Blood was laughing because he was joyful."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? No, Blood was laughing because he was joyful."}}, "resps": [[["-171.0", "False"]], [["-177.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-177.0", "False"], ["-171.0", "False"]], "doc_hash": "472f5fc677449008ad417c9a52ef0346af73cac93749541239853181293ad4b6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 864, "doc": {"premise": "That was in Bridgetown on the night of the Spanish raid.", "hypothesis": "People were killed in the Spanish raid.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Yes, People were killed in the Spanish raid."}, "gen_args_1": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Also, People were killed in the Spanish raid."}, "gen_args_2": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? No, People were killed in the Spanish raid."}}, "resps": [[["-103.0", "False"]], [["-104.0", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-103.0", "False"], ["-104.0", "False"], ["-104.0", "False"]], "doc_hash": "a6aaafcd4b2c2f3b5addeed10fdf4606a8b35934d9873ae1e55c7457067b2cfe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 872, "doc": {"premise": "In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone.", "hypothesis": "There was absolutely no one at the garden whatsoever.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Yes, There was absolutely no one at the garden whatsoever."}, "gen_args_1": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Also, There was absolutely no one at the garden whatsoever."}, "gen_args_2": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? No, There was absolutely no one at the garden whatsoever."}}, "resps": [[["-189.0", "False"]], [["-191.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-191.0", "False"], ["-188.0", "False"]], "doc_hash": "200a5ab4404c0249cecb313dd890094415fba55e5ba4b5ebb55ca98842086f34", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 880, "doc": {"premise": "And who the devil may you be?  he exploded at last.", "hypothesis": "He quietly murmured to himself the whole time.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Yes, He quietly murmured to himself the whole time."}, "gen_args_1": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Also, He quietly murmured to himself the whole time."}, "gen_args_2": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? No, He quietly murmured to himself the whole time."}}, "resps": [[["-132.0", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "9c7cfd2004063e19fa87fe5cb0c16e83c2cfe062865bb2414f48072e3cb21d06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 888, "doc": {"premise": "Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion.", "hypothesis": "He has only one eye.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Yes, He has only one eye."}, "gen_args_1": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Also, He has only one eye."}, "gen_args_2": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? No, He has only one eye."}}, "resps": [[["-159.0", "False"]], [["-161.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-161.0", "False"], ["-157.0", "False"]], "doc_hash": "3b13ff4b54f7d1f5cb0847f17c6acd1103e7e8afb1ecae345b3dec9e4f846ed3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 896, "doc": {"premise": "And that was practically the end of the matter.", "hypothesis": "The solution to the matter was more or less there.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Yes, The solution to the matter was more or less there."}, "gen_args_1": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Also, The solution to the matter was more or less there."}, "gen_args_2": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? No, The solution to the matter was more or less there."}}, "resps": [[["-98.0", "False"]], [["-102.5", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-102.5", "False"], ["-101.0", "False"]], "doc_hash": "0f4886eb7da549abb78dbd5204b1c753cc02ae6aa2d3d3947303b6f690f290bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 904, "doc": {"premise": "There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk.", "hypothesis": "There is a way for them to sink.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Yes, There is a way for them to sink."}, "gen_args_1": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Also, There is a way for them to sink."}, "gen_args_2": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? No, There is a way for them to sink."}}, "resps": [[["-168.0", "False"]], [["-170.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-170.0", "False"], ["-169.0", "False"]], "doc_hash": "cf0c6be88377aebd0c291ec14b27559e57459c51791cbd7434247b4f97661110", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 912, "doc": {"premise": "If it is a mistake to grant Captain Blood a commission, the mistake is not mine.", "hypothesis": "There might have been an error to give Captain Blood his commission.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Yes, There might have been an error to give Captain Blood his commission."}, "gen_args_1": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Also, There might have been an error to give Captain Blood his commission."}, "gen_args_2": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? No, There might have been an error to give Captain Blood his commission."}}, "resps": [[["-136.0", "False"]], [["-136.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-136.0", "False"], ["-137.0", "False"]], "doc_hash": "5b2515846092528b856a249c054255774730bf41a996101800c54b68837b926c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 920, "doc": {"premise": "But it'll be about the Old Wolf that he wants to see you.", "hypothesis": "He wants to see you today about the Old Wolf.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Yes, He wants to see you today about the Old Wolf."}, "gen_args_1": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Also, He wants to see you today about the Old Wolf."}, "gen_args_2": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? No, He wants to see you today about the Old Wolf."}}, "resps": [[["-121.5", "False"]], [["-131.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-121.5", "False"], ["-131.0", "False"], ["-126.0", "False"]], "doc_hash": "b0cdb925e3e1fbf033dbd43f4878153c9bb15e219ca836575e0466a33adee15e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.88939847e-01 7.40239572e-05 1.09861293e-02]"]}
{"doc_id": 928, "doc": {"premise": "England's,  she corrected him in reproof.", "hypothesis": "She fixed his issue.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Yes, She fixed his issue."}, "gen_args_1": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Also, She fixed his issue."}, "gen_args_2": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? No, She fixed his issue."}}, "resps": [[["-121.5", "False"]], [["-127.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-121.5", "False"], ["-127.0", "False"], ["-121.0", "False"]], "doc_hash": "6e48a8948e76408013377f278d73a2b6e9053623a99e5fb306909d245111d96b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37695905 0.00154055 0.6215004 ]"]}
{"doc_id": 936, "doc": {"premise": "Ah, now, can't ye, indeed?  he cried.", "hypothesis": "He asked because he was rather shocked about the whole situation.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Yes, He asked because he was rather shocked about the whole situation."}, "gen_args_1": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Also, He asked because he was rather shocked about the whole situation."}, "gen_args_2": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? No, He asked because he was rather shocked about the whole situation."}}, "resps": [[["-151.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "7b7385b5d4489a00e0f163ed39f1d19c5a25b73f0017f66b2d4c79fb691b4e65", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 944, "doc": {"premise": "If anything it increased his excitement.", "hypothesis": "It made him more excited.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Yes, It made him more excited."}, "gen_args_1": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Also, It made him more excited."}, "gen_args_2": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? No, It made him more excited."}}, "resps": [[["-83.5", "False"]], [["-93.0", "False"]], [["-83.5", "False"]]], "filtered_resps": [["-83.5", "False"], ["-93.0", "False"], ["-83.5", "False"]], "doc_hash": "2136b684a969ee5e20f95f62dfdddcfe7c7bce52348c614d4d27c135219d88a2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99981288e-01 3.74245143e-05 4.99981288e-01]"]}
{"doc_id": 952, "doc": {"premise": "Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way.", "hypothesis": "His Majesty's Deputy-Governer of Jamaica is already dead.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Yes, His Majesty's Deputy-Governer of Jamaica is already dead."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Also, His Majesty's Deputy-Governer of Jamaica is already dead."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? No, His Majesty's Deputy-Governer of Jamaica is already dead."}}, "resps": [[["-191.0", "False"]], [["-194.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-194.0", "False"], ["-188.0", "False"]], "doc_hash": "710f69546919e024df7bdb876ad7d699d279cf639440290fd317d1d72d206fbf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 960, "doc": {"premise": "Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course.", "hypothesis": "Ogle never mentioned anyone who disliked the current course.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Yes, Ogle never mentioned anyone who disliked the current course."}, "gen_args_1": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Also, Ogle never mentioned anyone who disliked the current course."}, "gen_args_2": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? No, Ogle never mentioned anyone who disliked the current course."}}, "resps": [[["-199.0", "False"]], [["-200.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-200.0", "False"], ["-193.0", "False"]], "doc_hash": "4feb7a0da6f0311b39df4b08c9c2fcee1f460e633e8289cd1ddd5fe22ecc25ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 968, "doc": {"premise": "I'll not be bubbled by what Wolverstone has said.", "hypothesis": "Wolverstone had said something that did not make one feel bubbled.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Yes, Wolverstone had said something that did not make one feel bubbled."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Also, Wolverstone had said something that did not make one feel bubbled."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? No, Wolverstone had said something that did not make one feel bubbled."}}, "resps": [[["-149.0", "False"]], [["-154.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-154.0", "False"], ["-149.0", "False"]], "doc_hash": "b72f6ef7ecbe774079e52075c1eea2313c5228ae814399f54d23654239f7c839", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 976, "doc": {"premise": "Bid them take in sail, Jeremy,  he said quietly.", "hypothesis": "Jeremy shouted very loudly to get their attention.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Yes, Jeremy shouted very loudly to get their attention."}, "gen_args_1": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Also, Jeremy shouted very loudly to get their attention."}, "gen_args_2": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? No, Jeremy shouted very loudly to get their attention."}}, "resps": [[["-142.0", "False"]], [["-142.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-142.0", "False"], ["-141.0", "False"]], "doc_hash": "0eef7d4fec1678a7ee8b3335cbc04e936e8a070409bb244b49a584479a0120e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 984, "doc": {"premise": "For myself, I am entirely of Wolverstone's opinion.", "hypothesis": "I admit that I have disagreed with Wolverstone before.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Yes, I admit that I have disagreed with Wolverstone before."}, "gen_args_1": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Also, I admit that I have disagreed with Wolverstone before."}, "gen_args_2": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? No, I admit that I have disagreed with Wolverstone before."}}, "resps": [[["-116.5", "False"]], [["-119.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-119.5", "False"], ["-116.0", "False"]], "doc_hash": "3833b4ae095801090cd51d075fca6d37b584734c37c581ca6c6e0ad65279ca78", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.3705751  0.01844985 0.61097505]"]}
{"doc_id": 992, "doc": {"premise": "He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic.", "hypothesis": "The officer had a mustache.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Yes, The officer had a mustache."}, "gen_args_1": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Also, The officer had a mustache."}, "gen_args_2": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? No, The officer had a mustache."}}, "resps": [[["-202.0", "False"]], [["-201.0", "False"]], [["-202.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-201.0", "False"], ["-202.0", "False"]], "doc_hash": "fb8912c67884b55e057366fda702adbf52e623cfd2267241ebbfe45b0324de0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 1000, "doc": {"premise": "The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December.", "hypothesis": "The NYC Ballet has performances in June.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Yes, The NYC Ballet has performances in June."}, "gen_args_1": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Also, The NYC Ballet has performances in June."}, "gen_args_2": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? No, The NYC Ballet has performances in June."}}, "resps": [[["-130.0", "False"]], [["-129.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-129.0", "False"], ["-130.0", "False"]], "doc_hash": "31c86eaf24ef582638a216ac3ef907c13ce46c52a6b5d81b3d00cda9040385a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 1008, "doc": {"premise": "Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables.", "hypothesis": "The Seven Gables is the best sight to see.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Yes, The Seven Gables is the best sight to see."}, "gen_args_1": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Also, The Seven Gables is the best sight to see."}, "gen_args_2": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? No, The Seven Gables is the best sight to see."}}, "resps": [[["-121.5", "False"]], [["-129.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-121.5", "False"], ["-129.0", "False"], ["-125.0", "False"]], "doc_hash": "ed237ef6b7a25385be8d4ddbcd98ea5db955304ad30ace626476563f47e3a8ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.70166914e-01 5.36584156e-04 2.92965023e-02]"]}
{"doc_id": 1016, "doc": {"premise": "There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society.", "hypothesis": "You do not have to worry about language issues there, since everyone speaks English.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Yes, You do not have to worry about language issues there, since everyone speaks English."}, "gen_args_1": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Also, You do not have to worry about language issues there, since everyone speaks English."}, "gen_args_2": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? No, You do not have to worry about language issues there, since everyone speaks English."}}, "resps": [[["-188.0", "False"]], [["-187.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-187.0", "False"], ["-189.0", "False"]], "doc_hash": "acb283fcc13381d6cd0e2b911acf7521dc4839a9d12a24096a83c9910401dd8a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 1024, "doc": {"premise": "The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture.", "hypothesis": "Sant Pau has Romanesque lines.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Yes, Sant Pau has Romanesque lines."}, "gen_args_1": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Also, Sant Pau has Romanesque lines."}, "gen_args_2": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? No, Sant Pau has Romanesque lines."}}, "resps": [[["-145.0", "False"]], [["-152.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-152.0", "False"], ["-149.0", "False"]], "doc_hash": "095352b4f3c0f87279389f08db03c880227870eec4bf340f6f9a5c5879fa5cea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1032, "doc": {"premise": "The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year.", "hypothesis": "The staff works to eliminate the flamingos.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Yes, The staff works to eliminate the flamingos."}, "gen_args_1": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Also, The staff works to eliminate the flamingos."}, "gen_args_2": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? No, The staff works to eliminate the flamingos."}}, "resps": [[["-182.0", "False"]], [["-184.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-184.0", "False"], ["-171.0", "False"]], "doc_hash": "2f6fd051a1f24a2cb8590f954c008027c7351f05d929a78325c15e91d53eac22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.67013841e-05 2.26028655e-06 9.99981038e-01]"]}
{"doc_id": 1040, "doc": {"premise": "The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast.", "hypothesis": "There are 27 harbors along the mountains", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Yes, There are 27 harbors along the mountains"}, "gen_args_1": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Also, There are 27 harbors along the mountains"}, "gen_args_2": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? No, There are 27 harbors along the mountains"}}, "resps": [[["-185.0", "False"]], [["-187.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-187.0", "False"], ["-179.0", "False"]], "doc_hash": "4dec95bab807d42aaaf5ee276dc647665490ff764dc57fd142a33ee6223ab918", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 1048, "doc": {"premise": "Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle.", "hypothesis": "Umeda is the largest part of the entertainment district.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Yes, Umeda is the largest part of the entertainment district."}, "gen_args_1": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Also, Umeda is the largest part of the entertainment district."}, "gen_args_2": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? No, Umeda is the largest part of the entertainment district."}}, "resps": [[["-183.0", "False"]], [["-184.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-184.0", "False"], ["-184.0", "False"]], "doc_hash": "b5c424a6044bdb8f4ad37cafeccb1e10b09fbfe552f9d7f329522dc27678fa2d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1056, "doc": {"premise": "Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that.", "hypothesis": "10000 people died in the war.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Yes, 10000 people died in the war."}, "gen_args_1": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Also, 10000 people died in the war."}, "gen_args_2": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? No, 10000 people died in the war."}}, "resps": [[["-152.0", "False"]], [["-150.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-150.0", "False"], ["-152.0", "False"]], "doc_hash": "c3eabbe88b2ccdca654bf782bcd45887c3190f46877e5d72e01d0593474dd0ed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 1064, "doc": {"premise": "The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor.", "hypothesis": "You can't see anything old on display.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Yes, You can't see anything old on display."}, "gen_args_1": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Also, You can't see anything old on display."}, "gen_args_2": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? No, You can't see anything old on display."}}, "resps": [[["-197.0", "False"]], [["-200.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-200.0", "False"], ["-195.0", "False"]], "doc_hash": "87da40d7519d23c6f595ad1556d62cd0a69e421b91b6456fadbc78f296d497ff", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1072, "doc": {"premise": "Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott.", "hypothesis": "Hawthorne lived on Pinckney Street for 7 years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Yes, Hawthorne lived on Pinckney Street for 7 years."}, "gen_args_1": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Also, Hawthorne lived on Pinckney Street for 7 years."}, "gen_args_2": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? No, Hawthorne lived on Pinckney Street for 7 years."}}, "resps": [[["-241.0", "False"]], [["-244.0", "False"]], [["-247.0", "False"]]], "filtered_resps": [["-241.0", "False"], ["-244.0", "False"], ["-247.0", "False"]], "doc_hash": "5a71d0bf092e0c033d0e18b2b9cb7fe72938c49ba4184e757439790158d8f242", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.04731416 0.00235563]"]}
{"doc_id": 1080, "doc": {"premise": "Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications.", "hypothesis": "The two towers were built with limestone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Yes, The two towers were built with limestone."}, "gen_args_1": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Also, The two towers were built with limestone."}, "gen_args_2": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? No, The two towers were built with limestone."}}, "resps": [[["-144.0", "False"]], [["-144.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-144.0", "False"], ["-148.0", "False"]], "doc_hash": "94d58d2753139b463ad77b29cd19d0ac9f96fe7de3811c010e4821efcae538dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.49546264 0.00907471]"]}
{"doc_id": 1088, "doc": {"premise": "May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them.", "hypothesis": "Those people will be killed immediately.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Yes, Those people will be killed immediately."}, "gen_args_1": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Also, Those people will be killed immediately."}, "gen_args_2": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? No, Those people will be killed immediately."}}, "resps": [[["-176.0", "False"]], [["-180.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-180.0", "False"], ["-175.0", "False"]], "doc_hash": "5639ff47ca21a7fcd77c0eb6470dea1fc41a9de77ef59337d777a9a2d0442c6d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1096, "doc": {"premise": "As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda.", "hypothesis": "The chimney, among other things, indicate the village used to be part of a hacienda.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Yes, The chimney, among other things, indicate the village used to be part of a hacienda."}, "gen_args_1": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Also, The chimney, among other things, indicate the village used to be part of a hacienda."}, "gen_args_2": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? No, The chimney, among other things, indicate the village used to be part of a hacienda."}}, "resps": [[["-177.0", "False"]], [["-182.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-182.0", "False"], ["-181.0", "False"]], "doc_hash": "bf2e10aaa1529dfeb28fe3fba167b3a006e23c2d1adacee6349598b021f3811f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1104, "doc": {"premise": "These instruments played together form the basic  orchestra  for several popular musical genres.", "hypothesis": "The instruments are violin, bass, and saxophone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Yes, The instruments are violin, bass, and saxophone."}, "gen_args_1": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Also, The instruments are violin, bass, and saxophone."}, "gen_args_2": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? No, The instruments are violin, bass, and saxophone."}}, "resps": [[["-143.0", "False"]], [["-146.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-146.0", "False"], ["-144.0", "False"]], "doc_hash": "6df8df3180aa7aa611acd9b52ff805ff5aa8398ae76a9fc53ee9dac2e1c23535", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1112, "doc": {"premise": "Don't fire unless fired upon!", "hypothesis": "Only shoot if you have to.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Yes, Only shoot if you have to."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Also, Only shoot if you have to."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? No, Only shoot if you have to."}}, "resps": [[["-74.0", "False"]], [["-74.5", "False"]], [["-73.5", "False"]]], "filtered_resps": [["-74.0", "False"], ["-74.5", "False"], ["-73.5", "False"]], "doc_hash": "ffa25733b4b73739872efe6094fd66e83684fa33c3c76dc16e244196655fb000", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.30719589 0.18632372 0.50648039]"]}
{"doc_id": 1120, "doc": {"premise": "At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany.", "hypothesis": "Canada was known for welcoming immigrants and refugees.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Yes, Canada was known for welcoming immigrants and refugees."}, "gen_args_1": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Also, Canada was known for welcoming immigrants and refugees."}, "gen_args_2": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? No, Canada was known for welcoming immigrants and refugees."}}, "resps": [[["-153.0", "False"]], [["-158.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-158.0", "False"], ["-154.0", "False"]], "doc_hash": "f61518d5e45a43874d0474024cd695ddd79d0c16eae77db8db92ec9d24d28459", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1128, "doc": {"premise": "As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders.", "hypothesis": "Pierre was appointed but had to arrest himself for selling to the Americans.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Yes, Pierre was appointed but had to arrest himself for selling to the Americans."}, "gen_args_1": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Also, Pierre was appointed but had to arrest himself for selling to the Americans."}, "gen_args_2": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? No, Pierre was appointed but had to arrest himself for selling to the Americans."}}, "resps": [[["-207.0", "False"]], [["-212.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-212.0", "False"], ["-209.0", "False"]], "doc_hash": "4818bba104c8c3cd44a9797ee0e5680575e91c05dfb21ad587c6d91c970adb2d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1136, "doc": {"premise": "Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge.", "hypothesis": "The growing collection of clubs are unique and have a more urban edge.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Yes, The growing collection of clubs are unique and have a more urban edge."}, "gen_args_1": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Also, The growing collection of clubs are unique and have a more urban edge."}, "gen_args_2": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? No, The growing collection of clubs are unique and have a more urban edge."}}, "resps": [[["-170.0", "False"]], [["-174.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-174.0", "False"], ["-171.0", "False"]], "doc_hash": "1f922b4abbbc609d5bf9bf4ec9678876c640e8fb32f2e1fd382e2973b52664a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1144, "doc": {"premise": "On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony.", "hypothesis": "The locals can be joined during the weekends in the Parque de Palapas.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Yes, The locals can be joined during the weekends in the Parque de Palapas."}, "gen_args_1": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Also, The locals can be joined during the weekends in the Parque de Palapas."}, "gen_args_2": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? No, The locals can be joined during the weekends in the Parque de Palapas."}}, "resps": [[["-178.0", "False"]], [["-180.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-180.0", "False"], ["-179.0", "False"]], "doc_hash": "70d2370efac40634c90f6d80825e0ba860bacdc2c5a83995dbc4d1a69079d784", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1152, "doc": {"premise": "The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia.", "hypothesis": "The Montesserant is a river.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Yes, The Montesserant is a river."}, "gen_args_1": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Also, The Montesserant is a river."}, "gen_args_2": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? No, The Montesserant is a river."}}, "resps": [[["-186.0", "False"]], [["-189.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-189.0", "False"], ["-184.0", "False"]], "doc_hash": "f94c54e9e1d38c25fa4c7f1b329aba7a489a701f9dd82b9e5226e882e6a8dc16", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1160, "doc": {"premise": "Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market.", "hypothesis": "There is a market called Mercat de la Concepcie.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Yes, There is a market called Mercat de la Concepcie."}, "gen_args_1": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Also, There is a market called Mercat de la Concepcie."}, "gen_args_2": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? No, There is a market called Mercat de la Concepcie."}}, "resps": [[["-212.0", "False"]], [["-216.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-216.0", "False"], ["-217.0", "False"]], "doc_hash": "62a2b4442944005ce5db3b52cddbbea8ca6b106d495089b8e5401447c8800a30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1168, "doc": {"premise": "The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay.", "hypothesis": "Visitors like the area around the cathedral.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Yes, Visitors like the area around the cathedral."}, "gen_args_1": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Also, Visitors like the area around the cathedral."}, "gen_args_2": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? No, Visitors like the area around the cathedral."}}, "resps": [[["-135.0", "False"]], [["-144.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-144.0", "False"], ["-138.0", "False"]], "doc_hash": "17657c9ca5e9c46670c6d1490981235607f9145cd21ef9d830b94e4810075135", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52462158e-01 1.17543168e-04 4.74202986e-02]"]}
{"doc_id": 1176, "doc": {"premise": "Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity.", "hypothesis": "10000 people lived in Europe in the Stone Age.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Yes, 10000 people lived in Europe in the Stone Age."}, "gen_args_1": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Also, 10000 people lived in Europe in the Stone Age."}, "gen_args_2": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? No, 10000 people lived in Europe in the Stone Age."}}, "resps": [[["-124.0", "False"]], [["-125.5", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-125.5", "False"], ["-123.5", "False"]], "doc_hash": "c885d929c522df1f30afd2f611da2d7cf2d8b90c1e6d3838f001a64ccffb93d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.34820743 0.07769558 0.57409699]"]}
{"doc_id": 1184, "doc": {"premise": "Today the site is called the Temple of Heaven Park (Tiantan Gongyuan).", "hypothesis": "The Temple of Heaven Park burned down.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Yes, The Temple of Heaven Park burned down."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Also, The Temple of Heaven Park burned down."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? No, The Temple of Heaven Park burned down."}}, "resps": [[["-102.0", "False"]], [["-106.0", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-102.0", "False"], ["-106.0", "False"], ["-101.5", "False"]], "doc_hash": "ee4fdca79a44f0ba635ea5e124f483643a77cffe3ade28e2ad16aed51084f7a0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 1192, "doc": {"premise": "Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport.", "hypothesis": "Miramar is a dump.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Yes, Miramar is a dump."}, "gen_args_1": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Also, Miramar is a dump."}, "gen_args_2": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? No, Miramar is a dump."}}, "resps": [[["-163.0", "False"]], [["-167.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-167.0", "False"], ["-160.0", "False"]], "doc_hash": "0cc315fdf1bf5d102b450c2e3a9eed1c0d50a755f1df982b1edad7997ea108a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1200, "doc": {"premise": "The spirit of liberalism prevalent in Europe was tardy in reaching Spain.", "hypothesis": "Liberalism came to spain in 1920.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Yes, Liberalism came to spain in 1920."}, "gen_args_1": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Also, Liberalism came to spain in 1920."}, "gen_args_2": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? No, Liberalism came to spain in 1920."}}, "resps": [[["-130.0", "False"]], [["-132.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-132.0", "False"], ["-128.0", "False"]], "doc_hash": "ed354e8610a0d73dba005044905042ad3c2beb153d01dad86bdbde366c928705", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1208, "doc": {"premise": "Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates.", "hypothesis": "THe garden is smelly so no one wants to eat in it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Yes, THe garden is smelly so no one wants to eat in it."}, "gen_args_1": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Also, THe garden is smelly so no one wants to eat in it."}, "gen_args_2": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? No, THe garden is smelly so no one wants to eat in it."}}, "resps": [[["-183.0", "False"]], [["-184.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-184.0", "False"], ["-184.0", "False"]], "doc_hash": "31f90e77482b1a387bb4fbd749eb5ebf9fdbe51501f4b0fd45e3a9e2b9644bcf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1216, "doc": {"premise": "s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion.", "hypothesis": "Charlottetown hosted leaders.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Yes, Charlottetown hosted leaders."}, "gen_args_1": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Also, Charlottetown hosted leaders."}, "gen_args_2": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? No, Charlottetown hosted leaders."}}, "resps": [[["-195.0", "False"]], [["-203.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-203.0", "False"], ["-197.0", "False"]], "doc_hash": "df29c8287c95b168092cc25416cea569ec8c04dc81ed6657ef04508d6fdcb750", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 1224, "doc": {"premise": "There are also plenty of venues for more  risque  or avant-garde performances.", "hypothesis": "All of the venues have child-friendly events.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Yes, All of the venues have child-friendly events."}, "gen_args_1": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Also, All of the venues have child-friendly events."}, "gen_args_2": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? No, All of the venues have child-friendly events."}}, "resps": [[["-137.0", "False"]], [["-139.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-139.0", "False"], ["-136.0", "False"]], "doc_hash": "bccf533a44545480d58f8cc5107b3537a021de2f4c3c1d9ce655662a9e92639a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1232, "doc": {"premise": "Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar.", "hypothesis": "Chinatown is very far from the water.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Yes, Chinatown is very far from the water."}, "gen_args_1": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Also, Chinatown is very far from the water."}, "gen_args_2": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? No, Chinatown is very far from the water."}}, "resps": [[["-135.0", "False"]], [["-138.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-138.0", "False"], ["-130.0", "False"]], "doc_hash": "888f35f7191513568409b9da0336dbe2e2915148da2aef517be1b27a1f8073cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 1240, "doc": {"premise": "Without doubt, the initial lure of the city is its numerous historic buildings.", "hypothesis": "The city was just constructed a few years ago and does not have much history.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Yes, The city was just constructed a few years ago and does not have much history."}, "gen_args_1": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Also, The city was just constructed a few years ago and does not have much history."}, "gen_args_2": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? No, The city was just constructed a few years ago and does not have much history."}}, "resps": [[["-127.5", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "a7be5739ecf1484bf5d7aa14efeea5ac28744339d3adb27c10431594720701a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 1248, "doc": {"premise": "Although funding strategies can be improved, funding is available for this work.", "hypothesis": "There are resources available for these tasks.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Yes, There are resources available for these tasks."}, "gen_args_1": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Also, There are resources available for these tasks."}, "gen_args_2": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? No, There are resources available for these tasks."}}, "resps": [[["-114.0", "False"]], [["-118.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-118.0", "False"], ["-117.5", "False"]], "doc_hash": "04fa63592a63791cb499a9522e69fffc7774f5ac6b306506c260ce19e5afecc8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.9537316 0.0174682 0.0288002]"]}
{"doc_id": 1256, "doc": {"premise": "Executives could also receive a rating of provisional or fail for each element.", "hypothesis": "Executives must get rated well in order to continue.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Yes, Executives must get rated well in order to continue."}, "gen_args_1": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Also, Executives must get rated well in order to continue."}, "gen_args_2": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? No, Executives must get rated well in order to continue."}}, "resps": [[["-149.0", "False"]], [["-151.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-151.0", "False"], ["-150.0", "False"]], "doc_hash": "84f96469ef4bb9019d0eee4f2981191986052d6a96ea3725ca7d196343acc377", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1264, "doc": {"premise": "For example, in GGD, a design study was done as a separate job, culminating", "hypothesis": "A design study was conducted in isolation.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Yes, A design study was conducted in isolation."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Also, A design study was conducted in isolation."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? No, A design study was conducted in isolation."}}, "resps": [[["-135.0", "False"]], [["-144.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-144.0", "False"], ["-138.0", "False"]], "doc_hash": "2695326b7626bfd0fad50418dc14dfae757cd108126ac646ee0ed347009bd01d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52462158e-01 1.17543168e-04 4.74202986e-02]"]}
{"doc_id": 1272, "doc": {"premise": "In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate.", "hypothesis": "The basic category is more than cost.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Yes, The basic category is more than cost."}, "gen_args_1": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Also, The basic category is more than cost."}, "gen_args_2": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? No, The basic category is more than cost."}}, "resps": [[["-187.0", "False"]], [["-188.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-188.0", "False"], ["-185.0", "False"]], "doc_hash": "d5b98faaffe2bbdb6138900804abf6e3f1958ec401637c9c75bb21da92a86922", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1280, "doc": {"premise": "19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler.", "hypothesis": "It took 13 months total to retrofit the boiler.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Yes, It took 13 months total to retrofit the boiler."}, "gen_args_1": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Also, It took 13 months total to retrofit the boiler."}, "gen_args_2": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? No, It took 13 months total to retrofit the boiler."}}, "resps": [[["-176.0", "False"]], [["-181.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-181.0", "False"], ["-176.0", "False"]], "doc_hash": "aaae74507d00ef7a7b78d07e64d3d993829531ed7305634d0dd4b3340a92c682", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1288, "doc": {"premise": "The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before.", "hypothesis": "They haven't figured out how to calculate technical cost effects.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Yes, They haven't figured out how to calculate technical cost effects."}, "gen_args_1": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Also, They haven't figured out how to calculate technical cost effects."}, "gen_args_2": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? No, They haven't figured out how to calculate technical cost effects."}}, "resps": [[["-184.0", "False"]], [["-187.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-187.0", "False"], ["-181.0", "False"]], "doc_hash": "74ce8e52571551d96e4b2cfaa5e84b2328ea9dce6452528692d581739c511f18", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1296, "doc": {"premise": "Some facility owners have been innovative in their construction plans to minimize down time.", "hypothesis": "Downtime can be reduced by using innovative construction plans.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Yes, Downtime can be reduced by using innovative construction plans."}, "gen_args_1": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Also, Downtime can be reduced by using innovative construction plans."}, "gen_args_2": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? No, Downtime can be reduced by using innovative construction plans."}}, "resps": [[["-126.0", "False"]], [["-131.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-131.0", "False"], ["-131.0", "False"]], "doc_hash": "cca0d1ec3a8e746d2925be7b88ea1367afb8963df778cd8ac2ff974a2bfbf481", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 1304, "doc": {"premise": "49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage.", "hypothesis": "Skimmers pay a lot more than everyone else.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Yes, Skimmers pay a lot more than everyone else."}, "gen_args_1": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Also, Skimmers pay a lot more than everyone else."}, "gen_args_2": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? No, Skimmers pay a lot more than everyone else."}}, "resps": [[["-170.0", "False"]], [["-175.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-175.0", "False"], ["-170.0", "False"]], "doc_hash": "8b25eba350be534bd4e95930676b1e9c94c22ace701d52cb8970181ece494f59", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1312, "doc": {"premise": "29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler.", "hypothesis": "It should take about 21 months to retrofit a single utility boiler.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Yes, It should take about 21 months to retrofit a single utility boiler."}, "gen_args_1": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Also, It should take about 21 months to retrofit a single utility boiler."}, "gen_args_2": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? No, It should take about 21 months to retrofit a single utility boiler."}}, "resps": [[["-161.0", "False"]], [["-167.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-167.0", "False"], ["-166.0", "False"]], "doc_hash": "b91ccd651725235e0811bdddde87c080f4ac95caaa146ba222a8b40a7fbac124", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 1320, "doc": {"premise": "The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits.", "hypothesis": "They calculate the welfare effects like they do how much money they make.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Yes, They calculate the welfare effects like they do how much money they make."}, "gen_args_1": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Also, They calculate the welfare effects like they do how much money they make."}, "gen_args_2": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? No, They calculate the welfare effects like they do how much money they make."}}, "resps": [[["-173.0", "False"]], [["-179.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-179.0", "False"], ["-175.0", "False"]], "doc_hash": "d8fddeb2d0ad9de7454707dc52852e12b474660ad9bb5438b866597b76ca64b3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1328, "doc": {"premise": "1) Increasing penetration of alternative modes of communication", "hypothesis": "Other modes of communication are becomming more popular.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Yes, Other modes of communication are becomming more popular."}, "gen_args_1": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Also, Other modes of communication are becomming more popular."}, "gen_args_2": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? No, Other modes of communication are becomming more popular."}}, "resps": [[["-104.0", "False"]], [["-109.5", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-109.5", "False"], ["-109.0", "False"]], "doc_hash": "d52a5950a68cbd364cd3ed36f94b8933fbe763dc3cead35f8a322e7a37d4fe8e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.9892912  0.00404301 0.00666579]"]}
{"doc_id": 1336, "doc": {"premise": "Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so.", "hypothesis": "Things move really fast in the ED because they see 2000 patients a week.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Yes, Things move really fast in the ED because they see 2000 patients a week."}, "gen_args_1": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Also, Things move really fast in the ED because they see 2000 patients a week."}, "gen_args_2": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? No, Things move really fast in the ED because they see 2000 patients a week."}}, "resps": [[["-196.0", "False"]], [["-194.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-194.0", "False"], ["-197.0", "False"]], "doc_hash": "5bae893fda9a1785f338a003fe04fb2fa0428d6fb51febbf17aaf65f4ca4da45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.84379473 0.04201007]"]}
{"doc_id": 1344, "doc": {"premise": "The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages.", "hypothesis": "Technology can reduce how long providers and staff need to screen people by up to 80%.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Yes, Technology can reduce how long providers and staff need to screen people by up to 80%."}, "gen_args_1": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Also, Technology can reduce how long providers and staff need to screen people by up to 80%."}, "gen_args_2": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? No, Technology can reduce how long providers and staff need to screen people by up to 80%."}}, "resps": [[["-210.0", "False"]], [["-218.0", "False"]], [["-213.0", "False"]]], "filtered_resps": [["-210.0", "False"], ["-218.0", "False"], ["-213.0", "False"]], "doc_hash": "e6443f332af1753f1b62f244c8c2e464cdbd48212d1bd5d4266578cc1243fca0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 1352, "doc": {"premise": "I would be pleased to respond to any questions that the Members of the Subcommittee may have.", "hypothesis": "I'd love to answer questions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Yes, I'd love to answer questions."}, "gen_args_1": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Also, I'd love to answer questions."}, "gen_args_2": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? No, I'd love to answer questions."}}, "resps": [[["-88.0", "False"]], [["-93.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-88.0", "False"], ["-93.0", "False"], ["-89.0", "False"]], "doc_hash": "aa870e39fe65c333efe0ecd2ad32287a676b06334c274bde53c26bf57026b96d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1360, "doc": {"premise": "Figure 3 shows the basic results for the two models.", "hypothesis": "Figure 3 shows the rate of growth of the city.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Yes, Figure 3 shows the rate of growth of the city."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Also, Figure 3 shows the rate of growth of the city."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? No, Figure 3 shows the rate of growth of the city."}}, "resps": [[["-104.0", "False"]], [["-103.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-104.0", "False"], ["-103.5", "False"], ["-104.5", "False"]], "doc_hash": "410835be48b7d4265463c7c5d44edb43007a20ef13d54900534d392a19c84ad6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.30719589 0.50648039 0.18632372]"]}
{"doc_id": 1368, "doc": {"premise": "In addition, few postal administrations pay their employees as large a wage premium as does the U.S.", "hypothesis": "In many countries postal employees make less than five dollars a day.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Yes, In many countries postal employees make less than five dollars a day."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Also, In many countries postal employees make less than five dollars a day."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? No, In many countries postal employees make less than five dollars a day."}}, "resps": [[["-139.0", "False"]], [["-139.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-139.0", "False"], ["-139.0", "False"]], "doc_hash": "ef5ed69d6602bafef15b7cb92998fb8fb979a830584ed46b2d0665815b9dc03c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1376, "doc": {"premise": "Dr. Gentilello recommends the development of an ED alcohol research center.", "hypothesis": "This research center would employ up to ten people.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Yes, This research center would employ up to ten people."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Also, This research center would employ up to ten people."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? No, This research center would employ up to ten people."}}, "resps": [[["-143.0", "False"]], [["-145.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-145.0", "False"], ["-147.0", "False"]], "doc_hash": "663ec66b956ba4dca68b24653f7f9f93d3975a18dc9ef1a8e953f9e08d3a1166", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 1384, "doc": {"premise": "Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice.", "hypothesis": "Nationally, attorneys withdraw from only five percent of all cases.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Yes, Nationally, attorneys withdraw from only five percent of all cases."}, "gen_args_1": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Also, Nationally, attorneys withdraw from only five percent of all cases."}, "gen_args_2": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? No, Nationally, attorneys withdraw from only five percent of all cases."}}, "resps": [[["-170.0", "False"]], [["-173.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-173.0", "False"], ["-171.0", "False"]], "doc_hash": "3901a8b76b32f43f1f1ca7d7f48e2eb1e6a029eaed22bc1d7f56c49984ee5c36", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1392, "doc": {"premise": "As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise.", "hypothesis": "By next year the state will have outstanding contracts totally five million dollars per year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Yes, By next year the state will have outstanding contracts totally five million dollars per year."}, "gen_args_1": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Also, By next year the state will have outstanding contracts totally five million dollars per year."}, "gen_args_2": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? No, By next year the state will have outstanding contracts totally five million dollars per year."}}, "resps": [[["-179.0", "False"]], [["-182.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-182.0", "False"], ["-182.0", "False"]], "doc_hash": "9b5472b157069484c5e2fbc39367e57ff8d90cf4fa10dd7afa43db3bc4a7a310", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1400, "doc": {"premise": "Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed.", "hypothesis": "Title V is a very important document.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Yes, Title V is a very important document."}, "gen_args_1": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Also, Title V is a very important document."}, "gen_args_2": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? No, Title V is a very important document."}}, "resps": [[["-148.0", "False"]], [["-148.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-148.0", "False"], ["-147.0", "False"]], "doc_hash": "7862c3ba34efd355532f90dc6bdeaffa8ec632ce1890e4260cd7a598ad20fda7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1408, "doc": {"premise": "The Title V operating permit must also be made available for public comment.", "hypothesis": "Public comment must be allowed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Yes, Public comment must be allowed."}, "gen_args_1": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Also, Public comment must be allowed."}, "gen_args_2": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? No, Public comment must be allowed."}}, "resps": [[["-99.0", "False"]], [["-104.5", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-99.0", "False"], ["-104.5", "False"], ["-105.5", "False"]], "doc_hash": "7c58cb00983b82dac885eb22bee29fea23c1228a5a223099c074e697bdc6c874", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99444087 0.00406405 0.00149508]"]}
{"doc_id": 1416, "doc": {"premise": "For clients who are illiterate in any language, materials would have to be carefully explained to them.", "hypothesis": "Illiterate people are very common and we need a plan to deal with them.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Yes, Illiterate people are very common and we need a plan to deal with them."}, "gen_args_1": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Also, Illiterate people are very common and we need a plan to deal with them."}, "gen_args_2": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? No, Illiterate people are very common and we need a plan to deal with them."}}, "resps": [[["-137.0", "False"]], [["-137.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-137.0", "False"], ["-139.0", "False"]], "doc_hash": "06a6c1d231fe6cd5254d680240d067d55c7b2ed81ceb8a81062ae30a9a651112", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 1424, "doc": {"premise": "Managing Change in the Postal and Delivery Industries, Ed.", "hypothesis": "There are people whose only job is to manage the changes in the Postal and Delivery Industries.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Yes, There are people whose only job is to manage the changes in the Postal and Delivery Industries."}, "gen_args_1": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Also, There are people whose only job is to manage the changes in the Postal and Delivery Industries."}, "gen_args_2": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? No, There are people whose only job is to manage the changes in the Postal and Delivery Industries."}}, "resps": [[["-116.0", "False"]], [["-120.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-120.5", "False"], ["-117.0", "False"]], "doc_hash": "2e533e47fddbf781db6cbfc92728b694b7ddef98243b34d927f9456ee4e49b0d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72516924 0.0080559  0.26677486]"]}
{"doc_id": 1432, "doc": {"premise": "Additional time is usually needed to develop the action plan.", "hypothesis": "They usually need another year to implement the plan.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Yes, They usually need another year to implement the plan."}, "gen_args_1": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Also, They usually need another year to implement the plan."}, "gen_args_2": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? No, They usually need another year to implement the plan."}}, "resps": [[["-103.0", "False"]], [["-106.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-103.0", "False"], ["-106.5", "False"], ["-104.5", "False"]], "doc_hash": "09a0f27d24dd24212bbe42a9a4354639d80c53aafd2313526bc3ec6721d0c9a6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 1440, "doc": {"premise": "One size fits all does not work in brief interventions, just as it does not work in clinical practice in general.", "hypothesis": "Every case needs to have a specific person working on it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Yes, Every case needs to have a specific person working on it."}, "gen_args_1": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Also, Every case needs to have a specific person working on it."}, "gen_args_2": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? No, Every case needs to have a specific person working on it."}}, "resps": [[["-132.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "163cba3abb88cfc35771462a9fd54f9038c399070ed4fdbf1a2574c2dfb136ab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1448, "doc": {"premise": "The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses.", "hypothesis": "The plan should also include a budget.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Yes, The plan should also include a budget."}, "gen_args_1": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Also, The plan should also include a budget."}, "gen_args_2": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? No, The plan should also include a budget."}}, "resps": [[["-152.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "25134c873e4ff706731c1e0fa28d73c711e47a7954f9a4c6dd54704816583b8d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1456, "doc": {"premise": "28 In some cases longer outages are needed.", "hypothesis": "Sometimes longer outages are needed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Yes, Sometimes longer outages are needed."}, "gen_args_1": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Also, Sometimes longer outages are needed."}, "gen_args_2": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? No, Sometimes longer outages are needed."}}, "resps": [[["-91.5", "False"]], [["-98.5", "False"]], [["-94.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-98.5", "False"], ["-94.0", "False"]], "doc_hash": "d0b9536676ad6ac9643cf7fe41c97a30855db1577bb90484c4a5971193269aca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.23363694e-01 8.41998700e-04 7.57943075e-02]"]}
{"doc_id": 1464, "doc": {"premise": "A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements.", "hypothesis": "Companies don't use keys.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Yes, Companies don't use keys."}, "gen_args_1": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Also, Companies don't use keys."}, "gen_args_2": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? No, Companies don't use keys."}}, "resps": [[["-189.0", "False"]], [["-189.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-189.0", "False"], ["-185.0", "False"]], "doc_hash": "6bfdc7331e3a8c9a2fcf45b3d2b677487d73971399b4c80849784c820b3b9b6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 1472, "doc": {"premise": "In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup.", "hypothesis": "9a is the rate difference.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Yes, 9a is the rate difference."}, "gen_args_1": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Also, 9a is the rate difference."}, "gen_args_2": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? No, 9a is the rate difference."}}, "resps": [[["-132.0", "False"]], [["-140.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-140.0", "False"], ["-133.0", "False"]], "doc_hash": "4b6fa8f4b8328e3b2054a45e6358617239926b4e5e35ce472f736a10c0e8935c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 1480, "doc": {"premise": "Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary.", "hypothesis": "Centrelink never has incorrect payments caused by incorrect income declaration by customers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Yes, Centrelink never has incorrect payments caused by incorrect income declaration by customers."}, "gen_args_1": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Also, Centrelink never has incorrect payments caused by incorrect income declaration by customers."}, "gen_args_2": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? No, Centrelink never has incorrect payments caused by incorrect income declaration by customers."}}, "resps": [[["-211.0", "False"]], [["-214.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-214.0", "False"], ["-207.0", "False"]], "doc_hash": "808c0c536481929f76b19b8e0713c4fefd08bbebe5ad0d8ccd1f7fd4f5d5bf4f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1488, "doc": {"premise": "receive a rating of pass if they meet the fully successful standard for an element.", "hypothesis": "Fully meeting a successful standard will result in a pass.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Yes, Fully meeting a successful standard will result in a pass."}, "gen_args_1": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Also, Fully meeting a successful standard will result in a pass."}, "gen_args_2": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? No, Fully meeting a successful standard will result in a pass."}}, "resps": [[["-130.0", "False"]], [["-135.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-135.0", "False"], ["-136.0", "False"]], "doc_hash": "27b0da7d5b388427a9be5e505f642caf2aca8d63c4a0c6a5df4015081f12ff5e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00667641 0.00245611]"]}
{"doc_id": 1496, "doc": {"premise": "The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization.", "hypothesis": "The Islamist movement was originally founded as an organization for social mobilization.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Yes, The Islamist movement was originally founded as an organization for social mobilization."}, "gen_args_1": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Also, The Islamist movement was originally founded as an organization for social mobilization."}, "gen_args_2": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? No, The Islamist movement was originally founded as an organization for social mobilization."}}, "resps": [[["-159.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "2c419b304c4721070e2a7553c5b0eca1eeb6e60d62c150e287875bc85d3f22aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1504, "doc": {"premise": "We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations.", "hypothesis": "We can't find proof that Clarke gave him his paper.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Yes, We can't find proof that Clarke gave him his paper."}, "gen_args_1": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Also, We can't find proof that Clarke gave him his paper."}, "gen_args_2": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? No, We can't find proof that Clarke gave him his paper."}}, "resps": [[["-209.0", "False"]], [["-209.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-209.0", "False"], ["-206.0", "False"]], "doc_hash": "579588bf13e6df72debef8d9a11bd25a00d09982a66c7d7ac992460539367256", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1512, "doc": {"premise": "Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties.", "hypothesis": "Americans don't need to worry about their civil liberties- they will always be protected.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Yes, Americans don't need to worry about their civil liberties- they will always be protected."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Also, Americans don't need to worry about their civil liberties- they will always be protected."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? No, Americans don't need to worry about their civil liberties- they will always be protected."}}, "resps": [[["-146.0", "False"]], [["-149.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-149.0", "False"], ["-143.0", "False"]], "doc_hash": "8886b50b5db028015a161dc0cc3a9e59affedcedcc615e5e7ae905f2b6e1a452", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1520, "doc": {"premise": "The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done.", "hypothesis": "The director thought it was all up to him.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Yes, The director thought it was all up to him."}, "gen_args_1": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Also, The director thought it was all up to him."}, "gen_args_2": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? No, The director thought it was all up to him."}}, "resps": [[["-189.0", "False"]], [["-193.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-193.0", "False"], ["-187.0", "False"]], "doc_hash": "c7c81cbe8fbb967775bc5e54f4a4294bcbd9c063ba6fc62be339cc7f7abf1d54", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1528, "doc": {"premise": "Pickard recalls the alleged statement being made at a briefing on July 12.", "hypothesis": "Pickard remembered the briefing covered the facts of the crash.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Yes, Pickard remembered the briefing covered the facts of the crash."}, "gen_args_1": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Also, Pickard remembered the briefing covered the facts of the crash."}, "gen_args_2": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? No, Pickard remembered the briefing covered the facts of the crash."}}, "resps": [[["-146.0", "False"]], [["-144.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-144.0", "False"], ["-145.0", "False"]], "doc_hash": "8d5997a3ece34a578bd08b54de9ea6ead50b24f2975e21b5a2e734ea26fe29e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 1536, "doc": {"premise": "They make targets harder to attack successfully, and they deter attacks by making capture more likely.", "hypothesis": "They knew making the targets more difficult would lead to a higher rate of captures.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Yes, They knew making the targets more difficult would lead to a higher rate of captures."}, "gen_args_1": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Also, They knew making the targets more difficult would lead to a higher rate of captures."}, "gen_args_2": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? No, They knew making the targets more difficult would lead to a higher rate of captures."}}, "resps": [[["-158.0", "False"]], [["-157.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-157.0", "False"], ["-158.0", "False"]], "doc_hash": "c87641eba595da97512aadc404cb78f021b82f5d0cab35e3dfa003bbe1e215b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 1544, "doc": {"premise": "We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate.", "hypothesis": "We would like to debate the recommendations.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Yes, We would like to debate the recommendations."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Also, We would like to debate the recommendations."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? No, We would like to debate the recommendations."}}, "resps": [[["-123.5", "False"]], [["-133.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-123.5", "False"], ["-133.0", "False"], ["-126.5", "False"]], "doc_hash": "b3c27f92b4503ca69c13bfcd58c00ca151162b45c29590647539baf6dc2dbe58", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52506211e-01 7.12968329e-05 4.74224919e-02]"]}
{"doc_id": 1552, "doc": {"premise": "After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24.", "hypothesis": "The airspace did not reopen until late October.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Yes, The airspace did not reopen until late October."}, "gen_args_1": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Also, The airspace did not reopen until late October."}, "gen_args_2": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? No, The airspace did not reopen until late October."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-156.0", "False"]], "doc_hash": "b03be3ac1f5389ae1259c6105812e08a6e2611e447d310f16ef752c5d7a382f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1560, "doc": {"premise": "The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911.", "hypothesis": "The FDNY and police were both using the same systems to communicate with the public.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Yes, The FDNY and police were both using the same systems to communicate with the public."}, "gen_args_1": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Also, The FDNY and police were both using the same systems to communicate with the public."}, "gen_args_2": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? No, The FDNY and police were both using the same systems to communicate with the public."}}, "resps": [[["-206.0", "False"]], [["-207.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-207.0", "False"], ["-206.0", "False"]], "doc_hash": "f86a25d46263333540d04e789de3e460ef81835e4624416e9bf08381a66edb48", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1568, "doc": {"premise": "Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles.", "hypothesis": "They boarded a flight to Los Angeles before 8:00.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Yes, They boarded a flight to Los Angeles before 8:00."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Also, They boarded a flight to Los Angeles before 8:00."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? No, They boarded a flight to Los Angeles before 8:00."}}, "resps": [[["-177.0", "False"]], [["-179.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-179.0", "False"], ["-172.0", "False"]], "doc_hash": "a325a04b9a305683ec34f4fcb71d43128ed8a7735fe64ff2bb008c7cd9f75774", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 1576, "doc": {"premise": "Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim.", "hypothesis": "Some newspapers in Arizona sound anti-Muslim.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Yes, Some newspapers in Arizona sound anti-Muslim."}, "gen_args_1": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Also, Some newspapers in Arizona sound anti-Muslim."}, "gen_args_2": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? No, Some newspapers in Arizona sound anti-Muslim."}}, "resps": [[["-201.0", "False"]], [["-204.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-204.0", "False"], ["-201.0", "False"]], "doc_hash": "d73a550216e7eb4574330268335d703e7e5ce9cead218d2bcaa0a859fe66e95f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1584, "doc": {"premise": "Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing.", "hypothesis": "McLaughlin has been the Deputy Director of Central Intelligence for 27 years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Yes, McLaughlin has been the Deputy Director of Central Intelligence for 27 years."}, "gen_args_1": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Also, McLaughlin has been the Deputy Director of Central Intelligence for 27 years."}, "gen_args_2": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? No, McLaughlin has been the Deputy Director of Central Intelligence for 27 years."}}, "resps": [[["-156.0", "False"]], [["-155.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-155.0", "False"], ["-155.0", "False"]], "doc_hash": "4dc994271725c6d26a8cf3dbf44789404582d3cb25e23d68b60143d23baa7a9f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1592, "doc": {"premise": "There is no indication that Atta or Shehhi received any additional flight training in June.", "hypothesis": "We do not suspect that Atta and Shehhi continued flight training in June.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Yes, We do not suspect that Atta and Shehhi continued flight training in June."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Also, We do not suspect that Atta and Shehhi continued flight training in June."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? No, We do not suspect that Atta and Shehhi continued flight training in June."}}, "resps": [[["-131.0", "False"]], [["-138.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-138.0", "False"], ["-131.0", "False"]], "doc_hash": "cad3bc7492883d7671ee500e280785245be17d75c54ed959e8717ee5874c2bd6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 1600, "doc": {"premise": "Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel.", "hypothesis": "Mihdhar had a wonderful stay at the Marriott Hotel in NYC.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Yes, Mihdhar had a wonderful stay at the Marriott Hotel in NYC."}, "gen_args_1": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Also, Mihdhar had a wonderful stay at the Marriott Hotel in NYC."}, "gen_args_2": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? No, Mihdhar had a wonderful stay at the Marriott Hotel in NYC."}}, "resps": [[["-149.0", "False"]], [["-151.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-151.0", "False"], ["-149.0", "False"]], "doc_hash": "0631fe54fc6635cc3d3220ff9130525f072b9afe417633b48c7ff4c027e763bf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1608, "doc": {"premise": "It did not suggest that there was a domestic threat.", "hypothesis": "It suggested a threat in Ireland, but not one in the US.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Yes, It suggested a threat in Ireland, but not one in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Also, It suggested a threat in Ireland, but not one in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? No, It suggested a threat in Ireland, but not one in the US."}}, "resps": [[["-113.5", "False"]], [["-115.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-115.5", "False"], ["-112.0", "False"]], "doc_hash": "c1394108ac59d21d81de7caf6cf81d8ffa06c338d57ae73fad59b199c9561747", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.17803021 0.02409377 0.79787603]"]}
{"doc_id": 1616, "doc": {"premise": "The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups.", "hypothesis": "The United States may have given money to al Qaeda.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Yes, The United States may have given money to al Qaeda."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Also, The United States may have given money to al Qaeda."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? No, The United States may have given money to al Qaeda."}}, "resps": [[["-137.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "da4eef127d00c7f458787f45aefd9557a8f1a8e871431ad6a5b7079768f57b9e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1624, "doc": {"premise": "If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official.", "hypothesis": "The Director of the DIA is not involved with defense intelligence at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Yes, The Director of the DIA is not involved with defense intelligence at all."}, "gen_args_1": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Also, The Director of the DIA is not involved with defense intelligence at all."}, "gen_args_2": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? No, The Director of the DIA is not involved with defense intelligence at all."}}, "resps": [[["-161.0", "False"]], [["-161.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-161.0", "False"], ["-155.0", "False"]], "doc_hash": "ee1afe6d0786195afeec3af1d4683dc6a0df313433f27894152b004885a37368", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1632, "doc": {"premise": "Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well.", "hypothesis": "One firefighter felt that this tower could fall.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Yes, One firefighter felt that this tower could fall."}, "gen_args_1": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Also, One firefighter felt that this tower could fall."}, "gen_args_2": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? No, One firefighter felt that this tower could fall."}}, "resps": [[["-190.0", "False"]], [["-194.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-194.0", "False"], ["-191.0", "False"]], "doc_hash": "18ca9ea16e69a6b44669f52768076402f465517bed60cad89c63b926de20a7cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1640, "doc": {"premise": "Hard Put to Find Proof Bin Laden Directed Attacks.", "hypothesis": "There was hard evidence of Bin Laden directing the attacks.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Yes, There was hard evidence of Bin Laden directing the attacks."}, "gen_args_1": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Also, There was hard evidence of Bin Laden directing the attacks."}, "gen_args_2": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? No, There was hard evidence of Bin Laden directing the attacks."}}, "resps": [[["-114.0", "False"]], [["-118.0", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-118.0", "False"], ["-113.5", "False"]], "doc_hash": "e9c0f2f1c05842debe3e4bc136773c3d109f4af6c75d5c183feb6be57f5fa450", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 1648, "doc": {"premise": "The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment.", "hypothesis": "The team rushed through the data to get the report done quickly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Yes, The team rushed through the data to get the report done quickly."}, "gen_args_1": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Also, The team rushed through the data to get the report done quickly."}, "gen_args_2": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? No, The team rushed through the data to get the report done quickly."}}, "resps": [[["-198.0", "False"]], [["-200.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-198.0", "False"], ["-200.0", "False"], ["-199.0", "False"]], "doc_hash": "2cd76de93500d4cfb6e6eb32e58ee8cfb7f9a577e6465b878cb66145feaed724", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1656, "doc": {"premise": "As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA.", "hypothesis": "Jane never wanted to share the information.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Yes, Jane never wanted to share the information."}, "gen_args_1": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Also, Jane never wanted to share the information."}, "gen_args_2": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? No, Jane never wanted to share the information."}}, "resps": [[["-175.0", "False"]], [["-177.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-177.0", "False"], ["-173.0", "False"]], "doc_hash": "d7c49748af21823f745ade5334aea6522ea48d1d9c7e55cf930420bce1e4a29a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1664, "doc": {"premise": "The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing.", "hypothesis": "The photograph was slightly blurry, but the face of the person was still visible.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Yes, The photograph was slightly blurry, but the face of the person was still visible."}, "gen_args_1": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Also, The photograph was slightly blurry, but the face of the person was still visible."}, "gen_args_2": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? No, The photograph was slightly blurry, but the face of the person was still visible."}}, "resps": [[["-147.0", "False"]], [["-147.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-147.0", "False"], ["-151.0", "False"]], "doc_hash": "73ea6e9ff3f8148ad5a200e5493e8012e6d81c2b2a04096839563e6764287bd6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.49546264 0.00907471]"]}
{"doc_id": 1672, "doc": {"premise": "They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House.", "hypothesis": "They talked about the architecture of landmarks and used it for code words.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Yes, They talked about the architecture of landmarks and used it for code words."}, "gen_args_1": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Also, They talked about the architecture of landmarks and used it for code words."}, "gen_args_2": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? No, They talked about the architecture of landmarks and used it for code words."}}, "resps": [[["-253.0", "False"]], [["-255.0", "False"]], [["-255.0", "False"]]], "filtered_resps": [["-253.0", "False"], ["-255.0", "False"], ["-255.0", "False"]], "doc_hash": "e777fd04e55b4d97ce943d4631469a946ae44197689386d6ed18775141a445ed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1680, "doc": {"premise": "Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time.", "hypothesis": "Hazmi's housemate has a good memory.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Yes, Hazmi's housemate has a good memory."}, "gen_args_1": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Also, Hazmi's housemate has a good memory."}, "gen_args_2": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? No, Hazmi's housemate has a good memory."}}, "resps": [[["-123.0", "False"]], [["-127.5", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-127.5", "False"], ["-126.0", "False"]], "doc_hash": "dccb224e2165fc8a4d65c09c6f01cd82d7f3767436d3e0bc02a84126fdef00cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 1688, "doc": {"premise": "For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed.", "hypothesis": "There were no rescue efforts to report on.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Yes, There were no rescue efforts to report on."}, "gen_args_1": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Also, There were no rescue efforts to report on."}, "gen_args_2": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? No, There were no rescue efforts to report on."}}, "resps": [[["-179.0", "False"]], [["-181.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-181.0", "False"], ["-173.0", "False"]], "doc_hash": "74ae4f48ddeea1efbc753bc67a205f0fd14c776199a1fdb7faeed7b3b82a1236", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 1696, "doc": {"premise": "NYPD recording, Special Operations Division radio channel, Sept. 11, 2001.", "hypothesis": "The NYPD did not attempt to use radio communications until 2004.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Yes, The NYPD did not attempt to use radio communications until 2004."}, "gen_args_1": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Also, The NYPD did not attempt to use radio communications until 2004."}, "gen_args_2": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? No, The NYPD did not attempt to use radio communications until 2004."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "4b876944addd5b4ec0d8ffad12b8509fada437e60f1124964c9c94634e0ec1cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1704, "doc": {"premise": "More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens.", "hypothesis": "More than half a billion people cross the border at entry points.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Yes, More than half a billion people cross the border at entry points."}, "gen_args_1": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Also, More than half a billion people cross the border at entry points."}, "gen_args_2": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? No, More than half a billion people cross the border at entry points."}}, "resps": [[["-140.0", "False"]], [["-145.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-145.0", "False"], ["-139.0", "False"]], "doc_hash": "86f6d5b1f370b007299e1c00a9ed6e0cc3446717a858cb6b34ef8d264c74bf92", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1712, "doc": {"premise": "This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque.", "hypothesis": "Thumairy is not known to have ever been part of any mosque.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Yes, Thumairy is not known to have ever been part of any mosque."}, "gen_args_1": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Also, Thumairy is not known to have ever been part of any mosque."}, "gen_args_2": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? No, Thumairy is not known to have ever been part of any mosque."}}, "resps": [[["-153.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "fe23e1eefc3601bd04fbc0ab8baa867c9344ddf0376accc4e675da79149cab86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00637746 0.04712342 0.94649912]"]}
{"doc_id": 1720, "doc": {"premise": "The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out.", "hypothesis": "The operators did not know that rooftop rescues were impossible.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Yes, The operators did not know that rooftop rescues were impossible."}, "gen_args_1": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Also, The operators did not know that rooftop rescues were impossible."}, "gen_args_2": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? No, The operators did not know that rooftop rescues were impossible."}}, "resps": [[["-166.0", "False"]], [["-170.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-170.0", "False"], ["-165.0", "False"]], "doc_hash": "f26c18bae4079f2083b0b955cf174bf7d68129861e7df3ad28674d4318bddd7d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1728, "doc": {"premise": "One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility.", "hypothesis": "Financial tracking primarily involves examining credit card receipts and bank statements.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Yes, Financial tracking primarily involves examining credit card receipts and bank statements."}, "gen_args_1": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Also, Financial tracking primarily involves examining credit card receipts and bank statements."}, "gen_args_2": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? No, Financial tracking primarily involves examining credit card receipts and bank statements."}}, "resps": [[["-203.0", "False"]], [["-204.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-204.0", "False"], ["-204.0", "False"]], "doc_hash": "4eea814a75a7ba55e6353c53f4b219be701cb5b8a52a372594eec50580a3c6d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1736, "doc": {"premise": "The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed.", "hypothesis": "There was never any indication that Bin Ladin represented a threat to the government.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Yes, There was never any indication that Bin Ladin represented a threat to the government."}, "gen_args_1": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Also, There was never any indication that Bin Ladin represented a threat to the government."}, "gen_args_2": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? No, There was never any indication that Bin Ladin represented a threat to the government."}}, "resps": [[["-172.0", "False"]], [["-176.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-176.0", "False"], ["-167.0", "False"]], "doc_hash": "3bb3205229903e9990bfc1339467508d3249bf21d37183e1b9f7faf997d82fa1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 1744, "doc": {"premise": "Your gift is important to the celebration of our 85th season.", "hypothesis": "We do not care about your gift at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Yes, We do not care about your gift at all."}, "gen_args_1": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Also, We do not care about your gift at all."}, "gen_args_2": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? No, We do not care about your gift at all."}}, "resps": [[["-107.5", "False"]], [["-112.0", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-107.5", "False"], ["-112.0", "False"], ["-104.0", "False"]], "doc_hash": "bbfdbe263138a7e08b4a4a5e308ddbcab15d6c0ea68533ef0050338cf0757bf4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93026889e-02 3.25523470e-04 9.70371788e-01]"]}
{"doc_id": 1752, "doc": {"premise": "Only with the help of our philanthropic partners have we been able to achieve so much.", "hypothesis": "Bill Gates donated $5 million to us.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Yes, Bill Gates donated $5 million to us."}, "gen_args_1": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Also, Bill Gates donated $5 million to us."}, "gen_args_2": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? No, Bill Gates donated $5 million to us."}}, "resps": [[["-105.0", "False"]], [["-108.0", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-105.0", "False"], ["-108.0", "False"], ["-106.5", "False"]], "doc_hash": "69e1d039dd7dd280ad406d6a5580ea4112d7b6f78a5f52803d413651fe087eab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78559703 0.03911257 0.17529039]"]}
{"doc_id": 1760, "doc": {"premise": "My hope is you were greatly blessed and encouraged by this issue.", "hypothesis": "I know you will do all in your power to fight breastfeeding cancer.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Yes, I know you will do all in your power to fight breastfeeding cancer."}, "gen_args_1": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Also, I know you will do all in your power to fight breastfeeding cancer."}, "gen_args_2": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? No, I know you will do all in your power to fight breastfeeding cancer."}}, "resps": [[["-130.0", "False"]], [["-129.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-129.0", "False"], ["-135.0", "False"]], "doc_hash": "7d6e7e356e9c78081891e0ab687c0b118aa301971ccff8a5f77f69fdc2e3cf0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26845495 0.72973621 0.00180884]"]}
{"doc_id": 1768, "doc": {"premise": "Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs.", "hypothesis": "Participants will have to sign a non-disclosure agreement, before accessing prospects' details.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Yes, Participants will have to sign a non-disclosure agreement, before accessing prospects' details."}, "gen_args_1": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Also, Participants will have to sign a non-disclosure agreement, before accessing prospects' details."}, "gen_args_2": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? No, Participants will have to sign a non-disclosure agreement, before accessing prospects' details."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-156.0", "False"]], "doc_hash": "8dfe21ab3dcfd1b573520ff9d8bdaba9156b93f43f13f41b0454f275ff889ed9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1776, "doc": {"premise": "Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment.", "hypothesis": "People in central Indiana never receive job training.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Yes, People in central Indiana never receive job training."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Also, People in central Indiana never receive job training."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? No, People in central Indiana never receive job training."}}, "resps": [[["-138.0", "False"]], [["-142.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-142.0", "False"], ["-138.0", "False"]], "doc_hash": "775229a4ec36b2ad9d943989b8f8589ebeb0d1e5e1a3fccadce60d6cdcc8b7b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1784, "doc": {"premise": "However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget.", "hypothesis": "We need at least $10,000 in donations to allow us to maintain our present collections.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Yes, We need at least $10,000 in donations to allow us to maintain our present collections."}, "gen_args_1": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Also, We need at least $10,000 in donations to allow us to maintain our present collections."}, "gen_args_2": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? No, We need at least $10,000 in donations to allow us to maintain our present collections."}}, "resps": [[["-165.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "24c84333f3c52290a315c1bab5ac100f2dfb29a5e9f008b0d4c57ad12bbf07d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1792, "doc": {"premise": "As a member of the law school's __, I know you are aware of our progress.", "hypothesis": "No one belongs to the law school.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Yes, No one belongs to the law school."}, "gen_args_1": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Also, No one belongs to the law school."}, "gen_args_2": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? No, No one belongs to the law school."}}, "resps": [[["-130.0", "False"]], [["-127.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-127.0", "False"], ["-124.0", "False"]], "doc_hash": "83f4be998bc9ee6b3bfccf82df5aed440c35fee47a3c5ad1597600e12a9147e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00235563 0.04731416 0.95033021]"]}
{"doc_id": 1800, "doc": {"premise": "Your investment continues the high quality of all aspects of the Museum and makes new achievements possible.", "hypothesis": "Investments do not affect the Museum in any way.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Yes, Investments do not affect the Museum in any way."}, "gen_args_1": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Also, Investments do not affect the Museum in any way."}, "gen_args_2": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? No, Investments do not affect the Museum in any way."}}, "resps": [[["-136.0", "False"]], [["-140.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-140.0", "False"], ["-131.0", "False"]], "doc_hash": "ca726fde7d04b6db88fc821ced5f185905c7c8b708c7c80c1e85995a9aec7192", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 1808, "doc": {"premise": "And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year.", "hypothesis": "The Civic Theater needs your support.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Yes, The Civic Theater needs your support."}, "gen_args_1": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Also, The Civic Theater needs your support."}, "gen_args_2": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? No, The Civic Theater needs your support."}}, "resps": [[["-119.5", "False"]], [["-123.5", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-123.5", "False"], ["-124.0", "False"]], "doc_hash": "fbcd63f01e42c1c32c9e0fe403e5118bbdc7cda623c93ab19a15c34a21841e20", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97141643 0.01779211 0.01079146]"]}
{"doc_id": 1816, "doc": {"premise": "I believe just the opposite.", "hypothesis": "I think you are correct!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I believe just the opposite., right? Yes, I think you are correct!"}, "gen_args_1": {"arg_0": "", "arg_1": " I believe just the opposite., right? Also, I think you are correct!"}, "gen_args_2": {"arg_0": "", "arg_1": " I believe just the opposite., right? No, I think you are correct!"}}, "resps": [[["-66.5", "False"]], [["-74.0", "False"]], [["-68.0", "False"]]], "filtered_resps": [["-66.5", "False"], ["-74.0", "False"], ["-68.0", "False"]], "doc_hash": "f8ff15afd75d1e680a83365ba248ba8c9f42bc98ab04dc9f06bcdb328108424c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[8.17204946e-01 4.51983283e-04 1.82343071e-01]"]}
{"doc_id": 1824, "doc": {"premise": "Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story.", "hypothesis": "It hasnt rained in 3 years.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Yes, It hasnt rained in 3 years."}, "gen_args_1": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Also, It hasnt rained in 3 years."}, "gen_args_2": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? No, It hasnt rained in 3 years."}}, "resps": [[["-185.0", "False"]], [["-185.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-185.0", "False"], ["-183.0", "False"]], "doc_hash": "c130641ac08c1c1288a2ef9a03b0e8f015ae58f6fe7aa2fedda121a561aec3d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1832, "doc": {"premise": "We need resources to recruit and develop outstanding teachers.", "hypothesis": "We need to hire 100 new, good teachers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Yes, We need to hire 100 new, good teachers."}, "gen_args_1": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Also, We need to hire 100 new, good teachers."}, "gen_args_2": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? No, We need to hire 100 new, good teachers."}}, "resps": [[["-104.5", "False"]], [["-108.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-104.5", "False"], ["-108.5", "False"], ["-108.5", "False"]], "doc_hash": "d03110f18756e57cbcdbc6dc67ecb5adff2b2c46f6cd97393f59a5d873af6d06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1840, "doc": {"premise": "I've got more than a job", "hypothesis": "I have a job that takes up all of my time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I've got more than a job, right? Yes, I have a job that takes up all of my time."}, "gen_args_1": {"arg_0": "", "arg_1": " I've got more than a job, right? Also, I have a job that takes up all of my time."}, "gen_args_2": {"arg_0": "", "arg_1": " I've got more than a job, right? No, I have a job that takes up all of my time."}}, "resps": [[["-68.0", "False"]], [["-72.0", "False"]], [["-67.5", "False"]]], "filtered_resps": [["-68.0", "False"], ["-72.0", "False"], ["-67.5", "False"]], "doc_hash": "6e37ca65e06201ab3721584542c5d20ca83cb7f4322843828b6de3a9ebf47f82", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 1848, "doc": {"premise": "Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ...", "hypothesis": "The group is full of Ivy League Scholars and philanthropists.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Yes, The group is full of Ivy League Scholars and philanthropists."}, "gen_args_1": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Also, The group is full of Ivy League Scholars and philanthropists."}, "gen_args_2": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? No, The group is full of Ivy League Scholars and philanthropists."}}, "resps": [[["-175.0", "False"]], [["-177.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-177.0", "False"], ["-175.0", "False"]], "doc_hash": "80e06ba3b77d4f17f2c5bdee81e448f98d28ecae6d061a1e8c28b5b360825330", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1856, "doc": {"premise": "Will you add your dreams to ours?", "hypothesis": "Will your dreams become part of ours?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Yes, Will your dreams become part of ours?"}, "gen_args_1": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Also, Will your dreams become part of ours?"}, "gen_args_2": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? No, Will your dreams become part of ours?"}}, "resps": [[["-88.5", "False"]], [["-89.5", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-88.5", "False"], ["-89.5", "False"], ["-90.0", "False"]], "doc_hash": "609ae29ce02297a3872aa9e6d08df15fc0184e125e5a91acf4dfcb1eb9c50295", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.62853172 0.2312239  0.14024438]"]}
{"doc_id": 1864, "doc": {"premise": "Chairman of the Board of Trustees", "hypothesis": "The Chairperson of the Board of Trustees.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Yes, The Chairperson of the Board of Trustees."}, "gen_args_1": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Also, The Chairperson of the Board of Trustees."}, "gen_args_2": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? No, The Chairperson of the Board of Trustees."}}, "resps": [[["-60.25", "False"]], [["-63.0", "False"]], [["-58.25", "False"]]], "filtered_resps": [["-60.25", "False"], ["-63.0", "False"], ["-58.25", "False"]], "doc_hash": "f6da5db2682d6f7468308cf2d07e48cb46c8d6a65badb54d67307a6332e37bb4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11830142 0.00756276 0.87413582]"]}
{"doc_id": 1872, "doc": {"premise": ".. why they have so little self-worth that they value the friendship of thieves and killers.", "hypothesis": "None of their friends are thieves and killers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Yes, None of their friends are thieves and killers."}, "gen_args_1": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Also, None of their friends are thieves and killers."}, "gen_args_2": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? No, None of their friends are thieves and killers."}}, "resps": [[["-130.0", "False"]], [["-130.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-130.0", "False"], ["-130.0", "False"], ["-125.5", "False"]], "doc_hash": "420cd4796d83dcea237709e50adfe6868f595dd473a779d0f53d917ff6751553", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01086754 0.01086754 0.97826492]"]}
{"doc_id": 1880, "doc": {"premise": "I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support.", "hypothesis": "I am asking you to make another gift to the IUPUI University Libraries.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Yes, I am asking you to make another gift to the IUPUI University Libraries."}, "gen_args_1": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Also, I am asking you to make another gift to the IUPUI University Libraries."}, "gen_args_2": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? No, I am asking you to make another gift to the IUPUI University Libraries."}}, "resps": [[["-114.5", "False"]], [["-122.0", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-122.0", "False"], ["-118.5", "False"]], "doc_hash": "3434c31c35bf50868dbffc5dc4e55d2ac9598f2f0b973d49990161e192cf7b68", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81480712e-01 5.42841641e-04 1.79764463e-02]"]}
{"doc_id": 1888, "doc": {"premise": "You are important to us and the I.U.", "hypothesis": "We and the I.U. consider you to be important.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Yes, We and the I.U. consider you to be important."}, "gen_args_1": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Also, We and the I.U. consider you to be important."}, "gen_args_2": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? No, We and the I.U. consider you to be important."}}, "resps": [[["-92.5", "False"]], [["-101.5", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-92.5", "False"], ["-101.5", "False"], ["-98.0", "False"]], "doc_hash": "e10fe5121d0bd39845a0d0b5fd82accb4a47867a1552c92d6c52427db7f87eb1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.95807470e-01 1.22892405e-04 4.06963753e-03]"]}
{"doc_id": 1896, "doc": {"premise": "Student tuition has been raised 12% for 1992-92, a significant increase.", "hypothesis": "The tuition rate has increased a lot.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Yes, The tuition rate has increased a lot."}, "gen_args_1": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Also, The tuition rate has increased a lot."}, "gen_args_2": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? No, The tuition rate has increased a lot."}}, "resps": [[["-120.0", "False"]], [["-124.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-120.0", "False"], ["-124.5", "False"], ["-122.5", "False"]], "doc_hash": "90f4d9fe1374a563c9a7fc3f07d0f2f229383fa7bb4bdfd309128175b25d6c59", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.91475073 0.01016196 0.07508731]"]}
{"doc_id": 1904, "doc": {"premise": "We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself.", "hypothesis": "Ticket sales bring in less than half of that money.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Yes, Ticket sales bring in less than half of that money."}, "gen_args_1": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Also, Ticket sales bring in less than half of that money."}, "gen_args_2": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? No, Ticket sales bring in less than half of that money."}}, "resps": [[["-164.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "ba242764881d3a000c53e0bd552d33969a1c97c8f5b6a6cdbe4a3f06b19cd452", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 1912, "doc": {"premise": "This situation could also impact our ability to mount another festival next year.", "hypothesis": "We might not have a festival if we don't have a lot of attendance this year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Yes, We might not have a festival if we don't have a lot of attendance this year."}, "gen_args_1": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Also, We might not have a festival if we don't have a lot of attendance this year."}, "gen_args_2": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? No, We might not have a festival if we don't have a lot of attendance this year."}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-134.0", "False"]], "doc_hash": "6e513dfaef0eefb67dc16b89dc81a456627372bc29f4cd0e60c13be8cc0a397e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1920, "doc": {"premise": "By May 1, we must conclude membership renewal options for 1991 contributors.", "hypothesis": "Some members can renew their memberships.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Yes, Some members can renew their memberships."}, "gen_args_1": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Also, Some members can renew their memberships."}, "gen_args_2": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? No, Some members can renew their memberships."}}, "resps": [[["-141.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "f53fba66badf5219e958fcdb044296631d990b1d7c8e399b976903f6973c8806", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1928, "doc": {"premise": "The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research.", "hypothesis": "Loren Field works at the school.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Yes, Loren Field works at the school."}, "gen_args_1": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Also, Loren Field works at the school."}, "gen_args_2": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? No, Loren Field works at the school."}}, "resps": [[["-187.0", "False"]], [["-191.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-191.0", "False"], ["-188.0", "False"]], "doc_hash": "155b0dcda766e13c81692c9f7b75e5b0952db03bacafb6ca50055069cfcb0625", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1936, "doc": {"premise": "Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy.", "hypothesis": "Visitors will be able to see several shows in the Hilbert Conservatory.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Yes, Visitors will be able to see several shows in the Hilbert Conservatory."}, "gen_args_1": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Also, Visitors will be able to see several shows in the Hilbert Conservatory."}, "gen_args_2": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? No, Visitors will be able to see several shows in the Hilbert Conservatory."}}, "resps": [[["-176.0", "False"]], [["-186.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-186.0", "False"], ["-176.0", "False"]], "doc_hash": "3cebc56bc50557145d369878381d29682a86872e051df8fd3c7a69551e68f8c6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99988650e-01 2.26994496e-05 4.99988650e-01]"]}
{"doc_id": 1944, "doc": {"premise": "Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana.", "hypothesis": "Our theatre productions have helped elementary school children learn how to paint.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Yes, Our theatre productions have helped elementary school children learn how to paint."}, "gen_args_1": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Also, Our theatre productions have helped elementary school children learn how to paint."}, "gen_args_2": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? No, Our theatre productions have helped elementary school children learn how to paint."}}, "resps": [[["-214.0", "False"]], [["-218.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-218.0", "False"], ["-216.0", "False"]], "doc_hash": "3db43e58f8e763da50cc412bbfe734afa2e01f4edef4820b341c543a27ba580a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1952, "doc": {"premise": "Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre.", "hypothesis": "IRT artists help kids put on a production.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Yes, IRT artists help kids put on a production."}, "gen_args_1": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Also, IRT artists help kids put on a production."}, "gen_args_2": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? No, IRT artists help kids put on a production."}}, "resps": [[["-153.0", "False"]], [["-155.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-155.0", "False"], ["-152.0", "False"]], "doc_hash": "06ccf5172cb920a3588478ad7f810455080f84f3379e9897a67828fda5080041", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1960, "doc": {"premise": "It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots.", "hypothesis": "The center focuses on helping other continents.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Yes, The center focuses on helping other continents."}, "gen_args_1": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Also, The center focuses on helping other continents."}, "gen_args_2": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? No, The center focuses on helping other continents."}}, "resps": [[["-188.0", "False"]], [["-187.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-187.0", "False"], ["-187.0", "False"]], "doc_hash": "23375e834e99932e75df031cc67f62587305127d371c3d69c257a4b590bd329a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1968, "doc": {"premise": ".. wisps of white clouds scattered across a clear, blue sky.", "hypothesis": "The sky is clear and blue, and there are clouds here and there.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Yes, The sky is clear and blue, and there are clouds here and there."}, "gen_args_1": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Also, The sky is clear and blue, and there are clouds here and there."}, "gen_args_2": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? No, The sky is clear and blue, and there are clouds here and there."}}, "resps": [[["-105.0", "False"]], [["-112.5", "False"]], [["-107.5", "False"]]], "filtered_resps": [["-105.0", "False"], ["-112.5", "False"], ["-107.5", "False"]], "doc_hash": "3ad1a3e4e1c7ef6e4931e51a64f6157d53f979f155fca68cf7529fc4cdac2588", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.23669706e-01 5.10867278e-04 7.58194266e-02]"]}
{"doc_id": 1976, "doc": {"premise": "P. S. A tribute donation to the IMA makes a wonderful holiday gift.", "hypothesis": "Gentle note that you could make donations any time not just around the holidays.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Yes, Gentle note that you could make donations any time not just around the holidays."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Also, Gentle note that you could make donations any time not just around the holidays."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? No, Gentle note that you could make donations any time not just around the holidays."}}, "resps": [[["-163.0", "False"]], [["-160.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-160.0", "False"], ["-166.0", "False"]], "doc_hash": "7cdc58f7fc9016b85d8101eb90cd5ce4e4a836f075af5992d2543e8b1745208d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04731416 0.95033021 0.00235563]"]}
{"doc_id": 1984, "doc": {"premise": "The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it.", "hypothesis": "The Indy Civic Theater has done 120 shows in 80 years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Yes, The Indy Civic Theater has done 120 shows in 80 years."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Also, The Indy Civic Theater has done 120 shows in 80 years."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? No, The Indy Civic Theater has done 120 shows in 80 years."}}, "resps": [[["-204.0", "False"]], [["-208.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-208.0", "False"], ["-205.0", "False"]], "doc_hash": "1d6e54ab9fd0084f62da128280fd41c850280b21ddf323c63a20f4ca2dea7c1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1992, "doc": {"premise": "With OPEN going platinum, why not a neon CLOSED sign?", "hypothesis": "The OPEN sign is black.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Yes, The OPEN sign is black."}, "gen_args_1": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Also, The OPEN sign is black."}, "gen_args_2": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? No, The OPEN sign is black."}}, "resps": [[["-131.0", "False"]], [["-130.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-130.0", "False"], ["-130.0", "False"]], "doc_hash": "aaabebe33e0ef4cf51ba92081a1060d15b81bec1e400e92438eea202dbecaee6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 2000, "doc": {"premise": "There is one detail of Southern japes that has inverted its class associations.", "hypothesis": "There is a class association here that has been inverted.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Yes, There is a class association here that has been inverted."}, "gen_args_1": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Also, There is a class association here that has been inverted."}, "gen_args_2": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? No, There is a class association here that has been inverted."}}, "resps": [[["-138.0", "False"]], [["-143.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-143.0", "False"], ["-140.0", "False"]], "doc_hash": "0bbe119bdf7c06cf477a6ebea21fc549771aa8a564ddcdbfab48040c87af640c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2008, "doc": {"premise": "Run Silent, Run Deep, Run the Answer", "hypothesis": "Run with arms flailing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Yes, Run with arms flailing."}, "gen_args_1": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Also, Run with arms flailing."}, "gen_args_2": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? No, Run with arms flailing."}}, "resps": [[["-93.5", "False"]], [["-91.0", "False"]], [["-89.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-91.0", "False"], ["-89.5", "False"]], "doc_hash": "f822cd999921aecdfa4346eec32e71f28de0fb34f42d3ce160bb515987638f70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01475347 0.17973411 0.80551241]"]}
{"doc_id": 2016, "doc": {"premise": "Steve, I couldn't even lift your wallet, Hatch shot back.", "hypothesis": "Hatch angrily said that he couldn't even lift Steve's wallet.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Yes, Hatch angrily said that he couldn't even lift Steve's wallet."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Also, Hatch angrily said that he couldn't even lift Steve's wallet."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? No, Hatch angrily said that he couldn't even lift Steve's wallet."}}, "resps": [[["-127.0", "False"]], [["-133.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-133.0", "False"], ["-128.0", "False"]], "doc_hash": "18288a85137056bc06a3122d5ab7d921794eff06bff06b8cf748e53a5d4a61ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 2024, "doc": {"premise": "Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre.", "hypothesis": "Tripp's conversations have never been listened to.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Yes, Tripp's conversations have never been listened to."}, "gen_args_1": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Also, Tripp's conversations have never been listened to."}, "gen_args_2": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? No, Tripp's conversations have never been listened to."}}, "resps": [[["-154.0", "False"]], [["-152.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-152.0", "False"], ["-154.0", "False"]], "doc_hash": "79d4ed3bb618b1e7c0b8291ebc619f6cd71334b5b58a73c218591cda1c0c06b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 2032, "doc": {"premise": "This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights.", "hypothesis": "Kennedy favors states rights when it comes to abortion.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Yes, Kennedy favors states rights when it comes to abortion."}, "gen_args_1": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Also, Kennedy favors states rights when it comes to abortion."}, "gen_args_2": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? No, Kennedy favors states rights when it comes to abortion."}}, "resps": [[["-121.5", "False"]], [["-123.5", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-121.5", "False"], ["-123.5", "False"], ["-124.0", "False"]], "doc_hash": "979d0407d1cdc0f5bdf13f016e788315772c0e3e7a14481e563d7e4cc349a033", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.82140902 0.11116562 0.06742536]"]}
{"doc_id": 2040, "doc": {"premise": "Sabol said he has to take the occasional pit stop, but even that is conveniently arranged.", "hypothesis": "Sabol does not need to take all those pit stops.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Yes, Sabol does not need to take all those pit stops."}, "gen_args_1": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Also, Sabol does not need to take all those pit stops."}, "gen_args_2": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? No, Sabol does not need to take all those pit stops."}}, "resps": [[["-142.0", "False"]], [["-143.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-143.0", "False"], ["-137.0", "False"]], "doc_hash": "5a71371b811da2ab4effd7a2a83f38fcd70b3898794dbbf50ded10a91c64f6fe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 2048, "doc": {"premise": "Why doesn't this apply on the Web?", "hypothesis": "This may apply in some cases on the Web.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Yes, This may apply in some cases on the Web."}, "gen_args_1": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Also, This may apply in some cases on the Web."}, "gen_args_2": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? No, This may apply in some cases on the Web."}}, "resps": [[["-93.0", "False"]], [["-98.0", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-93.0", "False"], ["-98.0", "False"], ["-95.0", "False"]], "doc_hash": "d0e942831cf87f51b24571f6897a75bed0291f56170a8125f5b8789b79daab6b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2056, "doc": {"premise": "You are not sure you've been clear about whose side you're on.", "hypothesis": "We don't know who you support in the election.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Yes, We don't know who you support in the election."}, "gen_args_1": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Also, We don't know who you support in the election."}, "gen_args_2": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? No, We don't know who you support in the election."}}, "resps": [[["-109.0", "False"]], [["-110.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-110.5", "False"], ["-112.0", "False"]], "doc_hash": "b7249aa5a0b1c30dde255281f854369a5e25a57bf6e6fac764354aee1d5bf94c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78559703 0.17529039 0.03911257]"]}
{"doc_id": 2064, "doc": {"premise": "The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous.", "hypothesis": "Livingston's resignation has let Clinton appear forgiving.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Yes, Livingston's resignation has let Clinton appear forgiving."}, "gen_args_1": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Also, Livingston's resignation has let Clinton appear forgiving."}, "gen_args_2": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? No, Livingston's resignation has let Clinton appear forgiving."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-130.0", "False"]], "doc_hash": "e7808e3ae64a7874d879bc602872abb7f01583b5798b6a593e9eb4370c7f6f6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 2072, "doc": {"premise": "The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat.", "hypothesis": "The university thinks art students cheated.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Yes, The university thinks art students cheated."}, "gen_args_1": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Also, The university thinks art students cheated."}, "gen_args_2": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? No, The university thinks art students cheated."}}, "resps": [[["-167.0", "False"]], [["-168.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-168.0", "False"], ["-165.0", "False"]], "doc_hash": "72b9d46fb33e51dcbe874a7676eed41a2821443e18c7fc27d2fa4911c0f931c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 2080, "doc": {"premise": "One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?", "hypothesis": "There is no way one can arrive at the answer.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Yes, There is no way one can arrive at the answer."}, "gen_args_1": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Also, There is no way one can arrive at the answer."}, "gen_args_2": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? No, There is no way one can arrive at the answer."}}, "resps": [[["-168.0", "False"]], [["-166.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-166.0", "False"], ["-165.0", "False"]], "doc_hash": "9afb58bd64e6cad20ba95568a5db54c2c4377361c19d4cf0734fd3dc8c1a9746", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.03511903 0.25949646 0.70538451]"]}
{"doc_id": 2088, "doc": {"premise": "This kind of treatment for big contributors is quite routine.", "hypothesis": "Big contributors are always given special treatment at these events.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Yes, Big contributors are always given special treatment at these events."}, "gen_args_1": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Also, Big contributors are always given special treatment at these events."}, "gen_args_2": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? No, Big contributors are always given special treatment at these events."}}, "resps": [[["-116.5", "False"]], [["-120.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-120.5", "False"], ["-120.0", "False"]], "doc_hash": "0b9f3b57f6fedaa330ce04ad353c7bdbcc94b4877f190ef2b348a5c1d492de8d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.9537316 0.0174682 0.0288002]"]}
{"doc_id": 2096, "doc": {"premise": "She was a big-haired brunette with a fleshy face, full lips, and large teeth.", "hypothesis": "She was completely bald, and she had no teeth at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Yes, She was completely bald, and she had no teeth at all."}, "gen_args_1": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Also, She was completely bald, and she had no teeth at all."}, "gen_args_2": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? No, She was completely bald, and she had no teeth at all."}}, "resps": [[["-127.0", "False"]], [["-130.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-130.0", "False"], ["-121.0", "False"]], "doc_hash": "70db1ddbd6c1f2f45c14a216fd580d96f62915c2834a702c6e0523beb919e0c0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47231880e-03 1.23089505e-04 9.97404592e-01]"]}
{"doc_id": 2104, "doc": {"premise": "Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner.", "hypothesis": "Morrison has worked very hard to deserve the right to be idiosyncratic.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Yes, Morrison has worked very hard to deserve the right to be idiosyncratic."}, "gen_args_1": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Also, Morrison has worked very hard to deserve the right to be idiosyncratic."}, "gen_args_2": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? No, Morrison has worked very hard to deserve the right to be idiosyncratic."}}, "resps": [[["-140.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "3a0a2f7f221a9525036edf09a26020fa5faec953e9e52cd94b0028bf13332f90", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2112, "doc": {"premise": "Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state.", "hypothesis": "Henry Kissinger was Nixon's secretary of state.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Yes, Henry Kissinger was Nixon's secretary of state."}, "gen_args_1": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Also, Henry Kissinger was Nixon's secretary of state."}, "gen_args_2": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? No, Henry Kissinger was Nixon's secretary of state."}}, "resps": [[["-114.0", "False"]], [["-117.5", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-114.0", "False"], ["-117.5", "False"], ["-114.0", "False"]], "doc_hash": "3f85a095565019f0c324a41d3b75a51d0628cd48b4223e6814a9840f344b5487", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49256294 0.01487411 0.49256294]"]}
{"doc_id": 2120, "doc": {"premise": "Like Ross, Mehta struggles to express William Shawn's ineffable virtues.", "hypothesis": "William Shawn's ineffable virtues are difficult to express for anyone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Yes, William Shawn's ineffable virtues are difficult to express for anyone."}, "gen_args_1": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Also, William Shawn's ineffable virtues are difficult to express for anyone."}, "gen_args_2": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? No, William Shawn's ineffable virtues are difficult to express for anyone."}}, "resps": [[["-142.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "58c4a36bb7296c91f99d3a6826a905fce312b67b9e09ff9423c49899082b812c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 2128, "doc": {"premise": "The decent and sensitive thing to do is tell the president.", "hypothesis": "Telling the president would be considered insensitive.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Yes, Telling the president would be considered insensitive."}, "gen_args_1": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Also, Telling the president would be considered insensitive."}, "gen_args_2": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? No, Telling the president would be considered insensitive."}}, "resps": [[["-108.0", "False"]], [["-110.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-108.0", "False"], ["-110.5", "False"], ["-104.5", "False"]], "doc_hash": "378a630415579148d2c388687edddde37356a812496cfa3cdae397adaad0767c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 2136, "doc": {"premise": "There is a difference between canny skepticism and dumbbell skepticism.", "hypothesis": "Canny skepticism and dumbbell skepticism are not exactly the same.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Yes, Canny skepticism and dumbbell skepticism are not exactly the same."}, "gen_args_1": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Also, Canny skepticism and dumbbell skepticism are not exactly the same."}, "gen_args_2": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? No, Canny skepticism and dumbbell skepticism are not exactly the same."}}, "resps": [[["-104.5", "False"]], [["-108.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-104.5", "False"], ["-108.0", "False"], ["-106.0", "False"]], "doc_hash": "4cd4417e1c4006f1e8077460f04e70d4a85b74e18fa5b82e7335f63f9d001ace", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 2144, "doc": {"premise": "John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting.", "hypothesis": "Richard Dawkins wrote a book called Climbing Mount Impossible (The Mystery of Life).", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Yes, Richard Dawkins wrote a book called Climbing Mount Impossible (The Mystery of Life)."}, "gen_args_1": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Also, Richard Dawkins wrote a book called Climbing Mount Impossible (The Mystery of Life)."}, "gen_args_2": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? No, Richard Dawkins wrote a book called Climbing Mount Impossible (The Mystery of Life)."}}, "resps": [[["-128.0", "False"]], [["-132.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-132.0", "False"], ["-132.0", "False"]], "doc_hash": "bde550e0dd6bbd6fe10e1ae56d3cd0fb39ecfd0734cc045f4c1b032a50b358e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2152, "doc": {"premise": "Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business.", "hypothesis": "Bruce apologizes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Yes, Bruce apologizes."}, "gen_args_1": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Also, Bruce apologizes."}, "gen_args_2": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? No, Bruce apologizes."}}, "resps": [[["-210.0", "False"]], [["-212.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-210.0", "False"], ["-212.0", "False"], ["-209.0", "False"]], "doc_hash": "df2e08ca44f59a007e120261a3425c85c7d885473df17c8bcfa94a6c42eeba2f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2160, "doc": {"premise": "The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal.", "hypothesis": "Brock does not defend Hillary.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Yes, Brock does not defend Hillary."}, "gen_args_1": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Also, Brock does not defend Hillary."}, "gen_args_2": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? No, Brock does not defend Hillary."}}, "resps": [[["-160.0", "False"]], [["-158.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-158.0", "False"], ["-153.0", "False"]], "doc_hash": "d2c80956d6762e1579d738d0767573d0aaf585da5411e0e9b4a94bd10c0f7dd9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.04959183e-04 6.68679417e-03 9.92408247e-01]"]}
{"doc_id": 2168, "doc": {"premise": "This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious.", "hypothesis": "Some people dislike Forbes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Yes, Some people dislike Forbes."}, "gen_args_1": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Also, Some people dislike Forbes."}, "gen_args_2": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? No, Some people dislike Forbes."}}, "resps": [[["-131.0", "False"]], [["-136.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-136.0", "False"], ["-135.0", "False"]], "doc_hash": "fb68a1b7365710722677b880765d5fd148ef3667c6b60c1ac3ff0e9d04a4d967", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 2176, "doc": {"premise": "My gender is interesting but really not the subject of the story here.", "hypothesis": "The main subject of this story is about my gender and revealing this to those closest to me.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Yes, The main subject of this story is about my gender and revealing this to those closest to me."}, "gen_args_1": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Also, The main subject of this story is about my gender and revealing this to those closest to me."}, "gen_args_2": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? No, The main subject of this story is about my gender and revealing this to those closest to me."}}, "resps": [[["-140.0", "False"]], [["-145.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-145.0", "False"], ["-142.0", "False"]], "doc_hash": "d1ce935396c9bdd1a1c5d1430da084f948ce2e595b1b7267b6dc1a4788ad416a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2184, "doc": {"premise": "When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card.", "hypothesis": "The sign lit up in Times Square.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Yes, The sign lit up in Times Square."}, "gen_args_1": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Also, The sign lit up in Times Square."}, "gen_args_2": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? No, The sign lit up in Times Square."}}, "resps": [[["-165.0", "False"]], [["-170.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-170.0", "False"], ["-166.0", "False"]], "doc_hash": "e0ccbed8444338f2097e9ffed5a56a7bf895c746e0fe876360133ae2dc464fd6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2192, "doc": {"premise": "Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;", "hypothesis": "There is only one type of irony.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Yes, There is only one type of irony."}, "gen_args_1": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Also, There is only one type of irony."}, "gen_args_2": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? No, There is only one type of irony."}}, "resps": [[["-169.0", "False"]], [["-169.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-169.0", "False"], ["-168.0", "False"]], "doc_hash": "23fe113cc44a2c74a0c18d9f47fc710fad8e62eca9a5bb2842b54afb86eedbd7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2200, "doc": {"premise": "The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di.", "hypothesis": "Hillary Rodham Clinton could learn from Princess Diana.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Yes, Hillary Rodham Clinton could learn from Princess Diana."}, "gen_args_1": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Also, Hillary Rodham Clinton could learn from Princess Diana."}, "gen_args_2": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? No, Hillary Rodham Clinton could learn from Princess Diana."}}, "resps": [[["-168.0", "False"]], [["-175.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-175.0", "False"], ["-172.0", "False"]], "doc_hash": "4c1aaa36df22c347d235e1959307254ee92374f75582794ad60c43ed874138c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 2208, "doc": {"premise": "There are, of course, many elegant and flirtatious scenes set on yachts.", "hypothesis": "Large yachts are very expensive to maintain as they need regular maintenance and use large amounts of fuel.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Yes, Large yachts are very expensive to maintain as they need regular maintenance and use large amounts of fuel."}, "gen_args_1": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Also, Large yachts are very expensive to maintain as they need regular maintenance and use large amounts of fuel."}, "gen_args_2": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? No, Large yachts are very expensive to maintain as they need regular maintenance and use large amounts of fuel."}}, "resps": [[["-146.0", "False"]], [["-146.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-146.0", "False"], ["-147.0", "False"]], "doc_hash": "67b17c02dd5c2ac01174944932a587723463898284c00d3268c8a0151b80c752", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 2216, "doc": {"premise": "The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future.", "hypothesis": "The New Yorker has fought back with more than 20 special issues, including whole magazines about racism, space travel, and education.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Yes, The New Yorker has fought back with more than 20 special issues, including whole magazines about racism, space travel, and education."}, "gen_args_1": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Also, The New Yorker has fought back with more than 20 special issues, including whole magazines about racism, space travel, and education."}, "gen_args_2": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? No, The New Yorker has fought back with more than 20 special issues, including whole magazines about racism, space travel, and education."}}, "resps": [[["-189.0", "False"]], [["-196.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-196.0", "False"], ["-189.0", "False"]], "doc_hash": "a351de8e0c5caffdf0099b3404c121b1d8bea8865a292bc5154a90419a40d182", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 2224, "doc": {"premise": "The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year.", "hypothesis": "Millions of people took fen-phen.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Yes, Millions of people took fen-phen."}, "gen_args_1": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Also, Millions of people took fen-phen."}, "gen_args_2": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? No, Millions of people took fen-phen."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-152.0", "False"]], "doc_hash": "5a62f4ee329f318b901457879ddc7c6dc7890d1581cb8596e3f9fc66c93d255b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2232, "doc": {"premise": "More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI.", "hypothesis": "BT offered 20 billion for MCT.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Yes, BT offered 20 billion for MCT."}, "gen_args_1": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Also, BT offered 20 billion for MCT."}, "gen_args_2": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? No, BT offered 20 billion for MCT."}}, "resps": [[["-176.0", "False"]], [["-180.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-180.0", "False"], ["-173.0", "False"]], "doc_hash": "ee0ea3b7b840d057bb16853dba3402c2ad3d398d1f6e81cf972eb2e0460bc8fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 2240, "doc": {"premise": "The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them.", "hypothesis": "Decter is old.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Yes, Decter is old."}, "gen_args_1": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Also, Decter is old."}, "gen_args_2": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? No, Decter is old."}}, "resps": [[["-150.0", "False"]], [["-152.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-152.0", "False"], ["-153.0", "False"]], "doc_hash": "27ac447c969a1bf01e0db8be56a82d1bb4fc9d4ce5a248c888d6ba8952a943c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 2248, "doc": {"premise": "On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders.", "hypothesis": "The car had veered off the road and fallen onto the base of the boulder.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Yes, The car had veered off the road and fallen onto the base of the boulder."}, "gen_args_1": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Also, The car had veered off the road and fallen onto the base of the boulder."}, "gen_args_2": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? No, The car had veered off the road and fallen onto the base of the boulder."}}, "resps": [[["-203.0", "False"]], [["-207.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-207.0", "False"], ["-204.0", "False"]], "doc_hash": "a6f431cca282d2dc8f64510b7589dfba09cf9ace14b170349baea958d1a88c87", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2256, "doc": {"premise": "Which do you like better, math or science?", "hypothesis": "Do you have a preference for math or science?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Yes, Do you have a preference for math or science?"}, "gen_args_1": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Also, Do you have a preference for math or science?"}, "gen_args_2": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? No, Do you have a preference for math or science?"}}, "resps": [[["-82.0", "False"]], [["-81.0", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-82.0", "False"], ["-81.0", "False"], ["-83.0", "False"]], "doc_hash": "5c2364f7239aa5d5ba14c87e886fdc3ee7f495a26e7b6a2dd125089d74788f31", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2264, "doc": {"premise": "The last sentence   We assume, of course, that you have not submitted this essay elsewhere.", "hypothesis": "We would like you to sign a form accepting that we are the only ones you have presented this essay to.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Yes, We would like you to sign a form accepting that we are the only ones you have presented this essay to."}, "gen_args_1": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Also, We would like you to sign a form accepting that we are the only ones you have presented this essay to."}, "gen_args_2": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? No, We would like you to sign a form accepting that we are the only ones you have presented this essay to."}}, "resps": [[["-155.0", "False"]], [["-159.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-159.0", "False"], ["-156.0", "False"]], "doc_hash": "6b3e6a8a155c36befd8cb2927c28cdca4c963fb8a902201f36b62d52609b6e5e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2272, "doc": {"premise": "good brother -- this expression of common present usage is found in Julius Caesar (iv.", "hypothesis": "The term good brother has only been used since the 20th Century.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Yes, The term good brother has only been used since the 20th Century."}, "gen_args_1": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Also, The term good brother has only been used since the 20th Century."}, "gen_args_2": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? No, The term good brother has only been used since the 20th Century."}}, "resps": [[["-169.0", "False"]], [["-167.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-167.0", "False"], ["-167.0", "False"]], "doc_hash": "21b685e55f408993a121bd1b0c93f5ffeb5d3c24c45369c8d378f667e7e1c65b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 2280, "doc": {"premise": "How old are  young people ?", "hypothesis": "I know exactly how old young people are.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " How old are  young people ?, right? Yes, I know exactly how old young people are."}, "gen_args_1": {"arg_0": "", "arg_1": " How old are  young people ?, right? Also, I know exactly how old young people are."}, "gen_args_2": {"arg_0": "", "arg_1": " How old are  young people ?, right? No, I know exactly how old young people are."}}, "resps": [[["-86.5", "False"]], [["-94.0", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-86.5", "False"], ["-94.0", "False"], ["-87.0", "False"]], "doc_hash": "b5920448be70ecf108002e3e9607dedbb2c4ff488a73af04006dcf7de73cc730", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.22245109e-01 3.44154044e-04 3.77410737e-01]"]}
{"doc_id": 2288, "doc": {"premise": "According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations.", "hypothesis": "The ODNW lacks enough of the information and entries required to make it useful.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Yes, The ODNW lacks enough of the information and entries required to make it useful."}, "gen_args_1": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Also, The ODNW lacks enough of the information and entries required to make it useful."}, "gen_args_2": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? No, The ODNW lacks enough of the information and entries required to make it useful."}}, "resps": [[["-222.0", "False"]], [["-218.0", "False"]], [["-218.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-218.0", "False"], ["-218.0", "False"]], "doc_hash": "ecd75d5fbc4c97a73b6e2ec7d22e2419c431a1c44609541ee9926ae3d581d72f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00907471 0.49546264 0.49546264]"]}
{"doc_id": 2296, "doc": {"premise": "As for challenges, I am currently looking for a word that can be cut into two successively smaller forms.", "hypothesis": "I have not had an easy time finding a word that can be cut into two successively smaller forms.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Yes, I have not had an easy time finding a word that can be cut into two successively smaller forms."}, "gen_args_1": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Also, I have not had an easy time finding a word that can be cut into two successively smaller forms."}, "gen_args_2": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? No, I have not had an easy time finding a word that can be cut into two successively smaller forms."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "eccfaa5a4e41ee94f57f9c36f453e9cd486fee7ef9aaa1818d4252db2b033b02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2304, "doc": {"premise": "In the closing years of the 19th century there was much discussion concerning the word", "hypothesis": "It was eventually decided that the word was not acceptable in polite company.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Yes, It was eventually decided that the word was not acceptable in polite company."}, "gen_args_1": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Also, It was eventually decided that the word was not acceptable in polite company."}, "gen_args_2": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? No, It was eventually decided that the word was not acceptable in polite company."}}, "resps": [[["-113.5", "False"]], [["-116.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-116.5", "False"], ["-115.5", "False"]], "doc_hash": "67b4190ad86e20bc5843574358a52a117691239a9862f8a058d2918237cdb193", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2312, "doc": {"premise": "But they have one private, hidden name which remains a family secret.", "hypothesis": "This family has a secret that remains hidden.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Yes, This family has a secret that remains hidden."}, "gen_args_1": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Also, This family has a secret that remains hidden."}, "gen_args_2": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? No, This family has a secret that remains hidden."}}, "resps": [[["-122.0", "False"]], [["-127.5", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-127.5", "False"], ["-123.5", "False"]], "doc_hash": "15091bb650c071edfa219f87025a5063514f9b5fe155a3d5f6b09d9d1fdfddc2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81485186 0.00333011 0.18181803]"]}
{"doc_id": 2320, "doc": {"premise": "consistency is a form of ritualism.", "hypothesis": "Consistency results in random chaotic outcomes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Yes, Consistency results in random chaotic outcomes."}, "gen_args_1": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Also, Consistency results in random chaotic outcomes."}, "gen_args_2": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? No, Consistency results in random chaotic outcomes."}}, "resps": [[["-106.5", "False"]], [["-107.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-107.0", "False"], ["-105.5", "False"]], "doc_hash": "19035c0ca2611278d72deae5af5acef9bbd7be42652b292413fc4d0a3b8300af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.2312239  0.14024438 0.62853172]"]}
{"doc_id": 2328, "doc": {"premise": "Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms.", "hypothesis": "The largest dictionary had more than 600'000 entries.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Yes, The largest dictionary had more than 600'000 entries."}, "gen_args_1": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Also, The largest dictionary had more than 600'000 entries."}, "gen_args_2": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? No, The largest dictionary had more than 600'000 entries."}}, "resps": [[["-160.0", "False"]], [["-165.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-165.0", "False"], ["-160.0", "False"]], "doc_hash": "3719b10f4ff70c3379cfb25c21efdadb5855e50eb56c2ea82a301a055c5c2db2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 2336, "doc": {"premise": "'  It is remarkable that this anomaly still persists, even in many modern sources.", "hypothesis": "This anomaly still exists today as it did in the past.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Yes, This anomaly still exists today as it did in the past."}, "gen_args_1": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Also, This anomaly still exists today as it did in the past."}, "gen_args_2": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? No, This anomaly still exists today as it did in the past."}}, "resps": [[["-132.0", "False"]], [["-136.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-136.0", "False"], ["-134.0", "False"]], "doc_hash": "afb96a846dd50518947c9b5bada042ba16e90ffd5ad53c103047c147991a44c1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2344, "doc": {"premise": "They teach us to be resolute, relentless, and resourceful.", "hypothesis": "Being resolute, relentless, and resourceful are skills that cannot be taught, but are simply instinctual.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Yes, Being resolute, relentless, and resourceful are skills that cannot be taught, but are simply instinctual."}, "gen_args_1": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Also, Being resolute, relentless, and resourceful are skills that cannot be taught, but are simply instinctual."}, "gen_args_2": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? No, Being resolute, relentless, and resourceful are skills that cannot be taught, but are simply instinctual."}}, "resps": [[["-126.0", "False"]], [["-125.5", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-125.5", "False"], ["-124.0", "False"]], "doc_hash": "70ae1f21b535c2feab88c786dd6420d110e351f6397e20679b8ec2bc5d494712", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09962365 0.16425163 0.73612472]"]}
{"doc_id": 2352, "doc": {"premise": "As we all know, there is an enormous number of publications dealing with highly specialized areas.", "hypothesis": "There are a lot of journals about the scientific studies.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Yes, There are a lot of journals about the scientific studies."}, "gen_args_1": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Also, There are a lot of journals about the scientific studies."}, "gen_args_2": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? No, There are a lot of journals about the scientific studies."}}, "resps": [[["-118.0", "False"]], [["-120.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-118.0", "False"], ["-120.5", "False"], ["-122.5", "False"]], "doc_hash": "54d480f67d28c15e4c70ecea13f88e24999769e3c4181c180c582fb654b61999", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.91475073 0.07508731 0.01016196]"]}
{"doc_id": 2360, "doc": {"premise": "Let it be remembered that they make no declarations.", "hypothesis": "We should keep in mind that they have made no statements.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Yes, We should keep in mind that they have made no statements."}, "gen_args_1": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Also, We should keep in mind that they have made no statements."}, "gen_args_2": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? No, We should keep in mind that they have made no statements."}}, "resps": [[["-103.5", "False"]], [["-107.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-103.5", "False"], ["-107.0", "False"], ["-106.0", "False"]], "doc_hash": "906d82be885172e956b1e0f7854bceeb39e39f00a8752b150b617e7ce671861e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.89905227 0.02714903 0.0737987 ]"]}
{"doc_id": 2368, "doc": {"premise": "buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble'", "hypothesis": "The saying is about cats with three legs.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Yes, The saying is about cats with three legs."}, "gen_args_1": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Also, The saying is about cats with three legs."}, "gen_args_2": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? No, The saying is about cats with three legs."}}, "resps": [[["-157.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "91d0c5e3a043d4f37aacf5983071805b91307d612c1b54af5d10ed94c109d257", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00235563 0.04731416 0.95033021]"]}
{"doc_id": 2376, "doc": {"premise": "to do (someone) wrong -- The Rape of Lucrece , line 1462:", "hypothesis": "someone did nothing wrong", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Yes, someone did nothing wrong"}, "gen_args_1": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Also, someone did nothing wrong"}, "gen_args_2": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? No, someone did nothing wrong"}}, "resps": [[["-134.0", "False"]], [["-134.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-134.0", "False"], ["-130.0", "False"]], "doc_hash": "dd53c0efc8afd62835b5c913baeff2c16f2260f6551b226b77f83c8bcee9c31b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 2384, "doc": {"premise": "Many languages have this ambiguity.", "hypothesis": "This makes learning the language more difficult.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Yes, This makes learning the language more difficult."}, "gen_args_1": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Also, This makes learning the language more difficult."}, "gen_args_2": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? No, This makes learning the language more difficult."}}, "resps": [[["-83.5", "False"]], [["-86.5", "False"]], [["-87.5", "False"]]], "filtered_resps": [["-83.5", "False"], ["-86.5", "False"], ["-87.5", "False"]], "doc_hash": "642d7790d881955da734f6de15a527ec6d6053b7bd96e67dab73371b73a3b3fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2392, "doc": {"premise": "If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations.", "hypothesis": "The book might need a second pitching.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Yes, The book might need a second pitching."}, "gen_args_1": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Also, The book might need a second pitching."}, "gen_args_2": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? No, The book might need a second pitching."}}, "resps": [[["-181.0", "False"]], [["-182.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-182.0", "False"], ["-184.0", "False"]], "doc_hash": "f8722a3e27158eae64550911783a39b5eeba953bd1ff5da8d010c56eb82dacd1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 2400, "doc": {"premise": "Serious crime down, but murders increase.", "hypothesis": "Thanks to the police force, murders are at an all-time low.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Yes, Thanks to the police force, murders are at an all-time low."}, "gen_args_1": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Also, Thanks to the police force, murders are at an all-time low."}, "gen_args_2": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? No, Thanks to the police force, murders are at an all-time low."}}, "resps": [[["-107.5", "False"]], [["-109.0", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-107.5", "False"], ["-109.0", "False"], ["-105.0", "False"]], "doc_hash": "a39e46ced50ad0ad1d1e768b5c54452a4b941fe94cdf926d2566e43e5a01d544", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07459556 0.01664452 0.90875992]"]}
{"doc_id": 2408, "doc": {"premise": "RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of.", "hypothesis": "This expression was imported into the US from Creole slang.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Yes, This expression was imported into the US from Creole slang."}, "gen_args_1": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Also, This expression was imported into the US from Creole slang."}, "gen_args_2": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? No, This expression was imported into the US from Creole slang."}}, "resps": [[["-226.0", "False"]], [["-225.0", "False"]], [["-227.0", "False"]]], "filtered_resps": [["-226.0", "False"], ["-225.0", "False"], ["-227.0", "False"]], "doc_hash": "7ea1cc931357802178ce725dfc08c02626a13b1fc15b0b2b0f2a222c64245e7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2416, "doc": {"premise": "The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony.", "hypothesis": "The word agon originally meant competition in Greek.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Yes, The word agon originally meant competition in Greek."}, "gen_args_1": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Also, The word agon originally meant competition in Greek."}, "gen_args_2": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? No, The word agon originally meant competition in Greek."}}, "resps": [[["-180.0", "False"]], [["-183.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-183.0", "False"], ["-182.0", "False"]], "doc_hash": "24f275e1d295b80cad36d1678e0b098dc3a7cde77537959e34793d48508a9860", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2424, "doc": {"premise": "Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North.", "hypothesis": "Peter C. Newman and Pierre Berton are popular writers of Canadian history.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Yes, Peter C. Newman and Pierre Berton are popular writers of Canadian history."}, "gen_args_1": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Also, Peter C. Newman and Pierre Berton are popular writers of Canadian history."}, "gen_args_2": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? No, Peter C. Newman and Pierre Berton are popular writers of Canadian history."}}, "resps": [[["-154.0", "False"]], [["-158.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-158.0", "False"], ["-155.0", "False"]], "doc_hash": "85a43c26735dc0cffa86c5723c67cd6c967ae6dd040534d0d90a6f448c294dc7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2432, "doc": {"premise": "The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament.", "hypothesis": "The King James Bible is made solely for a Christian audience.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Yes, The King James Bible is made solely for a Christian audience."}, "gen_args_1": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Also, The King James Bible is made solely for a Christian audience."}, "gen_args_2": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? No, The King James Bible is made solely for a Christian audience."}}, "resps": [[["-131.0", "False"]], [["-135.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-135.0", "False"], ["-131.0", "False"]], "doc_hash": "099dc49e31bd153395c29b30971b5d833d339dc34fd72b6674f21f2731322103", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 2440, "doc": {"premise": "She pointed to a patch of equally depressing but bushier shrubbery.", "hypothesis": "She gestured towards a bush that was somewhat depressing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Yes, She gestured towards a bush that was somewhat depressing."}, "gen_args_1": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Also, She gestured towards a bush that was somewhat depressing."}, "gen_args_2": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? No, She gestured towards a bush that was somewhat depressing."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-141.0", "False"]], "doc_hash": "9e6c223dd6341dc6a940214bc63af902ad49ece225eec4ae25cf0f18013998ab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2448, "doc": {"premise": "Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons.", "hypothesis": "Most people would not know the origin of the word quark and that it referenced the noise made by a frog.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Yes, Most people would not know the origin of the word quark and that it referenced the noise made by a frog."}, "gen_args_1": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Also, Most people would not know the origin of the word quark and that it referenced the noise made by a frog."}, "gen_args_2": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? No, Most people would not know the origin of the word quark and that it referenced the noise made by a frog."}}, "resps": [[["-198.0", "False"]], [["-199.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-198.0", "False"], ["-199.0", "False"], ["-199.0", "False"]], "doc_hash": "f1559b483dd245aa92bd19f828567d8e13192cec94fed03c94a412b04cda17e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2456, "doc": {"premise": "These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source.", "hypothesis": "These boxes can be connected together and powered by cables.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Yes, These boxes can be connected together and powered by cables."}, "gen_args_1": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Also, These boxes can be connected together and powered by cables."}, "gen_args_2": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? No, These boxes can be connected together and powered by cables."}}, "resps": [[["-172.0", "False"]], [["-178.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-178.0", "False"], ["-173.0", "False"]], "doc_hash": "a5e5a90d2909be5efa9ec3589ca811edae9120d503669336c7bbb79698e9e72b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 2464, "doc": {"premise": "Dr. Richards never stops astonishing us.", "hypothesis": "We howled with laughter when we heard Dr. Richards' latest news.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Yes, We howled with laughter when we heard Dr. Richards' latest news."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Also, We howled with laughter when we heard Dr. Richards' latest news."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? No, We howled with laughter when we heard Dr. Richards' latest news."}}, "resps": [[["-117.0", "False"]], [["-121.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-121.5", "False"], ["-119.0", "False"]], "doc_hash": "ce9cbe6aeb5ce936d8e40897ece2a58612839f95f2cbf24f11c220d6f8f7047a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 2472, "doc": {"premise": "My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes.", "hypothesis": "My sister is a nun and has never dated a man.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Yes, My sister is a nun and has never dated a man."}, "gen_args_1": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Also, My sister is a nun and has never dated a man."}, "gen_args_2": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? No, My sister is a nun and has never dated a man."}}, "resps": [[["-158.0", "False"]], [["-158.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-158.0", "False"], ["-156.0", "False"]], "doc_hash": "ebfc1f7e4b32267aad4e2228bb9dbbe14a9c6deb386688c0bb2997498463d8b9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 2480, "doc": {"premise": "John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip.", "hypothesis": "John Burke reviews accounts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Yes, John Burke reviews accounts."}, "gen_args_1": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Also, John Burke reviews accounts."}, "gen_args_2": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? No, John Burke reviews accounts."}}, "resps": [[["-222.0", "False"]], [["-225.0", "False"]], [["-222.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-225.0", "False"], ["-222.0", "False"]], "doc_hash": "9f982ef0d72a8bed02d866c9331cc7f0d2f7263bc15fb0e1755e60096ac528ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2488, "doc": {"premise": "While statement is better, answer gives the mental picture of completion.", "hypothesis": "Statement is not better.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Yes, Statement is not better."}, "gen_args_1": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Also, Statement is not better."}, "gen_args_2": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? No, Statement is not better."}}, "resps": [[["-127.5", "False"]], [["-128.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-127.5", "False"], ["-128.0", "False"], ["-122.5", "False"]], "doc_hash": "114121ba6971f015757057dbfa4f71b9e8dfd6003dc3f72da11fe395f4c0399f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00666579 0.00404301 0.9892912 ]"]}
{"doc_id": 1, "doc": {"premise": "And he said, Mama, I'm home.", "hypothesis": "He didn't say a word.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Yes, He didn't say a word."}, "gen_args_1": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Also, He didn't say a word."}, "gen_args_2": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? No, He didn't say a word."}}, "resps": [[["-81.5", "False"]], [["-85.5", "False"]], [["-78.5", "False"]]], "filtered_resps": [["-81.5", "False"], ["-85.5", "False"], ["-78.5", "False"]], "doc_hash": "56a7f065bbdc3bd37702e3759b62c34bf6f2d88e08fe23734ce167af47e59d36", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 9, "doc": {"premise": "And I was like OK, and that was it!", "hypothesis": "After I said yes, it ended.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Yes, After I said yes, it ended."}, "gen_args_1": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Also, After I said yes, it ended."}, "gen_args_2": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? No, After I said yes, it ended."}}, "resps": [[["-92.5", "False"]], [["-97.5", "False"]], [["-94.5", "False"]]], "filtered_resps": [["-92.5", "False"], ["-97.5", "False"], ["-94.5", "False"]], "doc_hash": "104d93cf34610fef14c8c8588c6184a917e6e86756df8b0a89291d0c0f365b7a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 17, "doc": {"premise": "And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white.", "hypothesis": "They stopped visiting the family when the racial tensions started.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Yes, They stopped visiting the family when the racial tensions started."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Also, They stopped visiting the family when the racial tensions started."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? No, They stopped visiting the family when the racial tensions started."}}, "resps": [[["-165.0", "False"]], [["-172.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-172.0", "False"], ["-165.0", "False"]], "doc_hash": "4ab787fab723712b3e14154d7c9abb80a7f45cf5aee631f01ab87af209989c7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 25, "doc": {"premise": "But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property.", "hypothesis": "His dad owned 2000 acres of farmland.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Yes, His dad owned 2000 acres of farmland."}, "gen_args_1": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Also, His dad owned 2000 acres of farmland."}, "gen_args_2": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? No, His dad owned 2000 acres of farmland."}}, "resps": [[["-146.0", "False"]], [["-150.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-150.0", "False"], ["-148.0", "False"]], "doc_hash": "427508de5842f09f47b7322870cbc3cd790b36ac33163402c6edc35dc14bb216", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 33, "doc": {"premise": "And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories.", "hypothesis": "He was so faithful and nice.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Yes, He was so faithful and nice."}, "gen_args_1": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Also, He was so faithful and nice."}, "gen_args_2": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? No, He was so faithful and nice."}}, "resps": [[["-201.0", "False"]], [["-205.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-205.0", "False"], ["-200.0", "False"]], "doc_hash": "3695ee2ae58a7773f0860604f402645d8059595b3583e6973123333d4f79d10e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 41, "doc": {"premise": "And, she didn't really understand.", "hypothesis": "She knew exactly what we were talking about.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Yes, She knew exactly what we were talking about."}, "gen_args_1": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Also, She knew exactly what we were talking about."}, "gen_args_2": {"arg_0": "", "arg_1": " And, she didn't really understand., right? No, She knew exactly what we were talking about."}}, "resps": [[["-82.0", "False"]], [["-87.0", "False"]], [["-79.5", "False"]]], "filtered_resps": [["-82.0", "False"], ["-87.0", "False"], ["-79.5", "False"]], "doc_hash": "a9d520044cbfee26211befa86d204aac2be820595acf4fff1ec36e3f6979dc70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58194266e-02 5.10867278e-04 9.23669706e-01]"]}
{"doc_id": 49, "doc": {"premise": "I need you to do something for me.", "hypothesis": "It is a big job that I need done.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I need you to do something for me., right? Yes, It is a big job that I need done."}, "gen_args_1": {"arg_0": "", "arg_1": " I need you to do something for me., right? Also, It is a big job that I need done."}, "gen_args_2": {"arg_0": "", "arg_1": " I need you to do something for me., right? No, It is a big job that I need done."}}, "resps": [[["-76.5", "False"]], [["-81.5", "False"]], [["-79.0", "False"]]], "filtered_resps": [["-76.5", "False"], ["-81.5", "False"], ["-79.0", "False"]], "doc_hash": "2ba585e757f03bff66d5adf86ff6201a45c89563d96b7957e0c6771d5417e412", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.91842297 0.00618829 0.07538875]"]}
{"doc_id": 57, "doc": {"premise": "She was still in there.", "hypothesis": "She was gone without a trace.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was still in there., right? Yes, She was gone without a trace."}, "gen_args_1": {"arg_0": "", "arg_1": " She was still in there., right? Also, She was gone without a trace."}, "gen_args_2": {"arg_0": "", "arg_1": " She was still in there., right? No, She was gone without a trace."}}, "resps": [[["-74.5", "False"]], [["-75.5", "False"]], [["-69.0", "False"]]], "filtered_resps": [["-74.5", "False"], ["-75.5", "False"], ["-69.0", "False"]], "doc_hash": "95a0a2f846b128fdece08a51d2586655b2af794725b711a129cb96b01dd61e24", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00406405 0.00149508 0.99444087]"]}
{"doc_id": 65, "doc": {"premise": "But all of a sudden, we was called out to look at what was flying.", "hypothesis": "We were told not to look outside.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Yes, We were told not to look outside."}, "gen_args_1": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Also, We were told not to look outside."}, "gen_args_2": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? No, We were told not to look outside."}}, "resps": [[["-118.0", "False"]], [["-119.5", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-119.5", "False"], ["-113.0", "False"]], "doc_hash": "174ef3d237d0406ea9d6abe9e81cf3d9d4487652fdacbb171153c42874d4dca5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00668287 0.00149115 0.99182598]"]}
{"doc_id": 73, "doc": {"premise": "That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities.", "hypothesis": "I've never had a job.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Yes, I've never had a job."}, "gen_args_1": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Also, I've never had a job."}, "gen_args_2": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? No, I've never had a job."}}, "resps": [[["-142.0", "False"]], [["-143.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-143.0", "False"], ["-139.0", "False"]], "doc_hash": "7f92c090d7f934ad1c570f8d5d20bb1a67e4cfac1080a459ffaacd851460c285", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 81, "doc": {"premise": "You don't have to stay there.", "hypothesis": "You can go home if you want to.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You don't have to stay there., right? Yes, You can go home if you want to."}, "gen_args_1": {"arg_0": "", "arg_1": " You don't have to stay there., right? Also, You can go home if you want to."}, "gen_args_2": {"arg_0": "", "arg_1": " You don't have to stay there., right? No, You can go home if you want to."}}, "resps": [[["-66.5", "False"]], [["-73.0", "False"]], [["-65.5", "False"]]], "filtered_resps": [["-66.5", "False"], ["-73.0", "False"], ["-65.5", "False"]], "doc_hash": "ca3cc20a09719f5f116bfa9ba22966e77760b45a7acee9c4e578b1bd9bd6c8e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[2.68832722e-01 4.04173651e-04 7.30763104e-01]"]}
{"doc_id": 89, "doc": {"premise": "Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas.", "hypothesis": "The speed was making me nervous.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Yes, The speed was making me nervous."}, "gen_args_1": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Also, The speed was making me nervous."}, "gen_args_2": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? No, The speed was making me nervous."}}, "resps": [[["-150.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "adb7285227fc22b4cc19f775075431ef5441269fdecc42d342aa9968ecca402b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 97, "doc": {"premise": "And then once you get everything entered you can go on from there.", "hypothesis": "You can continue once you enter the information into the database.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Yes, You can continue once you enter the information into the database."}, "gen_args_1": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Also, You can continue once you enter the information into the database."}, "gen_args_2": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? No, You can continue once you enter the information into the database."}}, "resps": [[["-109.5", "False"]], [["-119.0", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-109.5", "False"], ["-119.0", "False"], ["-114.0", "False"]], "doc_hash": "8fa164a4bcfbc21aae381b717b2d3769dba104a2904b36bf58ebc3c645a32fc0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.88939847e-01 7.40239572e-05 1.09861293e-02]"]}
{"doc_id": 105, "doc": {"premise": "The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake.", "hypothesis": "We had to take it apart and reassemble it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Yes, We had to take it apart and reassemble it."}, "gen_args_1": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Also, We had to take it apart and reassemble it."}, "gen_args_2": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? No, We had to take it apart and reassemble it."}}, "resps": [[["-157.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "06c2ed37b80b3d8ded24363c5ef86c79d2dc857fc13b47c0b1144b39ede18df6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 113, "doc": {"premise": "It wasn't nothing but a desert; there was sagebrush out on the runway.", "hypothesis": "There were tumbleweeds blowing across the runway.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Yes, There were tumbleweeds blowing across the runway."}, "gen_args_1": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Also, There were tumbleweeds blowing across the runway."}, "gen_args_2": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? No, There were tumbleweeds blowing across the runway."}}, "resps": [[["-122.5", "False"]], [["-123.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-123.0", "False"], ["-122.5", "False"]], "doc_hash": "768a7bd45a74be526e44b3336a4600bfc286dca97a040fea5accb7baa2bf0f40", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.38365173 0.23269654 0.38365173]"]}
{"doc_id": 121, "doc": {"premise": "So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing.", "hypothesis": "I never got a chance to ask the question.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Yes, I never got a chance to ask the question."}, "gen_args_1": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Also, I never got a chance to ask the question."}, "gen_args_2": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? No, I never got a chance to ask the question."}}, "resps": [[["-182.0", "False"]], [["-184.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-184.0", "False"], ["-176.0", "False"]], "doc_hash": "d4304f22231c0adee9b5010ede414b58cbf871352bfee203250e80de8c381209", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 129, "doc": {"premise": "The CIA unloaded the, the film, taken them to the United Nations the next day.", "hypothesis": "The CIA brought the film to the UN.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Yes, The CIA brought the film to the UN."}, "gen_args_1": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Also, The CIA brought the film to the UN."}, "gen_args_2": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? No, The CIA brought the film to the UN."}}, "resps": [[["-139.0", "False"]], [["-145.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-145.0", "False"], ["-140.0", "False"]], "doc_hash": "68a4bddbe3fe94c09aec53a4423258239cf600bbd9d83268a0c5cd97c1cfd917", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 137, "doc": {"premise": "That's why I didn't graduate college, but I never, I never read any of the books I was supposed to.", "hypothesis": "I flunked out of college in 2002.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Yes, I flunked out of college in 2002."}, "gen_args_1": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Also, I flunked out of college in 2002."}, "gen_args_2": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? No, I flunked out of college in 2002."}}, "resps": [[["-119.5", "False"]], [["-120.0", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-119.5", "False"], ["-120.0", "False"], ["-118.5", "False"]], "doc_hash": "c8e4656569cbd7739064a687e94de09480a10fe3cb618c1f40fdf9000ccc7cd6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.2312239  0.14024438 0.62853172]"]}
{"doc_id": 145, "doc": {"premise": "The story I shall talk about today is about my father and the culture diversities he had when he moved to America.", "hypothesis": "I'll tell you about my father's experience as an immigrant.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Yes, I'll tell you about my father's experience as an immigrant."}, "gen_args_1": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Also, I'll tell you about my father's experience as an immigrant."}, "gen_args_2": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? No, I'll tell you about my father's experience as an immigrant."}}, "resps": [[["-135.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "b3079e68b8fb5df045346f910b0f68e53f5de74d748e761a4c68578f1770b999", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 153, "doc": {"premise": "And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street.", "hypothesis": "They lived in a white house on Broad Street.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Yes, They lived in a white house on Broad Street."}, "gen_args_1": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Also, They lived in a white house on Broad Street."}, "gen_args_2": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? No, They lived in a white house on Broad Street."}}, "resps": [[["-133.0", "False"]], [["-138.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-138.0", "False"], ["-135.0", "False"]], "doc_hash": "233d787b0efbe95405de07e58739e71e48cee6859ba7e4f73112c53a9338b642", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 161, "doc": {"premise": "And so when they told her she had to go home with this guy, she said, Go home with him?", "hypothesis": "They told her to leave with the man.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Yes, They told her to leave with the man."}, "gen_args_1": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Also, They told her to leave with the man."}, "gen_args_2": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? No, They told her to leave with the man."}}, "resps": [[["-119.5", "False"]], [["-126.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-119.5", "False"], ["-126.0", "False"], ["-119.5", "False"]], "doc_hash": "87588ad47afcb7243239c02dd0cf365a9dc31ad518ab2677595f9cec10030995", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49962442 0.00075115 0.49962442]"]}
{"doc_id": 169, "doc": {"premise": "Even though I don't see how he could have expected me to have it done.", "hypothesis": "I don't understand why he thought i would finish it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Yes, I don't understand why he thought i would finish it."}, "gen_args_1": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Also, I don't understand why he thought i would finish it."}, "gen_args_2": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? No, I don't understand why he thought i would finish it."}}, "resps": [[["-114.0", "False"]], [["-116.0", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-114.0", "False"], ["-116.0", "False"], ["-113.0", "False"]], "doc_hash": "27feee3073be2d1c6ae720394262953e306fd5cea59d6f63c1d19294167a3dd1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 177, "doc": {"premise": "Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody.", "hypothesis": "We couldn't tell anyone the U2 had landed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Yes, We couldn't tell anyone the U2 had landed."}, "gen_args_1": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Also, We couldn't tell anyone the U2 had landed."}, "gen_args_2": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? No, We couldn't tell anyone the U2 had landed."}}, "resps": [[["-192.0", "False"]], [["-195.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-195.0", "False"], ["-192.0", "False"]], "doc_hash": "245d1825effcd1b1d744da7a8a7861b245ceccc6d1263353e964eb4bc2bb55ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 185, "doc": {"premise": "Is there any reason why she didn't tell you?", "hypothesis": "Why wouldn't she tell you about the baby?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Yes, Why wouldn't she tell you about the baby?"}, "gen_args_1": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Also, Why wouldn't she tell you about the baby?"}, "gen_args_2": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? No, Why wouldn't she tell you about the baby?"}}, "resps": [[["-88.0", "False"]], [["-86.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-88.0", "False"], ["-86.0", "False"], ["-89.0", "False"]], "doc_hash": "8456b6c80a1a55e13806124b001814e39bb6ccbbfc5d27b21e8710bb9dbf5e6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.84379473 0.04201007]"]}
{"doc_id": 193, "doc": {"premise": "We didn't know what a U2 was and nobody knew anything about a U2.", "hypothesis": "We didn't know what to call the thing we saw in the air.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Yes, We didn't know what to call the thing we saw in the air."}, "gen_args_1": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Also, We didn't know what to call the thing we saw in the air."}, "gen_args_2": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? No, We didn't know what to call the thing we saw in the air."}}, "resps": [[["-121.0", "False"]], [["-122.0", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-122.0", "False"], ["-121.5", "False"]], "doc_hash": "fa3824787dcc88c35ff24b81d0de43d6c4c7226de83b92b4ad20578d5fea244b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.50648039 0.18632372 0.30719589]"]}
{"doc_id": 201, "doc": {"premise": "Anyway it got up to, we had about uh, ah, I don't remember the numbers.", "hypothesis": "I don't remember how many we had.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Yes, I don't remember how many we had."}, "gen_args_1": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Also, I don't remember how many we had."}, "gen_args_2": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? No, I don't remember how many we had."}}, "resps": [[["-122.5", "False"]], [["-123.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-123.5", "False"], ["-117.0", "False"]], "doc_hash": "c25977284476538163d03415db3ab1d00f87e84e792ffedc427848a331db7673", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.00406405 0.00149508 0.99444087]"]}
{"doc_id": 209, "doc": {"premise": "And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast.", "hypothesis": "She stayed silent and looked down at her desk.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Yes, She stayed silent and looked down at her desk."}, "gen_args_1": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Also, She stayed silent and looked down at her desk."}, "gen_args_2": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? No, She stayed silent and looked down at her desk."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-168.0", "False"]], "doc_hash": "a3ae482c3f23f8c984f3d6f00a27d7738491cf98ee7b865c839adde908e0b5d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 217, "doc": {"premise": "I'll call you back in about an hour, he says.", "hypothesis": "He said he'd return the call.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Yes, He said he'd return the call."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Also, He said he'd return the call."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? No, He said he'd return the call."}}, "resps": [[["-88.0", "False"]], [["-90.0", "False"]], [["-86.5", "False"]]], "filtered_resps": [["-88.0", "False"], ["-90.0", "False"], ["-86.5", "False"]], "doc_hash": "d43d9b10de6a1f7253dc83ec4da5c1d45f761730117a6fccaad66b7901ffe5ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.17803021 0.02409377 0.79787603]"]}
{"doc_id": 225, "doc": {"premise": "Well anyway, I went back to my, my desk.", "hypothesis": "I refused to sit down again.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Yes, I refused to sit down again."}, "gen_args_1": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Also, I refused to sit down again."}, "gen_args_2": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? No, I refused to sit down again."}}, "resps": [[["-98.0", "False"]], [["-101.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-101.5", "False"], ["-95.0", "False"]], "doc_hash": "a0a7b744c7e8c967a50fedc4e9960e84a2663a64b0c1492776ff4dc5d372d626", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04735805 0.00143009 0.95121186]"]}
{"doc_id": 233, "doc": {"premise": "They didn't want to stay captive.", "hypothesis": "They were all terrified of being released from custody.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Yes, They were all terrified of being released from custody."}, "gen_args_1": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Also, They were all terrified of being released from custody."}, "gen_args_2": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? No, They were all terrified of being released from custody."}}, "resps": [[["-102.5", "False"]], [["-105.0", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-105.0", "False"], ["-102.0", "False"]], "doc_hash": "7986d5d5018eb6ec262e776dad88a73f20c3d5ce5f7b4d22f2a6ad243a6e0039", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.36619222 0.03005889 0.6037489 ]"]}
{"doc_id": 241, "doc": {"premise": "And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area.", "hypothesis": "They went downtown to the main street.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Yes, They went downtown to the main street."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Also, They went downtown to the main street."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? No, They went downtown to the main street."}}, "resps": [[["-205.0", "False"]], [["-210.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-210.0", "False"], ["-205.0", "False"]], "doc_hash": "286043abee456cca1c174e6308c763a66cdcb37c7431803400bd04d0517878a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 249, "doc": {"premise": "oh it was Snake River oh Snake River with a lot of snakes in it", "hypothesis": "Despite its name, Snake River doesn't actually contain any snakes; it's named for its S-shape.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Yes, Despite its name, Snake River doesn't actually contain any snakes; it's named for its S-shape."}, "gen_args_1": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Also, Despite its name, Snake River doesn't actually contain any snakes; it's named for its S-shape."}, "gen_args_2": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? No, Despite its name, Snake River doesn't actually contain any snakes; it's named for its S-shape."}}, "resps": [[["-136.0", "False"]], [["-137.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-137.0", "False"], ["-135.0", "False"]], "doc_hash": "4372c4cf3c00bfbc0263ae62849778e53daf7a564f6c45b456b735f26f8a7e23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 257, "doc": {"premise": "exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think", "hypothesis": "It's fine if you don't really take it seriously.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Yes, It's fine if you don't really take it seriously."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Also, It's fine if you don't really take it seriously."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? No, It's fine if you don't really take it seriously."}}, "resps": [[["-174.0", "False"]], [["-178.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-178.0", "False"], ["-175.0", "False"]], "doc_hash": "9888b26880c22d1a39636447ce77a259582176150ef79e2654ef52492c9f303a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 265, "doc": {"premise": "and it can go on for ten twenty years i i think this is a little ridiculous", "hypothesis": "I think it's nuts that it can last so long.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Yes, I think it's nuts that it can last so long."}, "gen_args_1": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Also, I think it's nuts that it can last so long."}, "gen_args_2": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? No, I think it's nuts that it can last so long."}}, "resps": [[["-117.0", "False"]], [["-124.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-124.5", "False"], ["-119.0", "False"]], "doc_hash": "957dd487a5f19a618f4b4797c10fd2434304afe0c4637117d5b188d42d0569e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80368202e-01 4.86917893e-04 1.19144880e-01]"]}
{"doc_id": 273, "doc": {"premise": "besides i probably would look at something uh maybe a a V six", "hypothesis": "I am thinking of looking at a V6.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Yes, I am thinking of looking at a V6."}, "gen_args_1": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Also, I am thinking of looking at a V6."}, "gen_args_2": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? No, I am thinking of looking at a V6."}}, "resps": [[["-124.0", "False"]], [["-134.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-134.0", "False"], ["-127.5", "False"]], "doc_hash": "b6b7b2e60d845a076a5d1651ddc11aa272595a2afab4c3a23c9b677afaa110ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70644994e-01 4.40672145e-05 2.93109390e-02]"]}
{"doc_id": 281, "doc": {"premise": "care about how the national news affects the local area", "hypothesis": "The national news outlets make our local places seem backwards.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Yes, The national news outlets make our local places seem backwards."}, "gen_args_1": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Also, The national news outlets make our local places seem backwards."}, "gen_args_2": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? No, The national news outlets make our local places seem backwards."}}, "resps": [[["-118.0", "False"]], [["-117.5", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-118.0", "False"], ["-117.5", "False"], ["-119.5", "False"]], "doc_hash": "a9a2087aaa6154feb5c7b7b5442d2c1543fd0743c3a27e25a0d6ae034e3c4c6e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.34820743 0.57409699 0.07769558]"]}
{"doc_id": 289, "doc": {"premise": "yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed", "hypothesis": "It would make me angry to find out that they had financed the corporation.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Yes, It would make me angry to find out that they had financed the corporation."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Also, It would make me angry to find out that they had financed the corporation."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? No, It would make me angry to find out that they had financed the corporation."}}, "resps": [[["-167.0", "False"]], [["-171.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-171.0", "False"], ["-165.0", "False"]], "doc_hash": "410f688d69d523b52c27013ab9e325e98d83f9cb5c462bd8b1538baeeef37662", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 297, "doc": {"premise": "but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of", "hypothesis": "I Do not eat any kind of meat.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Yes, I Do not eat any kind of meat."}, "gen_args_1": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Also, I Do not eat any kind of meat."}, "gen_args_2": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? No, I Do not eat any kind of meat."}}, "resps": [[["-124.5", "False"]], [["-128.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-128.0", "False"], ["-125.0", "False"]], "doc_hash": "245aebd3a6e6860cb87f18453033660e95546fcf890738e2a1583f6e9475f132", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.61097505 0.01844985 0.3705751 ]"]}
{"doc_id": 305, "doc": {"premise": "it's it's really bad it uh i", "hypothesis": "It's not bad at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Yes, It's not bad at all."}, "gen_args_1": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Also, It's not bad at all."}, "gen_args_2": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? No, It's not bad at all."}}, "resps": [[["-85.5", "False"]], [["-92.0", "False"]], [["-80.5", "False"]]], "filtered_resps": [["-85.5", "False"], ["-92.0", "False"], ["-80.5", "False"]], "doc_hash": "878688c1dee644670dba37f3bbb4c499c36b869b5f3333d91e762001f9407fda", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69278358e-03 1.00621931e-05 9.93297154e-01]"]}
{"doc_id": 313, "doc": {"premise": "exactly and i was very flattered until she told me she the company she was with", "hypothesis": "She did not flatter me at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Yes, She did not flatter me at all."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Also, She did not flatter me at all."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? No, She did not flatter me at all."}}, "resps": [[["-123.5", "False"]], [["-124.5", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-123.5", "False"], ["-124.5", "False"], ["-120.5", "False"]], "doc_hash": "5ecf98075d5ad8fa9e4dc31ca06d1a9a2951dcf987b4c4dd0f7ac4adef77bdf1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 321, "doc": {"premise": "i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think", "hypothesis": "Gun control is probably not popular in Texas.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Yes, Gun control is probably not popular in Texas."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Also, Gun control is probably not popular in Texas."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? No, Gun control is probably not popular in Texas."}}, "resps": [[["-176.0", "False"]], [["-184.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-184.0", "False"], ["-179.0", "False"]], "doc_hash": "c30c5ecdeb153b330e1fd0bd1895b43eddceef68547de05ce90cb5aadc4a5ce1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 329, "doc": {"premise": "course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know", "hypothesis": "That will cause a decrease in crime.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Yes, That will cause a decrease in crime."}, "gen_args_1": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Also, That will cause a decrease in crime."}, "gen_args_2": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? No, That will cause a decrease in crime."}}, "resps": [[["-199.0", "False"]], [["-204.0", "False"]], [["-202.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-204.0", "False"], ["-202.0", "False"]], "doc_hash": "3afda1a65337bad836fe83457c553c2173af1d7819e2598f462f42aff6506d49", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 337, "doc": {"premise": "uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news", "hypothesis": "What do you think about national newspapers and their global coverage?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Yes, What do you think about national newspapers and their global coverage?"}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Also, What do you think about national newspapers and their global coverage?"}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? No, What do you think about national newspapers and their global coverage?"}}, "resps": [[["-155.0", "False"]], [["-155.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-155.0", "False"], ["-157.0", "False"]], "doc_hash": "e60d95129cba2525172af96408d494bd76ed5addb1c1f0b23b4d7a50d07aaf2c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 345, "doc": {"premise": "um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news", "hypothesis": "Are you happy with network news coverage?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Yes, Are you happy with network news coverage?"}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Also, Are you happy with network news coverage?"}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? No, Are you happy with network news coverage?"}}, "resps": [[["-176.0", "False"]], [["-184.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-184.0", "False"], ["-178.0", "False"]], "doc_hash": "be5bae23e3d5053c52ce717c03b914f874dcafe9374a1018fce6f0125475d09a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 353, "doc": {"premise": "oh um no but they do have hay horse races  at the Oaklawn tracks", "hypothesis": "There are no races at Oaklawn tracks.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Yes, There are no races at Oaklawn tracks."}, "gen_args_1": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Also, There are no races at Oaklawn tracks."}, "gen_args_2": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? No, There are no races at Oaklawn tracks."}}, "resps": [[["-140.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "3f46fa1c9ae5751c7e5965fa7f5e6559e964795f21108b826a0bd1c07130c7da", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 361, "doc": {"premise": "is it twenty percent interest", "hypothesis": "Is the interest percent 20?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Yes, Is the interest percent 20?"}, "gen_args_1": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Also, Is the interest percent 20?"}, "gen_args_2": {"arg_0": "", "arg_1": " is it twenty percent interest, right? No, Is the interest percent 20?"}}, "resps": [[["-78.0", "False"]], [["-85.0", "False"]], [["-79.0", "False"]]], "filtered_resps": [["-78.0", "False"], ["-85.0", "False"], ["-79.0", "False"]], "doc_hash": "1202bdbe8a8aa4709045dab24516db46b16a5817d326f1f029144b08d600a780", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 369, "doc": {"premise": "i don't know  okay well it was good talking to you and have a good evening", "hypothesis": "I hope you have a great morning! It was nice chatting with you online.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Yes, I hope you have a great morning! It was nice chatting with you online."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Also, I hope you have a great morning! It was nice chatting with you online."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? No, I hope you have a great morning! It was nice chatting with you online."}}, "resps": [[["-123.0", "False"]], [["-123.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-123.0", "False"], ["-123.5", "False"], ["-122.5", "False"]], "doc_hash": "5a6407a949c4a6d1cb71cb02c44ff4e1750d2813a3b544b64b71d5ff6a4e013e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.30719589 0.18632372 0.50648039]"]}
{"doc_id": 377, "doc": {"premise": "do you do you wilderness camp", "hypothesis": "I thought you went to the camp.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Yes, I thought you went to the camp."}, "gen_args_1": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Also, I thought you went to the camp."}, "gen_args_2": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? No, I thought you went to the camp."}}, "resps": [[["-86.0", "False"]], [["-86.5", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-86.0", "False"], ["-86.5", "False"], ["-83.0", "False"]], "doc_hash": "a445efc8b4f3a3240f005c07b15064aa7a8a3714fc258f05d68cb62bb86307a4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0460998  0.02796094 0.92593926]"]}
{"doc_id": 385, "doc": {"premise": "tag them or anything you you do it all yourself they tell you what to do but you do it all yourself", "hypothesis": "They don't tell you how to do it at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Yes, They don't tell you how to do it at all."}, "gen_args_1": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Also, They don't tell you how to do it at all."}, "gen_args_2": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? No, They don't tell you how to do it at all."}}, "resps": [[["-128.0", "False"]], [["-131.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-128.0", "False"], ["-131.0", "False"], ["-125.5", "False"]], "doc_hash": "82233a28a661225a2f358d9cddb63a85cddcbbf1d67b28337365d3b02e66013d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 393, "doc": {"premise": "uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh", "hypothesis": "I really don't even know what I would pick.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Yes, I really don't even know what I would pick."}, "gen_args_1": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Also, I really don't even know what I would pick."}, "gen_args_2": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? No, I really don't even know what I would pick."}}, "resps": [[["-176.0", "False"]], [["-178.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-178.0", "False"], ["-171.0", "False"]], "doc_hash": "501d085fe0a9df4fb18011ed95e8234f7f33fa38e71e38e18e460bc3809df98b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 401, "doc": {"premise": "i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and", "hypothesis": "There were other independent tickets that ran as well.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Yes, There were other independent tickets that ran as well."}, "gen_args_1": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Also, There were other independent tickets that ran as well."}, "gen_args_2": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? No, There were other independent tickets that ran as well."}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-174.0", "False"]], "doc_hash": "c53e5e641c26db38a924cd9a1747d186a909e79a67cbea02cca2455b73ec6b5f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 409, "doc": {"premise": "but they did something a little different with them", "hypothesis": "Their way of using them was much better.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Yes, Their way of using them was much better."}, "gen_args_1": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Also, Their way of using them was much better."}, "gen_args_2": {"arg_0": "", "arg_1": " but they did something a little different with them, right? No, Their way of using them was much better."}}, "resps": [[["-85.0", "False"]], [["-88.5", "False"]], [["-86.5", "False"]]], "filtered_resps": [["-85.0", "False"], ["-88.5", "False"], ["-86.5", "False"]], "doc_hash": "9b81c4ed978cd39ec91c71e10f8babee8ab895ecdf061e1bc04869c1c6bf7762", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 417, "doc": {"premise": "huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women", "hypothesis": "I really didn't like the seminar that was done by satellite.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Yes, I really didn't like the seminar that was done by satellite."}, "gen_args_1": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Also, I really didn't like the seminar that was done by satellite."}, "gen_args_2": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? No, I really didn't like the seminar that was done by satellite."}}, "resps": [[["-213.0", "False"]], [["-214.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-214.0", "False"], ["-211.0", "False"]], "doc_hash": "176fada307a42e12913f33efaec6e80ab83c80f225839cb84fa2c653150c1671", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 425, "doc": {"premise": "well oh well that's interesting do you uh did you take classes to learn how to do that", "hypothesis": "Where did you learn how to do that?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Yes, Where did you learn how to do that?"}, "gen_args_1": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Also, Where did you learn how to do that?"}, "gen_args_2": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? No, Where did you learn how to do that?"}}, "resps": [[["-108.0", "False"]], [["-109.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-109.5", "False"], ["-108.0", "False"]], "doc_hash": "8f8b96f29cf97bd0574678a1554154be36c3d2edd3a87b3a9134249ecd329bb5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.44981622 0.10036756 0.44981622]"]}
{"doc_id": 433, "doc": {"premise": "yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families", "hypothesis": "Some people can't care for elderly relatives because their homes have lots of stairs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Yes, Some people can't care for elderly relatives because their homes have lots of stairs."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Also, Some people can't care for elderly relatives because their homes have lots of stairs."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? No, Some people can't care for elderly relatives because their homes have lots of stairs."}}, "resps": [[["-223.0", "False"]], [["-226.0", "False"]], [["-226.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-226.0", "False"], ["-226.0", "False"]], "doc_hash": "cc417ffb35966615be972960ece92b387bc8d7094173c6efef31a7015fc501c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 441, "doc": {"premise": "it's just that since my money is tight right now i don't even give myself a tempting", "hypothesis": "I don't have a lot of money right now.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Yes, I don't have a lot of money right now."}, "gen_args_1": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Also, I don't have a lot of money right now."}, "gen_args_2": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? No, I don't have a lot of money right now."}}, "resps": [[["-115.5", "False"]], [["-117.0", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-115.5", "False"], ["-117.0", "False"], ["-113.5", "False"]], "doc_hash": "c0fba4cbaf4f8f7e29bee41920861e9054042bb6d68058e191b58a572d8a0418", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11611453 0.02590865 0.85797681]"]}
{"doc_id": 449, "doc": {"premise": "um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you", "hypothesis": "Parents should just keep everything they have and not share it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Yes, Parents should just keep everything they have and not share it."}, "gen_args_1": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Also, Parents should just keep everything they have and not share it."}, "gen_args_2": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? No, Parents should just keep everything they have and not share it."}}, "resps": [[["-171.0", "False"]], [["-175.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-175.0", "False"], ["-171.0", "False"]], "doc_hash": "95dc35b666b4db3f5cb2a8101949111ae7a0edc560f562431f28a15cd65e1a7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 457, "doc": {"premise": "excuse me we pay for any you know the child care but we don't pay as much as they do off base", "hypothesis": "Childcare is cheaper on base.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Yes, Childcare is cheaper on base."}, "gen_args_1": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Also, Childcare is cheaper on base."}, "gen_args_2": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? No, Childcare is cheaper on base."}}, "resps": [[["-138.0", "False"]], [["-139.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-139.0", "False"], ["-138.0", "False"]], "doc_hash": "fb31a915b21eb37ecf787cbde3f1dfe3c56a4a0c6f7db6591f97eab4cb3fd6f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 465, "doc": {"premise": "yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home", "hypothesis": "It's a felony to have a handgun in public in Texas.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Yes, It's a felony to have a handgun in public in Texas."}, "gen_args_1": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Also, It's a felony to have a handgun in public in Texas."}, "gen_args_2": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? No, It's a felony to have a handgun in public in Texas."}}, "resps": [[["-133.0", "False"]], [["-141.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-141.0", "False"], ["-134.0", "False"]], "doc_hash": "26fba53e2550dfe31549bf7c88220b1cadaa043e8884d2d641c1bf042f6cbc02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 473, "doc": {"premise": "and uh sometimes it's nice to go out and have a salad", "hypothesis": "I occasionally like to eat salad.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Yes, I occasionally like to eat salad."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Also, I occasionally like to eat salad."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? No, I occasionally like to eat salad."}}, "resps": [[["-86.5", "False"]], [["-93.0", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-86.5", "False"], ["-93.0", "False"], ["-91.5", "False"]], "doc_hash": "56874df5f54117f6d26599ca476736e04e1cc3e884bd776b3d6a3c57d7845321", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99182598 0.00149115 0.00668287]"]}
{"doc_id": 481, "doc": {"premise": "and they just pretty much know how much they have coming in you know and they just make sure they don't buy over", "hypothesis": "They have no idea how much money they're getting.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Yes, They have no idea how much money they're getting."}, "gen_args_1": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Also, They have no idea how much money they're getting."}, "gen_args_2": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? No, They have no idea how much money they're getting."}}, "resps": [[["-133.0", "False"]], [["-138.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-138.0", "False"], ["-129.0", "False"]], "doc_hash": "3b79ccc6034fc4fc919dcace1fbc8286f2366a8ff96c28ba01be31abddf3325d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 489, "doc": {"premise": "yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be", "hypothesis": "I don't believe in any type of afterlife.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Yes, I don't believe in any type of afterlife."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Also, I don't believe in any type of afterlife."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? No, I don't believe in any type of afterlife."}}, "resps": [[["-137.0", "False"]], [["-136.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-136.0", "False"], ["-133.0", "False"]], "doc_hash": "da63f7db3e9650b7295e8e1c70d14709c2813372add58675775759dcaf384675", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 497, "doc": {"premise": "the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know", "hypothesis": "The contracts were all signed without an issue.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Yes, The contracts were all signed without an issue."}, "gen_args_1": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Also, The contracts were all signed without an issue."}, "gen_args_2": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? No, The contracts were all signed without an issue."}}, "resps": [[["-223.0", "False"]], [["-228.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-228.0", "False"], ["-217.0", "False"]], "doc_hash": "acae294fd1eb1892befd71931dadf71d2d5e722cc94001c71541d79ab7e16437", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47258196e-03 1.66601262e-05 9.97510758e-01]"]}
{"doc_id": 505, "doc": {"premise": "But I do not believe any such algorithmic tool can be complete.", "hypothesis": "There is no tool that can completely solve this problem on its own.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Yes, There is no tool that can completely solve this problem on its own."}, "gen_args_1": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Also, There is no tool that can completely solve this problem on its own."}, "gen_args_2": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? No, There is no tool that can completely solve this problem on its own."}}, "resps": [[["-113.0", "False"]], [["-119.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-113.0", "False"], ["-119.5", "False"], ["-113.5", "False"]], "doc_hash": "88b1bd80d5f637f0e2e41a07738b072e3d6e6ac769ddeab1ab346883e5d463f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.62187736 0.00093495 0.37718769]"]}
{"doc_id": 513, "doc": {"premise": "Steve Harris, a molecular biologist from Texas was visiting.", "hypothesis": "Steve Harris refused to leave his house for any reason.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Yes, Steve Harris refused to leave his house for any reason."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Also, Steve Harris refused to leave his house for any reason."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? No, Steve Harris refused to leave his house for any reason."}}, "resps": [[["-117.5", "False"]], [["-118.5", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-117.5", "False"], ["-118.5", "False"], ["-115.0", "False"]], "doc_hash": "b3d157ad351a468b1bdab0fc9c713c72b619a021fcb31dbb1b0197f965a3a397", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0737987  0.02714903 0.89905227]"]}
{"doc_id": 521, "doc": {"premise": "For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?", "hypothesis": "Five year olds are generally considered poor conversationalists.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Yes, Five year olds are generally considered poor conversationalists."}, "gen_args_1": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Also, Five year olds are generally considered poor conversationalists."}, "gen_args_2": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? No, Five year olds are generally considered poor conversationalists."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-159.0", "False"]], "doc_hash": "9ab319436dc54d0115c7995dada6ad072ea2c61e65eaadf2dd559e0b874150e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 529, "doc": {"premise": "In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself.", "hypothesis": "In the last chapter I wonder how much the universe is responsible for the eccentricities of human behavior.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Yes, In the last chapter I wonder how much the universe is responsible for the eccentricities of human behavior."}, "gen_args_1": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Also, In the last chapter I wonder how much the universe is responsible for the eccentricities of human behavior."}, "gen_args_2": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? No, In the last chapter I wonder how much the universe is responsible for the eccentricities of human behavior."}}, "resps": [[["-170.0", "False"]], [["-173.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-173.0", "False"], ["-170.0", "False"]], "doc_hash": "5a7aea40e50c8aecf2f92c6905f5e28b51966cafb67aed3c345d3fc42bc308fb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 537, "doc": {"premise": "In the postbellum legal order, the same result derived from federal constitutional principles.", "hypothesis": "Principles from the federal constitution are what caused the same result as the postbellum legal order.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Yes, Principles from the federal constitution are what caused the same result as the postbellum legal order."}, "gen_args_1": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Also, Principles from the federal constitution are what caused the same result as the postbellum legal order."}, "gen_args_2": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? No, Principles from the federal constitution are what caused the same result as the postbellum legal order."}}, "resps": [[["-151.0", "False"]], [["-166.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-166.0", "False"], ["-152.0", "False"]], "doc_hash": "cadb93a5275a48d1182be33303846afd2f36f6684948c22baddf500364508f63", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.31058415e-01 2.23632466e-07 2.68941361e-01]"]}
{"doc_id": 545, "doc": {"premise": "The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection.", "hypothesis": "The majority of toddlers will get a middle ear infection.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Yes, The majority of toddlers will get a middle ear infection."}, "gen_args_1": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Also, The majority of toddlers will get a middle ear infection."}, "gen_args_2": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? No, The majority of toddlers will get a middle ear infection."}}, "resps": [[["-119.5", "False"]], [["-122.5", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-119.5", "False"], ["-122.5", "False"], ["-120.5", "False"]], "doc_hash": "37fbc30b986b5608ab3204d8c21316de375815b45e7c5fe494f89727bbc4374f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 553, "doc": {"premise": "Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world.", "hypothesis": "We need to label the organization.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Yes, We need to label the organization."}, "gen_args_1": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Also, We need to label the organization."}, "gen_args_2": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? No, We need to label the organization."}}, "resps": [[["-142.0", "False"]], [["-148.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-148.0", "False"], ["-145.0", "False"]], "doc_hash": "941c6e0e146ec0ed89abbcc742b32ec9854fe79ce19ab1c598de5c246edfc7e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 561, "doc": {"premise": "Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American.", "hypothesis": "Americans all treat the flag with respect.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Yes, Americans all treat the flag with respect."}, "gen_args_1": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Also, Americans all treat the flag with respect."}, "gen_args_2": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? No, Americans all treat the flag with respect."}}, "resps": [[["-178.0", "False"]], [["-180.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-180.0", "False"], ["-178.0", "False"]], "doc_hash": "07aae4c5bf3badbdf524fef61012fd2cfdde0f10b9a55cd46d7ae489cef7d7be", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 569, "doc": {"premise": "We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance.", "hypothesis": "There is much more to learn about the organization.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Yes, There is much more to learn about the organization."}, "gen_args_1": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Also, There is much more to learn about the organization."}, "gen_args_2": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? No, There is much more to learn about the organization."}}, "resps": [[["-223.0", "False"]], [["-225.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-225.0", "False"], ["-224.0", "False"]], "doc_hash": "02d476b8720e3e4ec250fade235bad0ed127aaa834f9ee47edacee00d65089dc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 577, "doc": {"premise": "Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?", "hypothesis": "We don't look at something so amazing?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Yes, We don't look at something so amazing?"}, "gen_args_1": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Also, We don't look at something so amazing?"}, "gen_args_2": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? No, We don't look at something so amazing?"}}, "resps": [[["-155.0", "False"]], [["-160.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-160.0", "False"], ["-157.0", "False"]], "doc_hash": "5176beffda2ae49fe1eef0fe7a940d5c45eb40f8e2e66398eedbac4968625519", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 585, "doc": {"premise": "The audience is invisible; each viewer is in his little cubicle, called a living room.", "hypothesis": "The audience is hidden because of the cubicles.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Yes, The audience is hidden because of the cubicles."}, "gen_args_1": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Also, The audience is hidden because of the cubicles."}, "gen_args_2": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? No, The audience is hidden because of the cubicles."}}, "resps": [[["-132.0", "False"]], [["-135.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-135.0", "False"], ["-131.0", "False"]], "doc_hash": "5cdd13ce4d4ad9322bfca04a8cc8e3328f1c7aec67c0deaf4eb441ba3944db08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 593, "doc": {"premise": "I begin life with an endowment of a hundred pears and a thousand apples.", "hypothesis": "The fruit was given to me by my father.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Yes, The fruit was given to me by my father."}, "gen_args_1": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Also, The fruit was given to me by my father."}, "gen_args_2": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? No, The fruit was given to me by my father."}}, "resps": [[["-121.5", "False"]], [["-126.0", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-121.5", "False"], ["-126.0", "False"], ["-121.5", "False"]], "doc_hash": "49b64ae157d4a4562382cb901151e1394d728b34881bb2d393cde95adffc1087", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 601, "doc": {"premise": "The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions.", "hypothesis": "The descendants of the early Hispanos wrote using quills.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Yes, The descendants of the early Hispanos wrote using quills."}, "gen_args_1": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Also, The descendants of the early Hispanos wrote using quills."}, "gen_args_2": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? No, The descendants of the early Hispanos wrote using quills."}}, "resps": [[["-211.0", "False"]], [["-213.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-213.0", "False"], ["-214.0", "False"]], "doc_hash": "93868d387fdd222b1a459b1bcf077a1bb8f1a25f77db17ff79973451d8400c80", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 609, "doc": {"premise": "For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced.", "hypothesis": "Each nation has a right to vote.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Yes, Each nation has a right to vote."}, "gen_args_1": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Also, Each nation has a right to vote."}, "gen_args_2": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? No, Each nation has a right to vote."}}, "resps": [[["-200.0", "False"]], [["-203.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-203.0", "False"], ["-201.0", "False"]], "doc_hash": "70a3b24e31b621686368f3ec343d4023fcb6823a096389a91b06fa8bb2187a2b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 617, "doc": {"premise": "While this is being done prayers are recited.", "hypothesis": "Prayers are recited while clothes are washed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Yes, Prayers are recited while clothes are washed."}, "gen_args_1": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Also, Prayers are recited while clothes are washed."}, "gen_args_2": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? No, Prayers are recited while clothes are washed."}}, "resps": [[["-93.5", "False"]], [["-97.5", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-97.5", "False"], ["-96.5", "False"]], "doc_hash": "911cba226a2327a6fee2ac6a4ac52ce80d6362e92ab170878fbe6f45b5eee354", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 625, "doc": {"premise": "During the preschool and elementary school years, thought is largely tied to the here-and-now.", "hypothesis": "Preschool kids cannot comprehend the future.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Yes, Preschool kids cannot comprehend the future."}, "gen_args_1": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Also, Preschool kids cannot comprehend the future."}, "gen_args_2": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? No, Preschool kids cannot comprehend the future."}}, "resps": [[["-122.5", "False"]], [["-124.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-124.5", "False"], ["-122.0", "False"]], "doc_hash": "b085e98f74e7a10d18b145507b9a7924853bc5b4c7846e5605bb131367651846", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.35918811 0.04861082 0.59220107]"]}
{"doc_id": 633, "doc": {"premise": "I, in turn, happen to have desires such that I would be happier with rather more pears than apples.", "hypothesis": "I would like pears more than apples.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Yes, I would like pears more than apples."}, "gen_args_1": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Also, I would like pears more than apples."}, "gen_args_2": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? No, I would like pears more than apples."}}, "resps": [[["-135.0", "False"]], [["-137.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-137.0", "False"], ["-137.0", "False"]], "doc_hash": "c9f44193a10a32d17bfedf83559a74be27351ad5f00f7108d9807e60f66aa13f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 641, "doc": {"premise": "A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles.", "hypothesis": "Charles F. Lummis was funny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Yes, Charles F. Lummis was funny."}, "gen_args_1": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Also, Charles F. Lummis was funny."}, "gen_args_2": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? No, Charles F. Lummis was funny."}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-178.0", "False"]], "doc_hash": "3b199f7d56427ec472e6af30df193cdcd6c75adcfa0dd7b0963bf08cd30c557e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 649, "doc": {"premise": "I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game.", "hypothesis": "I do not have the solution for the puzzle of the natural game.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Yes, I do not have the solution for the puzzle of the natural game."}, "gen_args_1": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Also, I do not have the solution for the puzzle of the natural game."}, "gen_args_2": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? No, I do not have the solution for the puzzle of the natural game."}}, "resps": [[["-151.0", "False"]], [["-156.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-156.0", "False"], ["-146.0", "False"]], "doc_hash": "b03ef28916c419e39a13c77fb4bff5f34feff56718476772a95dbf91da54b6e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[6.69254912e-03 4.50940412e-05 9.93262357e-01]"]}
{"doc_id": 657, "doc": {"premise": "In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913.", "hypothesis": "The performance never occurs in San Antonio.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Yes, The performance never occurs in San Antonio."}, "gen_args_1": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Also, The performance never occurs in San Antonio."}, "gen_args_2": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? No, The performance never occurs in San Antonio."}}, "resps": [[["-151.0", "False"]], [["-150.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-150.0", "False"], ["-144.0", "False"]], "doc_hash": "d7bc10dca11834db4781a333f916cbf09cf3ff2401962a1677a349f2b3af30cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.08800555e-04 2.47037604e-03 9.96620823e-01]"]}
{"doc_id": 665, "doc": {"premise": "In turn, object must be on machine for minutes, then machine for minutes, and so on.", "hypothesis": "The object must be on the machine for more than a single second.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Yes, The object must be on the machine for more than a single second."}, "gen_args_1": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Also, The object must be on the machine for more than a single second."}, "gen_args_2": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? No, The object must be on the machine for more than a single second."}}, "resps": [[["-141.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "f9027989161b070c80f5a3362a685a37790e1cff4396436f8c7844d6179acf46", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 673, "doc": {"premise": "In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen.", "hypothesis": "Joaquan did not expect the body to be of his friend.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Yes, Joaquan did not expect the body to be of his friend."}, "gen_args_1": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Also, Joaquan did not expect the body to be of his friend."}, "gen_args_2": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? No, Joaquan did not expect the body to be of his friend."}}, "resps": [[["-224.0", "False"]], [["-224.0", "False"]], [["-222.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-224.0", "False"], ["-222.0", "False"]], "doc_hash": "1e852002827dc316b259f95b59df6c760dd13685121da8a66f961e7db3434e61", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 681, "doc": {"premise": "So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source.", "hypothesis": "Shannon determined that the message came from a negative source.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Yes, Shannon determined that the message came from a negative source."}, "gen_args_1": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Also, Shannon determined that the message came from a negative source."}, "gen_args_2": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? No, Shannon determined that the message came from a negative source."}}, "resps": [[["-179.0", "False"]], [["-177.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-177.0", "False"], ["-178.0", "False"]], "doc_hash": "9056a8c47351a1857b0cd4b245abb62fc48a0d29afe267ec7d9b4cab4e1b0415", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 689, "doc": {"premise": "A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions.", "hypothesis": "There is nothing important that we should discuss in the future.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Yes, There is nothing important that we should discuss in the future."}, "gen_args_1": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Also, There is nothing important that we should discuss in the future."}, "gen_args_2": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? No, There is nothing important that we should discuss in the future."}}, "resps": [[["-213.0", "False"]], [["-218.0", "False"]], [["-213.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-218.0", "False"], ["-213.0", "False"]], "doc_hash": "aa26ec3abbd07f3d6165fb99991ffdc0a2a4c09d6e0154b4b615e8b219cc2c44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 697, "doc": {"premise": "Riddles are fun and educational as well.", "hypothesis": "Riddles are two things.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Yes, Riddles are two things."}, "gen_args_1": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Also, Riddles are two things."}, "gen_args_2": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? No, Riddles are two things."}}, "resps": [[["-78.5", "False"]], [["-84.5", "False"]], [["-81.5", "False"]]], "filtered_resps": [["-78.5", "False"], ["-84.5", "False"], ["-81.5", "False"]], "doc_hash": "61568956da7a5a522c4c1cb9e0b4cc536b24afcffa66734936b6d49d1c61b527", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 705, "doc": {"premise": "Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits.", "hypothesis": "Children today spend more time watching TV than reading.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Yes, Children today spend more time watching TV than reading."}, "gen_args_1": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Also, Children today spend more time watching TV than reading."}, "gen_args_2": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? No, Children today spend more time watching TV than reading."}}, "resps": [[["-168.0", "False"]], [["-172.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-172.0", "False"], ["-174.0", "False"]], "doc_hash": "7952d05175aad7e07b4f0d6e584ad2bd6164c9202aca0e9a57477ad1689941f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.01794253 0.00242826]"]}
{"doc_id": 713, "doc": {"premise": "Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers.", "hypothesis": "Juan Cortina led the group that confronted the Texas Rangers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Yes, Juan Cortina led the group that confronted the Texas Rangers."}, "gen_args_1": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Also, Juan Cortina led the group that confronted the Texas Rangers."}, "gen_args_2": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? No, Juan Cortina led the group that confronted the Texas Rangers."}}, "resps": [[["-178.0", "False"]], [["-180.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-180.0", "False"], ["-181.0", "False"]], "doc_hash": "c55e4241c9681f2e7c2d62706b1423038993778cc6d97745c67a0c171e1b8ff3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 721, "doc": {"premise": "15 The commander wants us to do something, and has used the language of the law to move us toward action.", "hypothesis": "The commander has found a way to make us do what he wants us to do.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Yes, The commander has found a way to make us do what he wants us to do."}, "gen_args_1": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Also, The commander has found a way to make us do what he wants us to do."}, "gen_args_2": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? No, The commander has found a way to make us do what he wants us to do."}}, "resps": [[["-141.0", "False"]], [["-147.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-147.0", "False"], ["-142.0", "False"]], "doc_hash": "a5ef8af60b2535232686832caa28f03ecffdcaf13570c2571e0e74deb22a5b79", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 729, "doc": {"premise": "Should I help her with her homework, and if so, how should I do so?", "hypothesis": "I should ask her if she needs help with homework.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Yes, I should ask her if she needs help with homework."}, "gen_args_1": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Also, I should ask her if she needs help with homework."}, "gen_args_2": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? No, I should ask her if she needs help with homework."}}, "resps": [[["-88.5", "False"]], [["-90.5", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-88.5", "False"], ["-90.5", "False"], ["-89.0", "False"]], "doc_hash": "1c553f2f6643cf8422ff3793cbdb875476c644aa1c75b91334f307f21929b1eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57409699 0.07769558 0.34820743]"]}
{"doc_id": 737, "doc": {"premise": "La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale.", "hypothesis": "Linda Katz was a narc.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Yes, Linda Katz was a narc."}, "gen_args_1": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Also, Linda Katz was a narc."}, "gen_args_2": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? No, Linda Katz was a narc."}}, "resps": [[["-216.0", "False"]], [["-218.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-216.0", "False"], ["-218.0", "False"], ["-216.0", "False"]], "doc_hash": "b5bda6b97f15c8aed94b5af4e4cb03f8784492bc9f4c02f120ed79806d14cf0e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 745, "doc": {"premise": "What we see are details.", "hypothesis": "The details are visible.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What we see are details., right? Yes, The details are visible."}, "gen_args_1": {"arg_0": "", "arg_1": " What we see are details., right? Also, The details are visible."}, "gen_args_2": {"arg_0": "", "arg_1": " What we see are details., right? No, The details are visible."}}, "resps": [[["-76.5", "False"]], [["-84.0", "False"]], [["-80.0", "False"]]], "filtered_resps": [["-76.5", "False"], ["-84.0", "False"], ["-80.0", "False"]], "doc_hash": "826713918d2e33f313aad772ab05b1176f1027f47995450761386399b8695fbc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70166914e-01 5.36584156e-04 2.92965023e-02]"]}
{"doc_id": 753, "doc": {"premise": "Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging.", "hypothesis": "Pitt had never seen his lordship as grave as he was then.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Yes, Pitt had never seen his lordship as grave as he was then."}, "gen_args_1": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Also, Pitt had never seen his lordship as grave as he was then."}, "gen_args_2": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? No, Pitt had never seen his lordship as grave as he was then."}}, "resps": [[["-166.0", "False"]], [["-171.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-171.0", "False"], ["-167.0", "False"]], "doc_hash": "b9ca4ab6c2371b28dc98fa1223f3f2fcace2d840f7a2b2b0d7e548286205e3b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 761, "doc": {"premise": "You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed.", "hypothesis": "He chose to take her hands because they were small, delicate, and most of all, clean.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Yes, He chose to take her hands because they were small, delicate, and most of all, clean."}, "gen_args_1": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Also, He chose to take her hands because they were small, delicate, and most of all, clean."}, "gen_args_2": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? No, He chose to take her hands because they were small, delicate, and most of all, clean."}}, "resps": [[["-232.0", "False"]], [["-237.0", "False"]], [["-231.0", "False"]]], "filtered_resps": [["-232.0", "False"], ["-237.0", "False"], ["-231.0", "False"]], "doc_hash": "b87a1164b3dcdd05dc08adee37b331561d192db338d6277f48e69a671df333ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 769, "doc": {"premise": "You are Lord Julian Wade, I understand,  was his truculent greeting.", "hypothesis": "Lord Julian Wade welcomed others in a manner that would be considered truculent.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Yes, Lord Julian Wade welcomed others in a manner that would be considered truculent."}, "gen_args_1": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Also, Lord Julian Wade welcomed others in a manner that would be considered truculent."}, "gen_args_2": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? No, Lord Julian Wade welcomed others in a manner that would be considered truculent."}}, "resps": [[["-171.0", "False"]], [["-179.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-179.0", "False"], ["-178.0", "False"]], "doc_hash": "e52d50dad4556f8cb37f8d610065dcd86f5f2aaeb632d1525c2ba65274717131", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.98754209e-01 3.35044712e-04 9.10745952e-04]"]}
{"doc_id": 777, "doc": {"premise": "It'll not be Bishop himself,  said Wolverstone, between question and assertion.", "hypothesis": "Wolverstone had asked a question that demonstrated his assertiveness to others.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Yes, Wolverstone had asked a question that demonstrated his assertiveness to others."}, "gen_args_1": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Also, Wolverstone had asked a question that demonstrated his assertiveness to others."}, "gen_args_2": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? No, Wolverstone had asked a question that demonstrated his assertiveness to others."}}, "resps": [[["-191.0", "False"]], [["-190.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-190.0", "False"], ["-190.0", "False"]], "doc_hash": "51864e8d5e23814eacdf938aa092f95306e3f816f3319c3686c15ba4d906366b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 785, "doc": {"premise": "Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission.", "hypothesis": "The King's commission was a very prestigious title with many responsibilities.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Yes, The King's commission was a very prestigious title with many responsibilities."}, "gen_args_1": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Also, The King's commission was a very prestigious title with many responsibilities."}, "gen_args_2": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? No, The King's commission was a very prestigious title with many responsibilities."}}, "resps": [[["-158.0", "False"]], [["-159.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-159.0", "False"], ["-160.0", "False"]], "doc_hash": "2747dcbaf8b1f86162577f392edab3b1e8b478697edb82580ebf31766441a942", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 793, "doc": {"premise": "Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure.", "hypothesis": "She didn't ask anything, she told him to get out.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Yes, She didn't ask anything, she told him to get out."}, "gen_args_1": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Also, She didn't ask anything, she told him to get out."}, "gen_args_2": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? No, She didn't ask anything, she told him to get out."}}, "resps": [[["-211.0", "False"]], [["-213.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-213.0", "False"], ["-209.0", "False"]], "doc_hash": "620725e86ff2af7f152fee7c79b3936a9fd6359699ff842ba103035c11b10132", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 801, "doc": {"premise": "Don't think I accept it willingly.", "hypothesis": "I accept it willingly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Yes, I accept it willingly."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Also, I accept it willingly."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? No, I accept it willingly."}}, "resps": [[["-73.5", "False"]], [["-82.0", "False"]], [["-74.5", "False"]]], "filtered_resps": [["-73.5", "False"], ["-82.0", "False"], ["-74.5", "False"]], "doc_hash": "c8ac51443fde5d7c24f8a7e1c06d5e92b239da405f35a8a1965ce02a55520494", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.30949852e-01 1.48725174e-04 2.68901423e-01]"]}
{"doc_id": 809, "doc": {"premise": "Thoughtfully he stroked his golden beard.", "hypothesis": "His face was clean-shaven.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Yes, His face was clean-shaven."}, "gen_args_1": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Also, His face was clean-shaven."}, "gen_args_2": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? No, His face was clean-shaven."}}, "resps": [[["-94.0", "False"]], [["-97.5", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-94.0", "False"], ["-97.5", "False"], ["-92.0", "False"]], "doc_hash": "2513ad192579f51b3391d06f79296fdd45f997fad4a9da6a2720b39877e05ad2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11877538 0.00358671 0.87763792]"]}
{"doc_id": 817, "doc": {"premise": "He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example.", "hypothesis": "He was feeling very tired, so he did not stand up.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Yes, He was feeling very tired, so he did not stand up."}, "gen_args_1": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Also, He was feeling very tired, so he did not stand up."}, "gen_args_2": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? No, He was feeling very tired, so he did not stand up."}}, "resps": [[["-166.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "d7c6eac407900598a878b6b55f3fe5e44ba8a8a6ecc9294fdb1e03b6ad23b5b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 825, "doc": {"premise": "I... I believe that he has,  said Calverley, between doubt and suspicion.", "hypothesis": "Calverly responded in a way that made him seem like he was on-the-fence about something.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Yes, Calverly responded in a way that made him seem like he was on-the-fence about something."}, "gen_args_1": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Also, Calverly responded in a way that made him seem like he was on-the-fence about something."}, "gen_args_2": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? No, Calverly responded in a way that made him seem like he was on-the-fence about something."}}, "resps": [[["-178.0", "False"]], [["-179.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-179.0", "False"], ["-180.0", "False"]], "doc_hash": "5c811e1b32e0373ff6ffaafef8318cacfca0c7b7ba63a0598118d40d88dcc733", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 833, "doc": {"premise": "Your resolve delivered me from a horrible danger,  she admitted.", "hypothesis": "The resolve did not protect her at all from any dangers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Yes, The resolve did not protect her at all from any dangers."}, "gen_args_1": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Also, The resolve did not protect her at all from any dangers."}, "gen_args_2": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? No, The resolve did not protect her at all from any dangers."}}, "resps": [[["-156.0", "False"]], [["-158.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-158.0", "False"], ["-153.0", "False"]], "doc_hash": "a49a0ab5b0407161cf0787f6468394e3948352237b8ed79f5f2810c90c02ba66", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 841, "doc": {"premise": "Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully.", "hypothesis": "He was looking away from the Captain and then turned around to see him.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Yes, He was looking away from the Captain and then turned around to see him."}, "gen_args_1": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Also, He was looking away from the Captain and then turned around to see him."}, "gen_args_2": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? No, He was looking away from the Captain and then turned around to see him."}}, "resps": [[["-181.0", "False"]], [["-185.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-185.0", "False"], ["-182.0", "False"]], "doc_hash": "82d65d962adb81ff987dcd4544b688ba56890a94e5ae84e6929be56b75b88578", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 849, "doc": {"premise": "He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron.", "hypothesis": "He had never been to Port Royal.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Yes, He had never been to Port Royal."}, "gen_args_1": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Also, He had never been to Port Royal."}, "gen_args_2": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? No, He had never been to Port Royal."}}, "resps": [[["-146.0", "False"]], [["-146.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-146.0", "False"], ["-142.0", "False"]], "doc_hash": "a3d05b02c77e374ed7763d4eae5b18d61161d78caaf2767b84e4f7d9f125dfc1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 857, "doc": {"premise": "There's a thorn or two left on me.  And with a laugh Blood departed to his cabin.", "hypothesis": "Blood was scowling.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Yes, Blood was scowling."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Also, Blood was scowling."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? No, Blood was scowling."}}, "resps": [[["-164.0", "False"]], [["-170.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-170.0", "False"], ["-163.0", "False"]], "doc_hash": "f48652992922200fd5677daecab3876b768ffebd5303001bd9ccd22f3c37f5fb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68762254e-01 6.66195022e-04 7.30571551e-01]"]}
{"doc_id": 865, "doc": {"premise": "That was in Bridgetown on the night of the Spanish raid.", "hypothesis": "The Spanish raid was done at night.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Yes, The Spanish raid was done at night."}, "gen_args_1": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Also, The Spanish raid was done at night."}, "gen_args_2": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? No, The Spanish raid was done at night."}}, "resps": [[["-97.5", "False"]], [["-102.0", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-97.5", "False"], ["-102.0", "False"], ["-98.0", "False"]], "doc_hash": "ed98d7a6fa17bfad7379b22ca78450b9ee40225e7e932d411367aafb3935e819", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61818465 0.00686741 0.37494794]"]}
{"doc_id": 873, "doc": {"premise": "Mine is the safe and easy way.", "hypothesis": "My way is the most difficult.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Yes, My way is the most difficult."}, "gen_args_1": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Also, My way is the most difficult."}, "gen_args_2": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? No, My way is the most difficult."}}, "resps": [[["-94.5", "False"]], [["-97.5", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-94.5", "False"], ["-97.5", "False"], ["-91.5", "False"]], "doc_hash": "0f7b13c676e3bd1b7940bf8029803ad126e55c9f01a22f5ebc676718fa2bce86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 881, "doc": {"premise": "And who the devil may you be?  he exploded at last.", "hypothesis": "The person was actually the devil himself.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Yes, The person was actually the devil himself."}, "gen_args_1": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Also, The person was actually the devil himself."}, "gen_args_2": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? No, The person was actually the devil himself."}}, "resps": [[["-124.0", "False"]], [["-128.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-124.0", "False"], ["-128.0", "False"], ["-122.0", "False"]], "doc_hash": "36090eb48ada8deb2c7f56aa497bf66f9c7645b83b88ad781dc132b5c1115df2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 889, "doc": {"premise": "Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion.", "hypothesis": "He has three eyes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Yes, He has three eyes."}, "gen_args_1": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Also, He has three eyes."}, "gen_args_2": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? No, He has three eyes."}}, "resps": [[["-161.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "ea0d458761600afde450fe036fb44aacc3fb2786d5131c17e6fa6cbeac2a3e16", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 897, "doc": {"premise": "‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?", "hypothesis": "I want you to explain yourself! I know you know where Wolverstone is.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Yes, I want you to explain yourself! I know you know where Wolverstone is."}, "gen_args_1": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Also, I want you to explain yourself! I know you know where Wolverstone is."}, "gen_args_2": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? No, I want you to explain yourself! I know you know where Wolverstone is."}}, "resps": [[["-162.0", "False"]], [["-165.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-165.0", "False"], ["-159.0", "False"]], "doc_hash": "0d020abd629b3d82e279dec195dcbabda7dd00e831c5781b896c855eb44552b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 905, "doc": {"premise": "There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk.", "hypothesis": "They can not possibly sink in any circumstance.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Yes, They can not possibly sink in any circumstance."}, "gen_args_1": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Also, They can not possibly sink in any circumstance."}, "gen_args_2": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? No, They can not possibly sink in any circumstance."}}, "resps": [[["-178.0", "False"]], [["-177.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-177.0", "False"], ["-175.0", "False"]], "doc_hash": "768bd70e74cf96ee8557e5ab186b6d6b6e94d44b3822f8e6a808275899fa805b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 913, "doc": {"premise": "If it is a mistake to grant Captain Blood a commission, the mistake is not mine.", "hypothesis": "There was no mistake in providing Captain Blood with his commission.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Yes, There was no mistake in providing Captain Blood with his commission."}, "gen_args_1": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Also, There was no mistake in providing Captain Blood with his commission."}, "gen_args_2": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? No, There was no mistake in providing Captain Blood with his commission."}}, "resps": [[["-129.0", "False"]], [["-130.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-130.0", "False"], ["-127.0", "False"]], "doc_hash": "bc183555ec96d9a40b8267af8e189a4eedb2eb86463ae5064216350ff4a82771", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 921, "doc": {"premise": "I can't think that it would make the least difference if he did,  said his lordship gravely.", "hypothesis": "His choice was between buying 12 chickens or 3 oxen.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Yes, His choice was between buying 12 chickens or 3 oxen."}, "gen_args_1": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Also, His choice was between buying 12 chickens or 3 oxen."}, "gen_args_2": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? No, His choice was between buying 12 chickens or 3 oxen."}}, "resps": [[["-167.0", "False"]], [["-167.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-167.0", "False"], ["-167.0", "False"]], "doc_hash": "d25a461491895b7096a8fc9c9c65fe8358e952108f6f4d4e708073b152c36dec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 929, "doc": {"premise": "England's,  she corrected him in reproof.", "hypothesis": "She was always tasked with correcting him.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Yes, She was always tasked with correcting him."}, "gen_args_1": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Also, She was always tasked with correcting him."}, "gen_args_2": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? No, She was always tasked with correcting him."}}, "resps": [[["-127.0", "False"]], [["-134.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-134.0", "False"], ["-128.0", "False"]], "doc_hash": "09e1c8fcb0488b5451629c38f33a3e1719da782ccfb835ccfb4f08573826c8e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 937, "doc": {"premise": "Ah, now, can't ye, indeed?  he cried.", "hypothesis": "He had shouted a question.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Yes, He had shouted a question."}, "gen_args_1": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Also, He had shouted a question."}, "gen_args_2": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? No, He had shouted a question."}}, "resps": [[["-136.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "c4518e62982bb624cf2c6b05047cfb44caba317fd924a68e9568a6b8c6078e50", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 945, "doc": {"premise": "Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after.", "hypothesis": "There was no way of knowing if the boat would still move forward.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Yes, There was no way of knowing if the boat would still move forward."}, "gen_args_1": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Also, There was no way of knowing if the boat would still move forward."}, "gen_args_2": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? No, There was no way of knowing if the boat would still move forward."}}, "resps": [[["-204.0", "False"]], [["-204.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-204.0", "False"], ["-204.0", "False"]], "doc_hash": "9f866981278a1ab12474c6f51d55809a307f590c87424a6aef51c6bade82042a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 953, "doc": {"premise": "Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way.", "hypothesis": "One man told the other that he had done his work perfectly and that any mistakes were his own fault.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Yes, One man told the other that he had done his work perfectly and that any mistakes were his own fault."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Also, One man told the other that he had done his work perfectly and that any mistakes were his own fault."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? No, One man told the other that he had done his work perfectly and that any mistakes were his own fault."}}, "resps": [[["-224.0", "False"]], [["-229.0", "False"]], [["-225.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-229.0", "False"], ["-225.0", "False"]], "doc_hash": "e4e6c548e0b6f511a725bb286d5a5638bffb7b88c03d7744cf172f79c209c2ed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 961, "doc": {"premise": "Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course.", "hypothesis": "Some did not like the idea of the current course and refuted it, explicitly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Yes, Some did not like the idea of the current course and refuted it, explicitly."}, "gen_args_1": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Also, Some did not like the idea of the current course and refuted it, explicitly."}, "gen_args_2": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? No, Some did not like the idea of the current course and refuted it, explicitly."}}, "resps": [[["-221.0", "False"]], [["-225.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-221.0", "False"], ["-225.0", "False"], ["-228.0", "False"]], "doc_hash": "2a24d695f64190af315ce41ff81ad025f5a6dd59e79380deb94dfad81efe7deb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 1.79701181e-02 8.94679497e-04]"]}
{"doc_id": 969, "doc": {"premise": "About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men.", "hypothesis": "The night was considered restful though, there was a lot of commotion later on.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Yes, The night was considered restful though, there was a lot of commotion later on."}, "gen_args_1": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Also, The night was considered restful though, there was a lot of commotion later on."}, "gen_args_2": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? No, The night was considered restful though, there was a lot of commotion later on."}}, "resps": [[["-225.0", "False"]], [["-230.0", "False"]], [["-230.0", "False"]]], "filtered_resps": [["-225.0", "False"], ["-230.0", "False"], ["-230.0", "False"]], "doc_hash": "8607fa7b35158f14ef5d9df2ee0a81ded69b974bb1bee4b3b2b886664ea33bdb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 977, "doc": {"premise": "Bid them take in sail, Jeremy,  he said quietly.", "hypothesis": "Jeremy was a pirate for his entire life.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Yes, Jeremy was a pirate for his entire life."}, "gen_args_1": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Also, Jeremy was a pirate for his entire life."}, "gen_args_2": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? No, Jeremy was a pirate for his entire life."}}, "resps": [[["-140.0", "False"]], [["-141.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-141.0", "False"], ["-140.0", "False"]], "doc_hash": "6aa0564e7bc449e694f91357fec170b94c1eef0cc5cc4f3c606fad98dc190b71", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 985, "doc": {"premise": "For myself, I am entirely of Wolverstone's opinion.", "hypothesis": "I completely side with Wolverstone on this matter.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Yes, I completely side with Wolverstone on this matter."}, "gen_args_1": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Also, I completely side with Wolverstone on this matter."}, "gen_args_2": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? No, I completely side with Wolverstone on this matter."}}, "resps": [[["-110.5", "False"]], [["-115.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-115.5", "False"], ["-115.5", "False"]], "doc_hash": "bd5c9679535aac080dfa070146405ac32143593887bf76fc92f57a484e10a29a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 993, "doc": {"premise": "Ha!  Wolverstone vented an ejaculation of sneering mirth.", "hypothesis": "Wolverstone did not laugh.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Yes, Wolverstone did not laugh."}, "gen_args_1": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Also, Wolverstone did not laugh."}, "gen_args_2": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? No, Wolverstone did not laugh."}}, "resps": [[["-132.0", "False"]], [["-135.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-135.0", "False"], ["-128.0", "False"]], "doc_hash": "2707bf6eb20c942339449f8eb368514477ccc4d8d6201a7138c8289fae765137", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1001, "doc": {"premise": "The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December.", "hypothesis": "The San Francisco Ballet has performances during more than one season.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Yes, The San Francisco Ballet has performances during more than one season."}, "gen_args_1": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Also, The San Francisco Ballet has performances during more than one season."}, "gen_args_2": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? No, The San Francisco Ballet has performances during more than one season."}}, "resps": [[["-119.0", "False"]], [["-125.0", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-119.0", "False"], ["-125.0", "False"], ["-120.5", "False"]], "doc_hash": "809382de0c637926a5fe95e682c333fc25665a2f5b105a0b5566a25541054e50", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81592096 0.00202247 0.18205657]"]}
{"doc_id": 1009, "doc": {"premise": "Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables.", "hypothesis": "There are more sights to see.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Yes, There are more sights to see."}, "gen_args_1": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Also, There are more sights to see."}, "gen_args_2": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? No, There are more sights to see."}}, "resps": [[["-115.5", "False"]], [["-122.0", "False"]], [["-116.5", "False"]]], "filtered_resps": [["-115.5", "False"], ["-122.0", "False"], ["-116.5", "False"]], "doc_hash": "4220a5cee0f8389bb289086cbb2f741dd3cf5be93ed0cf0747a156275d3aa916", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.73025595 0.0010979  0.26864615]"]}
{"doc_id": 1017, "doc": {"premise": "Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet.", "hypothesis": "The Sailor's House is an ancient building found in the prince's garden.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Yes, The Sailor's House is an ancient building found in the prince's garden."}, "gen_args_1": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Also, The Sailor's House is an ancient building found in the prince's garden."}, "gen_args_2": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? No, The Sailor's House is an ancient building found in the prince's garden."}}, "resps": [[["-246.0", "False"]], [["-249.0", "False"]], [["-245.0", "False"]]], "filtered_resps": [["-246.0", "False"], ["-249.0", "False"], ["-245.0", "False"]], "doc_hash": "c0502ee42d77af6516ca64930a26d60edc7e872cfcb07b06553f3ba75c7fc0c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1025, "doc": {"premise": "The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture.", "hypothesis": "Sant Pau has churches.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Yes, Sant Pau has churches."}, "gen_args_1": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Also, Sant Pau has churches."}, "gen_args_2": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? No, Sant Pau has churches."}}, "resps": [[["-154.0", "False"]], [["-152.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-152.0", "False"], ["-157.0", "False"]], "doc_hash": "d6e8f355d6d348f82b64d638c9ca2568ae51788846714d16e03993ef03378eb1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.8756006  0.00589975]"]}
{"doc_id": 1033, "doc": {"premise": "The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year.", "hypothesis": "The staff works to increase how many flamingos are on the island so they can recover from near extinction.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Yes, The staff works to increase how many flamingos are on the island so they can recover from near extinction."}, "gen_args_1": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Also, The staff works to increase how many flamingos are on the island so they can recover from near extinction."}, "gen_args_2": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? No, The staff works to increase how many flamingos are on the island so they can recover from near extinction."}}, "resps": [[["-199.0", "False"]], [["-204.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-204.0", "False"], ["-199.0", "False"]], "doc_hash": "2e88bdce7c378081c9df26bfc14bb568911880bd6a68c2c197d247e6d616b14d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1041, "doc": {"premise": "The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex.", "hypothesis": "Karl-Marx-Allee has seen better days.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Yes, Karl-Marx-Allee has seen better days."}, "gen_args_1": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Also, Karl-Marx-Allee has seen better days."}, "gen_args_2": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? No, Karl-Marx-Allee has seen better days."}}, "resps": [[["-161.0", "False"]], [["-167.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-167.0", "False"], ["-163.0", "False"]], "doc_hash": "a11f09f16423068137a18869ea5aebd49220f01e0506ffacb19f65905b58869c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1049, "doc": {"premise": "Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle.", "hypothesis": "Umeda is the north end of the entertainment district.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Yes, Umeda is the north end of the entertainment district."}, "gen_args_1": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Also, Umeda is the north end of the entertainment district."}, "gen_args_2": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? No, Umeda is the north end of the entertainment district."}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-176.0", "False"]], "doc_hash": "33be3d4b8085e58f384433e9aa2a9a7f4b8de45589f88b0ba5676dff65450ec9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1057, "doc": {"premise": "Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that.", "hypothesis": "The war was months long.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Yes, The war was months long."}, "gen_args_1": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Also, The war was months long."}, "gen_args_2": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? No, The war was months long."}}, "resps": [[["-153.0", "False"]], [["-155.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-155.0", "False"], ["-154.0", "False"]], "doc_hash": "fc0edc758a7d6ceb77c852c2d4467ad952bd1f321386fe550e152f6ebd4f54c3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1065, "doc": {"premise": "In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling.", "hypothesis": "Weltkugelbrunnen is made of aluminum.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Yes, Weltkugelbrunnen is made of aluminum."}, "gen_args_1": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Also, Weltkugelbrunnen is made of aluminum."}, "gen_args_2": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? No, Weltkugelbrunnen is made of aluminum."}}, "resps": [[["-226.0", "False"]], [["-227.0", "False"]], [["-223.0", "False"]]], "filtered_resps": [["-226.0", "False"], ["-227.0", "False"], ["-223.0", "False"]], "doc_hash": "6a6041e99155898a9512d424d0a5d44d821d36d3378f439c9210cadb5d2d71c6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 1073, "doc": {"premise": "Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott.", "hypothesis": "Hawthorne lived on Pinckney Street.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Yes, Hawthorne lived on Pinckney Street."}, "gen_args_1": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Also, Hawthorne lived on Pinckney Street."}, "gen_args_2": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? No, Hawthorne lived on Pinckney Street."}}, "resps": [[["-231.0", "False"]], [["-234.0", "False"]], [["-234.0", "False"]]], "filtered_resps": [["-231.0", "False"], ["-234.0", "False"], ["-234.0", "False"]], "doc_hash": "d19e436d5c92c667ba878ccc78b63b9d587367b7ba936fb4218d9636a7cb2d6c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1081, "doc": {"premise": "Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications.", "hypothesis": "There are two towers that were built in the 14th century.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Yes, There are two towers that were built in the 14th century."}, "gen_args_1": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Also, There are two towers that were built in the 14th century."}, "gen_args_2": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? No, There are two towers that were built in the 14th century."}}, "resps": [[["-136.0", "False"]], [["-141.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-141.0", "False"], ["-141.0", "False"]], "doc_hash": "6efea04cf80d2bab0f300fbaec66698ef17fd7eec604e2818bce5bd4e79f5f67", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 1089, "doc": {"premise": "The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans.", "hypothesis": "James Cook never went west of California.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Yes, James Cook never went west of California."}, "gen_args_1": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Also, James Cook never went west of California."}, "gen_args_2": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? No, James Cook never went west of California."}}, "resps": [[["-153.0", "False"]], [["-153.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-153.0", "False"], ["-146.0", "False"]], "doc_hash": "9e60ad35579d40fb73c5e39b46aee4a254276dcc35d430f26dd98340f711c5f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10221936e-04 9.10221936e-04 9.98179556e-01]"]}
{"doc_id": 1097, "doc": {"premise": "As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda.", "hypothesis": "The chimneys indicate the village was part of a hacienda.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Yes, The chimneys indicate the village was part of a hacienda."}, "gen_args_1": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Also, The chimneys indicate the village was part of a hacienda."}, "gen_args_2": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? No, The chimneys indicate the village was part of a hacienda."}}, "resps": [[["-161.0", "False"]], [["-165.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-165.0", "False"], ["-164.0", "False"]], "doc_hash": "6cdf1b256525a0543b990e65ab8f181c911ed9df1524994686856d4d5232cf08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1105, "doc": {"premise": "These instruments played together form the basic  orchestra  for several popular musical genres.", "hypothesis": "The orchestra consists of the instruments mentioned before.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Yes, The orchestra consists of the instruments mentioned before."}, "gen_args_1": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Also, The orchestra consists of the instruments mentioned before."}, "gen_args_2": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? No, The orchestra consists of the instruments mentioned before."}}, "resps": [[["-137.0", "False"]], [["-143.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-143.0", "False"], ["-140.0", "False"]], "doc_hash": "1f6b5a0a5f66c6b3f85ee0f7ba931aec552caa6ffd0040eab90847ef55a8c85b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1113, "doc": {"premise": "A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark.", "hypothesis": "PEople like to party after the fish.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Yes, PEople like to party after the fish."}, "gen_args_1": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Also, PEople like to party after the fish."}, "gen_args_2": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? No, PEople like to party after the fish."}}, "resps": [[["-221.0", "False"]], [["-222.0", "False"]], [["-221.0", "False"]]], "filtered_resps": [["-221.0", "False"], ["-222.0", "False"], ["-221.0", "False"]], "doc_hash": "dd5f4dcaf24a45cf8c5ff60d69a85cade6e2ab2fb801b42f9e3d8a64ecc596b6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1121, "doc": {"premise": "At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany.", "hypothesis": "Canada welcomed refugees from African countries the most.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Yes, Canada welcomed refugees from African countries the most."}, "gen_args_1": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Also, Canada welcomed refugees from African countries the most."}, "gen_args_2": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? No, Canada welcomed refugees from African countries the most."}}, "resps": [[["-173.0", "False"]], [["-171.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-171.0", "False"], ["-168.0", "False"]], "doc_hash": "0337de31d6994699b2b53e0fb9fb08f1162075b50c5515a9a531e26c4a0d4718", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00637746 0.04712342 0.94649912]"]}
{"doc_id": 1129, "doc": {"premise": "As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders.", "hypothesis": "Pierre was arrested for selling to the Americans among other things.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Yes, Pierre was arrested for selling to the Americans among other things."}, "gen_args_1": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Also, Pierre was arrested for selling to the Americans among other things."}, "gen_args_2": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? No, Pierre was arrested for selling to the Americans among other things."}}, "resps": [[["-199.0", "False"]], [["-202.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-202.0", "False"], ["-203.0", "False"]], "doc_hash": "fcd7dbaa4990ec1c9b109b1c8326cbd065bb1973bb46af71f895f8f74d0ca115", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 1137, "doc": {"premise": "Detour to see the mansion designed by McKim Mead", "hypothesis": "McKim Mead designed the mansion.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Yes, McKim Mead designed the mansion."}, "gen_args_1": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Also, McKim Mead designed the mansion."}, "gen_args_2": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? No, McKim Mead designed the mansion."}}, "resps": [[["-89.5", "False"]], [["-98.5", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-89.5", "False"], ["-98.5", "False"], ["-92.0", "False"]], "doc_hash": "1391daac50cf0cb0df96e6c6e3396b7f190405c47aec146827ab5ed8bcc1c3e4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.24036435e-01 1.14035155e-04 7.58495295e-02]"]}
{"doc_id": 1145, "doc": {"premise": "On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony.", "hypothesis": "You can't ever go to the Parque de Palapas, it is forbidden.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Yes, You can't ever go to the Parque de Palapas, it is forbidden."}, "gen_args_1": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Also, You can't ever go to the Parque de Palapas, it is forbidden."}, "gen_args_2": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? No, You can't ever go to the Parque de Palapas, it is forbidden."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-186.0", "False"]], "doc_hash": "ff58fe486d1332f413c602b5c756b068ace9e784935c66df4e27e8b0d5d9ff93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1153, "doc": {"premise": "The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia.", "hypothesis": "The Montesserat are mountains.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Yes, The Montesserat are mountains."}, "gen_args_1": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Also, The Montesserat are mountains."}, "gen_args_2": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? No, The Montesserat are mountains."}}, "resps": [[["-176.0", "False"]], [["-179.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-179.0", "False"], ["-175.0", "False"]], "doc_hash": "166a13ffbe3b8e1ceaeeb9ea4707f4862c7e5858ade498c0b5899dd4a30f315a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1161, "doc": {"premise": "Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife.", "hypothesis": "Lagun Nichupte is a desert.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Yes, Lagun Nichupte is a desert."}, "gen_args_1": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Also, Lagun Nichupte is a desert."}, "gen_args_2": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? No, Lagun Nichupte is a desert."}}, "resps": [[["-164.0", "False"]], [["-168.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-168.0", "False"], ["-161.0", "False"]], "doc_hash": "bdf2fadbc2e1e82daf6b7c3a99cc5251f5c99d3b7fd2135c4c673cdd0e1a38f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1169, "doc": {"premise": "The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay.", "hypothesis": "Visitors like the flowers around the cathedra.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Yes, Visitors like the flowers around the cathedra."}, "gen_args_1": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Also, Visitors like the flowers around the cathedra."}, "gen_args_2": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? No, Visitors like the flowers around the cathedra."}}, "resps": [[["-159.0", "False"]], [["-162.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-162.0", "False"], ["-159.0", "False"]], "doc_hash": "796c9895ec8ba50fbf92d49464adb8ef2ae276924977f36401e0f5148be8b111", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1177, "doc": {"premise": "Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity.", "hypothesis": "PEople didn't move to Europe until 1000 years after the Stone Age.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Yes, PEople didn't move to Europe until 1000 years after the Stone Age."}, "gen_args_1": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Also, PEople didn't move to Europe until 1000 years after the Stone Age."}, "gen_args_2": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? No, PEople didn't move to Europe until 1000 years after the Stone Age."}}, "resps": [[["-145.0", "False"]], [["-145.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-145.0", "False"], ["-143.0", "False"]], "doc_hash": "7619485918fe73534f56c60a7186307e28e2e9d55cdd243591528d309f013d07", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1185, "doc": {"premise": "For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures.", "hypothesis": "Old nickelodeons are boring for film buffs.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Yes, Old nickelodeons are boring for film buffs."}, "gen_args_1": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Also, Old nickelodeons are boring for film buffs."}, "gen_args_2": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? No, Old nickelodeons are boring for film buffs."}}, "resps": [[["-187.0", "False"]], [["-193.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-193.0", "False"], ["-185.0", "False"]], "doc_hash": "7b14be2ad06fb4143e1fe0fdce46a32a5bbcb98c4c52c5373593c8614357475d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 1193, "doc": {"premise": "Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport.", "hypothesis": "Miramar is where rich people live.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Yes, Miramar is where rich people live."}, "gen_args_1": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Also, Miramar is where rich people live."}, "gen_args_2": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? No, Miramar is where rich people live."}}, "resps": [[["-165.0", "False"]], [["-170.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-170.0", "False"], ["-165.0", "False"]], "doc_hash": "9b560e0760f948a85c8079bdaa515c1ed22a0143c9da2c00a7d62cc2ece2fd12", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1201, "doc": {"premise": "The spirit of liberalism prevalent in Europe was tardy in reaching Spain.", "hypothesis": "Liberalism didn't come to Spain until later.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Yes, Liberalism didn't come to Spain until later."}, "gen_args_1": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Also, Liberalism didn't come to Spain until later."}, "gen_args_2": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? No, Liberalism didn't come to Spain until later."}}, "resps": [[["-119.0", "False"]], [["-123.0", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-119.0", "False"], ["-123.0", "False"], ["-118.0", "False"]], "doc_hash": "706ee41478afa474adf5bde49943dbf23d4559df17a2a91c17d2080d9b88f423", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1209, "doc": {"premise": "At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades.", "hypothesis": "There are a lot of 4 star restaurants.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Yes, There are a lot of 4 star restaurants."}, "gen_args_1": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Also, There are a lot of 4 star restaurants."}, "gen_args_2": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? No, There are a lot of 4 star restaurants."}}, "resps": [[["-180.0", "False"]], [["-182.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-182.0", "False"], ["-182.0", "False"]], "doc_hash": "58596e52818af66832b90117a873d481e207ec9f51e66e648f756004ee3b2c63", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1217, "doc": {"premise": "s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion.", "hypothesis": "Charlottetown was most famous in 2019.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Yes, Charlottetown was most famous in 2019."}, "gen_args_1": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Also, Charlottetown was most famous in 2019."}, "gen_args_2": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? No, Charlottetown was most famous in 2019."}}, "resps": [[["-212.0", "False"]], [["-215.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-215.0", "False"], ["-207.0", "False"]], "doc_hash": "2dde3dbd900714607f4102307f24e1884cdbc2539e7ad32a84366f7ceac273d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 1225, "doc": {"premise": "There are also plenty of venues for more  risque  or avant-garde performances.", "hypothesis": "There are places that have strip tease shows.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Yes, There are places that have strip tease shows."}, "gen_args_1": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Also, There are places that have strip tease shows."}, "gen_args_2": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? No, There are places that have strip tease shows."}}, "resps": [[["-137.0", "False"]], [["-139.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-139.0", "False"], ["-137.0", "False"]], "doc_hash": "a659ecb6d0dd87aa45eee217cd42950a89d355833bc1c3322d91d06d95277d9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1233, "doc": {"premise": "Later it held courts of law, and justice was dispensed here.", "hypothesis": "IT was just for church.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Yes, IT was just for church."}, "gen_args_1": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Also, IT was just for church."}, "gen_args_2": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? No, IT was just for church."}}, "resps": [[["-123.0", "False"]], [["-124.5", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-123.0", "False"], ["-124.5", "False"], ["-117.5", "False"]], "doc_hash": "3a999ccf82a191bd0e980e19a709f8a0ed51a6651ef7898148c00a77a9b3b709", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06644469e-03 9.07346455e-04 9.95026209e-01]"]}
{"doc_id": 1241, "doc": {"premise": "Without doubt, the initial lure of the city is its numerous historic buildings.", "hypothesis": "There are many historical buildings that are interesting.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Yes, There are many historical buildings that are interesting."}, "gen_args_1": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Also, There are many historical buildings that are interesting."}, "gen_args_2": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? No, There are many historical buildings that are interesting."}}, "resps": [[["-112.5", "False"]], [["-115.5", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-115.5", "False"], ["-117.5", "False"]], "doc_hash": "6fabce58a74d747f08523e8313dcb35cf65dbf372dd15d2dd15f36d8a7060219", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.04712342 0.00637746]"]}
{"doc_id": 1249, "doc": {"premise": "Although funding strategies can be improved, funding is available for this work.", "hypothesis": "There is no available funding for the work.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Yes, There is no available funding for the work."}, "gen_args_1": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Also, There is no available funding for the work."}, "gen_args_2": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? No, There is no available funding for the work."}}, "resps": [[["-115.0", "False"]], [["-117.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-117.0", "False"], ["-110.5", "False"]], "doc_hash": "29a5a10051d64a49b9a5b530bab10a82ad6df26e0c2cce825c8ecfb68923af26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01097063 0.00148471 0.98754466]"]}
{"doc_id": 1257, "doc": {"premise": "A subject that is discussed during the entry interview is the household's reaction to advertising mail.", "hypothesis": "Disagreeing in the entry interview won't get you the job.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Yes, Disagreeing in the entry interview won't get you the job."}, "gen_args_1": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Also, Disagreeing in the entry interview won't get you the job."}, "gen_args_2": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? No, Disagreeing in the entry interview won't get you the job."}}, "resps": [[["-165.0", "False"]], [["-163.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-163.0", "False"], ["-161.0", "False"]], "doc_hash": "48342b1bdfb19939563fdb9e01b1eac32ca3c430630d6db4a034a3e8e5d40756", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 1265, "doc": {"premise": "For example, in GGD, a design study was done as a separate job, culminating", "hypothesis": "The design study was not successful.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Yes, The design study was not successful."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Also, The design study was not successful."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? No, The design study was not successful."}}, "resps": [[["-133.0", "False"]], [["-138.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-138.0", "False"], ["-134.0", "False"]], "doc_hash": "35a07b2a0c81a49c24130876105228abda18f82a06313024a70d2ecef9bae2b7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1273, "doc": {"premise": "In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate.", "hypothesis": "The price is 10% more than cost.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Yes, The price is 10% more than cost."}, "gen_args_1": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Also, The price is 10% more than cost."}, "gen_args_2": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? No, The price is 10% more than cost."}}, "resps": [[["-189.0", "False"]], [["-189.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-189.0", "False"], ["-188.0", "False"]], "doc_hash": "3f1d55675a602d7ac193dbe990ef372b8e648e4893ad138c5bc1a72aed3d1499", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1281, "doc": {"premise": "The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource.", "hypothesis": "There are way too many IT workers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Yes, There are way too many IT workers."}, "gen_args_1": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Also, There are way too many IT workers."}, "gen_args_2": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? No, There are way too many IT workers."}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-128.0", "False"]], "doc_hash": "95d813ee594ff9a94ce6ed1e7ce3d48e5fbb1f682c96b33071a40fa8d0258cf6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1289, "doc": {"premise": "The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before.", "hypothesis": "They use the historical data to calculate the technical cost effects.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Yes, They use the historical data to calculate the technical cost effects."}, "gen_args_1": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Also, They use the historical data to calculate the technical cost effects."}, "gen_args_2": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? No, They use the historical data to calculate the technical cost effects."}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-178.0", "False"]], "doc_hash": "b1e182e345309de3b0cab1d76a8b802d6276b7b126db35d02c1be5847cad3770", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1297, "doc": {"premise": "Some facility owners have been innovative in their construction plans to minimize down time.", "hypothesis": "Facility owners are not concerned with minimizing down time.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Yes, Facility owners are not concerned with minimizing down time."}, "gen_args_1": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Also, Facility owners are not concerned with minimizing down time."}, "gen_args_2": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? No, Facility owners are not concerned with minimizing down time."}}, "resps": [[["-127.5", "False"]], [["-131.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-127.5", "False"], ["-131.0", "False"], ["-119.5", "False"]], "doc_hash": "5b7e4676a67ce0fda10ca8921c8368b931bab2e7d0cfb1558c2a22c0205850c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35346735e-04 1.01265939e-05 9.99654527e-01]"]}
{"doc_id": 1305, "doc": {"premise": "For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs.", "hypothesis": "Employees didn't have a charge card to use.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Yes, Employees didn't have a charge card to use."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Also, Employees didn't have a charge card to use."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? No, Employees didn't have a charge card to use."}}, "resps": [[["-150.0", "False"]], [["-151.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-151.0", "False"], ["-146.0", "False"]], "doc_hash": "fd889de7150dd3168822d04d0a463a15426902178c397c3e4942394ea6c78564", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1313, "doc": {"premise": "29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler.", "hypothesis": "Retrofitting a boiler can be done in just a few days.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Yes, Retrofitting a boiler can be done in just a few days."}, "gen_args_1": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Also, Retrofitting a boiler can be done in just a few days."}, "gen_args_2": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? No, Retrofitting a boiler can be done in just a few days."}}, "resps": [[["-173.0", "False"]], [["-172.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-172.0", "False"], ["-172.0", "False"]], "doc_hash": "9cc4d57d3affbaeeb46a3d19ec3b3ba7468e6a05db1234509d648a04725b7566", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1321, "doc": {"premise": "The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits.", "hypothesis": "They calculate welfare effects quickly on a calculator.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Yes, They calculate welfare effects quickly on a calculator."}, "gen_args_1": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Also, They calculate welfare effects quickly on a calculator."}, "gen_args_2": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? No, They calculate welfare effects quickly on a calculator."}}, "resps": [[["-178.0", "False"]], [["-180.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-180.0", "False"], ["-177.0", "False"]], "doc_hash": "fdac0844e7218d6fdee211101226123ec15c94ceb911ccd4671b8f026f1b6a9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1329, "doc": {"premise": "The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected.", "hypothesis": "The estimates all look at people who are exposed just once.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Yes, The estimates all look at people who are exposed just once."}, "gen_args_1": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Also, The estimates all look at people who are exposed just once."}, "gen_args_2": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? No, The estimates all look at people who are exposed just once."}}, "resps": [[["-185.0", "False"]], [["-186.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-186.0", "False"], ["-184.0", "False"]], "doc_hash": "e09bcb8176dabb35a4c7cfcab098da883d18479a2afcdc5a2a3120cfc146da17", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1337, "doc": {"premise": "Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so.", "hypothesis": "Things move really fast in the ED.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Yes, Things move really fast in the ED."}, "gen_args_1": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Also, Things move really fast in the ED."}, "gen_args_2": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? No, Things move really fast in the ED."}}, "resps": [[["-166.0", "False"]], [["-166.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-166.0", "False"], ["-167.0", "False"]], "doc_hash": "e0dc19b433852b70bfd502ffcace21fe75753da84863ba869352fda7891f2983", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1345, "doc": {"premise": "The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages.", "hypothesis": "Technology can reduce how long providers and staff need to screen people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Yes, Technology can reduce how long providers and staff need to screen people."}, "gen_args_1": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Also, Technology can reduce how long providers and staff need to screen people."}, "gen_args_2": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? No, Technology can reduce how long providers and staff need to screen people."}}, "resps": [[["-200.0", "False"]], [["-208.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-208.0", "False"], ["-203.0", "False"]], "doc_hash": "d7a8055a3c7fe4af4518b793f2033cb0a36d3d5dfad7c31ed807eb1d52cc7f79", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 1353, "doc": {"premise": "The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress.", "hypothesis": "We are requesting the $3billion we need.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Yes, We are requesting the $3billion we need."}, "gen_args_1": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Also, We are requesting the $3billion we need."}, "gen_args_2": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? No, We are requesting the $3billion we need."}}, "resps": [[["-155.0", "False"]], [["-158.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-158.0", "False"], ["-154.0", "False"]], "doc_hash": "53d1f5dad70b6b4661445036fe23612baa55982503c0ec40c942f19340476ec9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1361, "doc": {"premise": "Figure 3 shows the basic results for the two models.", "hypothesis": "Figure 3 shows what the models do.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Yes, Figure 3 shows what the models do."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Also, Figure 3 shows what the models do."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? No, Figure 3 shows what the models do."}}, "resps": [[["-96.5", "False"]], [["-99.0", "False"]], [["-96.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-99.0", "False"], ["-96.0", "False"]], "doc_hash": "83db8173cb5b4d56075a2caf485027bd502ec1e3fc4e77e9b3c74dc4de01ec83", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.36619222 0.03005889 0.6037489 ]"]}
{"doc_id": 1369, "doc": {"premise": "In addition, few postal administrations pay their employees as large a wage premium as does the U.S.", "hypothesis": "Postal employees in the US make much less money that postal workers in other countries.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Yes, Postal employees in the US make much less money that postal workers in other countries."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Also, Postal employees in the US make much less money that postal workers in other countries."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? No, Postal employees in the US make much less money that postal workers in other countries."}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-135.0", "False"]], "doc_hash": "5798940c674151a79bb72ba6fe71649d4ac170d711e1debbda463e5a3e09c140", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1377, "doc": {"premise": "The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes.", "hypothesis": "The United States Census Bureau has organized its data by Zip Code since the 1960s.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Yes, The United States Census Bureau has organized its data by Zip Code since the 1960s."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Also, The United States Census Bureau has organized its data by Zip Code since the 1960s."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? No, The United States Census Bureau has organized its data by Zip Code since the 1960s."}}, "resps": [[["-139.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "82c459e1e756f84094604f7e85d46088ed37d6bfa009e55e0f43cafbf067a32a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1385, "doc": {"premise": "Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice.", "hypothesis": "The attorney may face liability even if they withdraw from the case.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Yes, The attorney may face liability even if they withdraw from the case."}, "gen_args_1": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Also, The attorney may face liability even if they withdraw from the case."}, "gen_args_2": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? No, The attorney may face liability even if they withdraw from the case."}}, "resps": [[["-155.0", "False"]], [["-161.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-161.0", "False"], ["-156.0", "False"]], "doc_hash": "286ce756c3cf0a490066f5c254b149ca93c58ad34db9c486c7db89bd22b1fe02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 1393, "doc": {"premise": "As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise.", "hypothesis": "It is important to manage contracts well when signing more contracts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Yes, It is important to manage contracts well when signing more contracts."}, "gen_args_1": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Also, It is important to manage contracts well when signing more contracts."}, "gen_args_2": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? No, It is important to manage contracts well when signing more contracts."}}, "resps": [[["-156.0", "False"]], [["-159.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-159.0", "False"], ["-162.0", "False"]], "doc_hash": "0cfcfa3486ed5950f911c34ce11c86ea95129db32f59057bf751d293d063d37c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.04731416 0.00235563]"]}
{"doc_id": 1401, "doc": {"premise": "Employer entity contributions to social insurance programs.", "hypothesis": "Employers donate to food assistance programs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Yes, Employers donate to food assistance programs."}, "gen_args_1": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Also, Employers donate to food assistance programs."}, "gen_args_2": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? No, Employers donate to food assistance programs."}}, "resps": [[["-115.0", "False"]], [["-113.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-113.5", "False"], ["-113.5", "False"]], "doc_hash": "7e77e5755e4f8b0217020c2cba75c5b888c98dd107f63378c2cc6f9cda29c63e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10036756 0.44981622 0.44981622]"]}
{"doc_id": 1409, "doc": {"premise": "The Title V operating permit must also be made available for public comment.", "hypothesis": "There is no need to allow the public to comment.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Yes, There is no need to allow the public to comment."}, "gen_args_1": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Also, There is no need to allow the public to comment."}, "gen_args_2": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? No, There is no need to allow the public to comment."}}, "resps": [[["-114.5", "False"]], [["-114.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-114.0", "False"], ["-109.5", "False"]], "doc_hash": "a005456e0e05207a96f36a2403e35cd5cf48c6fdcde199298f946e9962120730", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0066198  0.01091421 0.98246599]"]}
{"doc_id": 1417, "doc": {"premise": "For clients who are illiterate in any language, materials would have to be carefully explained to them.", "hypothesis": "Illiterate people can figure it out on their own.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Yes, Illiterate people can figure it out on their own."}, "gen_args_1": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Also, Illiterate people can figure it out on their own."}, "gen_args_2": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? No, Illiterate people can figure it out on their own."}}, "resps": [[["-125.0", "False"]], [["-124.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-124.5", "False"], ["-122.0", "False"]], "doc_hash": "84d4d19d596e83bd770a69ebaf2d1704e7bbeec6e3fe0b2be0a558a636ec604b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04398648 0.07252145 0.88349207]"]}
{"doc_id": 1425, "doc": {"premise": "When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage.", "hypothesis": "The outage should have ended much sooner.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Yes, The outage should have ended much sooner."}, "gen_args_1": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Also, The outage should have ended much sooner."}, "gen_args_2": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? No, The outage should have ended much sooner."}}, "resps": [[["-202.0", "False"]], [["-205.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-205.0", "False"], ["-199.0", "False"]], "doc_hash": "9f5b98c6754557b5203673c3240b0c6c369a3a32b52e732bea651603189449f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1433, "doc": {"premise": "Additional time is usually needed to develop the action plan.", "hypothesis": "They usually need more time to create the action plan.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Yes, They usually need more time to create the action plan."}, "gen_args_1": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Also, They usually need more time to create the action plan."}, "gen_args_2": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? No, They usually need more time to create the action plan."}}, "resps": [[["-94.0", "False"]], [["-102.5", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-94.0", "False"], ["-102.5", "False"], ["-97.5", "False"]], "doc_hash": "58269276173dadd08285e916c48416e3bff514b24aa2d18f1d6041e85c70ac73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70496092e-01 1.97465257e-04 2.93064426e-02]"]}
{"doc_id": 1441, "doc": {"premise": "One size fits all does not work in brief interventions, just as it does not work in clinical practice in general.", "hypothesis": "One size fits all is not a good policy in clinical practice.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Yes, One size fits all is not a good policy in clinical practice."}, "gen_args_1": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Also, One size fits all is not a good policy in clinical practice."}, "gen_args_2": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? No, One size fits all is not a good policy in clinical practice."}}, "resps": [[["-114.0", "False"]], [["-119.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-114.0", "False"], ["-119.0", "False"], ["-115.0", "False"]], "doc_hash": "927749d58168b73aedd1ca435e95e71715a7f4ae2e1e6e1b60cd9d5cd24f0d29", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1449, "doc": {"premise": "Figure 6 displays the average unit costs generated with the cost function for the USPS.", "hypothesis": "The average cost for USPS is shown in figure 6 and shows all the profits.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Yes, The average cost for USPS is shown in figure 6 and shows all the profits."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Also, The average cost for USPS is shown in figure 6 and shows all the profits."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? No, The average cost for USPS is shown in figure 6 and shows all the profits."}}, "resps": [[["-159.0", "False"]], [["-161.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-161.0", "False"], ["-161.0", "False"]], "doc_hash": "fa9263200167c8d9040c7a276072c0b0cbc710203446ad3844cc77805b47898d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1457, "doc": {"premise": "28 In some cases longer outages are needed.", "hypothesis": "Sometimes you need to turn the power off for longer.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Yes, Sometimes you need to turn the power off for longer."}, "gen_args_1": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Also, Sometimes you need to turn the power off for longer."}, "gen_args_2": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? No, Sometimes you need to turn the power off for longer."}}, "resps": [[["-105.5", "False"]], [["-111.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-105.5", "False"], ["-111.5", "False"], ["-109.5", "False"]], "doc_hash": "d3cb6773e55c503cc57b8f0a4fd90d9eee80777d63ead2cae0e882f256e8d439", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 1465, "doc": {"premise": "A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements.", "hypothesis": "Each company key is different.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Yes, Each company key is different."}, "gen_args_1": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Also, Each company key is different."}, "gen_args_2": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? No, Each company key is different."}}, "resps": [[["-187.0", "False"]], [["-189.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-189.0", "False"], ["-188.0", "False"]], "doc_hash": "0f713b0bf1500b088c5aefa200c81af5e881b6a259e38befe2dfb7c99850d463", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1473, "doc": {"premise": "Case files would have to be copied and provided to the client.", "hypothesis": "It is procedure to send case files to the client.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Yes, It is procedure to send case files to the client."}, "gen_args_1": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Also, It is procedure to send case files to the client."}, "gen_args_2": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? No, It is procedure to send case files to the client."}}, "resps": [[["-106.5", "False"]], [["-110.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-110.5", "False"], ["-109.5", "False"]], "doc_hash": "cc05a52fd06d5372596442326a279860e278bb02e6242455937d75be4c7921b1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1481, "doc": {"premise": "Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary.", "hypothesis": "Incorrect payments that Centrelink has are preventable in some cases.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Yes, Incorrect payments that Centrelink has are preventable in some cases."}, "gen_args_1": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Also, Incorrect payments that Centrelink has are preventable in some cases."}, "gen_args_2": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? No, Incorrect payments that Centrelink has are preventable in some cases."}}, "resps": [[["-221.0", "False"]], [["-223.0", "False"]], [["-220.0", "False"]]], "filtered_resps": [["-221.0", "False"], ["-223.0", "False"], ["-220.0", "False"]], "doc_hash": "8403c23bc757c00afcbc1d1a65a93351ee58ef5a4c08e3792dcdc56decf55767", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1489, "doc": {"premise": "receive a rating of pass if they meet the fully successful standard for an element.", "hypothesis": "If they don't meet the standard they will fail.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Yes, If they don't meet the standard they will fail."}, "gen_args_1": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Also, If they don't meet the standard they will fail."}, "gen_args_2": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? No, If they don't meet the standard they will fail."}}, "resps": [[["-122.0", "False"]], [["-123.0", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-123.0", "False"], ["-120.5", "False"]], "doc_hash": "b8c59b6eb78d8cdd388fa011d2afda5a5a4f921edcd7e5f31ad502496a6f5095", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.17095278 0.06289001 0.76615721]"]}
{"doc_id": 1497, "doc": {"premise": "Other advisers have echoed this concern.", "hypothesis": "All of the advisers unanimously agreed that there was nothing to be worried about.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Yes, All of the advisers unanimously agreed that there was nothing to be worried about."}, "gen_args_1": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Also, All of the advisers unanimously agreed that there was nothing to be worried about."}, "gen_args_2": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? No, All of the advisers unanimously agreed that there was nothing to be worried about."}}, "resps": [[["-108.0", "False"]], [["-113.0", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-113.0", "False"], ["-107.0", "False"]], "doc_hash": "744d00538b7c11bca0d3896ef0a0aee7ab438e3bf46ae81d2ff2f983c84737bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1505, "doc": {"premise": "We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations.", "hypothesis": "We know for sure that Clarke gave them his paper on July 2.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Yes, We know for sure that Clarke gave them his paper on July 2."}, "gen_args_1": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Also, We know for sure that Clarke gave them his paper on July 2."}, "gen_args_2": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? No, We know for sure that Clarke gave them his paper on July 2."}}, "resps": [[["-213.0", "False"]], [["-213.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-213.0", "False"], ["-211.0", "False"]], "doc_hash": "79807e2c926e3983c2958ca8e331ba40bc7bc89ccf41a4735ba02d8cb978887f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1513, "doc": {"premise": "Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties.", "hypothesis": "Americans should make sure that their guns are not taken away.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Yes, Americans should make sure that their guns are not taken away."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Also, Americans should make sure that their guns are not taken away."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? No, Americans should make sure that their guns are not taken away."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-138.0", "False"]], "doc_hash": "f29082a92e0ba9fd5f39b5d4215bff9ef1db25078898e2d48e74a6267e516c13", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1521, "doc": {"premise": "Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993.", "hypothesis": "In 1993 there was an attempt to blow up the World Trade Center.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Yes, In 1993 there was an attempt to blow up the World Trade Center."}, "gen_args_1": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Also, In 1993 there was an attempt to blow up the World Trade Center."}, "gen_args_2": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? No, In 1993 there was an attempt to blow up the World Trade Center."}}, "resps": [[["-158.0", "False"]], [["-158.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-158.0", "False"], ["-162.0", "False"]], "doc_hash": "a977c727a65513dbc619b450d485c798a8ef0c9fbddbb0edac16b3f08fdbd48c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.49546264 0.00907471]"]}
{"doc_id": 1529, "doc": {"premise": "Pickard recalls the alleged statement being made at a briefing on July 12.", "hypothesis": "Pickard remembered what was said at the briefing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Yes, Pickard remembered what was said at the briefing."}, "gen_args_1": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Also, Pickard remembered what was said at the briefing."}, "gen_args_2": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? No, Pickard remembered what was said at the briefing."}}, "resps": [[["-126.0", "False"]], [["-126.5", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-126.5", "False"], ["-127.0", "False"]], "doc_hash": "7e8082e204fe93c64862d7ff11bf8a45ac030eddaa94fdd33386fe1446bdbc9a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.50648039 0.30719589 0.18632372]"]}
{"doc_id": 1537, "doc": {"premise": "They make targets harder to attack successfully, and they deter attacks by making capture more likely.", "hypothesis": "They made the targets so easy they were captured within mere minutes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Yes, They made the targets so easy they were captured within mere minutes."}, "gen_args_1": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Also, They made the targets so easy they were captured within mere minutes."}, "gen_args_2": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? No, They made the targets so easy they were captured within mere minutes."}}, "resps": [[["-159.0", "False"]], [["-157.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-157.0", "False"], ["-154.0", "False"]], "doc_hash": "2694ed8bd4a8fd17cf16fe964ffe54c3a2ee2a76bffe958b14d3d6385b2e8126", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00637746 0.04712342 0.94649912]"]}
{"doc_id": 1545, "doc": {"premise": "After Mihdhar left, other students moved into the house.", "hypothesis": "Mihdhar knew the students were waiting from him to leave.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Yes, Mihdhar knew the students were waiting from him to leave."}, "gen_args_1": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Also, Mihdhar knew the students were waiting from him to leave."}, "gen_args_2": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? No, Mihdhar knew the students were waiting from him to leave."}}, "resps": [[["-133.0", "False"]], [["-134.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-134.0", "False"], ["-133.0", "False"]], "doc_hash": "43d789b5ff4a39f4c26aa4bbfafb64d74997f1b898bb72f63c30fa2003220c8a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1553, "doc": {"premise": "After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24.", "hypothesis": "There were also several dozen British nationals who left the country.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Yes, There were also several dozen British nationals who left the country."}, "gen_args_1": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Also, There were also several dozen British nationals who left the country."}, "gen_args_2": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? No, There were also several dozen British nationals who left the country."}}, "resps": [[["-173.0", "False"]], [["-174.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-174.0", "False"], ["-175.0", "False"]], "doc_hash": "82144f764382be2a3bdac1b987e458a3c97174846af8eb94cf45d9fa4225b658", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1561, "doc": {"premise": "The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911.", "hypothesis": "The FDNY and the police desk were not giving everyone the same advice.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Yes, The FDNY and the police desk were not giving everyone the same advice."}, "gen_args_1": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Also, The FDNY and the police desk were not giving everyone the same advice."}, "gen_args_2": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? No, The FDNY and the police desk were not giving everyone the same advice."}}, "resps": [[["-200.0", "False"]], [["-202.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-202.0", "False"], ["-198.0", "False"]], "doc_hash": "4660f4b42310ed5db859f09fe5bbec1e5a51233f693b07deff5b1451dc10d94e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1569, "doc": {"premise": "The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat.", "hypothesis": "As the Soviet threat ended the US embarked on a massive military buildup.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Yes, As the Soviet threat ended the US embarked on a massive military buildup."}, "gen_args_1": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Also, As the Soviet threat ended the US embarked on a massive military buildup."}, "gen_args_2": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? No, As the Soviet threat ended the US embarked on a massive military buildup."}}, "resps": [[["-164.0", "False"]], [["-164.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-164.0", "False"], ["-159.0", "False"]], "doc_hash": "d1ed4742373ce4efe9094468e3c50bd39b3e544ee5bf6d0a1f5e3a402415270b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1577, "doc": {"premise": "Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim.", "hypothesis": "Some newspapers spread anti-Muslim rhetoric.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Yes, Some newspapers spread anti-Muslim rhetoric."}, "gen_args_1": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Also, Some newspapers spread anti-Muslim rhetoric."}, "gen_args_2": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? No, Some newspapers spread anti-Muslim rhetoric."}}, "resps": [[["-188.0", "False"]], [["-192.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-192.0", "False"], ["-189.0", "False"]], "doc_hash": "f9ccacd3a8e1369959c2a21e4a39e7f565f8adf9b8bcdf20573d5d8a32e1d974", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1585, "doc": {"premise": "Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing.", "hypothesis": "McLaughlin is the Deputy Director of Central Intelligence.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Yes, McLaughlin is the Deputy Director of Central Intelligence."}, "gen_args_1": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Also, McLaughlin is the Deputy Director of Central Intelligence."}, "gen_args_2": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? No, McLaughlin is the Deputy Director of Central Intelligence."}}, "resps": [[["-140.0", "False"]], [["-140.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-140.0", "False"], ["-138.0", "False"]], "doc_hash": "8b889b6bc3a5b7f2418bcadce65c44390a3c737872e4b233dfeea5ab77ea2527", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1593, "doc": {"premise": "The CTC analyst who drafted the briefing drew on reports over the previous four years.", "hypothesis": "The CTC analyst based his briefing only on information that had come to light in the past month.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Yes, The CTC analyst based his briefing only on information that had come to light in the past month."}, "gen_args_1": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Also, The CTC analyst based his briefing only on information that had come to light in the past month."}, "gen_args_2": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? No, The CTC analyst based his briefing only on information that had come to light in the past month."}}, "resps": [[["-157.0", "False"]], [["-154.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-154.0", "False"], ["-145.0", "False"]], "doc_hash": "54a8e7a45eb5c9a2e9878b9d9d143b833b38c4dab11097ded5d52b18a95e1959", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.14341645e-06 1.23393818e-04 9.99870463e-01]"]}
{"doc_id": 1601, "doc": {"premise": "Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel.", "hypothesis": "Mihdhar had meant to stay at the Marriott originally, but a last-minute fling led him to stay with a lover.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Yes, Mihdhar had meant to stay at the Marriott originally, but a last-minute fling led him to stay with a lover."}, "gen_args_1": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Also, Mihdhar had meant to stay at the Marriott originally, but a last-minute fling led him to stay with a lover."}, "gen_args_2": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? No, Mihdhar had meant to stay at the Marriott originally, but a last-minute fling led him to stay with a lover."}}, "resps": [[["-189.0", "False"]], [["-194.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-194.0", "False"], ["-191.0", "False"]], "doc_hash": "811851a2b8bcf4646d4071743ea7ede2c0114fc62829d77fb98907833f2e31a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1609, "doc": {"premise": "It did not suggest that there was a domestic threat.", "hypothesis": "There was no reason to believe there was a domestic threat.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Yes, There was no reason to believe there was a domestic threat."}, "gen_args_1": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Also, There was no reason to believe there was a domestic threat."}, "gen_args_2": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? No, There was no reason to believe there was a domestic threat."}}, "resps": [[["-89.5", "False"]], [["-93.5", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-89.5", "False"], ["-93.5", "False"], ["-90.0", "False"]], "doc_hash": "67f1d588dac28ebb7c68f7a601790aec5ec4d45d7079dbbb5a0b97f8223e58ba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61544283 0.01127223 0.37328494]"]}
{"doc_id": 1617, "doc": {"premise": "Current security requirements nurture overclassification and excessive compartmentation of information among agencies.", "hypothesis": "Security requirements are much stricter than they previously were.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Yes, Security requirements are much stricter than they previously were."}, "gen_args_1": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Also, Security requirements are much stricter than they previously were."}, "gen_args_2": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? No, Security requirements are much stricter than they previously were."}}, "resps": [[["-135.0", "False"]], [["-138.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-138.0", "False"], ["-135.0", "False"]], "doc_hash": "1128b7b4b8202dace200c121eea5a2cb360ed66328c9b3620d2e70afb5ef2994", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1625, "doc": {"premise": "If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official.", "hypothesis": "The director of the DIA is involved with defense intelligence.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Yes, The director of the DIA is involved with defense intelligence."}, "gen_args_1": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Also, The director of the DIA is involved with defense intelligence."}, "gen_args_2": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? No, The director of the DIA is involved with defense intelligence."}}, "resps": [[["-155.0", "False"]], [["-157.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-157.0", "False"], ["-155.0", "False"]], "doc_hash": "62373aa0361edb41fda91f54b4b6d4632f991d1cb456efa13977199965c25936", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1633, "doc": {"premise": "Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well.", "hypothesis": "The firefighter sent a message to his superiors about the tower falling.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Yes, The firefighter sent a message to his superiors about the tower falling."}, "gen_args_1": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Also, The firefighter sent a message to his superiors about the tower falling."}, "gen_args_2": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? No, The firefighter sent a message to his superiors about the tower falling."}}, "resps": [[["-207.0", "False"]], [["-209.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-209.0", "False"], ["-207.0", "False"]], "doc_hash": "d508d763935ca2c4bcd8bc180f82f323df0a3ac9c2ee81ae265209dc0ea64076", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1641, "doc": {"premise": "We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press.", "hypothesis": "KSM was never there at the guesthouse.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Yes, KSM was never there at the guesthouse."}, "gen_args_1": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Also, KSM was never there at the guesthouse."}, "gen_args_2": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? No, KSM was never there at the guesthouse."}}, "resps": [[["-152.0", "False"]], [["-156.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-156.0", "False"], ["-150.0", "False"]], "doc_hash": "22227b9ae599f342831a3e7430fe0c4d4f3661eff957011e134155a94b23859d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1649, "doc": {"premise": "The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment.", "hypothesis": "There were twenty people on Philip Zelikow's staff.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Yes, There were twenty people on Philip Zelikow's staff."}, "gen_args_1": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Also, There were twenty people on Philip Zelikow's staff."}, "gen_args_2": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? No, There were twenty people on Philip Zelikow's staff."}}, "resps": [[["-188.0", "False"]], [["-192.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-192.0", "False"], ["-187.0", "False"]], "doc_hash": "ef84a56b24ce47fa86c9185d4ce1d9c5157cffc115e190fc447ae540de3ab32c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1657, "doc": {"premise": "As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA.", "hypothesis": "Jane shared the information immediately.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Yes, Jane shared the information immediately."}, "gen_args_1": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Also, Jane shared the information immediately."}, "gen_args_2": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? No, Jane shared the information immediately."}}, "resps": [[["-177.0", "False"]], [["-180.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-180.0", "False"], ["-175.0", "False"]], "doc_hash": "c67791ca4ea1c828a1aac53730d1319c66c38c58051dba52514fb6ed6ce1732b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1665, "doc": {"premise": "Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005.", "hypothesis": "Some controversial provisions of the Patriot Act are likely to be renewed by Congress before it expires.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Yes, Some controversial provisions of the Patriot Act are likely to be renewed by Congress before it expires."}, "gen_args_1": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Also, Some controversial provisions of the Patriot Act are likely to be renewed by Congress before it expires."}, "gen_args_2": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? No, Some controversial provisions of the Patriot Act are likely to be renewed by Congress before it expires."}}, "resps": [[["-114.5", "False"]], [["-109.0", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-109.0", "False"], ["-108.5", "False"]], "doc_hash": "48f9ee0911f3029c410f95a2a4ec685f8c2a3f7d140045921ea93f3362a31a28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00154055 0.37695905 0.6215004 ]"]}
{"doc_id": 1673, "doc": {"premise": "They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House.", "hypothesis": "They talked about the targets they wanted to blow up in code.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Yes, They talked about the targets they wanted to blow up in code."}, "gen_args_1": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Also, They talked about the targets they wanted to blow up in code."}, "gen_args_2": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? No, They talked about the targets they wanted to blow up in code."}}, "resps": [[["-239.0", "False"]], [["-243.0", "False"]], [["-237.0", "False"]]], "filtered_resps": [["-239.0", "False"], ["-243.0", "False"], ["-237.0", "False"]], "doc_hash": "0168a18c16a2b7f0b7ca15a4d63ad732b7649a3f2411817cd14140248ad0454f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1681, "doc": {"premise": "Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time.", "hypothesis": "Hazmi's housemate has never heard of the San Diego airport.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Yes, Hazmi's housemate has never heard of the San Diego airport."}, "gen_args_1": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Also, Hazmi's housemate has never heard of the San Diego airport."}, "gen_args_2": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? No, Hazmi's housemate has never heard of the San Diego airport."}}, "resps": [[["-131.0", "False"]], [["-132.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-131.0", "False"], ["-132.0", "False"], ["-127.5", "False"]], "doc_hash": "adf86d1fd48cbeac2124e4c0a0e2d4d4ce812164257b1ed5210580e0ceb42ea7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02899952 0.01066833 0.96033216]"]}
{"doc_id": 1689, "doc": {"premise": "As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000.", "hypothesis": "He got a large raise in salary and allowances.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Yes, He got a large raise in salary and allowances."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Also, He got a large raise in salary and allowances."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? No, He got a large raise in salary and allowances."}}, "resps": [[["-187.0", "False"]], [["-191.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-191.0", "False"], ["-189.0", "False"]], "doc_hash": "db05a4c7dec9da5eac219f33d45ca57f75b81d1c93841d00f7117724d884ce6e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1697, "doc": {"premise": "NYPD recording, Special Operations Division radio channel, Sept. 11, 2001.", "hypothesis": "These recordings have not been released to the general public due to their sensitive nature.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Yes, These recordings have not been released to the general public due to their sensitive nature."}, "gen_args_1": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Also, These recordings have not been released to the general public due to their sensitive nature."}, "gen_args_2": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? No, These recordings have not been released to the general public due to their sensitive nature."}}, "resps": [[["-128.0", "False"]], [["-129.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-129.0", "False"], ["-129.0", "False"]], "doc_hash": "9740bb4b02d19d90fa0740b389cf9435ae8f8143256d130022cd5826f8c532ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1705, "doc": {"premise": "More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens.", "hypothesis": "More than half a billion people go from Mexico to the US.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Yes, More than half a billion people go from Mexico to the US."}, "gen_args_1": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Also, More than half a billion people go from Mexico to the US."}, "gen_args_2": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? No, More than half a billion people go from Mexico to the US."}}, "resps": [[["-141.0", "False"]], [["-143.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-143.0", "False"], ["-141.0", "False"]], "doc_hash": "849d876ea12b355c739ba9ec5e800893cbf4b97f2925e2828edf71b17325d738", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1713, "doc": {"premise": "The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject.", "hypothesis": "Information sharing barriers were still in place after two years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Yes, Information sharing barriers were still in place after two years."}, "gen_args_1": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Also, Information sharing barriers were still in place after two years."}, "gen_args_2": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? No, Information sharing barriers were still in place after two years."}}, "resps": [[["-185.0", "False"]], [["-190.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-190.0", "False"], ["-189.0", "False"]], "doc_hash": "c97eeb0bc752434ffaec38140a9d5e0bd661348ee9e1f4123a3841f03e566730", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1721, "doc": {"premise": "The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out.", "hypothesis": "The operators knew well in advance that they had to instruct everyone to evacuate from the ground.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Yes, The operators knew well in advance that they had to instruct everyone to evacuate from the ground."}, "gen_args_1": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Also, The operators knew well in advance that they had to instruct everyone to evacuate from the ground."}, "gen_args_2": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? No, The operators knew well in advance that they had to instruct everyone to evacuate from the ground."}}, "resps": [[["-204.0", "False"]], [["-203.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-203.0", "False"], ["-198.0", "False"]], "doc_hash": "a70109e6880bbe9c902d0ab9865c9489855d055dedad124c3b323f5921691941", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00245611 0.00667641 0.99086747]"]}
{"doc_id": 1729, "doc": {"premise": "One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility.", "hypothesis": "Some Treasury officials did not believe the CIA valued financial tracking.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Yes, Some Treasury officials did not believe the CIA valued financial tracking."}, "gen_args_1": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Also, Some Treasury officials did not believe the CIA valued financial tracking."}, "gen_args_2": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? No, Some Treasury officials did not believe the CIA valued financial tracking."}}, "resps": [[["-196.0", "False"]], [["-200.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-200.0", "False"], ["-196.0", "False"]], "doc_hash": "23b3d9f6e3957657762bed341178dfaab1426f08d33305a2d815f35c7d7ba8c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1737, "doc": {"premise": "The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M.", "hypothesis": "The NYPD failed to respond to the North Tower until after 10:00 AM.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Yes, The NYPD failed to respond to the North Tower until after 10:00 AM."}, "gen_args_1": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Also, The NYPD failed to respond to the North Tower until after 10:00 AM."}, "gen_args_2": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? No, The NYPD failed to respond to the North Tower until after 10:00 AM."}}, "resps": [[["-177.0", "False"]], [["-178.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-178.0", "False"], ["-172.0", "False"]], "doc_hash": "abfd4d243a761d3c740ba8f296164b16e4e17f84a91f306c75798a60704ee0a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1745, "doc": {"premise": "Your gift is important to the celebration of our 85th season.", "hypothesis": "We have been doing this for more than 80 years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Yes, We have been doing this for more than 80 years."}, "gen_args_1": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Also, We have been doing this for more than 80 years."}, "gen_args_2": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? No, We have been doing this for more than 80 years."}}, "resps": [[["-104.0", "False"]], [["-108.5", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-108.5", "False"], ["-107.0", "False"]], "doc_hash": "a0e2bfe17dd02b3206d50c2d492cd5f5fa913abfe644f8c9b360aee11aba57d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 1753, "doc": {"premise": "Only with the help of our philanthropic partners have we been able to achieve so much.", "hypothesis": "Given the state of the financial markets, our philanthropic partners have pulled back fro all their funding.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Yes, Given the state of the financial markets, our philanthropic partners have pulled back fro all their funding."}, "gen_args_1": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Also, Given the state of the financial markets, our philanthropic partners have pulled back fro all their funding."}, "gen_args_2": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? No, Given the state of the financial markets, our philanthropic partners have pulled back fro all their funding."}}, "resps": [[["-151.0", "False"]], [["-149.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-149.0", "False"], ["-148.0", "False"]], "doc_hash": "fbfff0c2da9f8cdfdefd1de102c7322c90fa6302e7900191c15d60b5f918762a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.03511903 0.25949646 0.70538451]"]}
{"doc_id": 1761, "doc": {"premise": "It's important that we hear from you during this last fundraising drive of the season.", "hypothesis": "This is the last donation drive we will have this season, so we need your help!", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Yes, This is the last donation drive we will have this season, so we need your help!"}, "gen_args_1": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Also, This is the last donation drive we will have this season, so we need your help!"}, "gen_args_2": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? No, This is the last donation drive we will have this season, so we need your help!"}}, "resps": [[["-119.0", "False"]], [["-122.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-119.0", "False"], ["-122.0", "False"], ["-125.5", "False"]], "doc_hash": "b990bc17bc25b06d36d746b0b27978c6e2fb09037fcda4f2e146cb16e18ac0e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95121186 0.04735805 0.00143009]"]}
{"doc_id": 1769, "doc": {"premise": "Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs.", "hypothesis": "Those participating can only know prospects names, but not their addresses.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Yes, Those participating can only know prospects names, but not their addresses."}, "gen_args_1": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Also, Those participating can only know prospects names, but not their addresses."}, "gen_args_2": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? No, Those participating can only know prospects names, but not their addresses."}}, "resps": [[["-158.0", "False"]], [["-161.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-161.0", "False"], ["-155.0", "False"]], "doc_hash": "f2663d036356fb38fc548daa868042c026742a0007458d308a37783788246e19", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1777, "doc": {"premise": "Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment.", "hypothesis": "Supporting Goodwill will benefit people in Indiana.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Yes, Supporting Goodwill will benefit people in Indiana."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Also, Supporting Goodwill will benefit people in Indiana."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? No, Supporting Goodwill will benefit people in Indiana."}}, "resps": [[["-123.0", "False"]], [["-132.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-132.0", "False"], ["-130.0", "False"]], "doc_hash": "1b20d3c4863e79f0c6956b0dd879e3098d0adc0caa68f82b332654c64d48e1d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.98965779e-01 1.23282171e-04 9.10938878e-04]"]}
{"doc_id": 1785, "doc": {"premise": "-conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol.", "hypothesis": "The costumes were entirely fabricated at a factory.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Yes, The costumes were entirely fabricated at a factory."}, "gen_args_1": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Also, The costumes were entirely fabricated at a factory."}, "gen_args_2": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? No, The costumes were entirely fabricated at a factory."}}, "resps": [[["-199.0", "False"]], [["-202.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-202.0", "False"], ["-193.0", "False"]], "doc_hash": "e7bd3c66e3ab8f6270c455c09550514de85654d699f37e63b6a5554b13072617", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47231880e-03 1.23089505e-04 9.97404592e-01]"]}
{"doc_id": 1793, "doc": {"premise": "As a member of the law school's __, I know you are aware of our progress.", "hypothesis": "The law school had accepted people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Yes, The law school had accepted people."}, "gen_args_1": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Also, The law school had accepted people."}, "gen_args_2": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? No, The law school had accepted people."}}, "resps": [[["-136.0", "False"]], [["-137.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-137.0", "False"], ["-136.0", "False"]], "doc_hash": "21d2e7bc87456b0ea90c5b7c959c652ee620899cd2cfe6942e3c5f053b32ee6c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1801, "doc": {"premise": "Your investment continues the high quality of all aspects of the Museum and makes new achievements possible.", "hypothesis": "Larger investments are more helpful for the Museum.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Yes, Larger investments are more helpful for the Museum."}, "gen_args_1": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Also, Larger investments are more helpful for the Museum."}, "gen_args_2": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? No, Larger investments are more helpful for the Museum."}}, "resps": [[["-139.0", "False"]], [["-144.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-144.0", "False"], ["-144.0", "False"]], "doc_hash": "2e5b87d42063af213a8e859ce54dddb4e464ae96fb898e6e40021c0c3898db45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 1809, "doc": {"premise": "The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students.", "hypothesis": "The IRT is involved in soccer.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Yes, The IRT is involved in soccer."}, "gen_args_1": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Also, The IRT is involved in soccer."}, "gen_args_2": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? No, The IRT is involved in soccer."}}, "resps": [[["-146.0", "False"]], [["-145.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-145.0", "False"], ["-145.0", "False"]], "doc_hash": "30ba39a33bbfc285a8cc049e926350f81957d40b5879e90ae3cf582dcf4767b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1817, "doc": {"premise": "I believe just the opposite.", "hypothesis": "I think you are wrong, that the answer is yes and not no.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I believe just the opposite., right? Yes, I think you are wrong, that the answer is yes and not no."}, "gen_args_1": {"arg_0": "", "arg_1": " I believe just the opposite., right? Also, I think you are wrong, that the answer is yes and not no."}, "gen_args_2": {"arg_0": "", "arg_1": " I believe just the opposite., right? No, I think you are wrong, that the answer is yes and not no."}}, "resps": [[["-91.5", "False"]], [["-95.0", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-95.0", "False"], ["-92.0", "False"]], "doc_hash": "5e8ff5f1befe15de15a0aa4a73276ca1f0ea9a485909e3c535d9a259e245995f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61097505 0.01844985 0.3705751 ]"]}
{"doc_id": 1825, "doc": {"premise": "Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story.", "hypothesis": "It rained 17 inches last Sunday.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Yes, It rained 17 inches last Sunday."}, "gen_args_1": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Also, It rained 17 inches last Sunday."}, "gen_args_2": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? No, It rained 17 inches last Sunday."}}, "resps": [[["-184.0", "False"]], [["-186.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-186.0", "False"], ["-180.0", "False"]], "doc_hash": "26c4c5c457851fa72e38a5a90559b31589184de0050a597a72a30470e1bfab23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1833, "doc": {"premise": "The law school's 5,539 alumni form a distinguished group.", "hypothesis": "The law school has been open for 100 years and has had 5,539 alumni.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Yes, The law school has been open for 100 years and has had 5,539 alumni."}, "gen_args_1": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Also, The law school has been open for 100 years and has had 5,539 alumni."}, "gen_args_2": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? No, The law school has been open for 100 years and has had 5,539 alumni."}}, "resps": [[["-124.0", "False"]], [["-129.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-129.0", "False"], ["-124.5", "False"]], "doc_hash": "8c38ab13856d1a0cb5f32374ba4d074388ab10b3e1f3482b8f81034401069856", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61985958 0.00417658 0.37596384]"]}
{"doc_id": 1841, "doc": {"premise": "I've got more than a job", "hypothesis": "I have a job.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I've got more than a job, right? Yes, I have a job."}, "gen_args_1": {"arg_0": "", "arg_1": " I've got more than a job, right? Also, I have a job."}, "gen_args_2": {"arg_0": "", "arg_1": " I've got more than a job, right? No, I have a job."}}, "resps": [[["-53.25", "False"]], [["-58.5", "False"]], [["-55.25", "False"]]], "filtered_resps": [["-53.25", "False"], ["-58.5", "False"], ["-55.25", "False"]], "doc_hash": "418a057905dd34161aabbb0a1c9d1b71af61a911df70349310b53b5dca898d8b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87674476 0.00460073 0.1186545 ]"]}
{"doc_id": 1849, "doc": {"premise": "Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ...", "hypothesis": "The group is full of important people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Yes, The group is full of important people."}, "gen_args_1": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Also, The group is full of important people."}, "gen_args_2": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? No, The group is full of important people."}}, "resps": [[["-155.0", "False"]], [["-158.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-158.0", "False"], ["-157.0", "False"]], "doc_hash": "633db7898cfd7030057ad1ac2420adc347473ed8b909248a3ce32614ebe1a5c1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1857, "doc": {"premise": "In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole.", "hypothesis": "They believed that the organization would destroy the city.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Yes, They believed that the organization would destroy the city."}, "gen_args_1": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Also, They believed that the organization would destroy the city."}, "gen_args_2": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? No, They believed that the organization would destroy the city."}}, "resps": [[["-138.0", "False"]], [["-143.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-143.0", "False"], ["-133.0", "False"]], "doc_hash": "0f4403d2ebbfb1932855d3de8c9388937ee7d2ed23b5a7fa9b117b24da159921", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69254912e-03 4.50940412e-05 9.93262357e-01]"]}
{"doc_id": 1865, "doc": {"premise": "Chairman of the Board of Trustees", "hypothesis": "The long-serving Chairman of the Board or Trustees.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Yes, The long-serving Chairman of the Board or Trustees."}, "gen_args_1": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Also, The long-serving Chairman of the Board or Trustees."}, "gen_args_2": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? No, The long-serving Chairman of the Board or Trustees."}}, "resps": [[["-78.0", "False"]], [["-82.0", "False"]], [["-80.0", "False"]]], "filtered_resps": [["-78.0", "False"], ["-82.0", "False"], ["-80.0", "False"]], "doc_hash": "cfa1c2224b88275cba71eb8b56125f7d4273232b53841e4538ecfb90524c8e7a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1873, "doc": {"premise": ".. why they have so little self-worth that they value the friendship of thieves and killers.", "hypothesis": "Some of their friends are thieves and killers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Yes, Some of their friends are thieves and killers."}, "gen_args_1": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Also, Some of their friends are thieves and killers."}, "gen_args_2": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? No, Some of their friends are thieves and killers."}}, "resps": [[["-125.0", "False"]], [["-128.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-128.0", "False"], ["-128.0", "False"]], "doc_hash": "8c9f0a04d1c1a27723c1688e5e3dae62a92e2dcc860a5a5f235f29b1c0a3a074", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1881, "doc": {"premise": "To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext.", "hypothesis": "Call Kathy Dannels only if you want to discuss last night's episode of The Walking Dead.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Yes, Call Kathy Dannels only if you want to discuss last night's episode of The Walking Dead."}, "gen_args_1": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Also, Call Kathy Dannels only if you want to discuss last night's episode of The Walking Dead."}, "gen_args_2": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? No, Call Kathy Dannels only if you want to discuss last night's episode of The Walking Dead."}}, "resps": [[["-178.0", "False"]], [["-183.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-183.0", "False"], ["-174.0", "False"]], "doc_hash": "f491901f22d5d09dec60ae28aac9c69afc78af64f53930df8a8b2657425448a1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 1889, "doc": {"premise": "You are important to us and the I.U.", "hypothesis": "We and the I.U. don't give a rat's ass about you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Yes, We and the I.U. don't give a rat's ass about you."}, "gen_args_1": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Also, We and the I.U. don't give a rat's ass about you."}, "gen_args_2": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? No, We and the I.U. don't give a rat's ass about you."}}, "resps": [[["-101.5", "False"]], [["-107.0", "False"]], [["-96.0", "False"]]], "filtered_resps": [["-101.5", "False"], ["-107.0", "False"], ["-96.0", "False"]], "doc_hash": "5e25e3e161195c23f030cc37a38a675f54ca11836a22b9632411a94b2b116589", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.07007002e-03 1.66334459e-05 9.95913297e-01]"]}
{"doc_id": 1897, "doc": {"premise": "Student tuition has been raised 12% for 1992-92, a significant increase.", "hypothesis": "The tuition rate went down 40%.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Yes, The tuition rate went down 40%."}, "gen_args_1": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Also, The tuition rate went down 40%."}, "gen_args_2": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? No, The tuition rate went down 40%."}}, "resps": [[["-129.0", "False"]], [["-130.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-130.0", "False"], ["-122.0", "False"]], "doc_hash": "20f85b2f87a71fe0b44bf22fb4f94930368cff15cc0500374a5abe63f0e6c9d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10745952e-04 3.35044712e-04 9.98754209e-01]"]}
{"doc_id": 1905, "doc": {"premise": "This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design.", "hypothesis": "The space has a ton of plants.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Yes, The space has a ton of plants."}, "gen_args_1": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Also, The space has a ton of plants."}, "gen_args_2": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? No, The space has a ton of plants."}}, "resps": [[["-188.0", "False"]], [["-189.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-189.0", "False"], ["-190.0", "False"]], "doc_hash": "108b4fdfdb64e545767556930fc1001647c74700cf54403762deeaee07e16c4a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1913, "doc": {"premise": "This situation could also impact our ability to mount another festival next year.", "hypothesis": "We might not have another festival next year.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Yes, We might not have another festival next year."}, "gen_args_1": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Also, We might not have another festival next year."}, "gen_args_2": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? No, We might not have another festival next year."}}, "resps": [[["-109.0", "False"]], [["-116.5", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-116.5", "False"], ["-113.0", "False"]], "doc_hash": "082611a1facc908d0e6ad90da4d32aa7eddedf2691fa3b3828079bfa021fcfb7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81480712e-01 5.42841641e-04 1.79764463e-02]"]}
{"doc_id": 1921, "doc": {"premise": "By May 1, we must conclude membership renewal options for 1991 contributors.", "hypothesis": "There is space for 1500 members to renew their memberships.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Yes, There is space for 1500 members to renew their memberships."}, "gen_args_1": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Also, There is space for 1500 members to renew their memberships."}, "gen_args_2": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? No, There is space for 1500 members to renew their memberships."}}, "resps": [[["-156.0", "False"]], [["-155.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-155.0", "False"], ["-153.0", "False"]], "doc_hash": "148fce186d2597454e3b0c7c42f6f4f1fad3893f00d5fab34d3d3facbadc1400", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 1929, "doc": {"premise": "learn to walk in someone else's shoes", "hypothesis": "Learn to experience what someone else experiences.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Yes, Learn to experience what someone else experiences."}, "gen_args_1": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Also, Learn to experience what someone else experiences."}, "gen_args_2": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? No, Learn to experience what someone else experiences."}}, "resps": [[["-77.0", "False"]], [["-76.0", "False"]], [["-77.5", "False"]]], "filtered_resps": [["-77.0", "False"], ["-76.0", "False"], ["-77.5", "False"]], "doc_hash": "9a02f50403bb5c16041af80c5b63c288b30f9269ea5c362db0addb590fc2f777", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.2312239  0.62853172 0.14024438]"]}
{"doc_id": 1937, "doc": {"premise": "Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy.", "hypothesis": "Visitors will only be able to see West Side Story in the Hilbert Conservatory.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Yes, Visitors will only be able to see West Side Story in the Hilbert Conservatory."}, "gen_args_1": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Also, Visitors will only be able to see West Side Story in the Hilbert Conservatory."}, "gen_args_2": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? No, Visitors will only be able to see West Side Story in the Hilbert Conservatory."}}, "resps": [[["-188.0", "False"]], [["-197.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-197.0", "False"], ["-182.0", "False"]], "doc_hash": "e23f97fd018ebea25ba72c8e7f40b9fd560cde1f471379d9d9bd27b86b89bce2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47262240e-03 3.05145846e-07 9.97527072e-01]"]}
{"doc_id": 1945, "doc": {"premise": "Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana.", "hypothesis": "Theatre has helped many children across Indiana.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Yes, Theatre has helped many children across Indiana."}, "gen_args_1": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Also, Theatre has helped many children across Indiana."}, "gen_args_2": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? No, Theatre has helped many children across Indiana."}}, "resps": [[["-187.0", "False"]], [["-196.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-196.0", "False"], ["-192.0", "False"]], "doc_hash": "f25d3859536fd26e8511d5dc59f9944225278ed8f647059ca1e2880c94d500cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.93185401e-01 1.22568816e-04 6.69203059e-03]"]}
{"doc_id": 1953, "doc": {"premise": "It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo.", "hypothesis": "It pays for care for the animals in the shelter.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Yes, It pays for care for the animals in the shelter."}, "gen_args_1": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Also, It pays for care for the animals in the shelter."}, "gen_args_2": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? No, It pays for care for the animals in the shelter."}}, "resps": [[["-122.0", "False"]], [["-125.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-122.0", "False"], ["-125.0", "False"], ["-122.0", "False"]], "doc_hash": "f63898dde46956c10656baf36ee0306fe21290f6ee54300613e4ad70289039fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1961, "doc": {"premise": "It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots.", "hypothesis": "The center wants to help the poor people in the community.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Yes, The center wants to help the poor people in the community."}, "gen_args_1": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Also, The center wants to help the poor people in the community."}, "gen_args_2": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? No, The center wants to help the poor people in the community."}}, "resps": [[["-183.0", "False"]], [["-184.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-184.0", "False"], ["-183.0", "False"]], "doc_hash": "d822091583a1b6954408f29029593d27ad31832fdd24164c2b0c6840026e5d75", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1969, "doc": {"premise": ".. wisps of white clouds scattered across a clear, blue sky.", "hypothesis": "The sky is clear and blue, with not a cloud in sight.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Yes, The sky is clear and blue, with not a cloud in sight."}, "gen_args_1": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Also, The sky is clear and blue, with not a cloud in sight."}, "gen_args_2": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? No, The sky is clear and blue, with not a cloud in sight."}}, "resps": [[["-101.5", "False"]], [["-107.0", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-101.5", "False"], ["-107.0", "False"], ["-101.5", "False"]], "doc_hash": "3ac89355694c0695d57cbd088302e2a7f1ca95b4680f2657f0ed478b90fc5605", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49898039 0.00203922 0.49898039]"]}
{"doc_id": 1977, "doc": {"premise": "Technology, although seemingly indispensable, has caused us to go into hyperspeed.", "hypothesis": "Technology has made the way we collect information ramp up to speeds we've never seen.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Yes, Technology has made the way we collect information ramp up to speeds we've never seen."}, "gen_args_1": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Also, Technology has made the way we collect information ramp up to speeds we've never seen."}, "gen_args_2": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? No, Technology has made the way we collect information ramp up to speeds we've never seen."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-153.0", "False"]], "doc_hash": "af1e308c55b69835d8f2b7873fa69ba90c97eba7e678b3f5e44af3ff90b010ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1985, "doc": {"premise": "The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it.", "hypothesis": "The Indy Civic Theater has only been operating for 2 years.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Yes, The Indy Civic Theater has only been operating for 2 years."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Also, The Indy Civic Theater has only been operating for 2 years."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? No, The Indy Civic Theater has only been operating for 2 years."}}, "resps": [[["-197.0", "False"]], [["-199.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-199.0", "False"], ["-197.0", "False"]], "doc_hash": "60ae0c924688f4001c44e0105667f1a78d834fa6812ab3500a9aebe6884bb1d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1993, "doc": {"premise": "With OPEN going platinum, why not a neon CLOSED sign?", "hypothesis": "The OPEN sign is on the front curb.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Yes, The OPEN sign is on the front curb."}, "gen_args_1": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Also, The OPEN sign is on the front curb."}, "gen_args_2": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? No, The OPEN sign is on the front curb."}}, "resps": [[["-142.0", "False"]], [["-141.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-141.0", "False"], ["-142.0", "False"]], "doc_hash": "6922d877727ac5dbc32564732314cdad2cb4f8ff71578d86f576c0e9da54ddf4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 2001, "doc": {"premise": "The main point, though, is that there aren't actually all that many Milosevics in the world.", "hypothesis": "There are fewer than 1000 Milosevics in the world.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Yes, There are fewer than 1000 Milosevics in the world."}, "gen_args_1": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Also, There are fewer than 1000 Milosevics in the world."}, "gen_args_2": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? No, There are fewer than 1000 Milosevics in the world."}}, "resps": [[["-114.0", "False"]], [["-118.5", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-118.5", "False"], ["-114.5", "False"]], "doc_hash": "dfc2b50ec647fc35089047ef550561671a591f76e00f7c08cfd3c2ee2f726082", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61818465 0.00686741 0.37494794]"]}
{"doc_id": 2009, "doc": {"premise": "Run Silent, Run Deep, Run the Answer", "hypothesis": "Run without being heard.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Yes, Run without being heard."}, "gen_args_1": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Also, Run without being heard."}, "gen_args_2": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? No, Run without being heard."}}, "resps": [[["-85.5", "False"]], [["-86.0", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-85.5", "False"], ["-86.0", "False"], ["-85.0", "False"]], "doc_hash": "ef18a59ae9066b47673822459a522d2ac5d36940a1bfab0e03dca879014eae13", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.30719589 0.18632372 0.50648039]"]}
{"doc_id": 2017, "doc": {"premise": "Steve, I couldn't even lift your wallet, Hatch shot back.", "hypothesis": "Hatch had no opinion about Steve's wallet.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Yes, Hatch had no opinion about Steve's wallet."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Also, Hatch had no opinion about Steve's wallet."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? No, Hatch had no opinion about Steve's wallet."}}, "resps": [[["-132.0", "False"]], [["-137.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-137.0", "False"], ["-128.0", "False"]], "doc_hash": "f24057cc597dd13fdfe6fcca110af14f92cd7dc6fd91e853bb4320b6f790d23b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 2025, "doc": {"premise": "Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters.", "hypothesis": "Kevin Lamarque has taken many photos of Bill Clinton including one in the Slate Table of Contents.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Yes, Kevin Lamarque has taken many photos of Bill Clinton including one in the Slate Table of Contents."}, "gen_args_1": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Also, Kevin Lamarque has taken many photos of Bill Clinton including one in the Slate Table of Contents."}, "gen_args_2": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? No, Kevin Lamarque has taken many photos of Bill Clinton including one in the Slate Table of Contents."}}, "resps": [[["-135.0", "False"]], [["-137.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-137.0", "False"], ["-138.0", "False"]], "doc_hash": "38f5a3436399f3497e93b4e3f756ebc98739fe9c5e0666909b1337865b10eedf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 2033, "doc": {"premise": "This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights.", "hypothesis": "Kennedy favors states' rights.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Yes, Kennedy favors states' rights."}, "gen_args_1": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Also, Kennedy favors states' rights."}, "gen_args_2": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? No, Kennedy favors states' rights."}}, "resps": [[["-113.0", "False"]], [["-115.0", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-113.0", "False"], ["-115.0", "False"], ["-115.5", "False"]], "doc_hash": "dd692663651b0dcb0b7d77268fef6e804e4982cd5b1bd3a3ca25797a2e06d6f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.82140902 0.11116562 0.06742536]"]}
{"doc_id": 2041, "doc": {"premise": "Sabol said he has to take the occasional pit stop, but even that is conveniently arranged.", "hypothesis": "Sabol mentioned that now and again he has to make a pit stop.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Yes, Sabol mentioned that now and again he has to make a pit stop."}, "gen_args_1": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Also, Sabol mentioned that now and again he has to make a pit stop."}, "gen_args_2": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? No, Sabol mentioned that now and again he has to make a pit stop."}}, "resps": [[["-144.0", "False"]], [["-147.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-147.0", "False"], ["-145.0", "False"]], "doc_hash": "0d1b0a1f85bdfe9062494abc0d0c218c9a23f8ff1038147d2f7a41bf7850d131", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 2049, "doc": {"premise": "The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority.", "hypothesis": "The USDA says police need to help them.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Yes, The USDA says police need to help them."}, "gen_args_1": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Also, The USDA says police need to help them."}, "gen_args_2": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? No, The USDA says police need to help them."}}, "resps": [[["-165.0", "False"]], [["-166.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-166.0", "False"], ["-161.0", "False"]], "doc_hash": "fae14efb8347c63101e12eb6cace4fe181794bdb5dd2bac03dd527c193f2a6b3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 2057, "doc": {"premise": "You are not sure you've been clear about whose side you're on.", "hypothesis": "We don't know who you support.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Yes, We don't know who you support."}, "gen_args_1": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Also, We don't know who you support."}, "gen_args_2": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? No, We don't know who you support."}}, "resps": [[["-102.5", "False"]], [["-105.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-105.5", "False"], ["-105.0", "False"]], "doc_hash": "4b5a0799c2d23b1a76450ce51148f517cc232a6e84a90dc19f1e1f0aaa47faa8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.88349207 0.04398648 0.07252145]"]}
{"doc_id": 2065, "doc": {"premise": "The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous.", "hypothesis": "Livingston's resignation made Clinton look bad.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Yes, Livingston's resignation made Clinton look bad."}, "gen_args_1": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Also, Livingston's resignation made Clinton look bad."}, "gen_args_2": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? No, Livingston's resignation made Clinton look bad."}}, "resps": [[["-129.0", "False"]], [["-126.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-129.0", "False"], ["-126.0", "False"], ["-122.5", "False"]], "doc_hash": "b57f4c68a1e2e5a5ca1a7bdb2fa9c74708173cb15476f56c8f82dd2d6eab609a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00145724 0.02926952 0.96927324]"]}
{"doc_id": 2073, "doc": {"premise": "Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system.", "hypothesis": "Humans are the only creatures that do not have an immune system.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Yes, Humans are the only creatures that do not have an immune system."}, "gen_args_1": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Also, Humans are the only creatures that do not have an immune system."}, "gen_args_2": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? No, Humans are the only creatures that do not have an immune system."}}, "resps": [[["-170.0", "False"]], [["-172.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-172.0", "False"], ["-169.0", "False"]], "doc_hash": "5ee97bb909a41011c91a61ad0089e585214555417273185df430d998b92900de", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2081, "doc": {"premise": "One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?", "hypothesis": "There may be more than one way to find the answer.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Yes, There may be more than one way to find the answer."}, "gen_args_1": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Also, There may be more than one way to find the answer."}, "gen_args_2": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? No, There may be more than one way to find the answer."}}, "resps": [[["-156.0", "False"]], [["-155.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-155.0", "False"], ["-156.0", "False"]], "doc_hash": "15ad8193e6728f310cd51234607d92a0c8e3d3dade5f8f79a30dadf9e8edfc35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 2089, "doc": {"premise": "This kind of treatment for big contributors is quite routine.", "hypothesis": "Everyone contributes the same amount, in order to prevent special treatment.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Yes, Everyone contributes the same amount, in order to prevent special treatment."}, "gen_args_1": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Also, Everyone contributes the same amount, in order to prevent special treatment."}, "gen_args_2": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? No, Everyone contributes the same amount, in order to prevent special treatment."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "700033d2ad2ec03a8abf77671740a18756982a2c7c8351bb702b097234b7ad98", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2097, "doc": {"premise": "Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private.", "hypothesis": "It is rumored that Pynchon has a son and daughter.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Yes, It is rumored that Pynchon has a son and daughter."}, "gen_args_1": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Also, It is rumored that Pynchon has a son and daughter."}, "gen_args_2": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? No, It is rumored that Pynchon has a son and daughter."}}, "resps": [[["-159.0", "False"]], [["-160.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-160.0", "False"], ["-158.0", "False"]], "doc_hash": "71feb6c0148a0243dd1d1cd7576b8a6b6209b5281ec032a97cfb23c2e749b5eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2105, "doc": {"premise": "Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner.", "hypothesis": "Morrison is allowed to be as idiosyncratic as William Gaddis.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Yes, Morrison is allowed to be as idiosyncratic as William Gaddis."}, "gen_args_1": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Also, Morrison is allowed to be as idiosyncratic as William Gaddis."}, "gen_args_2": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? No, Morrison is allowed to be as idiosyncratic as William Gaddis."}}, "resps": [[["-132.0", "False"]], [["-138.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-138.0", "False"], ["-132.0", "False"]], "doc_hash": "4346a94ab696eb757dda1c5b9dc021f87f9788af999760e8fab0725d44265278", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 2113, "doc": {"premise": "Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state.", "hypothesis": "Henry Kissinger was the best secretary of state.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Yes, Henry Kissinger was the best secretary of state."}, "gen_args_1": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Also, Henry Kissinger was the best secretary of state."}, "gen_args_2": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? No, Henry Kissinger was the best secretary of state."}}, "resps": [[["-122.5", "False"]], [["-126.0", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-126.0", "False"], ["-123.5", "False"]], "doc_hash": "8074db855a02ab9d20411b38c17fd17f889dd0f8626bd855d51680a886a573ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 2121, "doc": {"premise": "Three Japanese banks will merge to create the world's largest financial institution.", "hypothesis": "The bank will be the largest in the world.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Yes, The bank will be the largest in the world."}, "gen_args_1": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Also, The bank will be the largest in the world."}, "gen_args_2": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? No, The bank will be the largest in the world."}}, "resps": [[["-91.0", "False"]], [["-95.0", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-91.0", "False"], ["-95.0", "False"], ["-92.5", "False"]], "doc_hash": "6c8d9c18106ac59cc3502df688e6f9fc9a5ce54fb3cc1aaf9f9b1f9129e5a569", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.80551241 0.01475347 0.17973411]"]}
{"doc_id": 2129, "doc": {"premise": "The decent and sensitive thing to do is tell the president.", "hypothesis": "The president will be surprised and upset by this news.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Yes, The president will be surprised and upset by this news."}, "gen_args_1": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Also, The president will be surprised and upset by this news."}, "gen_args_2": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? No, The president will be surprised and upset by this news."}}, "resps": [[["-109.0", "False"]], [["-111.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-111.5", "False"], ["-112.0", "False"]], "doc_hash": "1c7b8800d5f5295fba48f140968343cfa1d2105b8d81cd2caf19c48201df9a71", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.88349207 0.07252145 0.04398648]"]}
{"doc_id": 2137, "doc": {"premise": "There is a difference between canny skepticism and dumbbell skepticism.", "hypothesis": "Canny skepticism and dumbbell skepticism are one in the same.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Yes, Canny skepticism and dumbbell skepticism are one in the same."}, "gen_args_1": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Also, Canny skepticism and dumbbell skepticism are one in the same."}, "gen_args_2": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? No, Canny skepticism and dumbbell skepticism are one in the same."}}, "resps": [[["-107.5", "False"]], [["-109.0", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-107.5", "False"], ["-109.0", "False"], ["-103.0", "False"]], "doc_hash": "0bb9d2c4031dd525e0de846e6b5b9f157c3ea475f3429855ced603a822d4c23f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01096007 0.00244552 0.9865944 ]"]}
{"doc_id": 2145, "doc": {"premise": "Soderbergh is one of those rare filmmakers who learn on the job.", "hypothesis": "It is very common for filmmakers to learn on the job.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Yes, It is very common for filmmakers to learn on the job."}, "gen_args_1": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Also, It is very common for filmmakers to learn on the job."}, "gen_args_2": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? No, It is very common for filmmakers to learn on the job."}}, "resps": [[["-100.5", "False"]], [["-104.0", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-100.5", "False"], ["-104.0", "False"], ["-99.0", "False"]], "doc_hash": "3880afed8d580dc70400b0cb3ac8968113301cd6b105da0ac906ce43f1594945", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18142609 0.00547859 0.81309532]"]}
{"doc_id": 2153, "doc": {"premise": "Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business.", "hypothesis": "Bruce never apologizes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Yes, Bruce never apologizes."}, "gen_args_1": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Also, Bruce never apologizes."}, "gen_args_2": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? No, Bruce never apologizes."}}, "resps": [[["-211.0", "False"]], [["-211.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-211.0", "False"], ["-212.0", "False"]], "doc_hash": "e7c66c31b87c8507bc460bdb80a810d809b54c2cc7dac165a3bdb138b8c4ba57", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 2161, "doc": {"premise": "The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal.", "hypothesis": "Some people believe it is false that Brock defends Hillary to elevate himself.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Yes, Some people believe it is false that Brock defends Hillary to elevate himself."}, "gen_args_1": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Also, Some people believe it is false that Brock defends Hillary to elevate himself."}, "gen_args_2": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? No, Some people believe it is false that Brock defends Hillary to elevate himself."}}, "resps": [[["-185.0", "False"]], [["-188.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-188.0", "False"], ["-185.0", "False"]], "doc_hash": "a237096771b6aaf6ff1d5f173beed0f33dbf9575b4cfaa159821cf645bb396e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2169, "doc": {"premise": "One measure of attachment to ordinary  Does the president carry a wallet?", "hypothesis": "Do you think the president carries a wallet?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Yes, Do you think the president carries a wallet?"}, "gen_args_1": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Also, Do you think the president carries a wallet?"}, "gen_args_2": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? No, Do you think the president carries a wallet?"}}, "resps": [[["-132.0", "False"]], [["-134.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-134.0", "False"], ["-134.0", "False"]], "doc_hash": "95532b7073ace643d1c85af1ab94d93bd7bf0f92a79450e3087e75430b571fd0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2177, "doc": {"premise": "My gender is interesting but really not the subject of the story here.", "hypothesis": "The story covers subject matter not based entirely on gender.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Yes, The story covers subject matter not based entirely on gender."}, "gen_args_1": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Also, The story covers subject matter not based entirely on gender."}, "gen_args_2": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? No, The story covers subject matter not based entirely on gender."}}, "resps": [[["-132.0", "False"]], [["-136.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-136.0", "False"], ["-134.0", "False"]], "doc_hash": "0f9a861747d0437e37a09876e9f15298a9c085e27d8a08796d5b3c94eaa8966a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2185, "doc": {"premise": "When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card.", "hypothesis": "The sign lit up.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Yes, The sign lit up."}, "gen_args_1": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Also, The sign lit up."}, "gen_args_2": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? No, The sign lit up."}}, "resps": [[["-157.0", "False"]], [["-162.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-162.0", "False"], ["-157.0", "False"]], "doc_hash": "8610908f4547c08449f5998f80f713faabae6bd7aece2cdcf1f0a28a3210ceab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 2193, "doc": {"premise": "The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies.", "hypothesis": "The European Union have bureaucrats.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Yes, The European Union have bureaucrats."}, "gen_args_1": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Also, The European Union have bureaucrats."}, "gen_args_2": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? No, The European Union have bureaucrats."}}, "resps": [[["-158.0", "False"]], [["-157.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-157.0", "False"], ["-155.0", "False"]], "doc_hash": "7fc90281e4243fd4b4c99a8ba82e73ac13d726c7599062e8118163f4f0428dd9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 2201, "doc": {"premise": "The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di.", "hypothesis": "Princess Diana was a much better person than Hillary Clinton.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Yes, Princess Diana was a much better person than Hillary Clinton."}, "gen_args_1": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Also, Princess Diana was a much better person than Hillary Clinton."}, "gen_args_2": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? No, Princess Diana was a much better person than Hillary Clinton."}}, "resps": [[["-175.0", "False"]], [["-178.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-178.0", "False"], ["-179.0", "False"]], "doc_hash": "bf695147146614528bab4e870a84670ed6f52355191226724b519fa9122d4075", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2209, "doc": {"premise": "There are, of course, many elegant and flirtatious scenes set on yachts.", "hypothesis": "Very few elegant or flirtatious scenes take place on yachts.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Yes, Very few elegant or flirtatious scenes take place on yachts."}, "gen_args_1": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Also, Very few elegant or flirtatious scenes take place on yachts."}, "gen_args_2": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? No, Very few elegant or flirtatious scenes take place on yachts."}}, "resps": [[["-123.5", "False"]], [["-127.5", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-127.5", "False"], ["-123.0", "False"]], "doc_hash": "090f51c97962846f1cc83385f59fe9b991442dcd70c1467ec7bd13ecec1a676e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 2217, "doc": {"premise": "While I'm not writing you from the United States, that's where I normally am, so sign me...", "hypothesis": "I am in Canada today, but I'm normally in the United States.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Yes, I am in Canada today, but I'm normally in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Also, I am in Canada today, but I'm normally in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? No, I am in Canada today, but I'm normally in the United States."}}, "resps": [[["-140.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "1bb844c40294828d26293f9de45010f6f15beef1d76a531a757640b9681d066d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2225, "doc": {"premise": "The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year.", "hypothesis": "No one took fen-phen in the US.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Yes, No one took fen-phen in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Also, No one took fen-phen in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? No, No one took fen-phen in the US."}}, "resps": [[["-161.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "15cf535d5581683f180bbc482d0381076502e888a536b7003b418c4570a96c46", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 2233, "doc": {"premise": "More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI.", "hypothesis": "WorldCom never bid against BT.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Yes, WorldCom never bid against BT."}, "gen_args_1": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Also, WorldCom never bid against BT."}, "gen_args_2": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? No, WorldCom never bid against BT."}}, "resps": [[["-164.0", "False"]], [["-164.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-164.0", "False"], ["-155.0", "False"]], "doc_hash": "531cfd896c2887cda76a8bd3cae85c738421661156b3e9f20a683ba0ca621d98", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.23379352e-04 1.23379352e-04 9.99753241e-01]"]}
{"doc_id": 2241, "doc": {"premise": "Alternative should not be used in place of alternate.", "hypothesis": "It is not proper to use alternative to mean alternate.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Yes, It is not proper to use alternative to mean alternate."}, "gen_args_1": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Also, It is not proper to use alternative to mean alternate."}, "gen_args_2": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? No, It is not proper to use alternative to mean alternate."}}, "resps": [[["-96.0", "False"]], [["-100.0", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-96.0", "False"], ["-100.0", "False"], ["-97.5", "False"]], "doc_hash": "a9bd000b693bd953e4afd45610a182daffd54e04a6a8bbce17ac428070143f21", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.80551241 0.01475347 0.17973411]"]}
{"doc_id": 2249, "doc": {"premise": "On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders.", "hypothesis": "The enormous size of the car made the boulder look like a small stone.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Yes, The enormous size of the car made the boulder look like a small stone."}, "gen_args_1": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Also, The enormous size of the car made the boulder look like a small stone."}, "gen_args_2": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? No, The enormous size of the car made the boulder look like a small stone."}}, "resps": [[["-201.0", "False"]], [["-204.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-204.0", "False"], ["-200.0", "False"]], "doc_hash": "9ca540c861016a56434d2d0375260bc3f6e76352cbbc4fd2b30a60f402638ca0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2257, "doc": {"premise": "Which do you like better, math or science?", "hypothesis": "What do you hate more, english or philosophy?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Yes, What do you hate more, english or philosophy?"}, "gen_args_1": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Also, What do you hate more, english or philosophy?"}, "gen_args_2": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? No, What do you hate more, english or philosophy?"}}, "resps": [[["-96.5", "False"]], [["-93.5", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-93.5", "False"], ["-93.0", "False"]], "doc_hash": "35e3889cac88d31b6c046b6d6c25fe1c28579ee4e009dca76b6a77a7cf6450ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01844985 0.3705751  0.61097505]"]}
{"doc_id": 2265, "doc": {"premise": "A cavalier is tied to his steed through Latin caballus `horse.", "hypothesis": "Cavaliers are known as foot soldiers used to defend fixed positions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Yes, Cavaliers are known as foot soldiers used to defend fixed positions."}, "gen_args_1": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Also, Cavaliers are known as foot soldiers used to defend fixed positions."}, "gen_args_2": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? No, Cavaliers are known as foot soldiers used to defend fixed positions."}}, "resps": [[["-169.0", "False"]], [["-170.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-170.0", "False"], ["-169.0", "False"]], "doc_hash": "46fa9870055e0bae752d11fe243331f5b521957d024ff818ed04299a15404d25", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2273, "doc": {"premise": "good brother -- this expression of common present usage is found in Julius Caesar (iv.", "hypothesis": "The term good brother is used to refer to a brother in law.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Yes, The term good brother is used to refer to a brother in law."}, "gen_args_1": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Also, The term good brother is used to refer to a brother in law."}, "gen_args_2": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? No, The term good brother is used to refer to a brother in law."}}, "resps": [[["-162.0", "False"]], [["-162.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-162.0", "False"], ["-163.0", "False"]], "doc_hash": "4481fadfff934110aef974f01e5ef44e31cea766a0d9ea3ebf814d100811e237", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 2281, "doc": {"premise": "How old are  young people ?", "hypothesis": "Young people are a group that some people have trouble classifying by age.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " How old are  young people ?, right? Yes, Young people are a group that some people have trouble classifying by age."}, "gen_args_1": {"arg_0": "", "arg_1": " How old are  young people ?, right? Also, Young people are a group that some people have trouble classifying by age."}, "gen_args_2": {"arg_0": "", "arg_1": " How old are  young people ?, right? No, Young people are a group that some people have trouble classifying by age."}}, "resps": [[["-115.0", "False"]], [["-119.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-115.0", "False"], ["-119.5", "False"], ["-117.0", "False"]], "doc_hash": "a88360e7deda4d9895f130fe0912c58671635c8525765b7ee10d05d265c71508", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 2289, "doc": {"premise": "Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events.", "hypothesis": "As their concept of time is linear, the passage of time is more important that the return of seasonal events.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Yes, As their concept of time is linear, the passage of time is more important that the return of seasonal events."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Also, As their concept of time is linear, the passage of time is more important that the return of seasonal events."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? No, As their concept of time is linear, the passage of time is more important that the return of seasonal events."}}, "resps": [[["-161.0", "False"]], [["-161.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-161.0", "False"], ["-158.0", "False"]], "doc_hash": "3e99f688ee99114cc9496d3fed02f0f2b7c62fd8c8a7cc30b567dbba4271de5c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 2297, "doc": {"premise": "As for challenges, I am currently looking for a word that can be cut into two successively smaller forms.", "hypothesis": "I have taken an interest in linguistics, since I took an introductory class last year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Yes, I have taken an interest in linguistics, since I took an introductory class last year."}, "gen_args_1": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Also, I have taken an interest in linguistics, since I took an introductory class last year."}, "gen_args_2": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? No, I have taken an interest in linguistics, since I took an introductory class last year."}}, "resps": [[["-167.0", "False"]], [["-166.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-166.0", "False"], ["-168.0", "False"]], "doc_hash": "083f69cd922be1b4d8f0c387140fe4d1b895e0abbf5cf1ad94d2a7aea0fba6cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2305, "doc": {"premise": "In the closing years of the 19th century there was much discussion concerning the word", "hypothesis": "The word was a subject of debate many years ago.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Yes, The word was a subject of debate many years ago."}, "gen_args_1": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Also, The word was a subject of debate many years ago."}, "gen_args_2": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? No, The word was a subject of debate many years ago."}}, "resps": [[["-106.5", "False"]], [["-113.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-113.0", "False"], ["-110.5", "False"]], "doc_hash": "1821f0a05882ff56448ae3f369fdba358565e8466e1fdf511d8167092185f3f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98056608 0.00147422 0.01795969]"]}
{"doc_id": 2313, "doc": {"premise": "The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores .", "hypothesis": "It is not easy to read the King James Bible, given its many archaisms.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Yes, It is not easy to read the King James Bible, given its many archaisms."}, "gen_args_1": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Also, It is not easy to read the King James Bible, given its many archaisms."}, "gen_args_2": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? No, It is not easy to read the King James Bible, given its many archaisms."}}, "resps": [[["-222.0", "False"]], [["-219.0", "False"]], [["-223.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-219.0", "False"], ["-223.0", "False"]], "doc_hash": "e162c08e14302b8a7aa4852a1dc98dab92435fc150013ee07e8d6b01ac1034c7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04661262 0.93623955 0.01714783]"]}
{"doc_id": 2321, "doc": {"premise": "consistency is a form of ritualism.", "hypothesis": "Ritualism is valued because it leads to a consistent result.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Yes, Ritualism is valued because it leads to a consistent result."}, "gen_args_1": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Also, Ritualism is valued because it leads to a consistent result."}, "gen_args_2": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? No, Ritualism is valued because it leads to a consistent result."}}, "resps": [[["-103.0", "False"]], [["-104.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-103.0", "False"], ["-104.0", "False"], ["-105.5", "False"]], "doc_hash": "8afb855c40b211a492f13d3315b74e71ff01901885f3857364b88e141214fab2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.68967209 0.25371618 0.05661173]"]}
{"doc_id": 2329, "doc": {"premise": "Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms.", "hypothesis": "The largest dictionary is now out of print.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Yes, The largest dictionary is now out of print."}, "gen_args_1": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Also, The largest dictionary is now out of print."}, "gen_args_2": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? No, The largest dictionary is now out of print."}}, "resps": [[["-148.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "fe9706381c9c4d89ed6df9646321af0dc5c78a0de073a8f6137571fea2a0a447", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2337, "doc": {"premise": "Words are, generally speaking, old.", "hypothesis": "Most words tend to be fairly old.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Yes, Most words tend to be fairly old."}, "gen_args_1": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Also, Most words tend to be fairly old."}, "gen_args_2": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? No, Most words tend to be fairly old."}}, "resps": [[["-94.0", "False"]], [["-99.0", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-94.0", "False"], ["-99.0", "False"], ["-99.0", "False"]], "doc_hash": "73ff8b7b506e3b611f2c18b9a965262d9fdc3bcd988774138bbc3671bbc61d75", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 2345, "doc": {"premise": "They teach us to be resolute, relentless, and resourceful.", "hypothesis": "Learning to be resolute, relentless, and resourceful is challenging and difficult, but they teach it skillfully.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Yes, Learning to be resolute, relentless, and resourceful is challenging and difficult, but they teach it skillfully."}, "gen_args_1": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Also, Learning to be resolute, relentless, and resourceful is challenging and difficult, but they teach it skillfully."}, "gen_args_2": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? No, Learning to be resolute, relentless, and resourceful is challenging and difficult, but they teach it skillfully."}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-134.0", "False"]], "doc_hash": "23fb1fb40db9d36d5f52fe0badd4932d3b37d75e51ca53837b6e6da7f56a2e62", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 2353, "doc": {"premise": "As we all know, there is an enormous number of publications dealing with highly specialized areas.", "hypothesis": "There are a lot of journals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Yes, There are a lot of journals."}, "gen_args_1": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Also, There are a lot of journals."}, "gen_args_2": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? No, There are a lot of journals."}}, "resps": [[["-102.5", "False"]], [["-106.5", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.5", "False"], ["-106.5", "False"]], "doc_hash": "b0f8089c97ac76ef00d38e7ac6864383c1e641fc3b832ad000294267ef6ff5ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2361, "doc": {"premise": "From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research.", "hypothesis": "The author of this dictionary does a very thorough job of documenting and acknowledging the research that went into practically every entry.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Yes, The author of this dictionary does a very thorough job of documenting and acknowledging the research that went into practically every entry."}, "gen_args_1": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Also, The author of this dictionary does a very thorough job of documenting and acknowledging the research that went into practically every entry."}, "gen_args_2": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? No, The author of this dictionary does a very thorough job of documenting and acknowledging the research that went into practically every entry."}}, "resps": [[["-204.0", "False"]], [["-206.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-206.0", "False"], ["-203.0", "False"]], "doc_hash": "18567403aec9674e685416fa07b0adc586261076a5e8e96c6d8c97e04c2c5c22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2369, "doc": {"premise": "buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble'", "hypothesis": "There is an idiom about a cat's fifth leg.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Yes, There is an idiom about a cat's fifth leg."}, "gen_args_1": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Also, There is an idiom about a cat's fifth leg."}, "gen_args_2": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? No, There is an idiom about a cat's fifth leg."}}, "resps": [[["-146.0", "False"]], [["-147.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-147.0", "False"], ["-148.0", "False"]], "doc_hash": "4c63d11f621c12406e5c66026334ba176f24ff2697f5572c92f57d7df331248b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 2377, "doc": {"premise": "to do (someone) wrong -- The Rape of Lucrece , line 1462:", "hypothesis": "someone was raped", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Yes, someone was raped"}, "gen_args_1": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Also, someone was raped"}, "gen_args_2": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? No, someone was raped"}}, "resps": [[["-129.0", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "3fbbbeb78355e2ff73bc1ce71973c85a890538896afb6ed46311a2374c12b48b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2385, "doc": {"premise": "But the question cannot even be asked when the details are mislaid.", "hypothesis": "Just clearing up the the details will make the question more understandable.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Yes, Just clearing up the the details will make the question more understandable."}, "gen_args_1": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Also, Just clearing up the the details will make the question more understandable."}, "gen_args_2": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? No, Just clearing up the the details will make the question more understandable."}}, "resps": [[["-140.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "76b0a9b06a87eeae0b13433d7b007498b585b6f812d430e039bc97be19aceef0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2393, "doc": {"premise": "If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations.", "hypothesis": "The book will only need one pitching no matter what.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Yes, The book will only need one pitching no matter what."}, "gen_args_1": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Also, The book will only need one pitching no matter what."}, "gen_args_2": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? No, The book will only need one pitching no matter what."}}, "resps": [[["-199.0", "False"]], [["-199.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-199.0", "False"], ["-199.0", "False"]], "doc_hash": "bf924fa2de52bd30af62f640589a8d05422c69ae9a6864b36c756382961d3a18", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2401, "doc": {"premise": "Serious crime down, but murders increase.", "hypothesis": "There has been a rise in murders because a serial killer is on the loose.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Yes, There has been a rise in murders because a serial killer is on the loose."}, "gen_args_1": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Also, There has been a rise in murders because a serial killer is on the loose."}, "gen_args_2": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? No, There has been a rise in murders because a serial killer is on the loose."}}, "resps": [[["-106.5", "False"]], [["-110.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-106.5", "False"], ["-110.5", "False"], ["-106.0", "False"]], "doc_hash": "c67e48a9a0abda336ca826dfba9c21f6e2829d73dc51244ad7007b0f76aa8123", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 2409, "doc": {"premise": "Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha", "hypothesis": "Al of the words are easy to understand.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Yes, Al of the words are easy to understand."}, "gen_args_1": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Also, Al of the words are easy to understand."}, "gen_args_2": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? No, Al of the words are easy to understand."}}, "resps": [[["-229.0", "False"]], [["-228.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-228.0", "False"], ["-228.0", "False"]], "doc_hash": "cfb22cb67c5f4f6fda59abf53222e329d5a832eb9c0422ab2352e8f24656cf90", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 2417, "doc": {"premise": "The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony.", "hypothesis": "The word agon originally meant pain and suffering in Greek", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Yes, The word agon originally meant pain and suffering in Greek"}, "gen_args_1": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Also, The word agon originally meant pain and suffering in Greek"}, "gen_args_2": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? No, The word agon originally meant pain and suffering in Greek"}}, "resps": [[["-190.0", "False"]], [["-194.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-194.0", "False"], ["-192.0", "False"]], "doc_hash": "964131b39fbf4f3aa48d3682f918aaeba3190642ca0d0628836c97ee8e5b6f5e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2425, "doc": {"premise": "Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North.", "hypothesis": "There have been exactly two books written on the history of Canada's North, and these were by popular writers Newman and Berton.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Yes, There have been exactly two books written on the history of Canada's North, and these were by popular writers Newman and Berton."}, "gen_args_1": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Also, There have been exactly two books written on the history of Canada's North, and these were by popular writers Newman and Berton."}, "gen_args_2": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? No, There have been exactly two books written on the history of Canada's North, and these were by popular writers Newman and Berton."}}, "resps": [[["-194.0", "False"]], [["-202.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-202.0", "False"], ["-199.0", "False"]], "doc_hash": "da8f71120d585f42d671f833c11f863b786127c12f1b7da3bd5d114713992aa9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.92976272e-01 3.33106430e-04 6.69062149e-03]"]}
{"doc_id": 2433, "doc": {"premise": "Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one.", "hypothesis": "The Omni Gazetteer of the United States is a first step.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Yes, The Omni Gazetteer of the United States is a first step."}, "gen_args_1": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Also, The Omni Gazetteer of the United States is a first step."}, "gen_args_2": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? No, The Omni Gazetteer of the United States is a first step."}}, "resps": [[["-180.0", "False"]], [["-186.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-186.0", "False"], ["-182.0", "False"]], "doc_hash": "fa004582591ffc2c26ee682fb7fcd8662533b601f1081fe47918c6ac0f94e7b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 2441, "doc": {"premise": "She pointed to a patch of equally depressing but bushier shrubbery.", "hypothesis": "That bush is less bushy than the other.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Yes, That bush is less bushy than the other."}, "gen_args_1": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Also, That bush is less bushy than the other."}, "gen_args_2": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? No, That bush is less bushy than the other."}}, "resps": [[["-131.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "187f9fcf85968703dfca0c264fe32ac54cf6267b42ae9888c482ad7a8bf4f910", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 2449, "doc": {"premise": "Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons.", "hypothesis": "The word quark has been listed in dictionaries as a verb defined as the croaking sound made by frogs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Yes, The word quark has been listed in dictionaries as a verb defined as the croaking sound made by frogs."}, "gen_args_1": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Also, The word quark has been listed in dictionaries as a verb defined as the croaking sound made by frogs."}, "gen_args_2": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? No, The word quark has been listed in dictionaries as a verb defined as the croaking sound made by frogs."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-193.0", "False"]], "doc_hash": "40d03496bb033a621b99a74113f8291b1faa59cc4766985d841e270732f4d6c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 2457, "doc": {"premise": "Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians.", "hypothesis": "The Indians disliked Sir William Johnson.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Yes, The Indians disliked Sir William Johnson."}, "gen_args_1": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Also, The Indians disliked Sir William Johnson."}, "gen_args_2": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? No, The Indians disliked Sir William Johnson."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-145.0", "False"]], "doc_hash": "df0d774141bdbc4af5e6b9aab98740ecd9faf02cf0fb78fdaa1c9e028d79d130", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 2465, "doc": {"premise": "Dr. Richards never stops astonishing us.", "hypothesis": "We've never heard of Dr. Richards or his ideas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Yes, We've never heard of Dr. Richards or his ideas."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Also, We've never heard of Dr. Richards or his ideas."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? No, We've never heard of Dr. Richards or his ideas."}}, "resps": [[["-106.5", "False"]], [["-109.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-109.5", "False"], ["-104.5", "False"]], "doc_hash": "0b771271f625bce7967e366f6c6885735db8287510070a0b834572337ce3b67d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2473, "doc": {"premise": "My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes.", "hypothesis": "My sister used to date a fan of the University of Iowa sports teams, which are called the Hawkeyes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Yes, My sister used to date a fan of the University of Iowa sports teams, which are called the Hawkeyes."}, "gen_args_1": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Also, My sister used to date a fan of the University of Iowa sports teams, which are called the Hawkeyes."}, "gen_args_2": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? No, My sister used to date a fan of the University of Iowa sports teams, which are called the Hawkeyes."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-150.0", "False"]], "doc_hash": "c10f347cdae1986f72622f1751ee8c31baf1c29ddcb1468d888e9ebef31ff6c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2481, "doc": {"premise": "A month has passed since the election and still Republicans and Democrats are high-fiving.", "hypothesis": "It has been a month since the election.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Yes, It has been a month since the election."}, "gen_args_1": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Also, It has been a month since the election."}, "gen_args_2": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? No, It has been a month since the election."}}, "resps": [[["-102.5", "False"]], [["-105.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-105.0", "False"], ["-104.5", "False"]], "doc_hash": "e7f7e81632d6464a4fcafecceddca46247f05cab247c036451c70862108759d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.82140902 0.06742536 0.11116562]"]}
{"doc_id": 2489, "doc": {"premise": "While statement is better, answer gives the mental picture of completion.", "hypothesis": "Statement is preferable.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Yes, Statement is preferable."}, "gen_args_1": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Also, Statement is preferable."}, "gen_args_2": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? No, Statement is preferable."}}, "resps": [[["-124.5", "False"]], [["-126.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-126.0", "False"], ["-125.0", "False"]], "doc_hash": "7de28662d6e3b0bdd33e8c0a5affab26be684ac7019140c959907606ce834601", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.54654939 0.12195165 0.33149896]"]}
{"doc_id": 2, "doc": {"premise": "And he said, Mama, I'm home.", "hypothesis": "He told his mom he had gotten home.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Yes, He told his mom he had gotten home."}, "gen_args_1": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? Also, He told his mom he had gotten home."}, "gen_args_2": {"arg_0": "", "arg_1": " And he said, Mama, I'm home., right? No, He told his mom he had gotten home."}}, "resps": [[["-93.0", "False"]], [["-95.5", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-93.0", "False"], ["-95.5", "False"], ["-93.5", "False"]], "doc_hash": "e3d0d41e238e835e92d0f0bc2978d63cdeef141d711a524338d36d68c4c671ae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 10, "doc": {"premise": "And I was like OK, and that was it!", "hypothesis": "I said no and it dragged on and on.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Yes, I said no and it dragged on and on."}, "gen_args_1": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Also, I said no and it dragged on and on."}, "gen_args_2": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? No, I said no and it dragged on and on."}}, "resps": [[["-94.0", "False"]], [["-98.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-94.0", "False"], ["-98.0", "False"], ["-89.0", "False"]], "doc_hash": "6cc0ecdc035040a7c4060a88ad75af40424358ff45a383ee2eb88d172e5d17b6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 18, "doc": {"premise": "And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white.", "hypothesis": "Granny's Sister was white and moved to Texas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Yes, Granny's Sister was white and moved to Texas."}, "gen_args_1": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Also, Granny's Sister was white and moved to Texas."}, "gen_args_2": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? No, Granny's Sister was white and moved to Texas."}}, "resps": [[["-171.0", "False"]], [["-174.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-174.0", "False"], ["-171.0", "False"]], "doc_hash": "6f55736638b51e25f651c70ec19186b125593e6bfd5bf50839e70d519f997d5e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 26, "doc": {"premise": "But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property.", "hypothesis": "His dad owned a lot of property.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Yes, His dad owned a lot of property."}, "gen_args_1": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? Also, His dad owned a lot of property."}, "gen_args_2": {"arg_0": "", "arg_1": " But he was, you know, in a lot of ways, just like a plantation owner's son because he was the son of this guy who owned a lot of property., right? No, His dad owned a lot of property."}}, "resps": [[["-134.0", "False"]], [["-138.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-138.0", "False"], ["-136.0", "False"]], "doc_hash": "e389ac69a3e40bc81448bec3b04dfdd1a1052ad204cdcb75aec532ec20eb9467", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 34, "doc": {"premise": "And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories.", "hypothesis": "I hated him because he was so arrogant.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Yes, I hated him because he was so arrogant."}, "gen_args_1": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Also, I hated him because he was so arrogant."}, "gen_args_2": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? No, I hated him because he was so arrogant."}}, "resps": [[["-191.0", "False"]], [["-191.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-191.0", "False"], ["-188.0", "False"]], "doc_hash": "f100d1940183b4d8d44a134eab19a45f86916f2eea3d36351f439cbc57e04384", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 42, "doc": {"premise": "Maybe she told everyone else and I wasn't paying attention at that particular time.", "hypothesis": "I didn't hear her when she told everyone else.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Yes, I didn't hear her when she told everyone else."}, "gen_args_1": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Also, I didn't hear her when she told everyone else."}, "gen_args_2": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? No, I didn't hear her when she told everyone else."}}, "resps": [[["-103.0", "False"]], [["-106.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-103.0", "False"], ["-106.0", "False"], ["-100.5", "False"]], "doc_hash": "410fece47339e2e03c722d0260b6d7e6f5233267e7e8f5d35b6577afe00d6d84", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 50, "doc": {"premise": "I need you to do something for me.", "hypothesis": "There is something I need done.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I need you to do something for me., right? Yes, There is something I need done."}, "gen_args_1": {"arg_0": "", "arg_1": " I need you to do something for me., right? Also, There is something I need done."}, "gen_args_2": {"arg_0": "", "arg_1": " I need you to do something for me., right? No, There is something I need done."}}, "resps": [[["-69.0", "False"]], [["-76.0", "False"]], [["-71.5", "False"]]], "filtered_resps": [["-69.0", "False"], ["-76.0", "False"], ["-71.5", "False"]], "doc_hash": "cbae744088bbd9d0e30def40fb91db9527e232449d48a0ff88bf978794d4a63a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.23363694e-01 8.41998700e-04 7.57943075e-02]"]}
{"doc_id": 58, "doc": {"premise": "She was still in there.", "hypothesis": "She was still in the vicinity.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was still in there., right? Yes, She was still in the vicinity."}, "gen_args_1": {"arg_0": "", "arg_1": " She was still in there., right? Also, She was still in the vicinity."}, "gen_args_2": {"arg_0": "", "arg_1": " She was still in there., right? No, She was still in the vicinity."}}, "resps": [[["-71.0", "False"]], [["-74.0", "False"]], [["-72.0", "False"]]], "filtered_resps": [["-71.0", "False"], ["-74.0", "False"], ["-72.0", "False"]], "doc_hash": "b34a409d6ff3281dce6da6247279fd04bdeba9c0fe3999c3c205ed42d6c3da19", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 66, "doc": {"premise": "He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that.", "hypothesis": "He was too afraid to burn anything so he just flushed it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Yes, He was too afraid to burn anything so he just flushed it."}, "gen_args_1": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Also, He was too afraid to burn anything so he just flushed it."}, "gen_args_2": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? No, He was too afraid to burn anything so he just flushed it."}}, "resps": [[["-209.0", "False"]], [["-212.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-212.0", "False"], ["-209.0", "False"]], "doc_hash": "8e939b3046646cf25bbb93321ea6f5d458afee429aa8c3ebd3725ad8596a16c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 74, "doc": {"premise": "That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities.", "hypothesis": "My favorite job was in Special Activities.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Yes, My favorite job was in Special Activities."}, "gen_args_1": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? Also, My favorite job was in Special Activities."}, "gen_args_2": {"arg_0": "", "arg_1": " That's kind of unique in that I, uh, spent, uh, about 16 years of my career in Special Activities., right? No, My favorite job was in Special Activities."}}, "resps": [[["-150.0", "False"]], [["-152.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-152.0", "False"], ["-151.0", "False"]], "doc_hash": "cfbf49b85edcee05fa6cae5daea6709c8d724e1a084420a2525bb2a34fe2bbfe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 82, "doc": {"premise": "You don't have to stay there.", "hypothesis": "You can leave.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You don't have to stay there., right? Yes, You can leave."}, "gen_args_1": {"arg_0": "", "arg_1": " You don't have to stay there., right? Also, You can leave."}, "gen_args_2": {"arg_0": "", "arg_1": " You don't have to stay there., right? No, You can leave."}}, "resps": [[["-60.25", "False"]], [["-68.5", "False"]], [["-60.75", "False"]]], "filtered_resps": [["-60.25", "False"], ["-68.5", "False"], ["-60.75", "False"]], "doc_hash": "bbeecb0db4b6d3e8a829bc090bc6e925055dfd8c92730737e736cea875134559", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22358122e-01 1.62596385e-04 3.77479282e-01]"]}
{"doc_id": 90, "doc": {"premise": "So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May.", "hypothesis": "General May and the pilots had a great time visiting the office.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Yes, General May and the pilots had a great time visiting the office."}, "gen_args_1": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Also, General May and the pilots had a great time visiting the office."}, "gen_args_2": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? No, General May and the pilots had a great time visiting the office."}}, "resps": [[["-219.0", "False"]], [["-221.0", "False"]], [["-222.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-221.0", "False"], ["-222.0", "False"]], "doc_hash": "efb8f73c3510b63ecf02927a9488ea3eb8a0b6f6775462fd554eaaa5940c4ed5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 98, "doc": {"premise": "And then once you get everything entered you can go on from there.", "hypothesis": "You should stop right now.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Yes, You should stop right now."}, "gen_args_1": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? Also, You should stop right now."}, "gen_args_2": {"arg_0": "", "arg_1": " And then once you get everything entered you can go on from there., right? No, You should stop right now."}}, "resps": [[["-105.5", "False"]], [["-107.5", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-105.5", "False"], ["-107.5", "False"], ["-102.0", "False"]], "doc_hash": "e2ac873cb691909c296506c99063b6034930f266cd2067c54ac4ddcd6f37479d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02919641 0.0039513  0.96685229]"]}
{"doc_id": 106, "doc": {"premise": "The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake.", "hypothesis": "We had to take the jets apart and then put them back together.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Yes, We had to take the jets apart and then put them back together."}, "gen_args_1": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Also, We had to take the jets apart and then put them back together."}, "gen_args_2": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? No, We had to take the jets apart and then put them back together."}}, "resps": [[["-169.0", "False"]], [["-173.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-173.0", "False"], ["-170.0", "False"]], "doc_hash": "04869809b8eec520b19e23e43880a5b15a81df21f66b30434ca7c7e592d98e3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 114, "doc": {"premise": "He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed.", "hypothesis": "I was worried because I didn't know what time.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Yes, I was worried because I didn't know what time."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Also, I was worried because I didn't know what time."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? No, I was worried because I didn't know what time."}}, "resps": [[["-169.0", "False"]], [["-170.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-170.0", "False"], ["-168.0", "False"]], "doc_hash": "0b4497932cc249728b16423f44f4844a9c6898c8930c6fd3ee1612a471c9de0d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 122, "doc": {"premise": "So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing.", "hypothesis": "I wanted to ask Ramona a question.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Yes, I wanted to ask Ramona a question."}, "gen_args_1": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? Also, I wanted to ask Ramona a question."}, "gen_args_2": {"arg_0": "", "arg_1": " So anyhow, I call Ramona back because I had a question about, I was like, All right, let me hurry up on with it, and I had a question about something I was doing., right? No, I wanted to ask Ramona a question."}}, "resps": [[["-174.0", "False"]], [["-177.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-177.0", "False"], ["-174.0", "False"]], "doc_hash": "ae777aeca8773b5a95eb5d7392c7932334ce6e26d5943a4b0f2a5515fa437348", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 130, "doc": {"premise": "The CIA unloaded the, the film, taken them to the United Nations the next day.", "hypothesis": "The CIA kept the film for themselves.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Yes, The CIA kept the film for themselves."}, "gen_args_1": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Also, The CIA kept the film for themselves."}, "gen_args_2": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? No, The CIA kept the film for themselves."}}, "resps": [[["-145.0", "False"]], [["-148.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-148.0", "False"], ["-140.0", "False"]], "doc_hash": "34203b2b29ff3b7fe41437257fbe386e5e2eee0a99c22d7e297de9b4ae627d4d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 138, "doc": {"premise": "Um, and so they just left town, and she, she never did see her sister again, never saw her sister again.", "hypothesis": "SHe moved to Texas and never saw her sister again.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Yes, SHe moved to Texas and never saw her sister again."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Also, SHe moved to Texas and never saw her sister again."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? No, SHe moved to Texas and never saw her sister again."}}, "resps": [[["-139.0", "False"]], [["-146.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-146.0", "False"], ["-141.0", "False"]], "doc_hash": "82e92a6c42de0bc204993accac863091f97331dcf78d943d8aa949e891d1fb0b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 146, "doc": {"premise": "The story I shall talk about today is about my father and the culture diversities he had when he moved to America.", "hypothesis": "I'll tell you what happened when my dad moved here from Mexico.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Yes, I'll tell you what happened when my dad moved here from Mexico."}, "gen_args_1": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? Also, I'll tell you what happened when my dad moved here from Mexico."}, "gen_args_2": {"arg_0": "", "arg_1": " The story I shall talk about today is about my father and the culture diversities he had when he moved to America., right? No, I'll tell you what happened when my dad moved here from Mexico."}}, "resps": [[["-142.0", "False"]], [["-150.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-150.0", "False"], ["-145.0", "False"]], "doc_hash": "af3fa5ce8fd2fe9bc78bb1365123a22c0192ec046d1d6d9b84b5ce00b148340f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 154, "doc": {"premise": "And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street.", "hypothesis": "They lived on Broad Street.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Yes, They lived on Broad Street."}, "gen_args_1": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Also, They lived on Broad Street."}, "gen_args_2": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? No, They lived on Broad Street."}}, "resps": [[["-122.0", "False"]], [["-129.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-122.0", "False"], ["-129.0", "False"], ["-124.0", "False"]], "doc_hash": "1f61a1006595dbfbf5be901acf1e21de877796f992ddec32d61fdd7741dc9fe3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 162, "doc": {"premise": "And our father always told us not to say they are animals.", "hypothesis": "Our dad said not to call them animals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Yes, Our dad said not to call them animals."}, "gen_args_1": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Also, Our dad said not to call them animals."}, "gen_args_2": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? No, Our dad said not to call them animals."}}, "resps": [[["-101.0", "False"]], [["-108.0", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-101.0", "False"], ["-108.0", "False"], ["-101.5", "False"]], "doc_hash": "8c61394ecf0f17ae472b99de7d3c0d44cce6de8c6304b1002f19c82e913acbf1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22106218e-01 5.67287441e-04 3.77326495e-01]"]}
{"doc_id": 170, "doc": {"premise": "Even though I don't see how he could have expected me to have it done.", "hypothesis": "I know he knew I wouldn't finish this tonight.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Yes, I know he knew I wouldn't finish this tonight."}, "gen_args_1": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? Also, I know he knew I wouldn't finish this tonight."}, "gen_args_2": {"arg_0": "", "arg_1": " Even though I don't see how he could have expected me to have it done., right? No, I know he knew I wouldn't finish this tonight."}}, "resps": [[["-118.5", "False"]], [["-121.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-118.5", "False"], ["-121.5", "False"], ["-115.5", "False"]], "doc_hash": "3303d809d4012fe35abfdc050277ee240bf6b4bdf1f9aeb6338837164254ff6b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 178, "doc": {"premise": "Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody.", "hypothesis": "We told everyone all about it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Yes, We told everyone all about it."}, "gen_args_1": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Also, We told everyone all about it."}, "gen_args_2": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? No, We told everyone all about it."}}, "resps": [[["-186.0", "False"]], [["-192.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-192.0", "False"], ["-183.0", "False"]], "doc_hash": "01ce59ec855c055631812c32853829a170a72fddb1cc49ca256547bc5cfdecc0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 186, "doc": {"premise": "They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them.", "hypothesis": "He never visited his family.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Yes, He never visited his family."}, "gen_args_1": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Also, He never visited his family."}, "gen_args_2": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? No, He never visited his family."}}, "resps": [[["-185.0", "False"]], [["-185.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-185.0", "False"], ["-183.0", "False"]], "doc_hash": "e06a54385afa844fdaea0a7e6f13510e2422e3e1ddff6c3fbf824e4ba132aa9c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 194, "doc": {"premise": "We didn't know what a U2 was and nobody knew anything about a U2.", "hypothesis": "We knew all about the U2!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Yes, We knew all about the U2!"}, "gen_args_1": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? Also, We knew all about the U2!"}, "gen_args_2": {"arg_0": "", "arg_1": " We didn't know what a U2 was and nobody knew anything about a U2., right? No, We knew all about the U2!"}}, "resps": [[["-104.0", "False"]], [["-109.5", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-109.5", "False"], ["-100.0", "False"]], "doc_hash": "66ae8417bce4f354089c9b9e52cfc9cd53ebb2999df83ccff2eaad8fedd633a2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79848880e-02 7.35001265e-05 9.81941612e-01]"]}
{"doc_id": 202, "doc": {"premise": "Anyway it got up to, we had about uh, ah, I don't remember the numbers.", "hypothesis": "I don't remember how many workers we had.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Yes, I don't remember how many workers we had."}, "gen_args_1": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Also, I don't remember how many workers we had."}, "gen_args_2": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? No, I don't remember how many workers we had."}}, "resps": [[["-127.0", "False"]], [["-126.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-126.5", "False"], ["-122.0", "False"]], "doc_hash": "c3242478c645335aab883026a10d4f3ab1b50a9cb508b48ef86cbccb590f3c14", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0066198  0.01091421 0.98246599]"]}
{"doc_id": 210, "doc": {"premise": "And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off.", "hypothesis": "If there is a surge of electricity, it's very dangerous to anyone around.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Yes, If there is a surge of electricity, it's very dangerous to anyone around."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Also, If there is a surge of electricity, it's very dangerous to anyone around."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? No, If there is a surge of electricity, it's very dangerous to anyone around."}}, "resps": [[["-197.0", "False"]], [["-200.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-200.0", "False"], ["-199.0", "False"]], "doc_hash": "738866618e2f883e4464e6069b8583019e97a69740ec75e7c52e806a390e56fc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 218, "doc": {"premise": "I'll call you back in about an hour, he says.", "hypothesis": "He said they were done speaking.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Yes, He said they were done speaking."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? Also, He said they were done speaking."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll call you back in about an hour, he says., right? No, He said they were done speaking."}}, "resps": [[["-96.0", "False"]], [["-97.5", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-96.0", "False"], ["-97.5", "False"], ["-92.5", "False"]], "doc_hash": "4517d6060b4ff05288127862faa1aab2dc6474600487269550c4733674633ecf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02912176 0.00649794 0.9643803 ]"]}
{"doc_id": 226, "doc": {"premise": "Well anyway, I went back to my, my desk.", "hypothesis": "I returned to my seat.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Yes, I returned to my seat."}, "gen_args_1": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Also, I returned to my seat."}, "gen_args_2": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? No, I returned to my seat."}}, "resps": [[["-90.0", "False"]], [["-94.0", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-90.0", "False"], ["-94.0", "False"], ["-90.0", "False"]], "doc_hash": "db9d2759b1262c6d17c91ef3c22865e2b89f8f8e32f2d8ffe027906ad2a70328", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 234, "doc": {"premise": "So it took me like, an hour to two hours just to find what I needed.", "hypothesis": "I found it in just a few seconds.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Yes, I found it in just a few seconds."}, "gen_args_1": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Also, I found it in just a few seconds."}, "gen_args_2": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? No, I found it in just a few seconds."}}, "resps": [[["-103.0", "False"]], [["-108.5", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-103.0", "False"], ["-108.5", "False"], ["-98.0", "False"]], "doc_hash": "bbd5f4e8a719995db6c942d6f182b6c75f09ef1771b2d895f3a96a51d08ddf30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69266787e-03 2.73514039e-05 9.93279981e-01]"]}
{"doc_id": 242, "doc": {"premise": "And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area.", "hypothesis": "They went to the street with the most restaurants and bars.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Yes, They went to the street with the most restaurants and bars."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? Also, They went to the street with the most restaurants and bars."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they moved downtown and, there was, uh, and it's still like this in Augusta, this big street downtown called Broad Street, and it really was just this broad street in a downtown area., right? No, They went to the street with the most restaurants and bars."}}, "resps": [[["-218.0", "False"]], [["-222.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-218.0", "False"], ["-222.0", "False"], ["-217.0", "False"]], "doc_hash": "092fb0fcfa9a227ab3ae8b3e8b458379f200373979e06c6b3d770bfd3f8b8c07", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 250, "doc": {"premise": "oh it was Snake River oh Snake River with a lot of snakes in it", "hypothesis": "Snake River has lots of snapping turtles.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Yes, Snake River has lots of snapping turtles."}, "gen_args_1": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Also, Snake River has lots of snapping turtles."}, "gen_args_2": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? No, Snake River has lots of snapping turtles."}}, "resps": [[["-104.0", "False"]], [["-111.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-111.0", "False"], ["-106.0", "False"]], "doc_hash": "74412139932d9a00bac4e88b6ce3348420d3f5094f52ee884d432ea70bc8f103", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 258, "doc": {"premise": "and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us", "hypothesis": "I just know it will be so boring and not worth changing those that represent us so we should not even try to change.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Yes, I just know it will be so boring and not worth changing those that represent us so we should not even try to change."}, "gen_args_1": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Also, I just know it will be so boring and not worth changing those that represent us so we should not even try to change."}, "gen_args_2": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? No, I just know it will be so boring and not worth changing those that represent us so we should not even try to change."}}, "resps": [[["-197.0", "False"]], [["-203.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-203.0", "False"], ["-198.0", "False"]], "doc_hash": "b10cd89a93bb1721dc0f387a10523f35cd4f593de7d104ff0e0146cab9f25e87", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 266, "doc": {"premise": "and it can go on for ten twenty years i i think this is a little ridiculous", "hypothesis": "It only lasts a week.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Yes, It only lasts a week."}, "gen_args_1": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? Also, It only lasts a week."}, "gen_args_2": {"arg_0": "", "arg_1": " and it can go on for ten twenty years i i think this is a little ridiculous, right? No, It only lasts a week."}}, "resps": [[["-115.5", "False"]], [["-120.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-115.5", "False"], ["-120.0", "False"], ["-115.0", "False"]], "doc_hash": "1fbb563bf525fd0a1297f5f75a133f0d0d454b9068a946af189b04964a298195", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 274, "doc": {"premise": "besides i probably would look at something uh maybe a a V six", "hypothesis": "I think a V6 is the best way to go.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Yes, I think a V6 is the best way to go."}, "gen_args_1": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Also, I think a V6 is the best way to go."}, "gen_args_2": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? No, I think a V6 is the best way to go."}}, "resps": [[["-121.5", "False"]], [["-131.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-121.5", "False"], ["-131.0", "False"], ["-124.5", "False"]], "doc_hash": "6a7e259a933d4a106dc771e5fd18e6a56b499b3201cac367fd06bba54e064212", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.52506211e-01 7.12968329e-05 4.74224919e-02]"]}
{"doc_id": 282, "doc": {"premise": "but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants", "hypothesis": "I don't dress up when I work at home.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Yes, I don't dress up when I work at home."}, "gen_args_1": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Also, I don't dress up when I work at home."}, "gen_args_2": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? No, I don't dress up when I work at home."}}, "resps": [[["-194.0", "False"]], [["-197.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-197.0", "False"], ["-191.0", "False"]], "doc_hash": "587bd1486ed7e9d1bb350e2ac60f2d6598e7e779cb8694cb54b16a3b4d183a9c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 290, "doc": {"premise": "yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed", "hypothesis": "It wouldn't bother me if the corporation was financed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Yes, It wouldn't bother me if the corporation was financed."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? Also, It wouldn't bother me if the corporation was financed."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah yeah i you know i i wouldn't even mind so much if they had a um corporation that is financed, right? No, It wouldn't bother me if the corporation was financed."}}, "resps": [[["-146.0", "False"]], [["-153.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-153.0", "False"], ["-145.0", "False"]], "doc_hash": "11785c007f670c29a879a8292fae6ce2362ce1d97b311401f127233bad9f5890", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.68875482e-01 2.45182703e-04 7.30879336e-01]"]}
{"doc_id": 298, "doc": {"premise": "but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of", "hypothesis": "I have ate unusual animals before such as turtle, raccoon and possum.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Yes, I have ate unusual animals before such as turtle, raccoon and possum."}, "gen_args_1": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Also, I have ate unusual animals before such as turtle, raccoon and possum."}, "gen_args_2": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? No, I have ate unusual animals before such as turtle, raccoon and possum."}}, "resps": [[["-140.0", "False"]], [["-144.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-144.0", "False"], ["-143.0", "False"]], "doc_hash": "00a6d4346bb89906db9a8b6defc64e55f6468f839432c12337ba0f6defa324c1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 306, "doc": {"premise": "yeah it was pretty reasonable", "hypothesis": "No, I think that is insane and highly irrational.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Yes, No, I think that is insane and highly irrational."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Also, No, I think that is insane and highly irrational."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? No, No, I think that is insane and highly irrational."}}, "resps": [[["-93.5", "False"]], [["-93.0", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-93.0", "False"], ["-88.5", "False"]], "doc_hash": "5a0d460bd119d0c904bf91d70131e3d2f7b6ddf1ab003a0152d652617a7ebd4c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0066198  0.01091421 0.98246599]"]}
{"doc_id": 314, "doc": {"premise": "exactly and i was very flattered until she told me she the company she was with", "hypothesis": "She made me feel good until I found out who she was with.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Yes, She made me feel good until I found out who she was with."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? Also, She made me feel good until I found out who she was with."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly and i was very flattered until she told me she the company she was with, right? No, She made me feel good until I found out who she was with."}}, "resps": [[["-136.0", "False"]], [["-140.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-140.0", "False"], ["-137.0", "False"]], "doc_hash": "d06cc9b0d584818b63653ab64de376e7498793bb826fd31a08c75da2087ec5f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 322, "doc": {"premise": "i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think", "hypothesis": "I don't think gun control would upset people in Texas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Yes, I don't think gun control would upset people in Texas."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Also, I don't think gun control would upset people in Texas."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? No, I don't think gun control would upset people in Texas."}}, "resps": [[["-183.0", "False"]], [["-189.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-189.0", "False"], ["-177.0", "False"]], "doc_hash": "c4e318193f8887f52566af0cf9fdd35595a70de8980e8e839213b1f4b29a29ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47260800e-03 6.12898247e-06 9.97521263e-01]"]}
{"doc_id": 330, "doc": {"premise": "yeah they had a whole bunch of things that that sort of broke at the same time", "hypothesis": "Most of their stuff broke at the same time.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Yes, Most of their stuff broke at the same time."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Also, Most of their stuff broke at the same time."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? No, Most of their stuff broke at the same time."}}, "resps": [[["-103.0", "False"]], [["-108.0", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-103.0", "False"], ["-108.0", "False"], ["-105.0", "False"]], "doc_hash": "983cf2ecde218eb1b1488a168722c356076978c16c56a54141b25f9fc50890b8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 338, "doc": {"premise": "uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news", "hypothesis": "What is your opinion on how the papers treat the local news?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Yes, What is your opinion on how the papers treat the local news?"}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? Also, What is your opinion on how the papers treat the local news?"}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh how do you feel the newspapers there in Colorado Springs treats local interest news, right? No, What is your opinion on how the papers treat the local news?"}}, "resps": [[["-149.0", "False"]], [["-153.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-153.0", "False"], ["-150.0", "False"]], "doc_hash": "67efc205aa45e7fac926ca28465c9e35feca81ea785f2183018260193087d145", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 346, "doc": {"premise": "um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news", "hypothesis": "I guess you don't ever watch network news.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Yes, I guess you don't ever watch network news."}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Also, I guess you don't ever watch network news."}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? No, I guess you don't ever watch network news."}}, "resps": [[["-182.0", "False"]], [["-186.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-186.0", "False"], ["-180.0", "False"]], "doc_hash": "95f114478ff489c7ed61215994424c757601b20492c939f2a2574a758982ffab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 354, "doc": {"premise": "but i know that in some i know in a lot of rural areas they're not that good", "hypothesis": "They are not very good in rural areas.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Yes, They are not very good in rural areas."}, "gen_args_1": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Also, They are not very good in rural areas."}, "gen_args_2": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? No, They are not very good in rural areas."}}, "resps": [[["-111.0", "False"]], [["-122.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-111.0", "False"], ["-122.5", "False"], ["-113.5", "False"]], "doc_hash": "f7490ac468a0111d72c3599a98652e2f0822e7c886261781fb5196321e4418b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.24133169e-01 9.36155550e-06 7.58574699e-02]"]}
{"doc_id": 362, "doc": {"premise": "is it twenty percent interest", "hypothesis": "There is no interest.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Yes, There is no interest."}, "gen_args_1": {"arg_0": "", "arg_1": " is it twenty percent interest, right? Also, There is no interest."}, "gen_args_2": {"arg_0": "", "arg_1": " is it twenty percent interest, right? No, There is no interest."}}, "resps": [[["-68.5", "False"]], [["-74.0", "False"]], [["-66.0", "False"]]], "filtered_resps": [["-68.5", "False"], ["-74.0", "False"], ["-66.0", "False"]], "doc_hash": "c45adb121a563b810dfc0e1b7f482cd7e5990e4fadcf3c0f2d3c6c5df8d7df35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58346701e-02 3.09918964e-04 9.23855411e-01]"]}
{"doc_id": 370, "doc": {"premise": "i don't know  okay well it was good talking to you and have a good evening", "hypothesis": "I think I know why I'm not well but I do not want to tell you.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Yes, I think I know why I'm not well but I do not want to tell you."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Also, I think I know why I'm not well but I do not want to tell you."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? No, I think I know why I'm not well but I do not want to tell you."}}, "resps": [[["-128.0", "False"]], [["-129.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-129.0", "False"], ["-129.0", "False"]], "doc_hash": "c279a5d2508710d589e3638a2264f22b95849f29a2d58db28dce50ef4d94a198", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 378, "doc": {"premise": "it's only getting worse exponentially it seems um", "hypothesis": "It is slowly getting worse.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Yes, It is slowly getting worse."}, "gen_args_1": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Also, It is slowly getting worse."}, "gen_args_2": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? No, It is slowly getting worse."}}, "resps": [[["-92.5", "False"]], [["-103.0", "False"]], [["-94.0", "False"]]], "filtered_resps": [["-92.5", "False"], ["-103.0", "False"], ["-94.0", "False"]], "doc_hash": "df0804935be696ba5ad394c917078cd20afc3401374e0f180bdb91227558ac7a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.17556070e-01 2.25125913e-05 1.82421417e-01]"]}
{"doc_id": 386, "doc": {"premise": "tag them or anything you you do it all yourself they tell you what to do but you do it all yourself", "hypothesis": "They give decent instructions on how to go about it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Yes, They give decent instructions on how to go about it."}, "gen_args_1": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? Also, They give decent instructions on how to go about it."}, "gen_args_2": {"arg_0": "", "arg_1": " tag them or anything you you do it all yourself they tell you what to do but you do it all yourself, right? No, They give decent instructions on how to go about it."}}, "resps": [[["-141.0", "False"]], [["-143.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-143.0", "False"], ["-141.0", "False"]], "doc_hash": "d2db7c106381b2e2bba7a7935f61af4698bf5b3f25bc73b33889196031e72862", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 394, "doc": {"premise": "uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh", "hypothesis": "I would choose I'll Fly Away.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Yes, I would choose I'll Fly Away."}, "gen_args_1": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Also, I would choose I'll Fly Away."}, "gen_args_2": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? No, I would choose I'll Fly Away."}}, "resps": [[["-165.0", "False"]], [["-168.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-168.0", "False"], ["-164.0", "False"]], "doc_hash": "8753763cd633ddf00f8d91f4e031babe383fa38da86617c036602abf0c8ef96c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 402, "doc": {"premise": "yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas", "hypothesis": "The are more economical because they are really good on gas.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Yes, The are more economical because they are really good on gas."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Also, The are more economical because they are really good on gas."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? No, The are more economical because they are really good on gas."}}, "resps": [[["-179.0", "False"]], [["-184.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-184.0", "False"], ["-180.0", "False"]], "doc_hash": "f72e14a6ae7911ddc4d4bd9ae4640bedf28283ef06befeae2f9e648d76fd4f55", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 410, "doc": {"premise": "but they did something a little different with them", "hypothesis": "They did things with them a little differently.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Yes, They did things with them a little differently."}, "gen_args_1": {"arg_0": "", "arg_1": " but they did something a little different with them, right? Also, They did things with them a little differently."}, "gen_args_2": {"arg_0": "", "arg_1": " but they did something a little different with them, right? No, They did things with them a little differently."}}, "resps": [[["-78.5", "False"]], [["-82.0", "False"]], [["-80.0", "False"]]], "filtered_resps": [["-78.5", "False"], ["-82.0", "False"], ["-80.0", "False"]], "doc_hash": "7411d0dd4b4b8e87bbb467bd5ebc4c8a80511f69d3fbca028614c3d0c6c538d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 418, "doc": {"premise": "huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women", "hypothesis": "I went to a seminar that was done by satellite.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Yes, I went to a seminar that was done by satellite."}, "gen_args_1": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Also, I went to a seminar that was done by satellite."}, "gen_args_2": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? No, I went to a seminar that was done by satellite."}}, "resps": [[["-194.0", "False"]], [["-201.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-201.0", "False"], ["-195.0", "False"]], "doc_hash": "548d5b92d86bfd03f90dea8e3350791fa5a44729f43aa3c369f38adfb42fef37", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 426, "doc": {"premise": "with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns", "hypothesis": "It was for Father's Day and Ellen always took care of it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Yes, It was for Father's Day and Ellen always took care of it."}, "gen_args_1": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Also, It was for Father's Day and Ellen always took care of it."}, "gen_args_2": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? No, It was for Father's Day and Ellen always took care of it."}}, "resps": [[["-195.0", "False"]], [["-198.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-198.0", "False"], ["-195.0", "False"]], "doc_hash": "c74310b76ca8d0f2d985ef272c84012af4374b589885ad1706f34fbca6c42562", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 434, "doc": {"premise": "yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families", "hypothesis": "Some people can't care for other people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Yes, Some people can't care for other people."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? Also, Some people can't care for other people."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they weren't course they weren't talking about uh where you know you're absolutely unable to care for them but it was it you know they would come from large extended families, right? No, Some people can't care for other people."}}, "resps": [[["-200.0", "False"]], [["-204.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-204.0", "False"], ["-201.0", "False"]], "doc_hash": "8d3c8131e865e18766a475c9d85a993980021b99ab13fd2cf03db61bb6fb7042", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 442, "doc": {"premise": "it's just that since my money is tight right now i don't even give myself a tempting", "hypothesis": "I have a ton of money right now so I want to go shopping.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Yes, I have a ton of money right now so I want to go shopping."}, "gen_args_1": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Also, I have a ton of money right now so I want to go shopping."}, "gen_args_2": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? No, I have a ton of money right now so I want to go shopping."}}, "resps": [[["-137.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "3d53afa3e728030cbbc39eaa7f2a1256a10e728138bf15920dce6e959d6b1700", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 450, "doc": {"premise": "Texas only had fifty five thousand when i was there", "hypothesis": "I have never been to Texas before.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Yes, I have never been to Texas before."}, "gen_args_1": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Also, I have never been to Texas before."}, "gen_args_2": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? No, I have never been to Texas before."}}, "resps": [[["-94.5", "False"]], [["-94.0", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-94.5", "False"], ["-94.0", "False"], ["-92.0", "False"]], "doc_hash": "b8b411444f880fe7fd26af58ebc4a4230c4d85bf87288512df5e814284bf2a2d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06742536 0.11116562 0.82140902]"]}
{"doc_id": 458, "doc": {"premise": "excuse me we pay for any you know the child care but we don't pay as much as they do off base", "hypothesis": "Childcare is free off base.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Yes, Childcare is free off base."}, "gen_args_1": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? Also, Childcare is free off base."}, "gen_args_2": {"arg_0": "", "arg_1": " excuse me we pay for any you know the child care but we don't pay as much as they do off base, right? No, Childcare is free off base."}}, "resps": [[["-139.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "f23e7611ed3fbb0a99e42381963aae4bcf9c31d6599228b3780a672d313336c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 466, "doc": {"premise": "yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home", "hypothesis": "You can take a handgun anywhere you want in Texas!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Yes, You can take a handgun anywhere you want in Texas!"}, "gen_args_1": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Also, You can take a handgun anywhere you want in Texas!"}, "gen_args_2": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? No, You can take a handgun anywhere you want in Texas!"}}, "resps": [[["-138.0", "False"]], [["-145.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-145.0", "False"], ["-139.0", "False"]], "doc_hash": "88a5beeb671cff779b2f7fa8099cfeaa853a1ecdface0345be9ea715849e3b3d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 474, "doc": {"premise": "and uh so i really enjoyed that", "hypothesis": "I truly liked that.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Yes, I truly liked that."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Also, I truly liked that."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? No, I truly liked that."}}, "resps": [[["-73.0", "False"]], [["-80.0", "False"]], [["-74.5", "False"]]], "filtered_resps": [["-73.0", "False"], ["-80.0", "False"], ["-74.5", "False"]], "doc_hash": "efaf0e99c875f0b17c1511a144808e4ec807620c5196a53f7f6da0bae5be9183", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.16965403e-01 7.44976017e-04 1.82289621e-01]"]}
{"doc_id": 482, "doc": {"premise": "and they just pretty much know how much they have coming in you know and they just make sure they don't buy over", "hypothesis": "They know that they are making $2903 a month.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Yes, They know that they are making $2903 a month."}, "gen_args_1": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? Also, They know that they are making $2903 a month."}, "gen_args_2": {"arg_0": "", "arg_1": " and they just pretty much know how much they have coming in you know and they just make sure they don't buy over, right? No, They know that they are making $2903 a month."}}, "resps": [[["-152.0", "False"]], [["-155.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-155.0", "False"], ["-152.0", "False"]], "doc_hash": "7993e3aed15a146ba343490ff2c32043edd29a8c9578272de925e9f67acd7cd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 490, "doc": {"premise": "yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be", "hypothesis": "I think most people who die come back as animals.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Yes, I think most people who die come back as animals."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Also, I think most people who die come back as animals."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? No, I think most people who die come back as animals."}}, "resps": [[["-142.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "39074cbf4f820d6605b3e66e237cfe06863c1e4c1e76599427832f5ed53dae52", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 498, "doc": {"premise": "Espinosa collected many romances from Californios in the 1920s.", "hypothesis": "Espinosa resold these romances in France at a healthy profit.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Yes, Espinosa resold these romances in France at a healthy profit."}, "gen_args_1": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Also, Espinosa resold these romances in France at a healthy profit."}, "gen_args_2": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? No, Espinosa resold these romances in France at a healthy profit."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-154.0", "False"]], "doc_hash": "28a9d9641e1a108b0646b089f8a21cf4a8fe0e6e17647eb25d2c5ef331da5bd7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 506, "doc": {"premise": "But I do not believe any such algorithmic tool can be complete.", "hypothesis": "These tools work flawlessly under any circumstances.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Yes, These tools work flawlessly under any circumstances."}, "gen_args_1": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? Also, These tools work flawlessly under any circumstances."}, "gen_args_2": {"arg_0": "", "arg_1": " But I do not believe any such algorithmic tool can be complete., right? No, These tools work flawlessly under any circumstances."}}, "resps": [[["-122.5", "False"]], [["-122.5", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-122.5", "False"], ["-123.0", "False"]], "doc_hash": "2325122a173cf7dba8382070ae46275e439636d0dcad8f88e0a6b84f679202e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.38365173 0.38365173 0.23269654]"]}
{"doc_id": 514, "doc": {"premise": "Steve Harris, a molecular biologist from Texas was visiting.", "hypothesis": "Steve was a biologist from out of town.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Yes, Steve was a biologist from out of town."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Also, Steve was a biologist from out of town."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? No, Steve was a biologist from out of town."}}, "resps": [[["-110.0", "False"]], [["-114.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-110.0", "False"], ["-114.5", "False"], ["-110.0", "False"]], "doc_hash": "990e3c7d28b38828a4d0845fe0019b91f1783d114a2a04e2300f88ae391104b8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 522, "doc": {"premise": "Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network.", "hypothesis": "Convergent flow allows classification.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Yes, Convergent flow allows classification."}, "gen_args_1": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Also, Convergent flow allows classification."}, "gen_args_2": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? No, Convergent flow allows classification."}}, "resps": [[["-206.0", "False"]], [["-210.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-210.0", "False"], ["-212.0", "False"]], "doc_hash": "1b6fdf8153d62354592ccf868dd15662252ee3000b8314ac90da73fc33497359", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.01794253 0.00242826]"]}
{"doc_id": 530, "doc": {"premise": "In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself.", "hypothesis": "In the last chapter, I considered the universe itself.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Yes, In the last chapter, I considered the universe itself."}, "gen_args_1": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? Also, In the last chapter, I considered the universe itself."}, "gen_args_2": {"arg_0": "", "arg_1": " In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself., right? No, In the last chapter, I considered the universe itself."}}, "resps": [[["-136.0", "False"]], [["-139.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-139.0", "False"], ["-137.0", "False"]], "doc_hash": "406112870d30cc76bdae291e9987633fa63f485b4f029d8eb4b44c5203b20fa6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 538, "doc": {"premise": "In the postbellum legal order, the same result derived from federal constitutional principles.", "hypothesis": "The postbellum legal order ended in the same result due to Barbados' federal constitution principles.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Yes, The postbellum legal order ended in the same result due to Barbados' federal constitution principles."}, "gen_args_1": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Also, The postbellum legal order ended in the same result due to Barbados' federal constitution principles."}, "gen_args_2": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? No, The postbellum legal order ended in the same result due to Barbados' federal constitution principles."}}, "resps": [[["-172.0", "False"]], [["-177.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-177.0", "False"], ["-173.0", "False"]], "doc_hash": "528112863fd0b759a771be80a8914cf4ad2fd8d309f64710b48f16e3d935c6be", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 546, "doc": {"premise": "When civil society turns a deaf ear, crazy ideas lose their edge.", "hypothesis": "Crazy ideas are less edgy when they are ignored by civil society.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Yes, Crazy ideas are less edgy when they are ignored by civil society."}, "gen_args_1": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Also, Crazy ideas are less edgy when they are ignored by civil society."}, "gen_args_2": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? No, Crazy ideas are less edgy when they are ignored by civil society."}}, "resps": [[["-122.0", "False"]], [["-132.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-132.0", "False"], ["-125.5", "False"]], "doc_hash": "558f6eef673c3d781edfa1357090a477095d452667f0b0b4c2f5f0b8c2e797f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70644994e-01 4.40672145e-05 2.93109390e-02]"]}
{"doc_id": 554, "doc": {"premise": "Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world.", "hypothesis": "We shouldn't label anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Yes, We shouldn't label anything."}, "gen_args_1": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? Also, We shouldn't label anything."}, "gen_args_2": {"arg_0": "", "arg_1": " Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world., right? No, We shouldn't label anything."}}, "resps": [[["-147.0", "False"]], [["-148.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-148.0", "False"], ["-144.0", "False"]], "doc_hash": "ed8ea4ba44bbde001c10895d6ff238f1b4d6a82e84ba503dc46a078894949b32", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 562, "doc": {"premise": "Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American.", "hypothesis": "Americans hate the flag.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Yes, Americans hate the flag."}, "gen_args_1": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Also, Americans hate the flag."}, "gen_args_2": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? No, Americans hate the flag."}}, "resps": [[["-170.0", "False"]], [["-172.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-172.0", "False"], ["-168.0", "False"]], "doc_hash": "5712bc892693f458c6957be7c837d74a99fd4090e0d16dc72bbcdb9570ffa8b6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 570, "doc": {"premise": "As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table.", "hypothesis": "The sand gets up in a pile.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Yes, The sand gets up in a pile."}, "gen_args_1": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Also, The sand gets up in a pile."}, "gen_args_2": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? No, The sand gets up in a pile."}}, "resps": [[["-162.0", "False"]], [["-165.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-165.0", "False"], ["-162.0", "False"]], "doc_hash": "2f36d183f644ef7d78be378afd200f95e506ac3c6ab294059242fec9ebd13782", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 578, "doc": {"premise": "Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?", "hypothesis": "We don't look at that famous building?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Yes, We don't look at that famous building?"}, "gen_args_1": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? Also, We don't look at that famous building?"}, "gen_args_2": {"arg_0": "", "arg_1": " Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose?, right? No, We don't look at that famous building?"}}, "resps": [[["-159.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "5a25ff8ce3585ed28b5980b37153e2092cde506e1bd17b56d5b6cf797f0eaf7d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 586, "doc": {"premise": "The audience is invisible; each viewer is in his little cubicle, called a living room.", "hypothesis": "You can see the audience.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Yes, You can see the audience."}, "gen_args_1": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Also, You can see the audience."}, "gen_args_2": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? No, You can see the audience."}}, "resps": [[["-120.5", "False"]], [["-126.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-120.5", "False"], ["-126.0", "False"], ["-117.5", "False"]], "doc_hash": "9d1902a729fbed5a37916c4ed8f618cc84558a422e3388697fa5e4ef28c066ae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74166829e-02 1.93781146e-04 9.52389536e-01]"]}
{"doc_id": 594, "doc": {"premise": "Your heart happened to be preadapted to pick up earthquake pretremors.", "hypothesis": "Earthquake pretremors can be felt by everyone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Yes, Earthquake pretremors can be felt by everyone."}, "gen_args_1": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Also, Earthquake pretremors can be felt by everyone."}, "gen_args_2": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? No, Earthquake pretremors can be felt by everyone."}}, "resps": [[["-141.0", "False"]], [["-145.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-145.0", "False"], ["-140.0", "False"]], "doc_hash": "00c65c29a174cdff9dfbc23e92c5f4bb816ded0de99c8d79d80b821258920724", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 602, "doc": {"premise": "The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions.", "hypothesis": "There is evidence that the descendants of the early Hispanos could write.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Yes, There is evidence that the descendants of the early Hispanos could write."}, "gen_args_1": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? Also, There is evidence that the descendants of the early Hispanos could write."}, "gen_args_2": {"arg_0": "", "arg_1": " The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions., right? No, There is evidence that the descendants of the early Hispanos could write."}}, "resps": [[["-203.0", "False"]], [["-205.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-205.0", "False"], ["-206.0", "False"]], "doc_hash": "534c7057210a2e2b6127e3737b0d0ef186f8768dcedd4a8260318def7850b050", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 610, "doc": {"premise": "For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced.", "hypothesis": "There are no voting rights.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Yes, There are no voting rights."}, "gen_args_1": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Also, There are no voting rights."}, "gen_args_2": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? No, There are no voting rights."}}, "resps": [[["-196.0", "False"]], [["-199.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-199.0", "False"], ["-194.0", "False"]], "doc_hash": "1b32d5f6c83670557a8eeb4b7448fba46bbd091cf1094a6d53c6cb07cedce187", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 618, "doc": {"premise": "The vaquero or buckaroo is a westerner and the cowboy is a southerner.", "hypothesis": "The cowboy is a northern guy.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Yes, The cowboy is a northern guy."}, "gen_args_1": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Also, The cowboy is a northern guy."}, "gen_args_2": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? No, The cowboy is a northern guy."}}, "resps": [[["-108.5", "False"]], [["-112.5", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-108.5", "False"], ["-112.5", "False"], ["-107.0", "False"]], "doc_hash": "6540fe07dfcc1e413097384200145af94d063414669318bc2f8c5b4ac70b42f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18181803 0.00333011 0.81485186]"]}
{"doc_id": 626, "doc": {"premise": "During the preschool and elementary school years, thought is largely tied to the here-and-now.", "hypothesis": "Preschool kids think mostly about today.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Yes, Preschool kids think mostly about today."}, "gen_args_1": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? Also, Preschool kids think mostly about today."}, "gen_args_2": {"arg_0": "", "arg_1": " During the preschool and elementary school years, thought is largely tied to the here-and-now., right? No, Preschool kids think mostly about today."}}, "resps": [[["-119.0", "False"]], [["-127.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-119.0", "False"], ["-127.0", "False"], ["-119.5", "False"]], "doc_hash": "2ea2267da8ab9f21cb60be000bfdfce1ad6ab6a8929062367ab60223411ecd27", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22329381e-01 2.08768250e-04 3.77461850e-01]"]}
{"doc_id": 634, "doc": {"premise": "I, in turn, happen to have desires such that I would be happier with rather more pears than apples.", "hypothesis": "I would rather eat 100 pears than 1 apple.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Yes, I would rather eat 100 pears than 1 apple."}, "gen_args_1": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Also, I would rather eat 100 pears than 1 apple."}, "gen_args_2": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? No, I would rather eat 100 pears than 1 apple."}}, "resps": [[["-144.0", "False"]], [["-145.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-145.0", "False"], ["-144.0", "False"]], "doc_hash": "b30122250bfb42051e5bfd69967acf92fa9b6ea8a01c3a7c0089b3c5a66e67ff", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 642, "doc": {"premise": "for in the image of God he made Adam.", "hypothesis": "Adam was created to look like God.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Yes, Adam was created to look like God."}, "gen_args_1": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Also, Adam was created to look like God."}, "gen_args_2": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? No, Adam was created to look like God."}}, "resps": [[["-85.0", "False"]], [["-90.5", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-85.0", "False"], ["-90.5", "False"], ["-85.0", "False"]], "doc_hash": "c5cdfbaaab295e657316e7ba537b3f00d5b4ec4af3bf6b29d9f109b8ebee097e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49898039 0.00203922 0.49898039]"]}
{"doc_id": 650, "doc": {"premise": "I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game.", "hypothesis": "This chapter has material on the natural game.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Yes, This chapter has material on the natural game."}, "gen_args_1": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? Also, This chapter has material on the natural game."}, "gen_args_2": {"arg_0": "", "arg_1": " I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game., right? No, This chapter has material on the natural game."}}, "resps": [[["-153.0", "False"]], [["-158.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-158.0", "False"], ["-155.0", "False"]], "doc_hash": "d20eda87412705a0e33f6d21ccaf2ea60ac857ce90a69607225b4020efa2e029", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 658, "doc": {"premise": "In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913.", "hypothesis": "The performance stopped in 1987.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Yes, The performance stopped in 1987."}, "gen_args_1": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Also, The performance stopped in 1987."}, "gen_args_2": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? No, The performance stopped in 1987."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-140.0", "False"]], "doc_hash": "0343e22616cbd1b0be6744cf950ecbb621a4a1753f79632aa4f14f93452c620b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 666, "doc": {"premise": "Economic growth is part and parcel of the creativity of the universe as a whole.", "hypothesis": "Economic growth is a monster of its own kind; an entity independent of the universe.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Yes, Economic growth is a monster of its own kind; an entity independent of the universe."}, "gen_args_1": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Also, Economic growth is a monster of its own kind; an entity independent of the universe."}, "gen_args_2": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? No, Economic growth is a monster of its own kind; an entity independent of the universe."}}, "resps": [[["-138.0", "False"]], [["-139.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-139.0", "False"], ["-132.0", "False"]], "doc_hash": "abd8b469800ef624c1e40abd4a13331225b8e84e310f6914b59feee290b0592e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 674, "doc": {"premise": "In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen.", "hypothesis": "The dead body belongs to Ramen.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Yes, The dead body belongs to Ramen."}, "gen_args_1": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? Also, The dead body belongs to Ramen."}, "gen_args_2": {"arg_0": "", "arg_1": " In this poem, Joaquan lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramen., right? No, The dead body belongs to Ramen."}}, "resps": [[["-214.0", "False"]], [["-218.0", "False"]], [["-215.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-218.0", "False"], ["-215.0", "False"]], "doc_hash": "8a8f7e3196db4e892a7a37b07e6f67eb83c4467b72090e814830ca5f5c7398ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 682, "doc": {"premise": "So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source.", "hypothesis": "Shannon did calculations about the message.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Yes, Shannon did calculations about the message."}, "gen_args_1": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Also, Shannon did calculations about the message."}, "gen_args_2": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? No, Shannon did calculations about the message."}}, "resps": [[["-170.0", "False"]], [["-171.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-171.0", "False"], ["-171.0", "False"]], "doc_hash": "ec90ac362f203a12bde99a4fdd76b50e646dac4816e678baa0e280ad23d6d270", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 690, "doc": {"premise": "In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness.", "hypothesis": "At higher fitness levels evolving populations are more likely to survive.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Yes, At higher fitness levels evolving populations are more likely to survive."}, "gen_args_1": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Also, At higher fitness levels evolving populations are more likely to survive."}, "gen_args_2": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? No, At higher fitness levels evolving populations are more likely to survive."}}, "resps": [[["-196.0", "False"]], [["-198.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-198.0", "False"], ["-200.0", "False"]], "doc_hash": "0aa9c3894f5028520c60316443eb6773b012708744e76e7374453cad81abd779", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 698, "doc": {"premise": "Riddles are fun and educational as well.", "hypothesis": "Riddles are very hard to solve.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Yes, Riddles are very hard to solve."}, "gen_args_1": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? Also, Riddles are very hard to solve."}, "gen_args_2": {"arg_0": "", "arg_1": " Riddles are fun and educational as well., right? No, Riddles are very hard to solve."}}, "resps": [[["-81.5", "False"]], [["-80.5", "False"]], [["-81.5", "False"]]], "filtered_resps": [["-81.5", "False"], ["-80.5", "False"], ["-81.5", "False"]], "doc_hash": "531453b5bcfe06d3cd13e110cc76b65b590d76c636e47187225b59955d8cdffd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 706, "doc": {"premise": "Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits.", "hypothesis": "TV has not been invented yet, which is why most children spend a lot of time reading.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Yes, TV has not been invented yet, which is why most children spend a lot of time reading."}, "gen_args_1": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Also, TV has not been invented yet, which is why most children spend a lot of time reading."}, "gen_args_2": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? No, TV has not been invented yet, which is why most children spend a lot of time reading."}}, "resps": [[["-193.0", "False"]], [["-193.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-193.0", "False"], ["-193.0", "False"]], "doc_hash": "ef08112ed262b718910da03768d13ced046cb9e6f5f685b592ba6de0bb7726a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 714, "doc": {"premise": "Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book.", "hypothesis": "According to this book, parents shouldn't spend time with their children.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Yes, According to this book, parents shouldn't spend time with their children."}, "gen_args_1": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Also, According to this book, parents shouldn't spend time with their children."}, "gen_args_2": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? No, According to this book, parents shouldn't spend time with their children."}}, "resps": [[["-182.0", "False"]], [["-186.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-186.0", "False"], ["-175.0", "False"]], "doc_hash": "7e7db51faa5db7e50280528ae633eafa806105f42c83e673b3b7e3dd7e043269", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11035992e-04 1.66862063e-05 9.99072278e-01]"]}
{"doc_id": 722, "doc": {"premise": "15 The commander wants us to do something, and has used the language of the law to move us toward action.", "hypothesis": "The commander knows that we will never listen to anything he says.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Yes, The commander knows that we will never listen to anything he says."}, "gen_args_1": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? Also, The commander knows that we will never listen to anything he says."}, "gen_args_2": {"arg_0": "", "arg_1": " 15 The commander wants us to do something, and has used the language of the law to move us toward action., right? No, The commander knows that we will never listen to anything he says."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-146.0", "False"]], "doc_hash": "e6e3f6742d0259f9d6fd581117dee6e87166f826a998077c7db0db4af5a62110", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 730, "doc": {"premise": "Should I help her with her homework, and if so, how should I do so?", "hypothesis": "I should ask myself how to help her with homework.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Yes, I should ask myself how to help her with homework."}, "gen_args_1": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Also, I should ask myself how to help her with homework."}, "gen_args_2": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? No, I should ask myself how to help her with homework."}}, "resps": [[["-95.0", "False"]], [["-97.0", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-95.0", "False"], ["-97.0", "False"], ["-95.5", "False"]], "doc_hash": "aa657d9e4abfcf12135901d3fc9df1df81c117d93e3edd26a1f7a6264cd7ffee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57409699 0.07769558 0.34820743]"]}
{"doc_id": 738, "doc": {"premise": "The disputes took on the tones of class struggle.", "hypothesis": "They fought about how rich CEOs were.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Yes, They fought about how rich CEOs were."}, "gen_args_1": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Also, They fought about how rich CEOs were."}, "gen_args_2": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? No, They fought about how rich CEOs were."}}, "resps": [[["-118.5", "False"]], [["-122.0", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-118.5", "False"], ["-122.0", "False"], ["-118.0", "False"]], "doc_hash": "736c8c76eaf4a6c5f60f343171387034fc36a78a2daa07b5037c5b7c23a060be", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37328494 0.01127223 0.61544283]"]}
{"doc_id": 746, "doc": {"premise": "What we see are details.", "hypothesis": "The details have been printed out on legal paper for everyone to see.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What we see are details., right? Yes, The details have been printed out on legal paper for everyone to see."}, "gen_args_1": {"arg_0": "", "arg_1": " What we see are details., right? Also, The details have been printed out on legal paper for everyone to see."}, "gen_args_2": {"arg_0": "", "arg_1": " What we see are details., right? No, The details have been printed out on legal paper for everyone to see."}}, "resps": [[["-109.5", "False"]], [["-116.0", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-109.5", "False"], ["-116.0", "False"], ["-110.0", "False"]], "doc_hash": "b115bba1930267884171b40fdf94a5518fb3e45ba3379516ea78e3c446aeb964", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.62187736 0.00093495 0.37718769]"]}
{"doc_id": 754, "doc": {"premise": "Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging.", "hypothesis": "Pitt swore that he did not get a glimpse of the scene.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Yes, Pitt swore that he did not get a glimpse of the scene."}, "gen_args_1": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Also, Pitt swore that he did not get a glimpse of the scene."}, "gen_args_2": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? No, Pitt swore that he did not get a glimpse of the scene."}}, "resps": [[["-182.0", "False"]], [["-185.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-185.0", "False"], ["-181.0", "False"]], "doc_hash": "2fc832c715937b2f31db4f6b654c617f81216485c5e5733095dc19cd7b63c382", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 762, "doc": {"premise": "He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted.", "hypothesis": "Lord Julian is from St. James's.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Yes, Lord Julian is from St. James's."}, "gen_args_1": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Also, Lord Julian is from St. James's."}, "gen_args_2": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? No, Lord Julian is from St. James's."}}, "resps": [[["-195.0", "False"]], [["-197.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-197.0", "False"], ["-196.0", "False"]], "doc_hash": "c473b212808c771a2abe00ff0b2747db63b5e7353a821819126b571bef89a592", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 770, "doc": {"premise": "You are Lord Julian Wade, I understand,  was his truculent greeting.", "hypothesis": "Though many had tried to approach him, Lord Wade was often cold and emotionless.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Yes, Though many had tried to approach him, Lord Wade was often cold and emotionless."}, "gen_args_1": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? Also, Though many had tried to approach him, Lord Wade was often cold and emotionless."}, "gen_args_2": {"arg_0": "", "arg_1": " You are Lord Julian Wade, I understand,  was his truculent greeting., right? No, Though many had tried to approach him, Lord Wade was often cold and emotionless."}}, "resps": [[["-185.0", "False"]], [["-187.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-187.0", "False"], ["-187.0", "False"]], "doc_hash": "c793505d3eb0ab2672fc405bd34d0cd3534d05f97a872d2d137b848be0f64b10", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 778, "doc": {"premise": "It'll not be Bishop himself,  said Wolverstone, between question and assertion.", "hypothesis": "Wolverstone had mentioned the Bishop to be one who was very pretty.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Yes, Wolverstone had mentioned the Bishop to be one who was very pretty."}, "gen_args_1": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Also, Wolverstone had mentioned the Bishop to be one who was very pretty."}, "gen_args_2": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? No, Wolverstone had mentioned the Bishop to be one who was very pretty."}}, "resps": [[["-189.0", "False"]], [["-189.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-189.0", "False"], ["-189.0", "False"]], "doc_hash": "14301ab127cf9240f991cae60e31d72c81f2257e766ee4435b80cdc20e0d02d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 786, "doc": {"premise": "They are within range,  cried Ogle.", "hypothesis": "Ogle said that they were reachable.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Yes, Ogle said that they were reachable."}, "gen_args_1": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Also, Ogle said that they were reachable."}, "gen_args_2": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? No, Ogle said that they were reachable."}}, "resps": [[["-119.5", "False"]], [["-122.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-122.5", "False"], ["-120.0", "False"]], "doc_hash": "41856239c0151997edecd89cdb5ddf5598103fcc07c57fd1dede09a5b4d1d98a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.6037489  0.03005889 0.36619222]"]}
{"doc_id": 794, "doc": {"premise": "Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure.", "hypothesis": "She was dressed in white when she asked: Why do you run, then?.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Yes, She was dressed in white when she asked: Why do you run, then?."}, "gen_args_1": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? Also, She was dressed in white when she asked: Why do you run, then?."}, "gen_args_2": {"arg_0": "", "arg_1": " Why do you run, then?  she asked him coolly, standing slim and straight before him, all in white and very maidenly save in her unnatural composure., right? No, She was dressed in white when she asked: Why do you run, then?."}}, "resps": [[["-224.0", "False"]], [["-224.0", "False"]], [["-222.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-224.0", "False"], ["-222.0", "False"]], "doc_hash": "92089fc18ddccc55177bb9c58ccf38e55066f868cbec4020b95f7265c8eeaf86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 802, "doc": {"premise": "Don't think I accept it willingly.", "hypothesis": "I am not willing to accept it, but I could be convinced.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Yes, I am not willing to accept it, but I could be convinced."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Also, I am not willing to accept it, but I could be convinced."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? No, I am not willing to accept it, but I could be convinced."}}, "resps": [[["-95.5", "False"]], [["-99.5", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-95.5", "False"], ["-99.5", "False"], ["-93.0", "False"]], "doc_hash": "d7adf71a3311114e4e1b85ee9b7046ade233c43899f9098ce97db5bd74638407", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07575293 0.00138746 0.92285961]"]}
{"doc_id": 810, "doc": {"premise": "It was she now who was on her defence, her voice quivering with indignation.", "hypothesis": "The woman had had enough of their bad behavior.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Yes, The woman had had enough of their bad behavior."}, "gen_args_1": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Also, The woman had had enough of their bad behavior."}, "gen_args_2": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? No, The woman had had enough of their bad behavior."}}, "resps": [[["-132.0", "False"]], [["-134.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-134.0", "False"], ["-132.0", "False"]], "doc_hash": "de85eab86ce452f694e4884ddcdca79050aaf6d3bf50ae40c95079e2f746391c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 818, "doc": {"premise": "He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example.", "hypothesis": "Lord Julian rose, showing good manners, but he did not bother standing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Yes, Lord Julian rose, showing good manners, but he did not bother standing."}, "gen_args_1": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? Also, Lord Julian rose, showing good manners, but he did not bother standing."}, "gen_args_2": {"arg_0": "", "arg_1": " He did not trouble to rise, not even when Lord Julian, obeying the instincts of finer breeding, set him the example., right? No, Lord Julian rose, showing good manners, but he did not bother standing."}}, "resps": [[["-172.0", "False"]], [["-178.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-178.0", "False"], ["-172.0", "False"]], "doc_hash": "b35299eebf49aad3b48c522c17e734610c1c396e3496ee452041fec5519c5748", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 826, "doc": {"premise": "I... I believe that he has,  said Calverley, between doubt and suspicion.", "hypothesis": "Calverly was only indecisive in his answer because he did not know all of the facts.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Yes, Calverly was only indecisive in his answer because he did not know all of the facts."}, "gen_args_1": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Also, Calverly was only indecisive in his answer because he did not know all of the facts."}, "gen_args_2": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? No, Calverly was only indecisive in his answer because he did not know all of the facts."}}, "resps": [[["-178.0", "False"]], [["-178.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-178.0", "False"], ["-176.0", "False"]], "doc_hash": "b5319d2d70a900c7a03e1852930b88ea5347a7febfdfdd33187c67528f191863", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 834, "doc": {"premise": "It is an honourable service.", "hypothesis": "It is a distinguished and eminent service.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is an honourable service., right? Yes, It is a distinguished and eminent service."}, "gen_args_1": {"arg_0": "", "arg_1": " It is an honourable service., right? Also, It is a distinguished and eminent service."}, "gen_args_2": {"arg_0": "", "arg_1": " It is an honourable service., right? No, It is a distinguished and eminent service."}}, "resps": [[["-83.0", "False"]], [["-88.0", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-83.0", "False"], ["-88.0", "False"], ["-84.0", "False"]], "doc_hash": "098fd743cfffd13038c97e5127b239a5503b5d0572c60d125fbc3785e00255b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 842, "doc": {"premise": "Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully.", "hypothesis": "The Captain was angry.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Yes, The Captain was angry."}, "gen_args_1": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? Also, The Captain was angry."}, "gen_args_2": {"arg_0": "", "arg_1": " Wait!  He swung back to face the Captain, who had placed a hand on is shoulder and was smiling, a trifle wistfully., right? No, The Captain was angry."}}, "resps": [[["-161.0", "False"]], [["-164.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-164.0", "False"], ["-157.0", "False"]], "doc_hash": "17f75cb848ee70d0abd1902db5b9901722ae5187c89b55159b9fd7d4a1b021e3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 850, "doc": {"premise": "He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron.", "hypothesis": "He spent 2 weeks in Port Royal.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Yes, He spent 2 weeks in Port Royal."}, "gen_args_1": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Also, He spent 2 weeks in Port Royal."}, "gen_args_2": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? No, He spent 2 weeks in Port Royal."}}, "resps": [[["-142.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "b08d1a4b4bce287b26e93012bf06bbd78040634a8b5f9a864521783cb4557af7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 858, "doc": {"premise": "Believe me, I am very grateful.", "hypothesis": "I am definitely ungrateful to you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Yes, I am definitely ungrateful to you."}, "gen_args_1": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Also, I am definitely ungrateful to you."}, "gen_args_2": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? No, I am definitely ungrateful to you."}}, "resps": [[["-79.5", "False"]], [["-84.5", "False"]], [["-78.0", "False"]]], "filtered_resps": [["-79.5", "False"], ["-84.5", "False"], ["-78.0", "False"]], "doc_hash": "95ac1d982e95c19b459b14954be8fdbd95908e3920d592beffd649cdbd457baf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18220157 0.00122766 0.81657077]"]}
{"doc_id": 866, "doc": {"premise": "That was in Bridgetown on the night of the Spanish raid.", "hypothesis": "There was never a raid on Bridgetown.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Yes, There was never a raid on Bridgetown."}, "gen_args_1": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? Also, There was never a raid on Bridgetown."}, "gen_args_2": {"arg_0": "", "arg_1": " That was in Bridgetown on the night of the Spanish raid., right? No, There was never a raid on Bridgetown."}}, "resps": [[["-102.5", "False"]], [["-102.0", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-102.0", "False"], ["-100.0", "False"]], "doc_hash": "87200a5acb82715b59bef533acd46565b8ad81b077b75133dba905d9e21a7115", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06742536 0.11116562 0.82140902]"]}
{"doc_id": 874, "doc": {"premise": "Mine is the safe and easy way.", "hypothesis": "Someone else's way is difficult.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Yes, Someone else's way is difficult."}, "gen_args_1": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Also, Someone else's way is difficult."}, "gen_args_2": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? No, Someone else's way is difficult."}}, "resps": [[["-98.0", "False"]], [["-102.0", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-102.0", "False"], ["-98.0", "False"]], "doc_hash": "2bdb95f24b8a7815f7a3723d2867cc8bc18b8c0045575eb9b4146c086164cd30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 882, "doc": {"premise": "Colder still and more distant than ever grew his lordship's voice.", "hypothesis": "As the lordship, he showed no mercy to his subjects.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Yes, As the lordship, he showed no mercy to his subjects."}, "gen_args_1": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Also, As the lordship, he showed no mercy to his subjects."}, "gen_args_2": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? No, As the lordship, he showed no mercy to his subjects."}}, "resps": [[["-144.0", "False"]], [["-146.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-146.0", "False"], ["-148.0", "False"]], "doc_hash": "3e9acb17a912a4976ce6a69c29dad16587292bc03b2ce68525be12e6eb9779b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 890, "doc": {"premise": "Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion.", "hypothesis": "He only has a left eye.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Yes, He only has a left eye."}, "gen_args_1": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? Also, He only has a left eye."}, "gen_args_2": {"arg_0": "", "arg_1": " Out of the tail of his single eye he had espied a trim figure in grey silk that was ascending the companion., right? No, He only has a left eye."}}, "resps": [[["-166.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "f2fb0e06561880a4c44cabf9517f136644d758e5035fd02ba94a483148201a29", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 898, "doc": {"premise": "‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?", "hypothesis": "Wolverstone is right here. No explanation needed.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Yes, Wolverstone is right here. No explanation needed."}, "gen_args_1": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Also, Wolverstone is right here. No explanation needed."}, "gen_args_2": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? No, Wolverstone is right here. No explanation needed."}}, "resps": [[["-155.0", "False"]], [["-160.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-160.0", "False"], ["-156.0", "False"]], "doc_hash": "03ae09fac8ae38cd9b44f1badcfb92dc44726327edc81c9ca24dacbca56f3e5b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 906, "doc": {"premise": "But Wolverstone would not stop.", "hypothesis": "The Wolverstone completely haulted.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Yes, The Wolverstone completely haulted."}, "gen_args_1": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Also, The Wolverstone completely haulted."}, "gen_args_2": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? No, The Wolverstone completely haulted."}}, "resps": [[["-106.5", "False"]], [["-114.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-114.0", "False"], ["-105.5", "False"]], "doc_hash": "31224b0bd4b41fb7c1ac04a008bb5944480163a5835d71690b85085191efaecf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68901423e-01 1.48725174e-04 7.30949852e-01]"]}
{"doc_id": 914, "doc": {"premise": "If it is a mistake to grant Captain Blood a commission, the mistake is not mine.", "hypothesis": "There was the potential for error as the accountant was recently fired.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Yes, There was the potential for error as the accountant was recently fired."}, "gen_args_1": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? Also, There was the potential for error as the accountant was recently fired."}, "gen_args_2": {"arg_0": "", "arg_1": " If it is a mistake to grant Captain Blood a commission, the mistake is not mine., right? No, There was the potential for error as the accountant was recently fired."}}, "resps": [[["-161.0", "False"]], [["-161.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-161.0", "False"], ["-162.0", "False"]], "doc_hash": "7bc8a630ce221b1b18e20283636e69fc0d55c4c03bb82a9de563991a91c3c2c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 922, "doc": {"premise": "I can't think that it would make the least difference if he did,  said his lordship gravely.", "hypothesis": "His lordship believed that either choice would have had a substantial impact.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Yes, His lordship believed that either choice would have had a substantial impact."}, "gen_args_1": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Also, His lordship believed that either choice would have had a substantial impact."}, "gen_args_2": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? No, His lordship believed that either choice would have had a substantial impact."}}, "resps": [[["-160.0", "False"]], [["-164.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-164.0", "False"], ["-161.0", "False"]], "doc_hash": "0ee34a32cd2d3dd557ef908ee3fe060340a233255b82a58541c6d46e64efc7c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 930, "doc": {"premise": "But I suspect this gravity for a mask under which Lord Julian was secretly amused.", "hypothesis": "Julian looked serious but was actually amused.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Yes, Julian looked serious but was actually amused."}, "gen_args_1": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Also, Julian looked serious but was actually amused."}, "gen_args_2": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? No, Julian looked serious but was actually amused."}}, "resps": [[["-158.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "4752500c0c37c6bd6e81b1046b60beb4e75e3eee2c9b046e0d3bfc4029915857", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 938, "doc": {"premise": "Ah, now, can't ye, indeed?  he cried.", "hypothesis": "He never posed a question as he remained silent.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Yes, He never posed a question as he remained silent."}, "gen_args_1": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? Also, He never posed a question as he remained silent."}, "gen_args_2": {"arg_0": "", "arg_1": " Ah, now, can't ye, indeed?  he cried., right? No, He never posed a question as he remained silent."}}, "resps": [[["-151.0", "False"]], [["-153.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-153.0", "False"], ["-150.0", "False"]], "doc_hash": "a809105223f4af41e62cd781efdd33c37b1773323be73d6ca7894a20fd558082", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 946, "doc": {"premise": "Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after.", "hypothesis": "There was nothing able to slow down the ship.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Yes, There was nothing able to slow down the ship."}, "gen_args_1": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Also, There was nothing able to slow down the ship."}, "gen_args_2": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? No, There was nothing able to slow down the ship."}}, "resps": [[["-197.0", "False"]], [["-195.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-195.0", "False"], ["-196.0", "False"]], "doc_hash": "7067c66b60a9914f6ac859b308433a17807067f74febd3d5584fb6acfba6532e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 954, "doc": {"premise": "So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import.", "hypothesis": "I was expecting your arrival said the Deputy-Governor.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Yes, I was expecting your arrival said the Deputy-Governor."}, "gen_args_1": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Also, I was expecting your arrival said the Deputy-Governor."}, "gen_args_2": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? No, I was expecting your arrival said the Deputy-Governor."}}, "resps": [[["-206.0", "False"]], [["-214.0", "False"]], [["-210.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-214.0", "False"], ["-210.0", "False"]], "doc_hash": "39e878bbce755014d0f1acc1b60455daa1fac6ad9fe36187e5253ed6bd832a93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 962, "doc": {"premise": "Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course.", "hypothesis": "The course was full of territory that was left unexplored and was, therefore, very dangerous.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Yes, The course was full of territory that was left unexplored and was, therefore, very dangerous."}, "gen_args_1": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? Also, The course was full of territory that was left unexplored and was, therefore, very dangerous."}, "gen_args_2": {"arg_0": "", "arg_1": " Aye,  said Ogle,  that is true.   But there were some who were still in open and frank revolt against the course., right? No, The course was full of territory that was left unexplored and was, therefore, very dangerous."}}, "resps": [[["-224.0", "False"]], [["-229.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-229.0", "False"], ["-228.0", "False"]], "doc_hash": "e41819401778f3c87f95ad52c17df42f3f1122b7fc034f94b4f148ba8ca0531f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 970, "doc": {"premise": "About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men.", "hypothesis": "The night was extremely busy as the streets were packed with people.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Yes, The night was extremely busy as the streets were packed with people."}, "gen_args_1": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Also, The night was extremely busy as the streets were packed with people."}, "gen_args_2": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? No, The night was extremely busy as the streets were packed with people."}}, "resps": [[["-206.0", "False"]], [["-209.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-209.0", "False"], ["-209.0", "False"]], "doc_hash": "d2e740f7cae8d0d98e239bfc0b797c7b2d2c4e8aaef9839e7601ebce2e6798f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 978, "doc": {"premise": "You'll not go?  he said, between question and assertion.", "hypothesis": "Are you not going? He asked.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Yes, Are you not going? He asked."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Also, Are you not going? He asked."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? No, Are you not going? He asked."}}, "resps": [[["-117.0", "False"]], [["-122.0", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-122.0", "False"], ["-118.0", "False"]], "doc_hash": "042ecf0209aac14909dc258abedce2b5859190a3506d904a9e67800490d44e21", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 986, "doc": {"premise": "For myself, I am entirely of Wolverstone's opinion.", "hypothesis": "I have never heard of a person called Wolverstone.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Yes, I have never heard of a person called Wolverstone."}, "gen_args_1": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? Also, I have never heard of a person called Wolverstone."}, "gen_args_2": {"arg_0": "", "arg_1": " For myself, I am entirely of Wolverstone's opinion., right? No, I have never heard of a person called Wolverstone."}}, "resps": [[["-116.0", "False"]], [["-116.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-116.0", "False"], ["-116.5", "False"], ["-112.5", "False"]], "doc_hash": "b5e21024db8c8f6dc64cae435b3e955cd153f8d06f58f2f0fd3cd109d780be87", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0288002 0.0174682 0.9537316]"]}
{"doc_id": 994, "doc": {"premise": "Ha!  Wolverstone vented an ejaculation of sneering mirth.", "hypothesis": "Wolverstone laughed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Yes, Wolverstone laughed."}, "gen_args_1": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Also, Wolverstone laughed."}, "gen_args_2": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? No, Wolverstone laughed."}}, "resps": [[["-125.0", "False"]], [["-130.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-130.0", "False"], ["-126.5", "False"]], "doc_hash": "50c81325c1756985064d04adc65f2b701a93f3989d90231ca2a665b7a655ec41", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81309532 0.00547859 0.18142609]"]}
{"doc_id": 1002, "doc": {"premise": "Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance.", "hypothesis": "The Perfume Factory has been in production since 1954.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Yes, The Perfume Factory has been in production since 1954."}, "gen_args_1": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Also, The Perfume Factory has been in production since 1954."}, "gen_args_2": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? No, The Perfume Factory has been in production since 1954."}}, "resps": [[["-136.0", "False"]], [["-140.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-140.0", "False"], ["-141.0", "False"]], "doc_hash": "1336ab13ba5d73522a1c85e68152a621f83bc9d3f7a62d4c16729143ec0bb033", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1010, "doc": {"premise": "Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables.", "hypothesis": "You must not go beyond these sights.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Yes, You must not go beyond these sights."}, "gen_args_1": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? Also, You must not go beyond these sights."}, "gen_args_2": {"arg_0": "", "arg_1": " Go beyond these sights to Nathaniel Hawthorne's House of the Seven Gables., right? No, You must not go beyond these sights."}}, "resps": [[["-120.5", "False"]], [["-123.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-120.5", "False"], ["-123.0", "False"], ["-117.5", "False"]], "doc_hash": "db20dfe245edb2b6965906307d350ca671001dd4f139141e7fb88d3e8957ed06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04724196 0.00387786 0.94888018]"]}
{"doc_id": 1018, "doc": {"premise": "Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet.", "hypothesis": "The Sailor's House was designed by a famous Italian architect.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Yes, The Sailor's House was designed by a famous Italian architect."}, "gen_args_1": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Also, The Sailor's House was designed by a famous Italian architect."}, "gen_args_2": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? No, The Sailor's House was designed by a famous Italian architect."}}, "resps": [[["-240.0", "False"]], [["-241.0", "False"]], [["-239.0", "False"]]], "filtered_resps": [["-240.0", "False"], ["-241.0", "False"], ["-239.0", "False"]], "doc_hash": "6a71a9c6199e4b346e1872629196324d67005e8263d6ff1d65878c355f335858", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1026, "doc": {"premise": "A flick of a tail or fluke, and it's gone.", "hypothesis": "It is easily intimidated by any sudden movements.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Yes, It is easily intimidated by any sudden movements."}, "gen_args_1": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Also, It is easily intimidated by any sudden movements."}, "gen_args_2": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? No, It is easily intimidated by any sudden movements."}}, "resps": [[["-120.0", "False"]], [["-124.0", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-124.0", "False"], ["-120.0", "False"]], "doc_hash": "26ed7129f6610a3a4d2b7518f1e24957263e4ccb448bc4540073e6a3756cf09d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1034, "doc": {"premise": "The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year.", "hypothesis": "The staff works to increase how many flamingos are on the island.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Yes, The staff works to increase how many flamingos are on the island."}, "gen_args_1": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? Also, The staff works to increase how many flamingos are on the island."}, "gen_args_2": {"arg_0": "", "arg_1": " The staff is working on a program to increase the numbers of flamingos in the US Virgin Islands, and you will find a small flock here successfully breeding each year., right? No, The staff works to increase how many flamingos are on the island."}}, "resps": [[["-178.0", "False"]], [["-183.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-183.0", "False"], ["-179.0", "False"]], "doc_hash": "93a3d37eacce1bf9b5ebf7070f1ba6fba1e2f31d2699afd8b94ae8f703b0f7b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1042, "doc": {"premise": "The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex.", "hypothesis": "Karl-Marx-Allee is falling apart.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Yes, Karl-Marx-Allee is falling apart."}, "gen_args_1": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Also, Karl-Marx-Allee is falling apart."}, "gen_args_2": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? No, Karl-Marx-Allee is falling apart."}}, "resps": [[["-165.0", "False"]], [["-170.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-170.0", "False"], ["-165.0", "False"]], "doc_hash": "24eba9ca531b03e2e21424dd837abd1a02cfab31367c0d9fbd0e33ae04975a0e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1050, "doc": {"premise": "Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs.", "hypothesis": "The Saguenay River was part of the coal market.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Yes, The Saguenay River was part of the coal market."}, "gen_args_1": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Also, The Saguenay River was part of the coal market."}, "gen_args_2": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? No, The Saguenay River was part of the coal market."}}, "resps": [[["-203.0", "False"]], [["-204.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-204.0", "False"], ["-201.0", "False"]], "doc_hash": "31ba2194eb179c70d18ac2d59345035c5fe333071f383ea6cfb5c58f7136e802", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1058, "doc": {"premise": "Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that.", "hypothesis": "The war was over in just a day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Yes, The war was over in just a day."}, "gen_args_1": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? Also, The war was over in just a day."}, "gen_args_2": {"arg_0": "", "arg_1": " Pedro took the throne, though armed struggle continued for months and the lingering bitterness long after that., right? No, The war was over in just a day."}}, "resps": [[["-155.0", "False"]], [["-158.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-158.0", "False"], ["-154.0", "False"]], "doc_hash": "9e9518475b83d7fdd1f1903a21af7e3f38867a188af3832098e6070500abd3bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1066, "doc": {"premise": "In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling.", "hypothesis": "Weltkugelbrunnen is made of granite that is very black and shiny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Yes, Weltkugelbrunnen is made of granite that is very black and shiny."}, "gen_args_1": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Also, Weltkugelbrunnen is made of granite that is very black and shiny."}, "gen_args_2": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? No, Weltkugelbrunnen is made of granite that is very black and shiny."}}, "resps": [[["-237.0", "False"]], [["-237.0", "False"]], [["-237.0", "False"]]], "filtered_resps": [["-237.0", "False"], ["-237.0", "False"], ["-237.0", "False"]], "doc_hash": "ebda1d7d055b81e8814f7c2601deb640004c1b86692de69dfd37c40b8391cb73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1074, "doc": {"premise": "A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known.", "hypothesis": "Boot is a small city.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Yes, Boot is a small city."}, "gen_args_1": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Also, Boot is a small city."}, "gen_args_2": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? No, Boot is a small city."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-168.0", "False"]], "doc_hash": "a560582da2dad203c4ba65de5530825357dd4c1c44c236563c551abf22f84277", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1082, "doc": {"premise": "Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications.", "hypothesis": "There is only one tower and it's brand new.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Yes, There is only one tower and it's brand new."}, "gen_args_1": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? Also, There is only one tower and it's brand new."}, "gen_args_2": {"arg_0": "", "arg_1": " Its entrance is guarded by two 14th-century towers reamainaing from the town's fortifications., right? No, There is only one tower and it's brand new."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-144.0", "False"]], "doc_hash": "eebace00bcb6ff6fde68a7fac13a33510efc3e37a57b30f3a9e4ceabfa2f2de0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1090, "doc": {"premise": "The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans.", "hypothesis": "James Cook traveled to Hawaii.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Yes, James Cook traveled to Hawaii."}, "gen_args_1": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Also, James Cook traveled to Hawaii."}, "gen_args_2": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? No, James Cook traveled to Hawaii."}}, "resps": [[["-139.0", "False"]], [["-144.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-144.0", "False"], ["-141.0", "False"]], "doc_hash": "a9a3b9435563c49c1389e868ce28675b1e204661384c137d7d31ac60bef15207", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1098, "doc": {"premise": "Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time.", "hypothesis": "The a5 coin is incredibly rare.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Yes, The a5 coin is incredibly rare."}, "gen_args_1": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Also, The a5 coin is incredibly rare."}, "gen_args_2": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? No, The a5 coin is incredibly rare."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-153.0", "False"]], "doc_hash": "5f6c15e1d693642af599e24d02e5a0f2b05be368c46fb6ff6a24e80035253401", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1106, "doc": {"premise": "These instruments played together form the basic  orchestra  for several popular musical genres.", "hypothesis": "The orchestra does not use instruments at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Yes, The orchestra does not use instruments at all."}, "gen_args_1": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? Also, The orchestra does not use instruments at all."}, "gen_args_2": {"arg_0": "", "arg_1": " These instruments played together form the basic  orchestra  for several popular musical genres., right? No, The orchestra does not use instruments at all."}}, "resps": [[["-143.0", "False"]], [["-145.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-145.0", "False"], ["-139.0", "False"]], "doc_hash": "64faf59bc0d135b82fa87561af672f4192d749ec34749d951482ae207ce8c71a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1114, "doc": {"premise": "A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark.", "hypothesis": "People go fishing and then go right to sleep.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Yes, People go fishing and then go right to sleep."}, "gen_args_1": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Also, People go fishing and then go right to sleep."}, "gen_args_2": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? No, People go fishing and then go right to sleep."}}, "resps": [[["-217.0", "False"]], [["-221.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-217.0", "False"], ["-221.0", "False"], ["-214.0", "False"]], "doc_hash": "6b64a92ffdad39ea2935f19d1317bc86e3a38160431e8afb957c4b6156d39766", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1122, "doc": {"premise": "Also check out Star Computer City in the Star House near the Star Ferry terminal.", "hypothesis": "Computer CIty is not located in the Star House.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Yes, Computer CIty is not located in the Star House."}, "gen_args_1": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Also, Computer CIty is not located in the Star House."}, "gen_args_2": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? No, Computer CIty is not located in the Star House."}}, "resps": [[["-140.0", "False"]], [["-137.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-137.0", "False"], ["-136.0", "False"]], "doc_hash": "4e9c4fc84806c6e7d938cb34d179d31d2696cbbf4becb1a617d49ca2e69f3ad2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01321289 0.26538793 0.72139918]"]}
{"doc_id": 1130, "doc": {"premise": "As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders.", "hypothesis": "Pierre was never arrested.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Yes, Pierre was never arrested."}, "gen_args_1": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? Also, Pierre was never arrested."}, "gen_args_2": {"arg_0": "", "arg_1": " As a Protestant, Pierre du Calvet was appointed by the British justice of the peace but then ended up in jail himself for selling supplies and information to the American invaders., right? No, Pierre was never arrested."}}, "resps": [[["-189.0", "False"]], [["-188.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-188.0", "False"], ["-183.0", "False"]], "doc_hash": "c4afc92800ad2f43902b9b2d688fb9f7aa5d3bd3a9506731fed1d904f95147eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00245611 0.00667641 0.99086747]"]}
{"doc_id": 1138, "doc": {"premise": "Detour to see the mansion designed by McKim Mead", "hypothesis": "The mansion cost 2 million dollars to build.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Yes, The mansion cost 2 million dollars to build."}, "gen_args_1": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Also, The mansion cost 2 million dollars to build."}, "gen_args_2": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? No, The mansion cost 2 million dollars to build."}}, "resps": [[["-104.0", "False"]], [["-104.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-104.0", "False"], ["-104.5", "False"], ["-108.5", "False"]], "doc_hash": "311540bac18c90710148be6ed101f7db3869879b78fd41569ea3a3405966547d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61818465 0.37494794 0.00686741]"]}
{"doc_id": 1146, "doc": {"premise": "The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe.", "hypothesis": "James Wilson Marshall did nothing special.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Yes, James Wilson Marshall did nothing special."}, "gen_args_1": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Also, James Wilson Marshall did nothing special."}, "gen_args_2": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? No, James Wilson Marshall did nothing special."}}, "resps": [[["-172.0", "False"]], [["-175.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-175.0", "False"], ["-170.0", "False"]], "doc_hash": "d3097c4a41eb11d475a0f456e4eae8e8c5f488eaea10fc8c897da817659608b9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1154, "doc": {"premise": "The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia.", "hypothesis": "The Mountesserat mountains are the tallest in the area.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Yes, The Mountesserat mountains are the tallest in the area."}, "gen_args_1": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? Also, The Mountesserat mountains are the tallest in the area."}, "gen_args_2": {"arg_0": "", "arg_1": " The jagged ridges of Montserrat rise out of the rather featureless Llobregat plain 62 kilometers (38 miles) northwest of Barcelona, in the very heart of Catalonia., right? No, The Mountesserat mountains are the tallest in the area."}}, "resps": [[["-185.0", "False"]], [["-187.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-187.0", "False"], ["-187.0", "False"]], "doc_hash": "40a4c7da118a4ac2291d67e434697be3e46ca0205176dd5f4e140210918e2ae9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1162, "doc": {"premise": "Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife.", "hypothesis": "Laguna Nichupte is 10 acres of water.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Yes, Laguna Nichupte is 10 acres of water."}, "gen_args_1": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Also, Laguna Nichupte is 10 acres of water."}, "gen_args_2": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? No, Laguna Nichupte is 10 acres of water."}}, "resps": [[["-162.0", "False"]], [["-165.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-165.0", "False"], ["-160.0", "False"]], "doc_hash": "7d8e6535d72b25447e4c98e08eb4633f7b96c42950a3791c0143b4af7a372ba9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1170, "doc": {"premise": "The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded.", "hypothesis": "The towns around Barbizon are the most populated.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Yes, The towns around Barbizon are the most populated."}, "gen_args_1": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Also, The towns around Barbizon are the most populated."}, "gen_args_2": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? No, The towns around Barbizon are the most populated."}}, "resps": [[["-193.0", "False"]], [["-194.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-194.0", "False"], ["-191.0", "False"]], "doc_hash": "c31d35930db49c0f656ab044dd8580e25ae62ef66865b0f179ba654fcd9a681c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1178, "doc": {"premise": "Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity.", "hypothesis": "Peopel lived in Europe during the Stone Age.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Yes, Peopel lived in Europe during the Stone Age."}, "gen_args_1": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? Also, Peopel lived in Europe during the Stone Age."}, "gen_args_2": {"arg_0": "", "arg_1": " Little is known of the earliest Stone Age inhabitants of Europe's southwestern extremity., right? No, Peopel lived in Europe during the Stone Age."}}, "resps": [[["-125.0", "False"]], [["-128.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-128.0", "False"], ["-127.0", "False"]], "doc_hash": "2370d47a06b1af7519937dc5073c14636c90f5e93b5504cb27e4b5e88ef3457b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1186, "doc": {"premise": "For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures.", "hypothesis": "Old nickelodeons are interesting for film buffs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Yes, Old nickelodeons are interesting for film buffs."}, "gen_args_1": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Also, Old nickelodeons are interesting for film buffs."}, "gen_args_2": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? No, Old nickelodeons are interesting for film buffs."}}, "resps": [[["-179.0", "False"]], [["-184.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-184.0", "False"], ["-181.0", "False"]], "doc_hash": "089a5e6a0ed214a12c3992e1937c0537409c25b64792d02b983536591891fb49", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1194, "doc": {"premise": "If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street.", "hypothesis": "Harvard Square is dangerous at night.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Yes, Harvard Square is dangerous at night."}, "gen_args_1": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Also, Harvard Square is dangerous at night."}, "gen_args_2": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? No, Harvard Square is dangerous at night."}}, "resps": [[["-139.0", "False"]], [["-139.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-139.0", "False"], ["-139.0", "False"]], "doc_hash": "6705e68da4d6272ee559119a6661dbd5ca7c9bbb4750e5a034e7a7b767f4be71", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1202, "doc": {"premise": "The spirit of liberalism prevalent in Europe was tardy in reaching Spain.", "hypothesis": "Spain has never been liberal.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Yes, Spain has never been liberal."}, "gen_args_1": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? Also, Spain has never been liberal."}, "gen_args_2": {"arg_0": "", "arg_1": " The spirit of liberalism prevalent in Europe was tardy in reaching Spain., right? No, Spain has never been liberal."}}, "resps": [[["-114.5", "False"]], [["-116.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-116.0", "False"], ["-109.5", "False"]], "doc_hash": "27b34556b67f4e45278ab241a5533f718ee6a72287e9775707b02f5978399ba9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00668287 0.00149115 0.99182598]"]}
{"doc_id": 1210, "doc": {"premise": "At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades.", "hypothesis": "There are a lot of place to go both day and night.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Yes, There are a lot of place to go both day and night."}, "gen_args_1": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Also, There are a lot of place to go both day and night."}, "gen_args_2": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? No, There are a lot of place to go both day and night."}}, "resps": [[["-183.0", "False"]], [["-186.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-186.0", "False"], ["-186.0", "False"]], "doc_hash": "47dbc7f2e38fd59b4f1a8056385b5ffd0ad7a943ebfe002292104973610da1c6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1218, "doc": {"premise": "Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French.", "hypothesis": "Rocroi is where the Spanish people won.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Yes, Rocroi is where the Spanish people won."}, "gen_args_1": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Also, Rocroi is where the Spanish people won."}, "gen_args_2": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? No, Rocroi is where the Spanish people won."}}, "resps": [[["-166.0", "False"]], [["-167.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-167.0", "False"], ["-164.0", "False"]], "doc_hash": "29636d09e3f1e15b63b3ebe1ec5a42d6b54c653857a7aaf65d775d0b7f13c297", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1226, "doc": {"premise": "There are also plenty of venues for more  risque  or avant-garde performances.", "hypothesis": "There are places to that have adult performances.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Yes, There are places to that have adult performances."}, "gen_args_1": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? Also, There are places to that have adult performances."}, "gen_args_2": {"arg_0": "", "arg_1": " There are also plenty of venues for more  risque  or avant-garde performances., right? No, There are places to that have adult performances."}}, "resps": [[["-137.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "01ed4f31159a6e473f73c844a6cffe192a7577a58cd8291e6c8999ad89c6e64f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 1234, "doc": {"premise": "Later it held courts of law, and justice was dispensed here.", "hypothesis": "It had court held there for divorces and family matters.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Yes, It had court held there for divorces and family matters."}, "gen_args_1": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Also, It had court held there for divorces and family matters."}, "gen_args_2": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? No, It had court held there for divorces and family matters."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-132.0", "False"]], "doc_hash": "0b873208f6e6f47ecdac48d53e7095a327bd2336da56e322e5d9fe225e971c62", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1242, "doc": {"premise": "The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla.", "hypothesis": "Commercial activity and pedestrians are prohibited in Passeig de Gracia.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Yes, Commercial activity and pedestrians are prohibited in Passeig de Gracia."}, "gen_args_1": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Also, Commercial activity and pedestrians are prohibited in Passeig de Gracia."}, "gen_args_2": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? No, Commercial activity and pedestrians are prohibited in Passeig de Gracia."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-191.0", "False"]], "doc_hash": "c35ec4dc27e32bab9f32d7d3b47eb69d873af892c7db7569414a63476c3f8ef9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1250, "doc": {"premise": "Although funding strategies can be improved, funding is available for this work.", "hypothesis": "There is not enough funding for the work.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Yes, There is not enough funding for the work."}, "gen_args_1": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? Also, There is not enough funding for the work."}, "gen_args_2": {"arg_0": "", "arg_1": " Although funding strategies can be improved, funding is available for this work., right? No, There is not enough funding for the work."}}, "resps": [[["-111.5", "False"]], [["-114.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-111.5", "False"], ["-114.5", "False"], ["-108.0", "False"]], "doc_hash": "ff7f920da271adeccb3d6df5300d18d769173c65cda338f5e3757851b709e89b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.02926952 0.00145724 0.96927324]"]}
{"doc_id": 1258, "doc": {"premise": "A subject that is discussed during the entry interview is the household's reaction to advertising mail.", "hypothesis": "The entry interview doesn't mention anything about advertising mail.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Yes, The entry interview doesn't mention anything about advertising mail."}, "gen_args_1": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Also, The entry interview doesn't mention anything about advertising mail."}, "gen_args_2": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? No, The entry interview doesn't mention anything about advertising mail."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-141.0", "False"]], "doc_hash": "152c34d9ac10afb34c866fccfe9939d641ce7fa605750bb95d8a6a9ec7cf855f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1266, "doc": {"premise": "All nine responding agencies report participation in a", "hypothesis": "Only two of the nine agencies bothered to respond to our questions about participation.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Yes, Only two of the nine agencies bothered to respond to our questions about participation."}, "gen_args_1": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Also, Only two of the nine agencies bothered to respond to our questions about participation."}, "gen_args_2": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? No, Only two of the nine agencies bothered to respond to our questions about participation."}}, "resps": [[["-121.0", "False"]], [["-123.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-123.5", "False"], ["-119.0", "False"]], "doc_hash": "0e3b2943d12093dc8f9f67f0732aae16d8635e996d2baebc6317f49f0667de5c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11804785 0.00968996 0.87226219]"]}
{"doc_id": 1274, "doc": {"premise": "In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate.", "hypothesis": "The price is always less than cost.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Yes, The price is always less than cost."}, "gen_args_1": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? Also, The price is always less than cost."}, "gen_args_2": {"arg_0": "", "arg_1": " In the subclass approach, the basic and the workshare category are each given a percentage markup over cost, in order to obtain their average rate., right? No, The price is always less than cost."}}, "resps": [[["-190.0", "False"]], [["-188.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-188.0", "False"], ["-187.0", "False"]], "doc_hash": "7641ac03291f478ad34bd01e93d45ab278c3406dbef39e3e8d375b8fcb2d60ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.03511903 0.25949646 0.70538451]"]}
{"doc_id": 1282, "doc": {"premise": "The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource.", "hypothesis": "There aren't enough IT workers because they all went to India.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Yes, There aren't enough IT workers because they all went to India."}, "gen_args_1": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Also, There aren't enough IT workers because they all went to India."}, "gen_args_2": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? No, There aren't enough IT workers because they all went to India."}}, "resps": [[["-142.0", "False"]], [["-146.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-146.0", "False"], ["-139.0", "False"]], "doc_hash": "7bde2272488548cd0b02d5cc7e9cb2aab5fc5a19cf4f38fd638163babe5ddf90", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1290, "doc": {"premise": "Practice 4: Manage Risk on a Continuing Basis", "hypothesis": "Chapter four contains a practice exercise on managing risk.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Yes, Chapter four contains a practice exercise on managing risk."}, "gen_args_1": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Also, Chapter four contains a practice exercise on managing risk."}, "gen_args_2": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? No, Chapter four contains a practice exercise on managing risk."}}, "resps": [[["-111.0", "False"]], [["-115.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-111.0", "False"], ["-115.5", "False"], ["-117.0", "False"]], "doc_hash": "cdec397dd28b728511cecdc547b62e19dfb6d9aa18b1c23e6135ad0c4a48d877", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.9865944  0.01096007 0.00244552]"]}
{"doc_id": 1298, "doc": {"premise": "Some facility owners have been innovative in their construction plans to minimize down time.", "hypothesis": "More efficient inventory storage is a key part of minimizing down time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Yes, More efficient inventory storage is a key part of minimizing down time."}, "gen_args_1": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? Also, More efficient inventory storage is a key part of minimizing down time."}, "gen_args_2": {"arg_0": "", "arg_1": " Some facility owners have been innovative in their construction plans to minimize down time., right? No, More efficient inventory storage is a key part of minimizing down time."}}, "resps": [[["-142.0", "False"]], [["-144.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-144.0", "False"], ["-143.0", "False"]], "doc_hash": "9fd31eb7adb4e8dea7c3ef4ef4491c01c84dd424469a63a0b2576b18b97fd813", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1306, "doc": {"premise": "For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs.", "hypothesis": "Employees needed to charge all their food to the card.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Yes, Employees needed to charge all their food to the card."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Also, Employees needed to charge all their food to the card."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? No, Employees needed to charge all their food to the card."}}, "resps": [[["-156.0", "False"]], [["-157.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-157.0", "False"], ["-157.0", "False"]], "doc_hash": "5186f6dd51b6c467e4eb38e2c156c9a061243fe768b0c45b2d28a5e04699b879", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1314, "doc": {"premise": "This has been true in primary care settings as well.", "hypothesis": "That happened in primary care, too.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Yes, That happened in primary care, too."}, "gen_args_1": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Also, That happened in primary care, too."}, "gen_args_2": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? No, That happened in primary care, too."}}, "resps": [[["-88.0", "False"]], [["-96.0", "False"]], [["-91.0", "False"]]], "filtered_resps": [["-88.0", "False"], ["-96.0", "False"], ["-91.0", "False"]], "doc_hash": "6e12816da2c1bfaa498f0c532af1b40db8ad9feb871169dbc73d60332ada6669", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 1322, "doc": {"premise": "The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits.", "hypothesis": "They don't know how to calculate welfare effects.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Yes, They don't know how to calculate welfare effects."}, "gen_args_1": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? Also, They don't know how to calculate welfare effects."}, "gen_args_2": {"arg_0": "", "arg_1": " The welfare effects on the mailers who shift are calculated in the same way as in the above section on profits., right? No, They don't know how to calculate welfare effects."}}, "resps": [[["-162.0", "False"]], [["-164.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-164.0", "False"], ["-158.0", "False"]], "doc_hash": "11881a08a426e2c8c0bcc3ccbd0fe170994d4aae2eca68d8873b45fa1dddf948", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1330, "doc": {"premise": "The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected.", "hypothesis": "The estimates deal with long-term exposure, so the short-term is probably a lot less.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Yes, The estimates deal with long-term exposure, so the short-term is probably a lot less."}, "gen_args_1": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Also, The estimates deal with long-term exposure, so the short-term is probably a lot less."}, "gen_args_2": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? No, The estimates deal with long-term exposure, so the short-term is probably a lot less."}}, "resps": [[["-194.0", "False"]], [["-192.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-192.0", "False"], ["-194.0", "False"]], "doc_hash": "072db7cbe47dacfe87871d77432f151780513996b1f37bcc46e7f88e993e9a8e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 1338, "doc": {"premise": "This is a large challenge and a large expectation for any one system of intervention.", "hypothesis": "Every kind of intervention has challenges, but some have much more than others.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Yes, Every kind of intervention has challenges, but some have much more than others."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Also, Every kind of intervention has challenges, but some have much more than others."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? No, Every kind of intervention has challenges, but some have much more than others."}}, "resps": [[["-140.0", "False"]], [["-143.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-143.0", "False"], ["-143.0", "False"]], "doc_hash": "3a3443ce78f9fe44b358b445e9dcd147c73ac2e02fa463f50e937a9e40547123", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1346, "doc": {"premise": "The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages.", "hypothesis": "Technology doesn't help screening at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Yes, Technology doesn't help screening at all."}, "gen_args_1": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? Also, Technology doesn't help screening at all."}, "gen_args_2": {"arg_0": "", "arg_1": " The use of technology may reduce the time needed for providers and staff to personally provide screening and intervention services and target patients who can derive benefit from the brief intervention messages., right? No, Technology doesn't help screening at all."}}, "resps": [[["-201.0", "False"]], [["-202.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-202.0", "False"], ["-192.0", "False"]], "doc_hash": "3be512cf2a908ceae221e309c9eb021a03102194052fa76acee92e645dea4266", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.23388975e-04 4.53922671e-05 9.99831219e-01]"]}
{"doc_id": 1354, "doc": {"premise": "The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress.", "hypothesis": "We are requesting the money we need for this year.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Yes, We are requesting the money we need for this year."}, "gen_args_1": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Also, We are requesting the money we need for this year."}, "gen_args_2": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? No, We are requesting the money we need for this year."}}, "resps": [[["-143.0", "False"]], [["-148.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-148.0", "False"], ["-140.0", "False"]], "doc_hash": "d15110fe47808c14f291505c4a1d42d26d73ade282fa2d24a035bba8de7c2cb6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 1362, "doc": {"premise": "In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements.", "hypothesis": "A supporting CIO and corporate CIO might share control of a company in some organizations.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Yes, A supporting CIO and corporate CIO might share control of a company in some organizations."}, "gen_args_1": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Also, A supporting CIO and corporate CIO might share control of a company in some organizations."}, "gen_args_2": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? No, A supporting CIO and corporate CIO might share control of a company in some organizations."}}, "resps": [[["-231.0", "False"]], [["-236.0", "False"]], [["-231.0", "False"]]], "filtered_resps": [["-231.0", "False"], ["-236.0", "False"], ["-231.0", "False"]], "doc_hash": "760231eb8490847dcf03c9150caedfbfda880308926e0bc5838d3ccdb64820a1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1370, "doc": {"premise": "In addition, few postal administrations pay their employees as large a wage premium as does the U.S.", "hypothesis": "The US pays postal employees better than most countries.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Yes, The US pays postal employees better than most countries."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? Also, The US pays postal employees better than most countries."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, few postal administrations pay their employees as large a wage premium as does the U.S., right? No, The US pays postal employees better than most countries."}}, "resps": [[["-124.5", "False"]], [["-129.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-124.5", "False"], ["-129.0", "False"], ["-125.5", "False"]], "doc_hash": "2bf82a56495d2fefbaf136e7d949218b0b7e50036006900c0553d49573ed640e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72516924 0.0080559  0.26677486]"]}
{"doc_id": 1378, "doc": {"premise": "The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes.", "hypothesis": "The data concerning Population and Housing gathered in the 1990 Census is organized by ZIP Code.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Yes, The data concerning Population and Housing gathered in the 1990 Census is organized by ZIP Code."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Also, The data concerning Population and Housing gathered in the 1990 Census is organized by ZIP Code."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? No, The data concerning Population and Housing gathered in the 1990 Census is organized by ZIP Code."}}, "resps": [[["-143.0", "False"]], [["-148.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-148.0", "False"], ["-149.0", "False"]], "doc_hash": "128b64de33c091a690aacaa8d22ec54469133405e0ca34104ba36d8423bae276", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00667641 0.00245611]"]}
{"doc_id": 1386, "doc": {"premise": "We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002.", "hypothesis": "We intend to sever our relationship with your organization effective immediately.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Yes, We intend to sever our relationship with your organization effective immediately."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Also, We intend to sever our relationship with your organization effective immediately."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? No, We intend to sever our relationship with your organization effective immediately."}}, "resps": [[["-140.0", "False"]], [["-143.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-143.0", "False"], ["-133.0", "False"]], "doc_hash": "68b7724f6c4cee7122111ae7b9b58449af153f61a83fa27db88de8047f18ff2e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11009872e-04 4.53565108e-05 9.99043634e-01]"]}
{"doc_id": 1394, "doc": {"premise": "As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise.", "hypothesis": "The state does not need to worry about managing contracts.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Yes, The state does not need to worry about managing contracts."}, "gen_args_1": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? Also, The state does not need to worry about managing contracts."}, "gen_args_2": {"arg_0": "", "arg_1": " As the state contracts out more of its information technology and management functions, it is also essential that it have good contract management expertise., right? No, The state does not need to worry about managing contracts."}}, "resps": [[["-143.0", "False"]], [["-147.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-147.0", "False"], ["-140.0", "False"]], "doc_hash": "a0268c39b8ad10ac55009bbac5f4cd31ed6576ca1ed29e0769e930a7d7bab9d4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1402, "doc": {"premise": "Employer entity contributions to social insurance programs.", "hypothesis": "Employers give to social programs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Yes, Employers give to social programs."}, "gen_args_1": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Also, Employers give to social programs."}, "gen_args_2": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? No, Employers give to social programs."}}, "resps": [[["-106.0", "False"]], [["-108.5", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-106.0", "False"], ["-108.5", "False"], ["-106.5", "False"]], "doc_hash": "14b70aec9e5116dbdbd50891a3c0cafac8f8710d3b9fb03fbc1ecec1f6b64ab6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 1410, "doc": {"premise": "In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes.", "hypothesis": "The impact in France is greater than that in the United States.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Yes, The impact in France is greater than that in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Also, The impact in France is greater than that in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? No, The impact in France is greater than that in the United States."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-154.0", "False"]], "doc_hash": "60b98ce62f431b9ae2d0e2633978f460b2ecd94ebd9affea1de3e8f8d176b25f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1418, "doc": {"premise": "For clients who are illiterate in any language, materials would have to be carefully explained to them.", "hypothesis": "Illiterate people wouldn't understand the materials.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Yes, Illiterate people wouldn't understand the materials."}, "gen_args_1": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? Also, Illiterate people wouldn't understand the materials."}, "gen_args_2": {"arg_0": "", "arg_1": " For clients who are illiterate in any language, materials would have to be carefully explained to them., right? No, Illiterate people wouldn't understand the materials."}}, "resps": [[["-124.0", "False"]], [["-125.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-125.0", "False"], ["-122.5", "False"]], "doc_hash": "af720a01b77555423b4101aaa0b7d906c9f1d608a39b50695be640136b724a7a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.17095278 0.06289001 0.76615721]"]}
{"doc_id": 1426, "doc": {"premise": "When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage.", "hypothesis": "There was a six-week service outage.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Yes, There was a six-week service outage."}, "gen_args_1": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Also, There was a six-week service outage."}, "gen_args_2": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? No, There was a six-week service outage."}}, "resps": [[["-198.0", "False"]], [["-202.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-198.0", "False"], ["-202.0", "False"], ["-200.0", "False"]], "doc_hash": "4a09c5eca98f9f579979efc86997e7bbec84c10b27db5505f42cea06c6f219b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1434, "doc": {"premise": "In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated.", "hypothesis": "A new method of estimating the concentration-response relationship is needed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Yes, A new method of estimating the concentration-response relationship is needed."}, "gen_args_1": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Also, A new method of estimating the concentration-response relationship is needed."}, "gen_args_2": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? No, A new method of estimating the concentration-response relationship is needed."}}, "resps": [[["-123.0", "False"]], [["-125.0", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-125.0", "False"], ["-123.0", "False"]], "doc_hash": "32cf4349510f7756bd8416c2193adfff3eb0cff5b4b5d054c3478bc6a2e5e0c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1442, "doc": {"premise": "One size fits all does not work in brief interventions, just as it does not work in clinical practice in general.", "hypothesis": "One size fits all when it comes to brief interventions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Yes, One size fits all when it comes to brief interventions."}, "gen_args_1": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? Also, One size fits all when it comes to brief interventions."}, "gen_args_2": {"arg_0": "", "arg_1": " One size fits all does not work in brief interventions, just as it does not work in clinical practice in general., right? No, One size fits all when it comes to brief interventions."}}, "resps": [[["-109.5", "False"]], [["-113.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-109.5", "False"], ["-113.0", "False"], ["-109.5", "False"]], "doc_hash": "b4887070cefc91bbc75ca3091e0628c3e5796b00f0cdce1fbad007a9c57e841a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49256294 0.01487411 0.49256294]"]}
{"doc_id": 1450, "doc": {"premise": "Figure 6 displays the average unit costs generated with the cost function for the USPS.", "hypothesis": "The average cost for USPS is shown in figure 6.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Yes, The average cost for USPS is shown in figure 6."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Also, The average cost for USPS is shown in figure 6."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? No, The average cost for USPS is shown in figure 6."}}, "resps": [[["-133.0", "False"]], [["-136.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-136.0", "False"], ["-136.0", "False"]], "doc_hash": "ae598d07b7dda518bc4f30134579f048cb4d0bd7161475ac3be3a0319ea876d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1458, "doc": {"premise": "This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies.", "hypothesis": "Partners for Justice is not a cooperative project.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Yes, Partners for Justice is not a cooperative project."}, "gen_args_1": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Also, Partners for Justice is not a cooperative project."}, "gen_args_2": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? No, Partners for Justice is not a cooperative project."}}, "resps": [[["-216.0", "False"]], [["-215.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-216.0", "False"], ["-215.0", "False"], ["-207.0", "False"]], "doc_hash": "2df85b9195acb38f7316a20e0dd27839061e0c6d2312ddb9e191d1f0504618b7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.23353201e-04 3.35308764e-04 9.99541338e-01]"]}
{"doc_id": 1466, "doc": {"premise": "A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements.", "hypothesis": "Each company uses keys.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Yes, Each company uses keys."}, "gen_args_1": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? Also, Each company uses keys."}, "gen_args_2": {"arg_0": "", "arg_1": " A key tool used by each company to ensure that a product's design was stable by the end of the product integration phase was a demonstration that the design would meet requirements., right? No, Each company uses keys."}}, "resps": [[["-182.0", "False"]], [["-186.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-186.0", "False"], ["-183.0", "False"]], "doc_hash": "ba6d2d014645993fca8afcaf0b1463de676b708a40962596b3d6de9466544dd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1474, "doc": {"premise": "Case files would have to be copied and provided to the client.", "hypothesis": "The client will be left in the dark.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Yes, The client will be left in the dark."}, "gen_args_1": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Also, The client will be left in the dark."}, "gen_args_2": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? No, The client will be left in the dark."}}, "resps": [[["-104.0", "False"]], [["-105.5", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-105.5", "False"], ["-103.0", "False"]], "doc_hash": "024b5cb1b184f141e473854ad9bc1104916cdbc9a24976fccba397ddc0b0d7d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25371618 0.05661173 0.68967209]"]}
{"doc_id": 1482, "doc": {"premise": "Assets accumulated can generate income in the form of interest and dividends that in turn may be saved.", "hypothesis": "Assets make you lose money with interest.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Yes, Assets make you lose money with interest."}, "gen_args_1": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Also, Assets make you lose money with interest."}, "gen_args_2": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? No, Assets make you lose money with interest."}}, "resps": [[["-138.0", "False"]], [["-140.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-140.0", "False"], ["-130.0", "False"]], "doc_hash": "e046cd1f8af149be8da871186a41e5828f203baa49dc667d9c08e077f7ad1118", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35334911e-04 4.53826452e-05 9.99619282e-01]"]}
{"doc_id": 1490, "doc": {"premise": "receive a rating of pass if they meet the fully successful standard for an element.", "hypothesis": "Meeting fully the standard for an element will result in a rating of failure.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Yes, Meeting fully the standard for an element will result in a rating of failure."}, "gen_args_1": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? Also, Meeting fully the standard for an element will result in a rating of failure."}, "gen_args_2": {"arg_0": "", "arg_1": " receive a rating of pass if they meet the fully successful standard for an element., right? No, Meeting fully the standard for an element will result in a rating of failure."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "ca51a4a8910678285e6ad15e5ad952ada1deb7d37aa29973da46671c29e269f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1498, "doc": {"premise": "Other advisers have echoed this concern.", "hypothesis": "Only one adviser did not voice concern over this plan.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Yes, Only one adviser did not voice concern over this plan."}, "gen_args_1": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Also, Only one adviser did not voice concern over this plan."}, "gen_args_2": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? No, Only one adviser did not voice concern over this plan."}}, "resps": [[["-110.0", "False"]], [["-113.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-110.0", "False"], ["-113.0", "False"], ["-109.0", "False"]], "doc_hash": "7a097d53d3491f2bf15cfb700df212bf37c95ab9fac82f1809f03dc56c92800b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1506, "doc": {"premise": "It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers.", "hypothesis": "It's hard to install the system because hackers attack it every night.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Yes, It's hard to install the system because hackers attack it every night."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Also, It's hard to install the system because hackers attack it every night."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? No, It's hard to install the system because hackers attack it every night."}}, "resps": [[["-185.0", "False"]], [["-183.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-183.0", "False"], ["-182.0", "False"]], "doc_hash": "313b42a92c2ef324f6632f4e0aa972362bb61ab8645d6030db85c33784658610", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.03511903 0.25949646 0.70538451]"]}
{"doc_id": 1514, "doc": {"premise": "Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties.", "hypothesis": "Americans should pay attention to threats to our liberties.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Yes, Americans should pay attention to threats to our liberties."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? Also, Americans should pay attention to threats to our liberties."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, while protecting our homeland, Americans should be mindful of threats to vital personal and civil liberties., right? No, Americans should pay attention to threats to our liberties."}}, "resps": [[["-124.5", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "a2c140048e05b4a25cf81ce18e490fe23728fae4469cad79b38881c0af51f4b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.88814075e-01 2.01192387e-04 1.09847321e-02]"]}
{"doc_id": 1522, "doc": {"premise": "Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993.", "hypothesis": "Khalid Sheikh Mohammed was well known for his efforts to stamp out terrorism around the world.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Yes, Khalid Sheikh Mohammed was well known for his efforts to stamp out terrorism around the world."}, "gen_args_1": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Also, Khalid Sheikh Mohammed was well known for his efforts to stamp out terrorism around the world."}, "gen_args_2": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? No, Khalid Sheikh Mohammed was well known for his efforts to stamp out terrorism around the world."}}, "resps": [[["-177.0", "False"]], [["-176.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-176.0", "False"], ["-179.0", "False"]], "doc_hash": "02a869b0fd77580d90511936a48a1e3d3c72a960ed9d5c1a0536ce28fa2b5bf2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.70538451 0.03511903]"]}
{"doc_id": 1530, "doc": {"premise": "He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan).", "hypothesis": "It was not unusual for terrorists to travel through Pakistan into Afghanistan.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Yes, It was not unusual for terrorists to travel through Pakistan into Afghanistan."}, "gen_args_1": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Also, It was not unusual for terrorists to travel through Pakistan into Afghanistan."}, "gen_args_2": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? No, It was not unusual for terrorists to travel through Pakistan into Afghanistan."}}, "resps": [[["-186.0", "False"]], [["-188.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-188.0", "False"], ["-188.0", "False"]], "doc_hash": "7ced9dbcb18d5fadf97a9c011814dd3239c5e3495d54ef36a85728c0785c9d11", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1538, "doc": {"premise": "They make targets harder to attack successfully, and they deter attacks by making capture more likely.", "hypothesis": "They make the targets themselves more challenging so in turn they are making captures happen more often.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Yes, They make the targets themselves more challenging so in turn they are making captures happen more often."}, "gen_args_1": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? Also, They make the targets themselves more challenging so in turn they are making captures happen more often."}, "gen_args_2": {"arg_0": "", "arg_1": " They make targets harder to attack successfully, and they deter attacks by making capture more likely., right? No, They make the targets themselves more challenging so in turn they are making captures happen more often."}}, "resps": [[["-174.0", "False"]], [["-175.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-175.0", "False"], ["-173.0", "False"]], "doc_hash": "2e8b023df30c0874879e25b808a3720f16ec1e4fed5587cf94be8976dd1dc411", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1546, "doc": {"premise": "After Mihdhar left, other students moved into the house.", "hypothesis": "The pupils went into the home after Mihdhar was gone.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Yes, The pupils went into the home after Mihdhar was gone."}, "gen_args_1": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Also, The pupils went into the home after Mihdhar was gone."}, "gen_args_2": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? No, The pupils went into the home after Mihdhar was gone."}}, "resps": [[["-124.5", "False"]], [["-131.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-131.0", "False"], ["-127.0", "False"]], "doc_hash": "533f8821c93bf1920a3c1916ea4d0e5c4941ccd416344f33c4bbdbb3772c881a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92285961 0.00138746 0.07575293]"]}
{"doc_id": 1554, "doc": {"premise": "We ask every nation to join us.", "hypothesis": "We need at least 10 countries to join us", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Yes, We need at least 10 countries to join us"}, "gen_args_1": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Also, We need at least 10 countries to join us"}, "gen_args_2": {"arg_0": "", "arg_1": " We ask every nation to join us., right? No, We need at least 10 countries to join us"}}, "resps": [[["-87.5", "False"]], [["-90.5", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-87.5", "False"], ["-90.5", "False"], ["-89.0", "False"]], "doc_hash": "e03b5472b569c7396e0ae03915aa1d7a448c9493b8cdfdaf9b819f08dd98bd94", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78559703 0.03911257 0.17529039]"]}
{"doc_id": 1562, "doc": {"premise": "The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911.", "hypothesis": "The police were telling civilians to evacuate the area while the fire department was telling them to wait for rescue.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Yes, The police were telling civilians to evacuate the area while the fire department was telling them to wait for rescue."}, "gen_args_1": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? Also, The police were telling civilians to evacuate the area while the fire department was telling them to wait for rescue."}, "gen_args_2": {"arg_0": "", "arg_1": " The third party informed the police desk that the employees had previously received contrary advice from the FDNY, which could only have come via 911., right? No, The police were telling civilians to evacuate the area while the fire department was telling them to wait for rescue."}}, "resps": [[["-218.0", "False"]], [["-218.0", "False"]], [["-219.0", "False"]]], "filtered_resps": [["-218.0", "False"], ["-218.0", "False"], ["-219.0", "False"]], "doc_hash": "d2ffc85239f8ff76a8002ab0ae2e50e95c3f07c7456065068ab9fb3edae474ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1570, "doc": {"premise": "The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat.", "hypothesis": "Defense budgets were cut by more than fifty billion dollars per year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Yes, Defense budgets were cut by more than fifty billion dollars per year."}, "gen_args_1": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Also, Defense budgets were cut by more than fifty billion dollars per year."}, "gen_args_2": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? No, Defense budgets were cut by more than fifty billion dollars per year."}}, "resps": [[["-163.0", "False"]], [["-165.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-165.0", "False"], ["-165.0", "False"]], "doc_hash": "a48ccde2b1ef4eba5d51b963cc28ad14c7e390854d6aea52ba21301092458df4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1578, "doc": {"premise": "Our border screening system should check people efficiently and welcome friends.", "hypothesis": "The screening process at the border should be welcoming while also being productive.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Yes, The screening process at the border should be welcoming while also being productive."}, "gen_args_1": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Also, The screening process at the border should be welcoming while also being productive."}, "gen_args_2": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? No, The screening process at the border should be welcoming while also being productive."}}, "resps": [[["-143.0", "False"]], [["-147.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-147.0", "False"], ["-143.0", "False"]], "doc_hash": "e0f6cb045bb68df86ec4ea98e26146e9b58dcd2689283802f8132ffe8d6e839b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1586, "doc": {"premise": "Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing.", "hypothesis": "McLaughlin is the head of the FDA.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Yes, McLaughlin is the head of the FDA."}, "gen_args_1": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? Also, McLaughlin is the head of the FDA."}, "gen_args_2": {"arg_0": "", "arg_1": " Deputy Director of Central Intelligence John McLaughlin testified that he was told about Moussaoui several days before Tenet was briefed, although he did not recall the specific date of the briefing., right? No, McLaughlin is the head of the FDA."}}, "resps": [[["-157.0", "False"]], [["-155.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-155.0", "False"], ["-155.0", "False"]], "doc_hash": "9d3771ece86ae183deb1b473217822d6942ab6d994b236d27539638eebdb97f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 1594, "doc": {"premise": "The CTC analyst who drafted the briefing drew on reports over the previous four years.", "hypothesis": "The analyst had been working for the CTC for a decade.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Yes, The analyst had been working for the CTC for a decade."}, "gen_args_1": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Also, The analyst had been working for the CTC for a decade."}, "gen_args_2": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? No, The analyst had been working for the CTC for a decade."}}, "resps": [[["-140.0", "False"]], [["-140.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-140.0", "False"], ["-137.0", "False"]], "doc_hash": "d5424b73f88222b9f82351179f89de4e86d4ec89fbbd10994715bcd00cc24e2f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1602, "doc": {"premise": "Other evidence corroborates her account.", "hypothesis": "Her husband can corroborate her story.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Yes, Her husband can corroborate her story."}, "gen_args_1": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Also, Her husband can corroborate her story."}, "gen_args_2": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? No, Her husband can corroborate her story."}}, "resps": [[["-84.5", "False"]], [["-87.0", "False"]], [["-88.0", "False"]]], "filtered_resps": [["-84.5", "False"], ["-87.0", "False"], ["-88.0", "False"]], "doc_hash": "253b43d7945d43d971cf409c06f3a342ff6f73d027c1c6294732374392447b09", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.89905227 0.0737987  0.02714903]"]}
{"doc_id": 1610, "doc": {"premise": "It did not suggest that there was a domestic threat.", "hypothesis": "We had good reason to suspect that terror alerts would be raised shortly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Yes, We had good reason to suspect that terror alerts would be raised shortly."}, "gen_args_1": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? Also, We had good reason to suspect that terror alerts would be raised shortly."}, "gen_args_2": {"arg_0": "", "arg_1": " It did not suggest that there was a domestic threat., right? No, We had good reason to suspect that terror alerts would be raised shortly."}}, "resps": [[["-126.5", "False"]], [["-129.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-126.5", "False"], ["-129.0", "False"], ["-126.5", "False"]], "doc_hash": "9c85d1bef45e5b8580068424efeaa42fb4fff87b231ad464d07b43e626480ab1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48028779 0.03942442 0.48028779]"]}
{"doc_id": 1618, "doc": {"premise": "Current security requirements nurture overclassification and excessive compartmentation of information among agencies.", "hypothesis": "Security requirements do not compartmentalize information too much.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Yes, Security requirements do not compartmentalize information too much."}, "gen_args_1": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Also, Security requirements do not compartmentalize information too much."}, "gen_args_2": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? No, Security requirements do not compartmentalize information too much."}}, "resps": [[["-139.0", "False"]], [["-142.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-142.0", "False"], ["-136.0", "False"]], "doc_hash": "42a7af826bd164f73519b5f3b8c0a9b7e6cc5dc58960754299a53b51eedf1d6a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1626, "doc": {"premise": "There were numerous technical problems, especially with the Hellfire missiles.", "hypothesis": "The Hellfire missiles had technical errors.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Yes, The Hellfire missiles had technical errors."}, "gen_args_1": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Also, The Hellfire missiles had technical errors."}, "gen_args_2": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? No, The Hellfire missiles had technical errors."}}, "resps": [[["-101.0", "False"]], [["-106.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-101.0", "False"], ["-106.5", "False"], ["-105.0", "False"]], "doc_hash": "1822d3b6bd265e08851219e80d6873775dfef76e610ab4831d68a97843c279da", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97808846 0.00399722 0.01791432]"]}
{"doc_id": 1634, "doc": {"premise": "Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well.", "hypothesis": "The firefighter was certain that the tower they were in was safe.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Yes, The firefighter was certain that the tower they were in was safe."}, "gen_args_1": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? Also, The firefighter was certain that the tower they were in was safe."}, "gen_args_2": {"arg_0": "", "arg_1": " Finally, one firefighter-who had earlier seen from a window that the SouthTower had collapsed-urged that they all leave, as this tower could fall as well., right? No, The firefighter was certain that the tower they were in was safe."}}, "resps": [[["-206.0", "False"]], [["-207.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-207.0", "False"], ["-199.0", "False"]], "doc_hash": "475f4fa28968dc1c2b72f92fc98c7df5cc0a9f6264547759ef3ee3fb1d775fbc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10745952e-04 3.35044712e-04 9.98754209e-01]"]}
{"doc_id": 1642, "doc": {"premise": "We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press.", "hypothesis": "Yousef was arrested.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Yes, Yousef was arrested."}, "gen_args_1": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Also, Yousef was arrested."}, "gen_args_2": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? No, Yousef was arrested."}}, "resps": [[["-147.0", "False"]], [["-150.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-150.0", "False"], ["-148.0", "False"]], "doc_hash": "2e90cb3b3e1a963e2856494300c1601cde715acd3275c2a8ad4ce7547d657386", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1650, "doc": {"premise": "He also ordered Secretary Rumsfeld to develop a military plan against the Taliban.", "hypothesis": "A military plan against the Taliban was needed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Yes, A military plan against the Taliban was needed."}, "gen_args_1": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Also, A military plan against the Taliban was needed."}, "gen_args_2": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? No, A military plan against the Taliban was needed."}}, "resps": [[["-107.5", "False"]], [["-113.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-107.5", "False"], ["-113.5", "False"], ["-112.0", "False"]], "doc_hash": "f85679c2a82676b220c1175d58afcf644cc13c8687d22707692b01dda4812a12", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.9865944  0.00244552 0.01096007]"]}
{"doc_id": 1658, "doc": {"premise": "As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA.", "hypothesis": "The NSA had looked at the information on Mihdhar.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Yes, The NSA had looked at the information on Mihdhar."}, "gen_args_1": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? Also, The NSA had looked at the information on Mihdhar."}, "gen_args_2": {"arg_0": "", "arg_1": " As discussed earlier, the reason Jane decided she could not share information was because the initial information on Mihdhar had been analyzed by the NSA., right? No, The NSA had looked at the information on Mihdhar."}}, "resps": [[["-173.0", "False"]], [["-181.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-181.0", "False"], ["-177.0", "False"]], "doc_hash": "5859299a0248f5e3bbcb5288e7579b03bcc126a0eda59b5afbaa24fd700884e0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 1666, "doc": {"premise": "Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005.", "hypothesis": "The Patriot Act contained several controversial provisions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Yes, The Patriot Act contained several controversial provisions."}, "gen_args_1": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Also, The Patriot Act contained several controversial provisions."}, "gen_args_2": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? No, The Patriot Act contained several controversial provisions."}}, "resps": [[["-93.0", "False"]], [["-95.5", "False"]], [["-94.0", "False"]]], "filtered_resps": [["-93.0", "False"], ["-95.5", "False"], ["-94.0", "False"]], "doc_hash": "152dd5071e26fd3da1eae68f30ff6dc67c1a32780eb3d9b0dc6c3966165bf8ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 1674, "doc": {"premise": "His relationship with her remained close throughout his time in the United States.", "hypothesis": "He had a relationship with an American woman.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Yes, He had a relationship with an American woman."}, "gen_args_1": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Also, He had a relationship with an American woman."}, "gen_args_2": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? No, He had a relationship with an American woman."}}, "resps": [[["-98.5", "False"]], [["-102.5", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-102.5", "False"], ["-100.5", "False"]], "doc_hash": "0b54548506e2b618046bde30d2930f3013e3c7ac4b8dc8620965ec66961853d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1682, "doc": {"premise": "Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time.", "hypothesis": "Hazmi's housemate was suspicious.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Yes, Hazmi's housemate was suspicious."}, "gen_args_1": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? Also, Hazmi's housemate was suspicious."}, "gen_args_2": {"arg_0": "", "arg_1": " Hazmi's housemate remembers him taking an unexplained trip to the San Diego airport around this time., right? No, Hazmi's housemate was suspicious."}}, "resps": [[["-122.0", "False"]], [["-127.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-127.0", "False"], ["-126.5", "False"]], "doc_hash": "2aa4b9cff6a9c0a1780fb54c53a8cdadcce83622becded6e3e2dbd0a33ecf51a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98246599 0.0066198  0.01091421]"]}
{"doc_id": 1690, "doc": {"premise": "As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000.", "hypothesis": "He needed more money in order to travel.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Yes, He needed more money in order to travel."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Also, He needed more money in order to travel."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? No, He needed more money in order to travel."}}, "resps": [[["-193.0", "False"]], [["-195.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-195.0", "False"], ["-193.0", "False"]], "doc_hash": "c27d8de5ff1859b465ce43563684fb426badfa62d880b9bccbdbcb250e976268", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1698, "doc": {"premise": "His key personnel shared very little information with the National Security Council and the rest of the national security community.", "hypothesis": "His staff shared some information with the national security community.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Yes, His staff shared some information with the national security community."}, "gen_args_1": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Also, His staff shared some information with the national security community."}, "gen_args_2": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? No, His staff shared some information with the national security community."}}, "resps": [[["-126.5", "False"]], [["-130.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-130.0", "False"], ["-125.0", "False"]], "doc_hash": "0d5ad5a64765c6c74d34aa3736fe1e06cd2f15c9259edbc1603eb914162a1af1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.18142609 0.00547859 0.81309532]"]}
{"doc_id": 1706, "doc": {"premise": "More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens.", "hypothesis": "Only 20,000 people cross the border each year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Yes, Only 20,000 people cross the border each year."}, "gen_args_1": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? Also, Only 20,000 people cross the border each year."}, "gen_args_2": {"arg_0": "", "arg_1": " More than 500 million people annually cross U.S. borders at legal entry points, about 330 million of them noncitizens., right? No, Only 20,000 people cross the border each year."}}, "resps": [[["-143.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "c445dcc098778bc5de93b6254b6a931033a4cf65a03f06e1a535d651a80044fe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1714, "doc": {"premise": "The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject.", "hypothesis": "The Director did not believe that information sharing barriers should be entirely removed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Yes, The Director did not believe that information sharing barriers should be entirely removed."}, "gen_args_1": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Also, The Director did not believe that information sharing barriers should be entirely removed."}, "gen_args_2": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? No, The Director did not believe that information sharing barriers should be entirely removed."}}, "resps": [[["-192.0", "False"]], [["-194.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-194.0", "False"], ["-188.0", "False"]], "doc_hash": "7082727d86b502d222a9a63b0d1bdd6d4d0d1b628430257597a22ca8cde477db", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1722, "doc": {"premise": "Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted.", "hypothesis": "All of the 9/11 attackers were denied entry at the border.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Yes, All of the 9/11 attackers were denied entry at the border."}, "gen_args_1": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Also, All of the 9/11 attackers were denied entry at the border."}, "gen_args_2": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? No, All of the 9/11 attackers were denied entry at the border."}}, "resps": [[["-138.0", "False"]], [["-137.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-137.0", "False"], ["-136.0", "False"]], "doc_hash": "275c037220a44b0bfe9d2e489a2efc6539affb36f8dcbd2fa587848c340d5645", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 1730, "doc": {"premise": "One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility.", "hypothesis": "The CIA relied on financial tracking as it's primary counter terrorism tool.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Yes, The CIA relied on financial tracking as it's primary counter terrorism tool."}, "gen_args_1": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? Also, The CIA relied on financial tracking as it's primary counter terrorism tool."}, "gen_args_2": {"arg_0": "", "arg_1": " One Treasury official described CIA's posture as benign neglect toward the Foreign Terrorist Asset Tracking Center (FTATC), and characterized the CIA as believing that financial tracking had limited utility., right? No, The CIA relied on financial tracking as it's primary counter terrorism tool."}}, "resps": [[["-196.0", "False"]], [["-200.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-200.0", "False"], ["-196.0", "False"]], "doc_hash": "e832d7183c791bfe3ebd2082c4ff44faa939d948a70d232219de06b9445bb3bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1738, "doc": {"premise": "The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M.", "hypothesis": "The team consisted of more than a dozen people.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Yes, The team consisted of more than a dozen people."}, "gen_args_1": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Also, The team consisted of more than a dozen people."}, "gen_args_2": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? No, The team consisted of more than a dozen people."}}, "resps": [[["-169.0", "False"]], [["-170.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-170.0", "False"], ["-171.0", "False"]], "doc_hash": "fd1b5f480c3fce3aa427c985c3762c68dba2ae9b06cd5a361e8868ae02adfb6a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1746, "doc": {"premise": "It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence.", "hypothesis": "Our law school depends on private funding alone.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Yes, Our law school depends on private funding alone."}, "gen_args_1": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Also, Our law school depends on private funding alone."}, "gen_args_2": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? No, Our law school depends on private funding alone."}}, "resps": [[["-131.0", "False"]], [["-138.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-138.0", "False"], ["-130.0", "False"]], "doc_hash": "531aaf6283baaf9a705c879b34d354dd2a4bd8566acb441997316c031912d623", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68875482e-01 2.45182703e-04 7.30879336e-01]"]}
{"doc_id": 1754, "doc": {"premise": "Only with the help of our philanthropic partners have we been able to achieve so much.", "hypothesis": "We've been able to achieve a lot, due to the philanthropy we've received.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Yes, We've been able to achieve a lot, due to the philanthropy we've received."}, "gen_args_1": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? Also, We've been able to achieve a lot, due to the philanthropy we've received."}, "gen_args_2": {"arg_0": "", "arg_1": " Only with the help of our philanthropic partners have we been able to achieve so much., right? No, We've been able to achieve a lot, due to the philanthropy we've received."}}, "resps": [[["-113.5", "False"]], [["-120.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-120.0", "False"], ["-117.0", "False"]], "doc_hash": "6fd962ca4a465922519a404fe41e9b94ce670708c05dc7c16c9fcef7d4b53d11", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 1762, "doc": {"premise": "It's important that we hear from you during this last fundraising drive of the season.", "hypothesis": "We have two more fundraising drives this year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Yes, We have two more fundraising drives this year."}, "gen_args_1": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Also, We have two more fundraising drives this year."}, "gen_args_2": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? No, We have two more fundraising drives this year."}}, "resps": [[["-107.5", "False"]], [["-110.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-107.5", "False"], ["-110.0", "False"], ["-110.5", "False"]], "doc_hash": "c0e80aa1cf12276654df566f36e239e0222d60afec7d5be1021c2202a7e95574", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.88349207 0.07252145 0.04398648]"]}
{"doc_id": 1770, "doc": {"premise": "(dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling.", "hypothesis": "Everyone is paid a lot of money to work there.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Yes, Everyone is paid a lot of money to work there."}, "gen_args_1": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Also, Everyone is paid a lot of money to work there."}, "gen_args_2": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? No, Everyone is paid a lot of money to work there."}}, "resps": [[["-211.0", "False"]], [["-211.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-211.0", "False"], ["-211.0", "False"]], "doc_hash": "b90e204ece4744d6a657aee376cc79d835527e85374c34ced30b5d4bf9c49b09", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1778, "doc": {"premise": "Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment.", "hypothesis": "Supporting Goodwill will lower the unemployment rate.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Yes, Supporting Goodwill will lower the unemployment rate."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? Also, Supporting Goodwill will lower the unemployment rate."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support of Goodwill will provide job training and placement services to help the hardest to serve in central Indiana find meaningful employment., right? No, Supporting Goodwill will lower the unemployment rate."}}, "resps": [[["-124.0", "False"]], [["-129.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-129.0", "False"], ["-127.5", "False"]], "doc_hash": "187760492adca5d12bc8b5e320f81c6c15d939fb76a0b3d9ca69d98ed51b4456", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.9643803  0.00649794 0.02912176]"]}
{"doc_id": 1786, "doc": {"premise": "-conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol.", "hypothesis": "The costumes were only worked on by human hands.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Yes, The costumes were only worked on by human hands."}, "gen_args_1": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Also, The costumes were only worked on by human hands."}, "gen_args_2": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? No, The costumes were only worked on by human hands."}}, "resps": [[["-201.0", "False"]], [["-200.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-200.0", "False"], ["-200.0", "False"]], "doc_hash": "7060a282ca860150f47120eb68b0aa887e8dbd21646bb04603d3591ab1ece860", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1794, "doc": {"premise": "The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable.", "hypothesis": "Creating the homes was completely free of charge.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Yes, Creating the homes was completely free of charge."}, "gen_args_1": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Also, Creating the homes was completely free of charge."}, "gen_args_2": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? No, Creating the homes was completely free of charge."}}, "resps": [[["-169.0", "False"]], [["-173.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-173.0", "False"], ["-165.0", "False"]], "doc_hash": "a828e3c699b1177d0dbde728c5a0bb9ca761cfa06cae2d9ce9cde82b84a3486e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 1802, "doc": {"premise": "Your investment continues the high quality of all aspects of the Museum and makes new achievements possible.", "hypothesis": "The Museum is impacted by investments.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Yes, The Museum is impacted by investments."}, "gen_args_1": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? Also, The Museum is impacted by investments."}, "gen_args_2": {"arg_0": "", "arg_1": " Your investment continues the high quality of all aspects of the Museum and makes new achievements possible., right? No, The Museum is impacted by investments."}}, "resps": [[["-132.0", "False"]], [["-139.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-139.0", "False"], ["-137.0", "False"]], "doc_hash": "a21c9187b9412f9267c15975ee6b4353c0b35f6d1fb7e3cd1f2542c934dfe54d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 9.04959183e-04 6.68679417e-03]"]}
{"doc_id": 1810, "doc": {"premise": "The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students.", "hypothesis": "The IRT is involved in the theater for middle schoolers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Yes, The IRT is involved in the theater for middle schoolers."}, "gen_args_1": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Also, The IRT is involved in the theater for middle schoolers."}, "gen_args_2": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? No, The IRT is involved in the theater for middle schoolers."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-154.0", "False"]], "doc_hash": "8f63c455674060f1964161aa6f8e30fe570ffbdb75113088c24d3630d06aa3d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1818, "doc": {"premise": "Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs.", "hypothesis": "We don't plan on expanding at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Yes, We don't plan on expanding at all."}, "gen_args_1": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Also, We don't plan on expanding at all."}, "gen_args_2": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? No, We don't plan on expanding at all."}}, "resps": [[["-167.0", "False"]], [["-171.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-171.0", "False"], ["-164.0", "False"]], "doc_hash": "cc4afc81e03b78ab28c979e20bf99274bd26088592cde870b344a2be4b721aaf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1826, "doc": {"premise": "Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story.", "hypothesis": "It rained last Sunday.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Yes, It rained last Sunday."}, "gen_args_1": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? Also, It rained last Sunday."}, "gen_args_2": {"arg_0": "", "arg_1": " Last Sunday, June 18th, the rain came and severely curtailed attendance at this year's Keepers of the Lore/Joseph Campbell Festival of Myth, Folklore and Story., right? No, It rained last Sunday."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-168.0", "False"]], "doc_hash": "0278a71279cace893be37f1165fc949c5032bb1cf107da478dbe0530bda018e0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1834, "doc": {"premise": "The law school's 5,539 alumni form a distinguished group.", "hypothesis": "The law school has only had 20 graduates.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Yes, The law school has only had 20 graduates."}, "gen_args_1": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Also, The law school has only had 20 graduates."}, "gen_args_2": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? No, The law school has only had 20 graduates."}}, "resps": [[["-121.0", "False"]], [["-123.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-123.5", "False"], ["-116.0", "False"]], "doc_hash": "e83a5041c9a485838909358c484d0455a53e6f9f1fe3c2bd437e3d016acf05fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68917601e-03 5.49081003e-04 9.92761743e-01]"]}
{"doc_id": 1842, "doc": {"premise": "Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school.", "hypothesis": "The Maennerchor Society gets donations.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Yes, The Maennerchor Society gets donations."}, "gen_args_1": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Also, The Maennerchor Society gets donations."}, "gen_args_2": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? No, The Maennerchor Society gets donations."}}, "resps": [[["-144.0", "False"]], [["-148.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-148.0", "False"], ["-147.0", "False"]], "doc_hash": "5884c8b295f61f5387ce9fa66e70111cd4cee996ba5635f1739c617fdabdf4a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1850, "doc": {"premise": "Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ...", "hypothesis": "The group is full of inmates and crooks.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Yes, The group is full of inmates and crooks."}, "gen_args_1": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? Also, The group is full of inmates and crooks."}, "gen_args_2": {"arg_0": "", "arg_1": " Specifically, you will be joining a group of distinguished foundation executives, business leaders, scholars, development professionals and volunteers in the nonprofit sector ..., right? No, The group is full of inmates and crooks."}}, "resps": [[["-171.0", "False"]], [["-172.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-172.0", "False"], ["-167.0", "False"]], "doc_hash": "57aecdfc8788e99d4c22c80f783a567efe1ba20fd120979591fa096355185a77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1858, "doc": {"premise": "In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole.", "hypothesis": "They believed that the organization would make life better for the city's elderly.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Yes, They believed that the organization would make life better for the city's elderly."}, "gen_args_1": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Also, They believed that the organization would make life better for the city's elderly."}, "gen_args_2": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? No, They believed that the organization would make life better for the city's elderly."}}, "resps": [[["-147.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "7e946847e10e3641499f8c6385c0d7b0b60b1b0b35297c370f3a3fee2b7102d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1866, "doc": {"premise": "Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age.", "hypothesis": "The programs focused on getting kids to go outside and play.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Yes, The programs focused on getting kids to go outside and play."}, "gen_args_1": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Also, The programs focused on getting kids to go outside and play."}, "gen_args_2": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? No, The programs focused on getting kids to go outside and play."}}, "resps": [[["-189.0", "False"]], [["-191.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-191.0", "False"], ["-190.0", "False"]], "doc_hash": "24843545571a8f4e3c97f64b94886d91f9354ff900ba9ef0f66cd3c460f036ba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1874, "doc": {"premise": ".. why they have so little self-worth that they value the friendship of thieves and killers.", "hypothesis": "Some of their friends have stolen bubble gum.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Yes, Some of their friends have stolen bubble gum."}, "gen_args_1": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? Also, Some of their friends have stolen bubble gum."}, "gen_args_2": {"arg_0": "", "arg_1": " .. why they have so little self-worth that they value the friendship of thieves and killers., right? No, Some of their friends have stolen bubble gum."}}, "resps": [[["-146.0", "False"]], [["-147.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-147.0", "False"], ["-148.0", "False"]], "doc_hash": "c1c99a1ed824b7a0f253958a37a0470b532b6326fb6bfd90fb7147033a55a9cc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1882, "doc": {"premise": "To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext.", "hypothesis": "Kathy Dannels answers calls promptly", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Yes, Kathy Dannels answers calls promptly"}, "gen_args_1": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Also, Kathy Dannels answers calls promptly"}, "gen_args_2": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? No, Kathy Dannels answers calls promptly"}}, "resps": [[["-152.0", "False"]], [["-158.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-158.0", "False"], ["-154.0", "False"]], "doc_hash": "9d115b3dfa7545ce6f69c9bd1207066bcb8ea7b273d519948605aef82c769fbc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1890, "doc": {"premise": "When Urban left for Vietnam, we'd only been married a short time, JoAnn said.", "hypothesis": "JoAnn and Urban had just celebrated their 50th wedding anniversary when he left for Vietnam.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Yes, JoAnn and Urban had just celebrated their 50th wedding anniversary when he left for Vietnam."}, "gen_args_1": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Also, JoAnn and Urban had just celebrated their 50th wedding anniversary when he left for Vietnam."}, "gen_args_2": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? No, JoAnn and Urban had just celebrated their 50th wedding anniversary when he left for Vietnam."}}, "resps": [[["-139.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "f71c4de23abc841c3f3d554bf369d148bd70d20a6ce6a9789e72f1cc32a596ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1898, "doc": {"premise": "Student tuition has been raised 12% for 1992-92, a significant increase.", "hypothesis": "The tuition rate will continue to climb each year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Yes, The tuition rate will continue to climb each year."}, "gen_args_1": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? Also, The tuition rate will continue to climb each year."}, "gen_args_2": {"arg_0": "", "arg_1": " Student tuition has been raised 12% for 1992-92, a significant increase., right? No, The tuition rate will continue to climb each year."}}, "resps": [[["-124.5", "False"]], [["-126.5", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-124.5", "False"], ["-126.5", "False"], ["-125.5", "False"]], "doc_hash": "a479488212423df5a22a09df309ea5978b4b3b28253a3ebd4771f7fe67958198", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1906, "doc": {"premise": "This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design.", "hypothesis": "The space is all concrete and is really ugly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Yes, The space is all concrete and is really ugly."}, "gen_args_1": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Also, The space is all concrete and is really ugly."}, "gen_args_2": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? No, The space is all concrete and is really ugly."}}, "resps": [[["-203.0", "False"]], [["-203.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-203.0", "False"], ["-200.0", "False"]], "doc_hash": "155e982f046340ae3dd292335ff5ae65892675549a30c435a0498a0a4f8f95cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1914, "doc": {"premise": "Many see philanthropy as no more than the grand gestures of the rich.", "hypothesis": "Everyone realizes that we all have to donate if we want to make an impact.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Yes, Everyone realizes that we all have to donate if we want to make an impact."}, "gen_args_1": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Also, Everyone realizes that we all have to donate if we want to make an impact."}, "gen_args_2": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? No, Everyone realizes that we all have to donate if we want to make an impact."}}, "resps": [[["-129.0", "False"]], [["-131.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-131.0", "False"], ["-131.0", "False"]], "doc_hash": "4ba6f9bcdf8ac6287a56dbafaa5615a7b0be911194a085fb88cb6a2402e000bf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1922, "doc": {"premise": "By May 1, we must conclude membership renewal options for 1991 contributors.", "hypothesis": "We just accept renewals whenever.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Yes, We just accept renewals whenever."}, "gen_args_1": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? Also, We just accept renewals whenever."}, "gen_args_2": {"arg_0": "", "arg_1": " By May 1, we must conclude membership renewal options for 1991 contributors., right? No, We just accept renewals whenever."}}, "resps": [[["-149.0", "False"]], [["-153.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-153.0", "False"], ["-144.0", "False"]], "doc_hash": "4d378ba4e2990b48681d39610b9578d249d1da070af524edfb136000e6922a66", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 1930, "doc": {"premise": "learn to walk in someone else's shoes", "hypothesis": "Live under the conditions that someone does.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Yes, Live under the conditions that someone does."}, "gen_args_1": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Also, Live under the conditions that someone does."}, "gen_args_2": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? No, Live under the conditions that someone does."}}, "resps": [[["-86.5", "False"]], [["-88.5", "False"]], [["-89.5", "False"]]], "filtered_resps": [["-86.5", "False"], ["-88.5", "False"], ["-89.5", "False"]], "doc_hash": "b986ac0a8f7ea799d2d4e526efa5e02b2619bf8d95c1f810e6da512407c45870", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1938, "doc": {"premise": "These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state.", "hypothesis": "Campus visits show students what college life is like.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Yes, Campus visits show students what college life is like."}, "gen_args_1": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Also, Campus visits show students what college life is like."}, "gen_args_2": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? No, Campus visits show students what college life is like."}}, "resps": [[["-179.0", "False"]], [["-178.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-178.0", "False"], ["-179.0", "False"]], "doc_hash": "8be32ddd3e12ca26951d19a42b27f171db8edd0318b05bb59893b43c5fa3fe76", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 1946, "doc": {"premise": "Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana.", "hypothesis": "We wish we could afford to create fully professional theatre productions, but we have never had the funds here in Indiana.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Yes, We wish we could afford to create fully professional theatre productions, but we have never had the funds here in Indiana."}, "gen_args_1": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? Also, We wish we could afford to create fully professional theatre productions, but we have never had the funds here in Indiana."}, "gen_args_2": {"arg_0": "", "arg_1": " Fully professional, fully produced theatre has made a difference to children like Becky, Stephanie, Marcus, Emily, and their classmates from across the state of Indiana., right? No, We wish we could afford to create fully professional theatre productions, but we have never had the funds here in Indiana."}}, "resps": [[["-234.0", "False"]], [["-238.0", "False"]], [["-236.0", "False"]]], "filtered_resps": [["-234.0", "False"], ["-238.0", "False"], ["-236.0", "False"]], "doc_hash": "71f6f7338b1778677d596940bd9abfcffd73ed80b8036b59d4f580b95fc1b5ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1954, "doc": {"premise": "It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo.", "hypothesis": "The animals at the zoo benefit from this a lot.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Yes, The animals at the zoo benefit from this a lot."}, "gen_args_1": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Also, The animals at the zoo benefit from this a lot."}, "gen_args_2": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? No, The animals at the zoo benefit from this a lot."}}, "resps": [[["-121.0", "False"]], [["-122.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-122.0", "False"], ["-124.0", "False"]], "doc_hash": "950a68d13a471a3c1258aab211b3d8bd13c5a928f914cdd4c148ce744be80337", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 1962, "doc": {"premise": "Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre.", "hypothesis": "The Civic Theater is downtown Indianapolis.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Yes, The Civic Theater is downtown Indianapolis."}, "gen_args_1": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Also, The Civic Theater is downtown Indianapolis."}, "gen_args_2": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? No, The Civic Theater is downtown Indianapolis."}}, "resps": [[["-133.0", "False"]], [["-140.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-140.0", "False"], ["-137.0", "False"]], "doc_hash": "dc392f76a52a044dd8ba2af1e01c63fb07f401e674c7159b085dad4338e9ee9f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1970, "doc": {"premise": ".. wisps of white clouds scattered across a clear, blue sky.", "hypothesis": "The sun is behind a fluffy cloud, the shape of a bunny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Yes, The sun is behind a fluffy cloud, the shape of a bunny."}, "gen_args_1": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? Also, The sun is behind a fluffy cloud, the shape of a bunny."}, "gen_args_2": {"arg_0": "", "arg_1": " .. wisps of white clouds scattered across a clear, blue sky., right? No, The sun is behind a fluffy cloud, the shape of a bunny."}}, "resps": [[["-127.5", "False"]], [["-130.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-130.0", "False"], ["-125.0", "False"]], "doc_hash": "7f6eeae05ff1fb5e8227f51fc407919582845153f2d513966c4fcf9cd6291c1f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07538875 0.00618829 0.91842297]"]}
{"doc_id": 1978, "doc": {"premise": "Technology, although seemingly indispensable, has caused us to go into hyperspeed.", "hypothesis": "Technology has made us speed up.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Yes, Technology has made us speed up."}, "gen_args_1": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Also, Technology has made us speed up."}, "gen_args_2": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? No, Technology has made us speed up."}}, "resps": [[["-110.0", "False"]], [["-117.0", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-110.0", "False"], ["-117.0", "False"], ["-113.0", "False"]], "doc_hash": "b58dc8283343f846bf6fffd4543c4aaa6d96e62eed2437ed1b75ebc67cfe5901", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 1986, "doc": {"premise": "For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000.", "hypothesis": "The law school has to deal with budget cuts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Yes, The law school has to deal with budget cuts."}, "gen_args_1": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Also, The law school has to deal with budget cuts."}, "gen_args_2": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? No, The law school has to deal with budget cuts."}}, "resps": [[["-156.0", "False"]], [["-159.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-159.0", "False"], ["-157.0", "False"]], "doc_hash": "f07bb7854f6379ada0a994e8b31b9f0d0605085df7502945f31b3840477eda1f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1994, "doc": {"premise": "With OPEN going platinum, why not a neon CLOSED sign?", "hypothesis": "The OPEN sign lights up.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Yes, The OPEN sign lights up."}, "gen_args_1": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? Also, The OPEN sign lights up."}, "gen_args_2": {"arg_0": "", "arg_1": " With OPEN going platinum, why not a neon CLOSED sign?, right? No, The OPEN sign lights up."}}, "resps": [[["-129.0", "False"]], [["-130.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-130.0", "False"], ["-130.0", "False"]], "doc_hash": "3043ce381efae63788e9235000ffb62f0cf6f8eb504f31415064cd50201e08bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2002, "doc": {"premise": "The main point, though, is that there aren't actually all that many Milosevics in the world.", "hypothesis": "There are many Milosevics in the world.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Yes, There are many Milosevics in the world."}, "gen_args_1": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Also, There are many Milosevics in the world."}, "gen_args_2": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? No, There are many Milosevics in the world."}}, "resps": [[["-107.0", "False"]], [["-112.0", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-107.0", "False"], ["-112.0", "False"], ["-106.5", "False"]], "doc_hash": "539f4205a715cbed5e6b0158bb71ea7c1c11575d16bdcd43116b00feee17aac6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.3765827  0.00253739 0.62087991]"]}
{"doc_id": 2010, "doc": {"premise": "Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory.", "hypothesis": "Alan Greenspan has economic theories regarding the unemployment rate.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Yes, Alan Greenspan has economic theories regarding the unemployment rate."}, "gen_args_1": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Also, Alan Greenspan has economic theories regarding the unemployment rate."}, "gen_args_2": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? No, Alan Greenspan has economic theories regarding the unemployment rate."}}, "resps": [[["-159.0", "False"]], [["-162.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-162.0", "False"], ["-163.0", "False"]], "doc_hash": "160005d3c0d17bcdae8b4453980c58e0dfac18f3e704c0f75866271019495d95", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2018, "doc": {"premise": "Steve, I couldn't even lift your wallet, Hatch shot back.", "hypothesis": "Hatch joked thay he couldn't even lift Steve's wallet.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Yes, Hatch joked thay he couldn't even lift Steve's wallet."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? Also, Hatch joked thay he couldn't even lift Steve's wallet."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve, I couldn't even lift your wallet, Hatch shot back., right? No, Hatch joked thay he couldn't even lift Steve's wallet."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "af22c23dbae9e395de6573bd09989ce142246f3c3f1912eff813be8c0d8d98a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 2026, "doc": {"premise": "Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters.", "hypothesis": "Photograph of Bill Clinton on the Vanity Fair Table of Contents by Ralph Emerson/AP News.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Yes, Photograph of Bill Clinton on the Vanity Fair Table of Contents by Ralph Emerson/AP News."}, "gen_args_1": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Also, Photograph of Bill Clinton on the Vanity Fair Table of Contents by Ralph Emerson/AP News."}, "gen_args_2": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? No, Photograph of Bill Clinton on the Vanity Fair Table of Contents by Ralph Emerson/AP News."}}, "resps": [[["-145.0", "False"]], [["-144.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-144.0", "False"], ["-138.0", "False"]], "doc_hash": "327293e48fc8ebc4a3fbb5f683140b47e58fe7e980b6e0f415e63c7f1c288ebe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.08800555e-04 2.47037604e-03 9.96620823e-01]"]}
{"doc_id": 2034, "doc": {"premise": "Population growth is like pollution in reverse.", "hypothesis": "Pollution is a limiting factor for population growth.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Yes, Pollution is a limiting factor for population growth."}, "gen_args_1": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Also, Pollution is a limiting factor for population growth."}, "gen_args_2": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? No, Pollution is a limiting factor for population growth."}}, "resps": [[["-92.5", "False"]], [["-95.0", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-92.5", "False"], ["-95.0", "False"], ["-95.0", "False"]], "doc_hash": "9606cb99545b336d5edb8fc1c22f8c0fc43580ea86d360404c99fd2e88d6da23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.85898108 0.07050946 0.07050946]"]}
{"doc_id": 2042, "doc": {"premise": "Sabol said he has to take the occasional pit stop, but even that is conveniently arranged.", "hypothesis": "Sabol remarked that he does not need to take any breaks.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Yes, Sabol remarked that he does not need to take any breaks."}, "gen_args_1": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? Also, Sabol remarked that he does not need to take any breaks."}, "gen_args_2": {"arg_0": "", "arg_1": " Sabol said he has to take the occasional pit stop, but even that is conveniently arranged., right? No, Sabol remarked that he does not need to take any breaks."}}, "resps": [[["-147.0", "False"]], [["-147.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-147.0", "False"], ["-143.0", "False"]], "doc_hash": "5edff4032bcdeb894c0972edab1634e51020d81ed95f60c0d7ce2eddaaca3a92", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 2050, "doc": {"premise": "The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority.", "hypothesis": "The USDA says they need a bigger force.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Yes, The USDA says they need a bigger force."}, "gen_args_1": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Also, The USDA says they need a bigger force."}, "gen_args_2": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? No, The USDA says they need a bigger force."}}, "resps": [[["-158.0", "False"]], [["-159.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-159.0", "False"], ["-156.0", "False"]], "doc_hash": "f33925d5700aa60ff64fe407e171b73f8b6342b686532780d89795791ada521d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 2058, "doc": {"premise": "The junk yards of history are strewn with wreckage.", "hypothesis": "Junk yards are storage facilities with clean, new, products stored in neat columns.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Yes, Junk yards are storage facilities with clean, new, products stored in neat columns."}, "gen_args_1": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Also, Junk yards are storage facilities with clean, new, products stored in neat columns."}, "gen_args_2": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? No, Junk yards are storage facilities with clean, new, products stored in neat columns."}}, "resps": [[["-152.0", "False"]], [["-155.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-155.0", "False"], ["-147.0", "False"]], "doc_hash": "8da92df705eef00e44316ca66d93f1803b7b284c1e6e044ec88c2a47bda1a068", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 2066, "doc": {"premise": "The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous.", "hypothesis": "Livingston's resignation may have let Clinton appear generous.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Yes, Livingston's resignation may have let Clinton appear generous."}, "gen_args_1": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? Also, Livingston's resignation may have let Clinton appear generous."}, "gen_args_2": {"arg_0": "", "arg_1": " The ultimate perverse consequence of Livingston's resignation is that it has allowed Clinton to appear magnanimous., right? No, Livingston's resignation may have let Clinton appear generous."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "d63c419c98d893a5ed0868a44b3efdd785a397895008fc587433c9bd18e2dc84", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 2074, "doc": {"premise": "Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system.", "hypothesis": "Less people are getting sick these days because of improved hygiene.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Yes, Less people are getting sick these days because of improved hygiene."}, "gen_args_1": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Also, Less people are getting sick these days because of improved hygiene."}, "gen_args_2": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? No, Less people are getting sick these days because of improved hygiene."}}, "resps": [[["-175.0", "False"]], [["-175.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-175.0", "False"], ["-177.0", "False"]], "doc_hash": "729a99e8ed4c94dcfe0de61181b967a1c340116366744afc5cc2fe4afe1a5e3c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 2082, "doc": {"premise": "Prudie agrees there is something tacky about being seen chewing gum.", "hypothesis": "Prudie gave up chewing bubble gum when he was in college.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Yes, Prudie gave up chewing bubble gum when he was in college."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Also, Prudie gave up chewing bubble gum when he was in college."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? No, Prudie gave up chewing bubble gum when he was in college."}}, "resps": [[["-133.0", "False"]], [["-132.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-132.0", "False"], ["-134.0", "False"]], "doc_hash": "bf32129f04eb8ce45451789a68652cae6e0938b3e3cb35891445b8fbb0ccfd45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2090, "doc": {"premise": "This kind of treatment for big contributors is quite routine.", "hypothesis": "There is nothing new in this kind of treatment for big contributors.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Yes, There is nothing new in this kind of treatment for big contributors."}, "gen_args_1": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? Also, There is nothing new in this kind of treatment for big contributors."}, "gen_args_2": {"arg_0": "", "arg_1": " This kind of treatment for big contributors is quite routine., right? No, There is nothing new in this kind of treatment for big contributors."}}, "resps": [[["-111.5", "False"]], [["-118.0", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-111.5", "False"], ["-118.0", "False"], ["-114.0", "False"]], "doc_hash": "df08eb889cc743628bd6543fb22f5e9b1b6447d09667626cceffabe722f859ef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92285961 0.00138746 0.07575293]"]}
{"doc_id": 2098, "doc": {"premise": "Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private.", "hypothesis": "The public knows very little about Pynchon's private life.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Yes, The public knows very little about Pynchon's private life."}, "gen_args_1": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Also, The public knows very little about Pynchon's private life."}, "gen_args_2": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? No, The public knows very little about Pynchon's private life."}}, "resps": [[["-152.0", "False"]], [["-157.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-157.0", "False"], ["-154.0", "False"]], "doc_hash": "567a1d11ed7920380e5b7ab30a2f88fa9e61d7ddbfaa1df913a1cc3c563fd890", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2106, "doc": {"premise": "Let me show you how the American people in the end viewed your performance as independent counsel.", "hypothesis": "The American people formed an opinion about your performance as independent counsel.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Yes, The American people formed an opinion about your performance as independent counsel."}, "gen_args_1": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Also, The American people formed an opinion about your performance as independent counsel."}, "gen_args_2": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? No, The American people formed an opinion about your performance as independent counsel."}}, "resps": [[["-129.0", "False"]], [["-132.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-132.0", "False"], ["-130.0", "False"]], "doc_hash": "aeaddf53b54e05510983b41960e655124313295fc5a6ef5d3df6b6027ef6441f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 2114, "doc": {"premise": "Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state.", "hypothesis": "Time has never written about Henry Kissinger.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Yes, Time has never written about Henry Kissinger."}, "gen_args_1": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? Also, Time has never written about Henry Kissinger."}, "gen_args_2": {"arg_0": "", "arg_1": " Speaking of White House advisers, Time excerpts Henry Kissinger's account of his years as Nixon's secretary of state., right? No, Time has never written about Henry Kissinger."}}, "resps": [[["-127.0", "False"]], [["-130.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-130.0", "False"], ["-121.0", "False"]], "doc_hash": "42a196dce648e3a0f7a381b6bc4bedc48f664d32a955cd20227eee44da0e6d70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47231880e-03 1.23089505e-04 9.97404592e-01]"]}
{"doc_id": 2122, "doc": {"premise": "Three Japanese banks will merge to create the world's largest financial institution.", "hypothesis": "The merger will make another insignificant bank.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Yes, The merger will make another insignificant bank."}, "gen_args_1": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Also, The merger will make another insignificant bank."}, "gen_args_2": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? No, The merger will make another insignificant bank."}}, "resps": [[["-111.5", "False"]], [["-113.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-111.5", "False"], ["-113.5", "False"], ["-105.0", "False"]], "doc_hash": "8b59b804f7de21888d051c0b5f1e7b0e290161c571b0ebea44862f4b9f941066", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.50087733e-03 2.03121659e-04 9.98296001e-01]"]}
{"doc_id": 2130, "doc": {"premise": "Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done.", "hypothesis": "Prudie says you should take this very seriously.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Yes, Prudie says you should take this very seriously."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Also, Prudie says you should take this very seriously."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? No, Prudie says you should take this very seriously."}}, "resps": [[["-160.0", "False"]], [["-161.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-161.0", "False"], ["-154.0", "False"]], "doc_hash": "9c92cc2bcf47811397304776100847cf4b27f20de788c0e4736585ba176d7b6d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 2138, "doc": {"premise": "There is a difference between canny skepticism and dumbbell skepticism.", "hypothesis": "Canny skepticism is more common than dumbbell skepticism.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Yes, Canny skepticism is more common than dumbbell skepticism."}, "gen_args_1": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? Also, Canny skepticism is more common than dumbbell skepticism."}, "gen_args_2": {"arg_0": "", "arg_1": " There is a difference between canny skepticism and dumbbell skepticism., right? No, Canny skepticism is more common than dumbbell skepticism."}}, "resps": [[["-102.5", "False"]], [["-104.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-104.0", "False"], ["-105.5", "False"]], "doc_hash": "ac3a7147e6ade734c5604458cbd3e3883db29a0789a29273db20732815f30dc4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78559703 0.17529039 0.03911257]"]}
{"doc_id": 2146, "doc": {"premise": "Soderbergh is one of those rare filmmakers who learn on the job.", "hypothesis": "Rob Soderbergh is an award winning filmmaker.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Yes, Rob Soderbergh is an award winning filmmaker."}, "gen_args_1": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Also, Rob Soderbergh is an award winning filmmaker."}, "gen_args_2": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? No, Rob Soderbergh is an award winning filmmaker."}}, "resps": [[["-104.5", "False"]], [["-106.5", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-104.5", "False"], ["-106.5", "False"], ["-103.5", "False"]], "doc_hash": "2e50ae4efb48fb8b2f310cb740551080ca142e74fe567f55ec5b89ab378dcee8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2154, "doc": {"premise": "Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah.", "hypothesis": "Bush doesn't agree with the way his party paints a picture.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Yes, Bush doesn't agree with the way his party paints a picture."}, "gen_args_1": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Also, Bush doesn't agree with the way his party paints a picture."}, "gen_args_2": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? No, Bush doesn't agree with the way his party paints a picture."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-167.0", "False"]], "doc_hash": "a5d158789163f738ba93de1715f69ada028c2a3a1be7ff327f649a562391fe28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2162, "doc": {"premise": "The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal.", "hypothesis": "The next level of lies is that Brock Defends Hillary to  elevate himself.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Yes, The next level of lies is that Brock Defends Hillary to  elevate himself."}, "gen_args_1": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? Also, The next level of lies is that Brock Defends Hillary to  elevate himself."}, "gen_args_2": {"arg_0": "", "arg_1": " The second level of falsity is that Brock defends Hillary only to elevate his own, proprietary scandal., right? No, The next level of lies is that Brock Defends Hillary to  elevate himself."}}, "resps": [[["-206.0", "False"]], [["-206.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-206.0", "False"], ["-204.0", "False"]], "doc_hash": "62f49fa4eb5201963ad2d16d8d618c988640f822867d9dca65d25bde6a7b5a0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 2170, "doc": {"premise": "One measure of attachment to ordinary  Does the president carry a wallet?", "hypothesis": "No one cares if the president carries a wallet.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Yes, No one cares if the president carries a wallet."}, "gen_args_1": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Also, No one cares if the president carries a wallet."}, "gen_args_2": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? No, No one cares if the president carries a wallet."}}, "resps": [[["-140.0", "False"]], [["-140.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-140.0", "False"], ["-135.0", "False"]], "doc_hash": "a1335f14c861832006a1a523ba1e30c342fce6c5c2e047cded70dcca40f96c22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 2178, "doc": {"premise": "Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill.", "hypothesis": "New York state has its own government representatives.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Yes, New York state has its own government representatives."}, "gen_args_1": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Also, New York state has its own government representatives."}, "gen_args_2": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? No, New York state has its own government representatives."}}, "resps": [[["-169.0", "False"]], [["-168.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-168.0", "False"], ["-169.0", "False"]], "doc_hash": "6e9b189f797630f6974d72e0b99d78d1d9dbf03547e8509eb102b4b62945a6aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 2186, "doc": {"premise": "When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card.", "hypothesis": "The sign stayed black.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Yes, The sign stayed black."}, "gen_args_1": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? Also, The sign stayed black."}, "gen_args_2": {"arg_0": "", "arg_1": " When the ball fell, a huge sign was illuminated and transmitted on every  2000 Discover Card., right? No, The sign stayed black."}}, "resps": [[["-165.0", "False"]], [["-169.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-169.0", "False"], ["-160.0", "False"]], "doc_hash": "64835fc806fe247f249b46811be91ffe95aca3a7ef18ba0eaa897393b3835727", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 2194, "doc": {"premise": "The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies.", "hypothesis": "The environmental and immigration policies are not good.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Yes, The environmental and immigration policies are not good."}, "gen_args_1": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Also, The environmental and immigration policies are not good."}, "gen_args_2": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? No, The environmental and immigration policies are not good."}}, "resps": [[["-157.0", "False"]], [["-161.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-161.0", "False"], ["-156.0", "False"]], "doc_hash": "6e0ddd71fc4f13c9340c4fc4b2a64f1093c7042cad7f5ec94a655a7de822b747", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 2202, "doc": {"premise": "So why does Gates produce at such a frantic pace?", "hypothesis": "Gates does not produce slowly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Yes, Gates does not produce slowly."}, "gen_args_1": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Also, Gates does not produce slowly."}, "gen_args_2": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? No, Gates does not produce slowly."}}, "resps": [[["-98.5", "False"]], [["-103.5", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-103.5", "False"], ["-97.5", "False"]], "doc_hash": "178990e128b789c822f81ecea87e0bc6b78c601fad16bc4386290e54cb78bc0a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 2210, "doc": {"premise": "There are, of course, many elegant and flirtatious scenes set on yachts.", "hypothesis": "Yachts are used as the setting for many elegant scenes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Yes, Yachts are used as the setting for many elegant scenes."}, "gen_args_1": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? Also, Yachts are used as the setting for many elegant scenes."}, "gen_args_2": {"arg_0": "", "arg_1": " There are, of course, many elegant and flirtatious scenes set on yachts., right? No, Yachts are used as the setting for many elegant scenes."}}, "resps": [[["-122.5", "False"]], [["-127.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-127.0", "False"], ["-126.0", "False"]], "doc_hash": "31354b5eb5bc5b93ce99b5d0ef1d419785715ae0e6edda1833ad302d7fa0a569", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96033216 0.01066833 0.02899952]"]}
{"doc_id": 2218, "doc": {"premise": "While I'm not writing you from the United States, that's where I normally am, so sign me...", "hypothesis": "I am writing you while on a two-week vacation in the United States.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Yes, I am writing you while on a two-week vacation in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Also, I am writing you while on a two-week vacation in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? No, I am writing you while on a two-week vacation in the United States."}}, "resps": [[["-139.0", "False"]], [["-144.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-144.0", "False"], ["-144.0", "False"]], "doc_hash": "3fc8a1f24992d28ff337c5fc3a42e96a3deea3deac2da3a9de6200cc2f40e03e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 2226, "doc": {"premise": "There are two evolutionary advantages to looking average.", "hypothesis": "It's beneficial to look average because people leave you alone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Yes, It's beneficial to look average because people leave you alone."}, "gen_args_1": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Also, It's beneficial to look average because people leave you alone."}, "gen_args_2": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? No, It's beneficial to look average because people leave you alone."}}, "resps": [[["-110.5", "False"]], [["-112.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-110.5", "False"], ["-112.0", "False"], ["-112.0", "False"]], "doc_hash": "3610ef51b8e7202009049e9d864ad9a1b64447edbca1079938e5b3c505577a09", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.69143845 0.15428077 0.15428077]"]}
{"doc_id": 2234, "doc": {"premise": "More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI.", "hypothesis": "WorldCom was in a bidding war against BT.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Yes, WorldCom was in a bidding war against BT."}, "gen_args_1": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? Also, WorldCom was in a bidding war against BT."}, "gen_args_2": {"arg_0": "", "arg_1": " More  Capitalizing on frayed relations between British Telecom and MCI, WorldCom outbid BT by offering $30 billion for MCI., right? No, WorldCom was in a bidding war against BT."}}, "resps": [[["-160.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "4b54d6bde914ab4f46a63c19e960f9f593e7b67bcab145a70b02752600c2b4fe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2242, "doc": {"premise": "Alternative should not be used in place of alternate.", "hypothesis": "It is permitted to substitute alternate for alternative.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Yes, It is permitted to substitute alternate for alternative."}, "gen_args_1": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Also, It is permitted to substitute alternate for alternative."}, "gen_args_2": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? No, It is permitted to substitute alternate for alternative."}}, "resps": [[["-99.0", "False"]], [["-101.0", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-99.0", "False"], ["-101.0", "False"], ["-96.5", "False"]], "doc_hash": "8784bd3d28a1c6a3a17828dd3f8e659411d33cc2363b9907a1d7ca6a2acae76c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07508731 0.01016196 0.91475073]"]}
{"doc_id": 2250, "doc": {"premise": "The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator.", "hypothesis": "Dr. Spooner left New College after serving twenty years as a scholar and administrator.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Yes, Dr. Spooner left New College after serving twenty years as a scholar and administrator."}, "gen_args_1": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Also, Dr. Spooner left New College after serving twenty years as a scholar and administrator."}, "gen_args_2": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? No, Dr. Spooner left New College after serving twenty years as a scholar and administrator."}}, "resps": [[["-194.0", "False"]], [["-199.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-199.0", "False"], ["-190.0", "False"]], "doc_hash": "130a37a02386214ce2d1c37441432a800f24e101d19af4319bd00267e9fa03ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 2258, "doc": {"premise": "Which do you like better, math or science?", "hypothesis": "You can like other things other than math and science.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Yes, You can like other things other than math and science."}, "gen_args_1": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? Also, You can like other things other than math and science."}, "gen_args_2": {"arg_0": "", "arg_1": " Which do you like better, math or science?, right? No, You can like other things other than math and science."}}, "resps": [[["-87.5", "False"]], [["-90.0", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-87.5", "False"], ["-90.0", "False"], ["-87.0", "False"]], "doc_hash": "0796ab101358dd3218f17650602a2ac6ec7bc8774b28e43cc5b0a877e394c8dc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.36619222 0.03005889 0.6037489 ]"]}
{"doc_id": 2266, "doc": {"premise": "A cavalier is tied to his steed through Latin caballus `horse.", "hypothesis": "The very name of a cavalier indicates his connection to his horse.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Yes, The very name of a cavalier indicates his connection to his horse."}, "gen_args_1": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Also, The very name of a cavalier indicates his connection to his horse."}, "gen_args_2": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? No, The very name of a cavalier indicates his connection to his horse."}}, "resps": [[["-154.0", "False"]], [["-160.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-160.0", "False"], ["-156.0", "False"]], "doc_hash": "760b32e9bc7674bf931fe13cabee0d610c4198d9c1131bdbd5508df9a584deb1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 2274, "doc": {"premise": "If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published.", "hypothesis": "This book has many new words that were not published before.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Yes, This book has many new words that were not published before."}, "gen_args_1": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Also, This book has many new words that were not published before."}, "gen_args_2": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? No, This book has many new words that were not published before."}}, "resps": [[["-164.0", "False"]], [["-167.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-167.0", "False"], ["-166.0", "False"]], "doc_hash": "556cfe8f7a2fa918267a806059fd590bce231bcba39b70e8774179fdaa470a24", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2282, "doc": {"premise": "How old are  young people ?", "hypothesis": "Young people are all under twenty five years old.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " How old are  young people ?, right? Yes, Young people are all under twenty five years old."}, "gen_args_1": {"arg_0": "", "arg_1": " How old are  young people ?, right? Also, Young people are all under twenty five years old."}, "gen_args_2": {"arg_0": "", "arg_1": " How old are  young people ?, right? No, Young people are all under twenty five years old."}}, "resps": [[["-97.5", "False"]], [["-103.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-103.0", "False"], ["-100.5", "False"]], "doc_hash": "c01cfce59ba23dcf89c9ea5dc50ab9a1d1cd70aeb2068cd3c238ae48924aa02f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94888018 0.00387786 0.04724196]"]}
{"doc_id": 2290, "doc": {"premise": "Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events.", "hypothesis": "Because they view time as circular, the return of seasonal events is more important to them.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Yes, Because they view time as circular, the return of seasonal events is more important to them."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Also, Because they view time as circular, the return of seasonal events is more important to them."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? No, Because they view time as circular, the return of seasonal events is more important to them."}}, "resps": [[["-156.0", "False"]], [["-159.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-159.0", "False"], ["-157.0", "False"]], "doc_hash": "b4866f1eedab5bc2fc900ad826f8b06f12ba0692967e2027a21d20617104bc37", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 2298, "doc": {"premise": "To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing.", "hypothesis": "I could not think of a title of a book I would write about literacy", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Yes, I could not think of a title of a book I would write about literacy"}, "gen_args_1": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Also, I could not think of a title of a book I would write about literacy"}, "gen_args_2": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? No, I could not think of a title of a book I would write about literacy"}}, "resps": [[["-167.0", "False"]], [["-164.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-164.0", "False"], ["-162.0", "False"]], "doc_hash": "31fa599eeac69d57d09ed58fe21525bf0303c507a699e9f8e68919edbf504fe7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00589975 0.11849965 0.8756006 ]"]}
{"doc_id": 2306, "doc": {"premise": "In the closing years of the 19th century there was much discussion concerning the word", "hypothesis": "The word was abandoned and forgotten before the end of the 19th century.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Yes, The word was abandoned and forgotten before the end of the 19th century."}, "gen_args_1": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? Also, The word was abandoned and forgotten before the end of the 19th century."}, "gen_args_2": {"arg_0": "", "arg_1": " In the closing years of the 19th century there was much discussion concerning the word, right? No, The word was abandoned and forgotten before the end of the 19th century."}}, "resps": [[["-115.0", "False"]], [["-118.0", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-118.0", "False"], ["-114.5", "False"]], "doc_hash": "9f3095da36bb95b107f79152d9c46d39d009abb00ad2a2b8849f5c6ecda31a1f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.3705751  0.01844985 0.61097505]"]}
{"doc_id": 2314, "doc": {"premise": "The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores .", "hypothesis": "The King James Bible has been fully revised to modern and simple English.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Yes, The King James Bible has been fully revised to modern and simple English."}, "gen_args_1": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Also, The King James Bible has been fully revised to modern and simple English."}, "gen_args_2": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? No, The King James Bible has been fully revised to modern and simple English."}}, "resps": [[["-220.0", "False"]], [["-218.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-220.0", "False"], ["-218.0", "False"], ["-216.0", "False"]], "doc_hash": "49c168a9a6662669c2bb7369594d331e0edac983870eec1102f5cc1796be6ac3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 2322, "doc": {"premise": "Make my coat look new, dear, sew it!", "hypothesis": "I need you to mend my coat by sewing it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Yes, I need you to mend my coat by sewing it."}, "gen_args_1": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Also, I need you to mend my coat by sewing it."}, "gen_args_2": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? No, I need you to mend my coat by sewing it."}}, "resps": [[["-108.0", "False"]], [["-113.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-113.5", "False"], ["-110.0", "False"]], "doc_hash": "069b001078d27b686dd0c332336552c74db214babed2924e7bf558d3b0451739", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87763792 0.00358671 0.11877538]"]}
{"doc_id": 2330, "doc": {"premise": "Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms.", "hypothesis": "The largest dictionary is still being printed today.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Yes, The largest dictionary is still being printed today."}, "gen_args_1": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? Also, The largest dictionary is still being printed today."}, "gen_args_2": {"arg_0": "", "arg_1": " Consider this figure in light of the fact that the largest English dictionary--now out of print--had 600,000 or so entries, including many obsolete forms., right? No, The largest dictionary is still being printed today."}}, "resps": [[["-157.0", "False"]], [["-159.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-159.0", "False"], ["-154.0", "False"]], "doc_hash": "bb0470f8131d458ece6e256226bf864230f5eb1eeca03b22b0339bb9006975ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 2338, "doc": {"premise": "Words are, generally speaking, old.", "hypothesis": "Nearly all words are very new inventions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Yes, Nearly all words are very new inventions."}, "gen_args_1": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Also, Nearly all words are very new inventions."}, "gen_args_2": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? No, Nearly all words are very new inventions."}}, "resps": [[["-104.5", "False"]], [["-106.5", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-104.5", "False"], ["-106.5", "False"], ["-101.5", "False"]], "doc_hash": "5ba3a64646d58c597e5eeb521efe79efa7af666be53fe622e5e6563af3862133", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 2346, "doc": {"premise": "Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account.", "hypothesis": "Clear verbal communication is the only way to gain information", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Yes, Clear verbal communication is the only way to gain information"}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Also, Clear verbal communication is the only way to gain information"}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? No, Clear verbal communication is the only way to gain information"}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-172.0", "False"]], "doc_hash": "f9b55dad71f59167f848c1ec38aeccd53dcf7c0d79c0e5c85d2995b79e4fc9a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2354, "doc": {"premise": "As we all know, there is an enormous number of publications dealing with highly specialized areas.", "hypothesis": "There are only 2 journals.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Yes, There are only 2 journals."}, "gen_args_1": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? Also, There are only 2 journals."}, "gen_args_2": {"arg_0": "", "arg_1": " As we all know, there is an enormous number of publications dealing with highly specialized areas., right? No, There are only 2 journals."}}, "resps": [[["-116.0", "False"]], [["-119.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-119.0", "False"], ["-112.0", "False"]], "doc_hash": "a9b542826ba73b1ef164bbaa3e0c8d38d1db320bfd2cd48c61fee58c87937366", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 2362, "doc": {"premise": "From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research.", "hypothesis": "This dictionary appears to be plagiarized from an existing dictionary written by a competitor.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Yes, This dictionary appears to be plagiarized from an existing dictionary written by a competitor."}, "gen_args_1": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Also, This dictionary appears to be plagiarized from an existing dictionary written by a competitor."}, "gen_args_2": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? No, This dictionary appears to be plagiarized from an existing dictionary written by a competitor."}}, "resps": [[["-196.0", "False"]], [["-196.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-196.0", "False"], ["-192.0", "False"]], "doc_hash": "d8431cd05eaf465c3b7fd9d13d25ef5b86a84022b9b59c94b07dcf75317274cc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 2370, "doc": {"premise": "And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings.", "hypothesis": "Xerography is about just nouns.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Yes, Xerography is about just nouns."}, "gen_args_1": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Also, Xerography is about just nouns."}, "gen_args_2": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? No, Xerography is about just nouns."}}, "resps": [[["-260.0", "False"]], [["-262.0", "False"]], [["-260.0", "False"]]], "filtered_resps": [["-260.0", "False"], ["-262.0", "False"], ["-260.0", "False"]], "doc_hash": "abcd1794099c370283a261aa76abafee609a0cd4f50ed45ac6fcb78270d1a1f0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2378, "doc": {"premise": "to do (someone) wrong -- The Rape of Lucrece , line 1462:", "hypothesis": "something was dong wrong", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Yes, something was dong wrong"}, "gen_args_1": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? Also, something was dong wrong"}, "gen_args_2": {"arg_0": "", "arg_1": " to do (someone) wrong -- The Rape of Lucrece , line 1462:, right? No, something was dong wrong"}}, "resps": [[["-146.0", "False"]], [["-145.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-145.0", "False"], ["-145.0", "False"]], "doc_hash": "08e5a622814a617c74a35b758aa2f99f43e52697dec942cdfdc093a36a594775", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 2386, "doc": {"premise": "But the question cannot even be asked when the details are mislaid.", "hypothesis": "The question should be answerable even with the mislaid details.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Yes, The question should be answerable even with the mislaid details."}, "gen_args_1": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Also, The question should be answerable even with the mislaid details."}, "gen_args_2": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? No, The question should be answerable even with the mislaid details."}}, "resps": [[["-121.0", "False"]], [["-123.5", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-123.5", "False"], ["-119.5", "False"]], "doc_hash": "707c2180564259fbf80cc54afabe411e925e836711cfc704a380cd1d0a4a8ecb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17973411 0.01475347 0.80551241]"]}
{"doc_id": 2394, "doc": {"premise": "In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson.", "hypothesis": "Everyone in Santa Fe has an American name.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Yes, Everyone in Santa Fe has an American name."}, "gen_args_1": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Also, Everyone in Santa Fe has an American name."}, "gen_args_2": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? No, Everyone in Santa Fe has an American name."}}, "resps": [[["-185.0", "False"]], [["-185.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-185.0", "False"], ["-183.0", "False"]], "doc_hash": "e3a31f789bfaf1cceac55b6606e635972c66431cebeeb94c3b68e7c13b5273c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 2402, "doc": {"premise": "Serious crime down, but murders increase.", "hypothesis": "There has been a rise in murders.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Yes, There has been a rise in murders."}, "gen_args_1": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? Also, There has been a rise in murders."}, "gen_args_2": {"arg_0": "", "arg_1": " Serious crime down, but murders increase., right? No, There has been a rise in murders."}}, "resps": [[["-89.5", "False"]], [["-94.5", "False"]], [["-90.5", "False"]]], "filtered_resps": [["-89.5", "False"], ["-94.5", "False"], ["-90.5", "False"]], "doc_hash": "7e46020f76d3eda245170d42b41697721922b8fe9f26af9d87d4473620a99ac6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2410, "doc": {"premise": "Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha", "hypothesis": "There are lots of silly words that decribe the government.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Yes, There are lots of silly words that decribe the government."}, "gen_args_1": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Also, There are lots of silly words that decribe the government."}, "gen_args_2": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? No, There are lots of silly words that decribe the government."}}, "resps": [[["-239.0", "False"]], [["-242.0", "False"]], [["-241.0", "False"]]], "filtered_resps": [["-239.0", "False"], ["-242.0", "False"], ["-241.0", "False"]], "doc_hash": "a6b5a6fcd1ac6bb69f12287d94c96418bc7d9c43c46b04aead3d02fb77c19c97", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2418, "doc": {"premise": "The flashes of wisdom should not be overlooked,", "hypothesis": "The flashes of wisdom are of  no importance.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Yes, The flashes of wisdom are of  no importance."}, "gen_args_1": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Also, The flashes of wisdom are of  no importance."}, "gen_args_2": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? No, The flashes of wisdom are of  no importance."}}, "resps": [[["-115.0", "False"]], [["-118.0", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-115.0", "False"], ["-118.0", "False"], ["-113.0", "False"]], "doc_hash": "959769d561d387dae61e82b728571b1b19bd4dd6a49623c6ce9894772d74800f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2426, "doc": {"premise": "Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North.", "hypothesis": "Though they wrote many popular modern songs, Peter C. Newman and Pierre Berton never wrote books about history.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Yes, Though they wrote many popular modern songs, Peter C. Newman and Pierre Berton never wrote books about history."}, "gen_args_1": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? Also, Though they wrote many popular modern songs, Peter C. Newman and Pierre Berton never wrote books about history."}, "gen_args_2": {"arg_0": "", "arg_1": " Two of Canada's best-known popular history writers, Peter C. Newman and Pierre Berton, use the term almost exclusively in works they have written on Canada's North., right? No, Though they wrote many popular modern songs, Peter C. Newman and Pierre Berton never wrote books about history."}}, "resps": [[["-213.0", "False"]], [["-215.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-215.0", "False"], ["-209.0", "False"]], "doc_hash": "c39113f7415ac452a22a2d4ab7c14447a9abd8f881b992a99b19c1fe91383159", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 2434, "doc": {"premise": "Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one.", "hypothesis": "The Omni Gazetteer of the United States is about animals.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Yes, The Omni Gazetteer of the United States is about animals."}, "gen_args_1": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Also, The Omni Gazetteer of the United States is about animals."}, "gen_args_2": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? No, The Omni Gazetteer of the United States is about animals."}}, "resps": [[["-192.0", "False"]], [["-194.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-194.0", "False"], ["-193.0", "False"]], "doc_hash": "d5e311e84d453b180af5ad37ffab6febc0421086ba93f974821fcfe44df36315", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2442, "doc": {"premise": "The difference between a president and a king is that a king has no vice .", "hypothesis": "A king that sets up an order of succession is always accused of showing signs of weakness.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Yes, A king that sets up an order of succession is always accused of showing signs of weakness."}, "gen_args_1": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Also, A king that sets up an order of succession is always accused of showing signs of weakness."}, "gen_args_2": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? No, A king that sets up an order of succession is always accused of showing signs of weakness."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-138.0", "False"]], "doc_hash": "211324772b8acb1af2fe52291a0ed1deae444f357b50cedd33f2038666447124", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2450, "doc": {"premise": "Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons.", "hypothesis": "The word quark is a modern word first invented by scientists in the 1960s.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Yes, The word quark is a modern word first invented by scientists in the 1960s."}, "gen_args_1": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? Also, The word quark is a modern word first invented by scientists in the 1960s."}, "gen_args_2": {"arg_0": "", "arg_1": " Actually, the word quark is in the OED as a verb meaning `croak,' with 19th-century references to frogs, rooks, and herons., right? No, The word quark is a modern word first invented by scientists in the 1960s."}}, "resps": [[["-183.0", "False"]], [["-182.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-182.0", "False"], ["-180.0", "False"]], "doc_hash": "608741d8add53d27af8e9ffd8f070f03f5b8c7d74b78500c99a601fe92058a22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 2458, "doc": {"premise": "Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians.", "hypothesis": "The Indians liked Sir William Johnson.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Yes, The Indians liked Sir William Johnson."}, "gen_args_1": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Also, The Indians liked Sir William Johnson."}, "gen_args_2": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? No, The Indians liked Sir William Johnson."}}, "resps": [[["-143.0", "False"]], [["-149.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-149.0", "False"], ["-146.0", "False"]], "doc_hash": "6ebaff7c1378189f92af4439d94f7cf7ec5763e6b4b1aa3fa1d7ff85d73c267a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2466, "doc": {"premise": "It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him.", "hypothesis": "Lover had a target on his head and thus had to hide between the rocks.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Yes, Lover had a target on his head and thus had to hide between the rocks."}, "gen_args_1": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Also, Lover had a target on his head and thus had to hide between the rocks."}, "gen_args_2": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? No, Lover had a target on his head and thus had to hide between the rocks."}}, "resps": [[["-167.0", "False"]], [["-172.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-172.0", "False"], ["-172.0", "False"]], "doc_hash": "b9f0e084c65e292485ee496d4178fa58a424163626a46409bb4c1b4d3c926774", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 2474, "doc": {"premise": "My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes.", "hypothesis": "The young man my sister was dating felt obligated to be a Hawkeyes fan because he worked for the University of Iowa.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Yes, The young man my sister was dating felt obligated to be a Hawkeyes fan because he worked for the University of Iowa."}, "gen_args_1": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? Also, The young man my sister was dating felt obligated to be a Hawkeyes fan because he worked for the University of Iowa."}, "gen_args_2": {"arg_0": "", "arg_1": " My sister once dated a strapping young man who was a diehard booster of the University of Iowa, the sports teams of which are called the Hawkeyes., right? No, The young man my sister was dating felt obligated to be a Hawkeyes fan because he worked for the University of Iowa."}}, "resps": [[["-184.0", "False"]], [["-184.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-184.0", "False"], ["-183.0", "False"]], "doc_hash": "d43d3bfcb8698e337069551e1417a1d45c5a98794e21f094833beda65c78af23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2482, "doc": {"premise": "A month has passed since the election and still Republicans and Democrats are high-fiving.", "hypothesis": "It has been a month since the presidential election.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Yes, It has been a month since the presidential election."}, "gen_args_1": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Also, It has been a month since the presidential election."}, "gen_args_2": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? No, It has been a month since the presidential election."}}, "resps": [[["-105.0", "False"]], [["-109.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-105.0", "False"], ["-109.5", "False"], ["-108.0", "False"]], "doc_hash": "32c4e0a4c43ed84b8314bef7785c006d8f8bb21bb5d11719c1dd03e006f58f94", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 3, "doc": {"premise": "I didn't know what I was going for or anything, so was to report to a designated place in Washington.", "hypothesis": "I have never been to Washington so when I was assigned there I got lost trying to find the place.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Yes, I have never been to Washington so when I was assigned there I got lost trying to find the place."}, "gen_args_1": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Also, I have never been to Washington so when I was assigned there I got lost trying to find the place."}, "gen_args_2": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? No, I have never been to Washington so when I was assigned there I got lost trying to find the place."}}, "resps": [[["-163.0", "False"]], [["-163.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-163.0", "False"], ["-162.0", "False"]], "doc_hash": "0932a879f30dad6e04f50203d12ca20a8a33eee6824cbe48f961e4352d4b2942", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 11, "doc": {"premise": "And I was like OK, and that was it!", "hypothesis": "When I said yes, we decided that we would get married that day.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Yes, When I said yes, we decided that we would get married that day."}, "gen_args_1": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? Also, When I said yes, we decided that we would get married that day."}, "gen_args_2": {"arg_0": "", "arg_1": " And I was like OK, and that was it!, right? No, When I said yes, we decided that we would get married that day."}}, "resps": [[["-104.0", "False"]], [["-107.5", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-107.5", "False"], ["-103.0", "False"]], "doc_hash": "47124dd5a79459f83ea7b87b10fdd36ac1984e6bea0254f060acc4af9dcfac3f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26677486 0.0080559  0.72516924]"]}
{"doc_id": 19, "doc": {"premise": "And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white.", "hypothesis": "Granny's sister was not white.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Yes, Granny's sister was not white."}, "gen_args_1": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Also, Granny's sister was not white."}, "gen_args_2": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? No, Granny's sister was not white."}}, "resps": [[["-149.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "991dc4beadecd995fa1a8298b13d8a411a243801ce5693a7371bd4ddcdf25593", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 27, "doc": {"premise": "But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location.", "hypothesis": "I didn't have a job so I just kept all the boxes at home.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Yes, I didn't have a job so I just kept all the boxes at home."}, "gen_args_1": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Also, I didn't have a job so I just kept all the boxes at home."}, "gen_args_2": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? No, I didn't have a job so I just kept all the boxes at home."}}, "resps": [[["-187.0", "False"]], [["-187.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-187.0", "False"], ["-184.0", "False"]], "doc_hash": "c0e8431ef97704cdda61237a2d6d071772439bbc834ca96a21dafcce71594129", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 35, "doc": {"premise": "And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories.", "hypothesis": "I wasn't a fan of his.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Yes, I wasn't a fan of his."}, "gen_args_1": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? Also, I wasn't a fan of his."}, "gen_args_2": {"arg_0": "", "arg_1": " And he was a philanderer, an d oh yeah, he was like out there . And, ah, so, you know, I didn't like him, but anyway those are my stories., right? No, I wasn't a fan of his."}}, "resps": [[["-184.0", "False"]], [["-186.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-186.0", "False"], ["-181.0", "False"]], "doc_hash": "895b2f112d0bb945e0e3f61630b73dd340b148ba627b97bb67b701c292eab2bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 43, "doc": {"premise": "Maybe she told everyone else and I wasn't paying attention at that particular time.", "hypothesis": "I heard everything she said.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Yes, I heard everything she said."}, "gen_args_1": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Also, I heard everything she said."}, "gen_args_2": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? No, I heard everything she said."}}, "resps": [[["-99.5", "False"]], [["-103.5", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-99.5", "False"], ["-103.5", "False"], ["-95.5", "False"]], "doc_hash": "56fb71027a04b43cc2c80752d7fd04758e6fa1f348cfc6e76226cf7b4e69213b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 51, "doc": {"premise": "Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour.", "hypothesis": "It flies over 20,000 miles an hour.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Yes, It flies over 20,000 miles an hour."}, "gen_args_1": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Also, It flies over 20,000 miles an hour."}, "gen_args_2": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? No, It flies over 20,000 miles an hour."}}, "resps": [[["-179.0", "False"]], [["-184.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-184.0", "False"], ["-178.0", "False"]], "doc_hash": "d81f587b790f4170fc1417727f529d16f0305ffa6f8441852e5b0ee47afc1b73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 59, "doc": {"premise": "She was still in there.", "hypothesis": "We thought she left but she remained.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was still in there., right? Yes, We thought she left but she remained."}, "gen_args_1": {"arg_0": "", "arg_1": " She was still in there., right? Also, We thought she left but she remained."}, "gen_args_2": {"arg_0": "", "arg_1": " She was still in there., right? No, We thought she left but she remained."}}, "resps": [[["-83.0", "False"]], [["-89.5", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-83.0", "False"], ["-89.5", "False"], ["-83.0", "False"]], "doc_hash": "fafba1aad3831c0011e0d8cef8db487bb8881e05c4dd3a2983ca5293d4e8788f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49962442 0.00075115 0.49962442]"]}
{"doc_id": 67, "doc": {"premise": "He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that.", "hypothesis": "He would burn the paper.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Yes, He would burn the paper."}, "gen_args_1": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Also, He would burn the paper."}, "gen_args_2": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? No, He would burn the paper."}}, "resps": [[["-174.0", "False"]], [["-180.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-180.0", "False"], ["-174.0", "False"]], "doc_hash": "2d1d1c990bef122980c14801fed929ce98c8707303627ab9647b317c8383e13b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 75, "doc": {"premise": "I think that's why I remember that.", "hypothesis": "I didn't remember it at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Yes, I didn't remember it at all."}, "gen_args_1": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Also, I didn't remember it at all."}, "gen_args_2": {"arg_0": "", "arg_1": " I think that's why I remember that., right? No, I didn't remember it at all."}}, "resps": [[["-75.5", "False"]], [["-75.5", "False"]], [["-72.0", "False"]]], "filtered_resps": [["-75.5", "False"], ["-75.5", "False"], ["-72.0", "False"]], "doc_hash": "734279b64175fbbdc61ed3a417299ebc932c6b621e8191fa8f70228d843ba693", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02847749 0.02847749 0.94304502]"]}
{"doc_id": 83, "doc": {"premise": "You don't have to stay there.", "hypothesis": "You need to stay in that exact spot!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You don't have to stay there., right? Yes, You need to stay in that exact spot!"}, "gen_args_1": {"arg_0": "", "arg_1": " You don't have to stay there., right? Also, You need to stay in that exact spot!"}, "gen_args_2": {"arg_0": "", "arg_1": " You don't have to stay there., right? No, You need to stay in that exact spot!"}}, "resps": [[["-81.0", "False"]], [["-87.5", "False"]], [["-81.0", "False"]]], "filtered_resps": [["-81.0", "False"], ["-87.5", "False"], ["-81.0", "False"]], "doc_hash": "da0de10f2ecaf2fbb893b7d83b4d8c0aed8a03496cd10fbb4083ef3fa9f17678", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49962442 0.00075115 0.49962442]"]}
{"doc_id": 91, "doc": {"premise": "So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May.", "hypothesis": "General May never went to President Kennedy's office.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Yes, General May never went to President Kennedy's office."}, "gen_args_1": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Also, General May never went to President Kennedy's office."}, "gen_args_2": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? No, General May never went to President Kennedy's office."}}, "resps": [[["-203.0", "False"]], [["-207.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-207.0", "False"], ["-197.0", "False"]], "doc_hash": "0037ece2eb5190f6124d08ae3d8cc4241c9eca09e985b901547c4fee74d43c08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47251118e-03 4.52856220e-05 9.97482203e-01]"]}
{"doc_id": 99, "doc": {"premise": "But uh, think about it.", "hypothesis": "I think about it often.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But uh, think about it., right? Yes, I think about it often."}, "gen_args_1": {"arg_0": "", "arg_1": " But uh, think about it., right? Also, I think about it often."}, "gen_args_2": {"arg_0": "", "arg_1": " But uh, think about it., right? No, I think about it often."}}, "resps": [[["-65.5", "False"]], [["-72.5", "False"]], [["-66.0", "False"]]], "filtered_resps": [["-65.5", "False"], ["-72.5", "False"], ["-66.0", "False"]], "doc_hash": "13ccc9cc0bd0e6ffe580b583e8040907cc80153c07f4edc5c451ce04a3c067ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[6.22106218e-01 5.67287441e-04 3.77326495e-01]"]}
{"doc_id": 107, "doc": {"premise": "The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake.", "hypothesis": "We weren't allowed to touch it at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Yes, We weren't allowed to touch it at all."}, "gen_args_1": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? Also, We weren't allowed to touch it at all."}, "gen_args_2": {"arg_0": "", "arg_1": " The part was, there was 158 parts to it and we had to break it down put it back together break it down and never make a mistake., right? No, We weren't allowed to touch it at all."}}, "resps": [[["-163.0", "False"]], [["-164.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-164.0", "False"], ["-160.0", "False"]], "doc_hash": "0196a9cf16e4aabef6aecb5959e1e23c6e472344b3a65181fc6e4e2426a4ae19", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 115, "doc": {"premise": "He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed.", "hypothesis": "I was worried that I would miss the show because I didn't know what time it was.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Yes, I was worried that I would miss the show because I didn't know what time it was."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Also, I was worried that I would miss the show because I didn't know what time it was."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? No, I was worried that I would miss the show because I didn't know what time it was."}}, "resps": [[["-180.0", "False"]], [["-178.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-178.0", "False"], ["-179.0", "False"]], "doc_hash": "dd02c37c70012fcd316455375e87bc84f81aa608f6b4dfd574f2e9b7d0515a65", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 123, "doc": {"premise": "Little things like that made a big difference in what I was trying to do.", "hypothesis": "I didn't even try to do it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Yes, I didn't even try to do it."}, "gen_args_1": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Also, I didn't even try to do it."}, "gen_args_2": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? No, I didn't even try to do it."}}, "resps": [[["-96.5", "False"]], [["-97.0", "False"]], [["-90.5", "False"]]], "filtered_resps": [["-96.5", "False"], ["-97.0", "False"], ["-90.5", "False"]], "doc_hash": "c9ba44d982ab36f71fa335ff1db536b1e2135f03bb6f812f34fed742b2ad699b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246892 0.00149748 0.9960336 ]"]}
{"doc_id": 131, "doc": {"premise": "The CIA unloaded the, the film, taken them to the United Nations the next day.", "hypothesis": "The CIA thought the UN needed to see the film right away.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Yes, The CIA thought the UN needed to see the film right away."}, "gen_args_1": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? Also, The CIA thought the UN needed to see the film right away."}, "gen_args_2": {"arg_0": "", "arg_1": " The CIA unloaded the, the film, taken them to the United Nations the next day., right? No, The CIA thought the UN needed to see the film right away."}}, "resps": [[["-157.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "d347e9bbb73c58eee3b0229dcf1ce30645df279ecf6f7f65121b100d50e1eee9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 139, "doc": {"premise": "Um, and so they just left town, and she, she never did see her sister again, never saw her sister again.", "hypothesis": "She never saw her sister after that.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Yes, She never saw her sister after that."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Also, She never saw her sister after that."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? No, She never saw her sister after that."}}, "resps": [[["-121.0", "False"]], [["-130.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-130.0", "False"], ["-122.5", "False"]], "doc_hash": "8bf2dd2d4f9d8ecb97204187e2107d49abbb20e3b2b27df5b00fd8027b0e8079", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.17491994e-01 1.00886527e-04 1.82407120e-01]"]}
{"doc_id": 147, "doc": {"premise": "It was still cultural area but suburbs was still the dominant form.", "hypothesis": "It was all very urban.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Yes, It was all very urban."}, "gen_args_1": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Also, It was all very urban."}, "gen_args_2": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? No, It was all very urban."}}, "resps": [[["-125.0", "False"]], [["-126.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-126.0", "False"], ["-124.0", "False"]], "doc_hash": "1df6349b010d4142fdeb160cf806f2a8d41f0d578f6db4a2fdf80762b982a592", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 155, "doc": {"premise": "And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street.", "hypothesis": "They lived on Main street in a tent.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Yes, They lived on Main street in a tent."}, "gen_args_1": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? Also, They lived on Main street in a tent."}, "gen_args_2": {"arg_0": "", "arg_1": " And they found this house or this apartment building or whatever it was that they could live in, and it was right on the edge of Broad Street., right? No, They lived on Main street in a tent."}}, "resps": [[["-146.0", "False"]], [["-150.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-150.0", "False"], ["-145.0", "False"]], "doc_hash": "c09d5b66cb3ddd682708dd8ef4507759c28afed1a0a7b705c0892648e91770d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 163, "doc": {"premise": "And our father always told us not to say they are animals.", "hypothesis": "Our dad said they were animals.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Yes, Our dad said they were animals."}, "gen_args_1": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Also, Our dad said they were animals."}, "gen_args_2": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? No, Our dad said they were animals."}}, "resps": [[["-102.5", "False"]], [["-110.0", "False"]], [["-102.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-110.0", "False"], ["-102.5", "False"]], "doc_hash": "25dd9af388f4633148d89eea602b6cb4d816cabe4cb5ee84cd66c418831eef86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.99861767e-01 2.76465731e-04 4.99861767e-01]"]}
{"doc_id": 171, "doc": {"premise": "I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever.", "hypothesis": "I didn't see it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Yes, I didn't see it."}, "gen_args_1": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Also, I didn't see it."}, "gen_args_2": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? No, I didn't see it."}}, "resps": [[["-191.0", "False"]], [["-193.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-193.0", "False"], ["-186.0", "False"]], "doc_hash": "3079799e18a84174d1ade81e6971c66d35990efe76ce97726b06b4e2464debbb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 179, "doc": {"premise": "Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody.", "hypothesis": "We weren't allowed to talk about the U2.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Yes, We weren't allowed to talk about the U2."}, "gen_args_1": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? Also, We weren't allowed to talk about the U2."}, "gen_args_2": {"arg_0": "", "arg_1": " Come to find out it was a U2 aircraft but we couldn't, we could not say one word about what it was; nothing to our wives, kids or anybody., right? No, We weren't allowed to talk about the U2."}}, "resps": [[["-182.0", "False"]], [["-186.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-186.0", "False"], ["-182.0", "False"]], "doc_hash": "13ab96c06af5868590b19fc22696e01f32f79694bd6eadcdc10022d492a69836", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 187, "doc": {"premise": "They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them.", "hypothesis": "He stayed in Brooklynn with his family.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Yes, He stayed in Brooklynn with his family."}, "gen_args_1": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Also, He stayed in Brooklynn with his family."}, "gen_args_2": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? No, He stayed in Brooklynn with his family."}}, "resps": [[["-195.0", "False"]], [["-200.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-200.0", "False"], ["-197.0", "False"]], "doc_hash": "96b164063b655baa8ea68d75ca3223f9ec9567294cf50507d7e4dc32eb45daee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 195, "doc": {"premise": "My grandmother was born in 1910, she was a little girl.", "hypothesis": "My grandma was born 10 years after the turn of the century.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Yes, My grandma was born 10 years after the turn of the century."}, "gen_args_1": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Also, My grandma was born 10 years after the turn of the century."}, "gen_args_2": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? No, My grandma was born 10 years after the turn of the century."}}, "resps": [[["-92.5", "False"]], [["-96.5", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-92.5", "False"], ["-96.5", "False"], ["-92.5", "False"]], "doc_hash": "64b0a020bf13baddde4ed04db50433f0134de6e347a3478a4ee26f5bcabdd85f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 203, "doc": {"premise": "Anyway it got up to, we had about uh, ah, I don't remember the numbers.", "hypothesis": "I know the exact numbers for everything", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Yes, I know the exact numbers for everything"}, "gen_args_1": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? Also, I know the exact numbers for everything"}, "gen_args_2": {"arg_0": "", "arg_1": " Anyway it got up to, we had about uh, ah, I don't remember the numbers., right? No, I know the exact numbers for everything"}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-127.0", "False"]], "doc_hash": "44019f1655355bd554bad5918fe08083c8be8455288fb2ea5530d5959fbc6ed7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 211, "doc": {"premise": "And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off.", "hypothesis": "If there is a surge, there is a noise that accompanies it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Yes, If there is a surge, there is a noise that accompanies it."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Also, If there is a surge, there is a noise that accompanies it."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? No, If there is a surge, there is a noise that accompanies it."}}, "resps": [[["-185.0", "False"]], [["-189.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-189.0", "False"], ["-187.0", "False"]], "doc_hash": "cc75c83b620352010033a680a83a41e19cc21fc666bdf08ea0c1cdb23262b355", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 219, "doc": {"premise": "Of course, they questioned me there, why I went.", "hypothesis": "They asked me why I had gone there.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Yes, They asked me why I had gone there."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Also, They asked me why I had gone there."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? No, They asked me why I had gone there."}}, "resps": [[["-97.5", "False"]], [["-105.5", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-105.5", "False"], ["-101.5", "False"]], "doc_hash": "08d3cdee7b31b19642d9a0b974c6ceb777b009a3e11896f944bc3f5f8761bd5a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 227, "doc": {"premise": "Well anyway, I went back to my, my desk.", "hypothesis": "I went back and sat down because my boss told me to.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Yes, I went back and sat down because my boss told me to."}, "gen_args_1": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? Also, I went back and sat down because my boss told me to."}, "gen_args_2": {"arg_0": "", "arg_1": " Well anyway, I went back to my, my desk., right? No, I went back and sat down because my boss told me to."}}, "resps": [[["-105.5", "False"]], [["-111.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-105.5", "False"], ["-111.0", "False"], ["-104.5", "False"]], "doc_hash": "2663d96dc13346fb98ef88dcaca93c7e30a4e52bd86e705b7f6f5f0a235d4529", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26864615 0.0010979  0.73025595]"]}
{"doc_id": 235, "doc": {"premise": "So it took me like, an hour to two hours just to find what I needed.", "hypothesis": "It took me a long time because the book was really thick and confusing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Yes, It took me a long time because the book was really thick and confusing."}, "gen_args_1": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Also, It took me a long time because the book was really thick and confusing."}, "gen_args_2": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? No, It took me a long time because the book was really thick and confusing."}}, "resps": [[["-119.0", "False"]], [["-121.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-119.0", "False"], ["-121.5", "False"], ["-122.0", "False"]], "doc_hash": "a3948670f91672d627830c8b5f7e191df3b000cc0b16d9f88d017eec7bb53a97", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.88349207 0.07252145 0.04398648]"]}
{"doc_id": 243, "doc": {"premise": "That was my messed up.", "hypothesis": "I did it without any errors.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was my messed up., right? Yes, I did it without any errors."}, "gen_args_1": {"arg_0": "", "arg_1": " That was my messed up., right? Also, I did it without any errors."}, "gen_args_2": {"arg_0": "", "arg_1": " That was my messed up., right? No, I did it without any errors."}}, "resps": [[["-82.0", "False"]], [["-80.0", "False"]], [["-80.0", "False"]]], "filtered_resps": [["-82.0", "False"], ["-80.0", "False"], ["-80.0", "False"]], "doc_hash": "bc22a4c34250c296032c5c4d152cc75bb57f71d0bc01dc41bbb09313ffd1c39d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 251, "doc": {"premise": "oh it was Snake River oh Snake River with a lot of snakes in it", "hypothesis": "Snake River is filled with snakes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Yes, Snake River is filled with snakes."}, "gen_args_1": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? Also, Snake River is filled with snakes."}, "gen_args_2": {"arg_0": "", "arg_1": " oh it was Snake River oh Snake River with a lot of snakes in it, right? No, Snake River is filled with snakes."}}, "resps": [[["-96.5", "False"]], [["-104.5", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-104.5", "False"], ["-101.0", "False"]], "doc_hash": "abaa52317e8b5ce55d2526b87afa2a8760c90c76c8bc4eb025d9aae87756aac7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.88685034e-01 3.31666880e-04 1.09832986e-02]"]}
{"doc_id": 259, "doc": {"premise": "and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us", "hypothesis": "I think it will be challenging to change our representatives but worthwhile in the end.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Yes, I think it will be challenging to change our representatives but worthwhile in the end."}, "gen_args_1": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Also, I think it will be challenging to change our representatives but worthwhile in the end."}, "gen_args_2": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? No, I think it will be challenging to change our representatives but worthwhile in the end."}}, "resps": [[["-156.0", "False"]], [["-163.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-163.0", "False"], ["-162.0", "False"]], "doc_hash": "8ac64ac1c133ed3b02278ec4af5b984c91936548fc6803a5f14c7a47b5977a66", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.96620823e-01 9.08800555e-04 2.47037604e-03]"]}
{"doc_id": 267, "doc": {"premise": "yeah you you must've had a cordless", "hypothesis": "Correct the one you had was cordless.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Yes, Correct the one you had was cordless."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Also, Correct the one you had was cordless."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? No, Correct the one you had was cordless."}}, "resps": [[["-98.5", "False"]], [["-108.0", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-108.0", "False"], ["-101.5", "False"]], "doc_hash": "f820dfccb7abee1b446808e8a3d6cbb7dbf4642d8ae63a008336eb21f3db6ba1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52506211e-01 7.12968329e-05 4.74224919e-02]"]}
{"doc_id": 275, "doc": {"premise": "besides i probably would look at something uh maybe a a V six", "hypothesis": "I would never consider a V6.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Yes, I would never consider a V6."}, "gen_args_1": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? Also, I would never consider a V6."}, "gen_args_2": {"arg_0": "", "arg_1": " besides i probably would look at something uh maybe a a V six, right? No, I would never consider a V6."}}, "resps": [[["-120.5", "False"]], [["-129.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-120.5", "False"], ["-129.0", "False"], ["-117.0", "False"]], "doc_hash": "d26c6d75b4b1f410f0920c249f49b34bd6eb286be9a9695795ed1704714c4a73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93120559e-02 5.96407621e-06 9.70681980e-01]"]}
{"doc_id": 283, "doc": {"premise": "but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants", "hypothesis": "I don't wear anything other than sweats when I work at home.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Yes, I don't wear anything other than sweats when I work at home."}, "gen_args_1": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Also, I don't wear anything other than sweats when I work at home."}, "gen_args_2": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? No, I don't wear anything other than sweats when I work at home."}}, "resps": [[["-204.0", "False"]], [["-209.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-209.0", "False"], ["-201.0", "False"]], "doc_hash": "2e9e8c98c9a9cd4b5d1e260004d72c697857c9aeace1c9c545413a9bde3184cc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 291, "doc": {"premise": "yeah it's ours up here we have our rural connections are real bad", "hypothesis": "The connections around here are sometimes okay.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Yes, The connections around here are sometimes okay."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Also, The connections around here are sometimes okay."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? No, The connections around here are sometimes okay."}}, "resps": [[["-141.0", "False"]], [["-145.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-145.0", "False"], ["-139.0", "False"]], "doc_hash": "45e03008a2bf6f0fe26d7bd04af8ef451b8aaf2bb7adfefa2202f5cdd7118e5d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 299, "doc": {"premise": "but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of", "hypothesis": "I have tried many different types of animals for food.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Yes, I have tried many different types of animals for food."}, "gen_args_1": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? Also, I have tried many different types of animals for food."}, "gen_args_2": {"arg_0": "", "arg_1": " but on the other hand we've eaten a lot of raccoon and possum and turtle all kinds of, right? No, I have tried many different types of animals for food."}}, "resps": [[["-125.0", "False"]], [["-129.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-129.0", "False"], ["-127.5", "False"]], "doc_hash": "ce64f067f1182037a6da3092a88946bfe1d9d9b1bde3cfa20201dd7aa83e887d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.90875992 0.01664452 0.07459556]"]}
{"doc_id": 307, "doc": {"premise": "yeah it was pretty reasonable", "hypothesis": "Yes, it was very acceptable.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Yes, Yes, it was very acceptable."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Also, Yes, it was very acceptable."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? No, Yes, it was very acceptable."}}, "resps": [[["-69.0", "False"]], [["-75.5", "False"]], [["-73.0", "False"]]], "filtered_resps": [["-69.0", "False"], ["-75.5", "False"], ["-73.0", "False"]], "doc_hash": "9f1c641887658b749c2b9359f85665c5233eb6d41dfef6b1eac5231dd7b5ab74", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98056608 0.00147422 0.01795969]"]}
{"doc_id": 315, "doc": {"premise": "have you read The Firm", "hypothesis": "Did you read The Firm?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " have you read The Firm, right? Yes, Did you read The Firm?"}, "gen_args_1": {"arg_0": "", "arg_1": " have you read The Firm, right? Also, Did you read The Firm?"}, "gen_args_2": {"arg_0": "", "arg_1": " have you read The Firm, right? No, Did you read The Firm?"}}, "resps": [[["-69.5", "False"]], [["-67.0", "False"]], [["-67.5", "False"]]], "filtered_resps": [["-69.5", "False"], ["-67.0", "False"], ["-67.5", "False"]], "doc_hash": "0999ddf2f21f3e0f3158f7cd28b00a01ccee55f43ff4b001279c472a0448a9f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04861082 0.59220107 0.35918811]"]}
{"doc_id": 323, "doc": {"premise": "i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think", "hypothesis": "Texas should have stronger gun control laws.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Yes, Texas should have stronger gun control laws."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? Also, Texas should have stronger gun control laws."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know coming from Texas you're probably i don't know i i shouldn't make stereo types but gun control is probably frowned on quite a bit down there i would think, right? No, Texas should have stronger gun control laws."}}, "resps": [[["-176.0", "False"]], [["-184.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-184.0", "False"], ["-178.0", "False"]], "doc_hash": "4fa97e472acd6391cc28de90579120f063cd5eaaf82cf67fd7c1038ed32d6198", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 331, "doc": {"premise": "yeah they had a whole bunch of things that that sort of broke at the same time", "hypothesis": "None of their stuff broke.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Yes, None of their stuff broke."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Also, None of their stuff broke."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? No, None of their stuff broke."}}, "resps": [[["-106.0", "False"]], [["-108.5", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-108.5", "False"], ["-102.0", "False"]], "doc_hash": "f6f3223d3a8c2720d46771256fde50648b5aa20953fc6c62ac60e23d8cb68ebf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01795969 0.00147422 0.98056608]"]}
{"doc_id": 339, "doc": {"premise": "you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education", "hypothesis": "It would be worth it to work for a larger company if they gave me money for college.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Yes, It would be worth it to work for a larger company if they gave me money for college."}, "gen_args_1": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Also, It would be worth it to work for a larger company if they gave me money for college."}, "gen_args_2": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? No, It would be worth it to work for a larger company if they gave me money for college."}}, "resps": [[["-230.0", "False"]], [["-235.0", "False"]], [["-233.0", "False"]]], "filtered_resps": [["-230.0", "False"], ["-235.0", "False"], ["-233.0", "False"]], "doc_hash": "33863a6a378e5c8fdfcbbe3eae5a8d9a99e6b0784a4ccc81dac3b437b52c86df", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 347, "doc": {"premise": "um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news", "hypothesis": "I think the networks spin the news to make you think what they want you to think.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Yes, I think the networks spin the news to make you think what they want you to think."}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? Also, I think the networks spin the news to make you think what they want you to think."}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum do you find that you're uh  uh disappointed or pleased with uh uh the performance of like network coverage of news, right? No, I think the networks spin the news to make you think what they want you to think."}}, "resps": [[["-190.0", "False"]], [["-200.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-200.0", "False"], ["-189.0", "False"]], "doc_hash": "1d41122c3ce3a996bb584261e8991b59c95f97a8c2ec124df8b595990bc672d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[2.68938138e-01 1.22097726e-05 7.31049653e-01]"]}
{"doc_id": 355, "doc": {"premise": "but i know that in some i know in a lot of rural areas they're not that good", "hypothesis": "They are really good in urban areas.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Yes, They are really good in urban areas."}, "gen_args_1": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Also, They are really good in urban areas."}, "gen_args_2": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? No, They are really good in urban areas."}}, "resps": [[["-116.0", "False"]], [["-121.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-121.5", "False"], ["-117.0", "False"]], "doc_hash": "d5d9c9c59a09fe902d3d494f884f1553dacfdf0e0f48a78c116f226de2b8527a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72888092 0.00297877 0.26814031]"]}
{"doc_id": 363, "doc": {"premise": "now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark", "hypothesis": "Robbers don't like dogs because they are loud and often bite them.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Yes, Robbers don't like dogs because they are loud and often bite them."}, "gen_args_1": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Also, Robbers don't like dogs because they are loud and often bite them."}, "gen_args_2": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? No, Robbers don't like dogs because they are loud and often bite them."}}, "resps": [[["-174.0", "False"]], [["-178.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-178.0", "False"], ["-176.0", "False"]], "doc_hash": "332ef5372df8b0e5d1c4d26bb182508f210999707ecf2c13ae16a6e7177d4820", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 371, "doc": {"premise": "i don't know  okay well it was good talking to you and have a good evening", "hypothesis": "I'm not certain but I'm kinda fine, it was nice to speak with you tonight.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Yes, I'm not certain but I'm kinda fine, it was nice to speak with you tonight."}, "gen_args_1": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? Also, I'm not certain but I'm kinda fine, it was nice to speak with you tonight."}, "gen_args_2": {"arg_0": "", "arg_1": " i don't know  okay well it was good talking to you and have a good evening, right? No, I'm not certain but I'm kinda fine, it was nice to speak with you tonight."}}, "resps": [[["-143.0", "False"]], [["-145.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-145.0", "False"], ["-140.0", "False"]], "doc_hash": "2b75b087a929b918e1c3f81e5adfbdf5e2607317657f321c563952ba448eeba1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 379, "doc": {"premise": "it's only getting worse exponentially it seems um", "hypothesis": "It seems to be getting worse.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Yes, It seems to be getting worse."}, "gen_args_1": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Also, It seems to be getting worse."}, "gen_args_2": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? No, It seems to be getting worse."}}, "resps": [[["-86.5", "False"]], [["-96.0", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-86.5", "False"], ["-96.0", "False"], ["-90.0", "False"]], "doc_hash": "b72c840bc5ddcc2010c07978c11e8661fa109bbfab511bf24ddec955e05199ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70617246e-01 7.26524770e-05 2.93101011e-02]"]}
{"doc_id": 387, "doc": {"premise": "not just lawyers but police officers and judges and the whole legal profession in general", "hypothesis": "It has nothing to do with anyone involved in the legal system.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Yes, It has nothing to do with anyone involved in the legal system."}, "gen_args_1": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Also, It has nothing to do with anyone involved in the legal system."}, "gen_args_2": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? No, It has nothing to do with anyone involved in the legal system."}}, "resps": [[["-110.0", "False"]], [["-114.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-110.0", "False"], ["-114.0", "False"], ["-104.5", "False"]], "doc_hash": "aee9acde631c8cce9c6797967a4810c152e917d3b74137e759112e83a31fcbc3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06983432e-03 7.45416158e-05 9.95855624e-01]"]}
{"doc_id": 395, "doc": {"premise": "uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh", "hypothesis": "I'll Fly Away is my favorite movie and I watch it weekly.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Yes, I'll Fly Away is my favorite movie and I watch it weekly."}, "gen_args_1": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? Also, I'll Fly Away is my favorite movie and I watch it weekly."}, "gen_args_2": {"arg_0": "", "arg_1": " uh yeah and i was gonna say uh I'll Fly Away which uh i think it was supposed to uh catch some of the same viewers as uh, right? No, I'll Fly Away is my favorite movie and I watch it weekly."}}, "resps": [[["-179.0", "False"]], [["-178.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-178.0", "False"], ["-176.0", "False"]], "doc_hash": "d464200b6497425ad874fa557ceb1879ce36c46126d6ffd4eb4da2d23340364f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 403, "doc": {"premise": "yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas", "hypothesis": "The gas mileage is terrible and I'm constantly paying for gas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Yes, The gas mileage is terrible and I'm constantly paying for gas."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Also, The gas mileage is terrible and I'm constantly paying for gas."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? No, The gas mileage is terrible and I'm constantly paying for gas."}}, "resps": [[["-179.0", "False"]], [["-182.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-182.0", "False"], ["-176.0", "False"]], "doc_hash": "d452d920bd2b0b921d79e58d84c5c09a4985c59ab62a1c9e277c6990f5151cc3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 411, "doc": {"premise": "i never have can't do anything with cakes so", "hypothesis": "I am not able to use the cakes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Yes, I am not able to use the cakes."}, "gen_args_1": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Also, I am not able to use the cakes."}, "gen_args_2": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? No, I am not able to use the cakes."}}, "resps": [[["-107.0", "False"]], [["-108.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-107.0", "False"], ["-108.5", "False"], ["-108.5", "False"]], "doc_hash": "7e4af3483ba65a36cd95ab58f4bc95c56b1cc6c2a436d7ffce148cbfb10cbf1c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.69143845 0.15428077 0.15428077]"]}
{"doc_id": 419, "doc": {"premise": "huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women", "hypothesis": "There were a lot of people attending the satellite seminar.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Yes, There were a lot of people attending the satellite seminar."}, "gen_args_1": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? Also, There were a lot of people attending the satellite seminar."}, "gen_args_2": {"arg_0": "", "arg_1": " huh well that's neat well um it was real funny i went to a seminar that was just it was is a satellite seminar it was really neat and it was just for women, right? No, There were a lot of people attending the satellite seminar."}}, "resps": [[["-202.0", "False"]], [["-204.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-204.0", "False"], ["-205.0", "False"]], "doc_hash": "7439b3d9e4538065d15c09ecd6b7e04d729beff0d81a82b1a31dc3f61076f8c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 427, "doc": {"premise": "with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns", "hypothesis": "Some friends celebrated Mother's Day.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Yes, Some friends celebrated Mother's Day."}, "gen_args_1": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Also, Some friends celebrated Mother's Day."}, "gen_args_2": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? No, Some friends celebrated Mother's Day."}}, "resps": [[["-172.0", "False"]], [["-176.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-176.0", "False"], ["-175.0", "False"]], "doc_hash": "d70d9d9f0ca40943dfe69c152b0da628a1895bbe22059d55ff22eebf10325507", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 435, "doc": {"premise": "uh-huh all right bye now", "hypothesis": "Goodbye!", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Yes, Goodbye!"}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Also, Goodbye!"}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? No, Goodbye!"}}, "resps": [[["-69.5", "False"]], [["-76.0", "False"]], [["-71.0", "False"]]], "filtered_resps": [["-69.5", "False"], ["-76.0", "False"], ["-71.0", "False"]], "doc_hash": "a5304c71ea4ada38ad2f17d4fd0b70282e35e58520d7b8555321db49e967a908", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81657077 0.00122766 0.18220157]"]}
{"doc_id": 443, "doc": {"premise": "it's just that since my money is tight right now i don't even give myself a tempting", "hypothesis": "I only have $20 until payday.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Yes, I only have $20 until payday."}, "gen_args_1": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? Also, I only have $20 until payday."}, "gen_args_2": {"arg_0": "", "arg_1": " it's just that since my money is tight right now i don't even give myself a tempting, right? No, I only have $20 until payday."}}, "resps": [[["-122.0", "False"]], [["-123.5", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-122.0", "False"], ["-123.5", "False"], ["-123.0", "False"]], "doc_hash": "56a1bd725bcff31ded034c86b34003b3df827c8b12125989b454b2ece13cb969", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.62853172 0.14024438 0.2312239 ]"]}
{"doc_id": 451, "doc": {"premise": "Texas only had fifty five thousand when i was there", "hypothesis": "I lived in Texas in the 1980's.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Yes, I lived in Texas in the 1980's."}, "gen_args_1": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Also, I lived in Texas in the 1980's."}, "gen_args_2": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? No, I lived in Texas in the 1980's."}}, "resps": [[["-97.0", "False"]], [["-98.0", "False"]], [["-97.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-98.0", "False"], ["-97.0", "False"]], "doc_hash": "a41c4d884930b77bcad9b7ef24621f3f3e4b1bd6b55e7b92e6e722a785d5d3f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 459, "doc": {"premise": "um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line", "hypothesis": "It's not a good idea to put signs up saying you have an alarm.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Yes, It's not a good idea to put signs up saying you have an alarm."}, "gen_args_1": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Also, It's not a good idea to put signs up saying you have an alarm."}, "gen_args_2": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? No, It's not a good idea to put signs up saying you have an alarm."}}, "resps": [[["-179.0", "False"]], [["-179.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-179.0", "False"], ["-178.0", "False"]], "doc_hash": "a8ed11b29ff8a9fb7ab811e3a0ce2f10640022242b673ed61347b869f1a07c70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 467, "doc": {"premise": "yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home", "hypothesis": "You can't carry a handgun in Texas outside of your house.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Yes, You can't carry a handgun in Texas outside of your house."}, "gen_args_1": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? Also, You can't carry a handgun in Texas outside of your house."}, "gen_args_2": {"arg_0": "", "arg_1": " yes well it it's not it's not legal to carry a handgun in Texas but no it's not you can have it in your home, right? No, You can't carry a handgun in Texas outside of your house."}}, "resps": [[["-133.0", "False"]], [["-140.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-140.0", "False"], ["-132.0", "False"]], "doc_hash": "e5a643992696d7c00a65f784186460ef54379f1e04cdfd9e766151f0e2746ed5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.68875482e-01 2.45182703e-04 7.30879336e-01]"]}
{"doc_id": 475, "doc": {"premise": "and uh so i really enjoyed that", "hypothesis": "I would love to have another since I found it to be so nice.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Yes, I would love to have another since I found it to be so nice."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Also, I would love to have another since I found it to be so nice."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? No, I would love to have another since I found it to be so nice."}}, "resps": [[["-102.0", "False"]], [["-104.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-102.0", "False"], ["-104.0", "False"], ["-106.0", "False"]], "doc_hash": "df1323de2dddf01e25ce36a3ec13b367f96209743c345644f0d4c6200638e961", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 483, "doc": {"premise": "well we're definitely keeping them poor and down trodden and helpless", "hypothesis": "Our actions prevent them from improving.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Yes, Our actions prevent them from improving."}, "gen_args_1": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Also, Our actions prevent them from improving."}, "gen_args_2": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? No, Our actions prevent them from improving."}}, "resps": [[["-110.0", "False"]], [["-114.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-110.0", "False"], ["-114.5", "False"], ["-109.5", "False"]], "doc_hash": "f7dee18dd0145b4acc97d097214018a03662b8871d2de30d5f375f91a3fa39cc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 491, "doc": {"premise": "yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be", "hypothesis": "If I die, I always believe I will be reincarnated as a dog.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Yes, If I die, I always believe I will be reincarnated as a dog."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? Also, If I die, I always believe I will be reincarnated as a dog."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i always said if i died well i always said if i died i'd come back as a dog  that'd be the best way to be, right? No, If I die, I always believe I will be reincarnated as a dog."}}, "resps": [[["-151.0", "False"]], [["-154.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-154.0", "False"], ["-154.0", "False"]], "doc_hash": "6dd3b5649c6d04a6e82e5bb480cabccd2a211bd25e65f78db484cf65c15bb789", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 499, "doc": {"premise": "Espinosa collected many romances from Californios in the 1920s.", "hypothesis": "Espinosa was interested in collecting romances.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Yes, Espinosa was interested in collecting romances."}, "gen_args_1": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Also, Espinosa was interested in collecting romances."}, "gen_args_2": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? No, Espinosa was interested in collecting romances."}}, "resps": [[["-122.5", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "27241e21614e5a55a79c34f0541e7ccff3d8507ad884cfdd85bd2c0c058924f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.95381573e-01 5.50529990e-04 4.06789698e-03]"]}
{"doc_id": 507, "doc": {"premise": "The law redeems not the individual but the community or the nation as a whole.", "hypothesis": "For redemption, individuals should turn to the law.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Yes, For redemption, individuals should turn to the law."}, "gen_args_1": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Also, For redemption, individuals should turn to the law."}, "gen_args_2": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? No, For redemption, individuals should turn to the law."}}, "resps": [[["-123.0", "False"]], [["-127.5", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-127.5", "False"], ["-126.0", "False"]], "doc_hash": "5b73b65b9785088aff7262874d8fdd4e8bafa70590e7e86296f93ccc98c3803c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 515, "doc": {"premise": "Steve Harris, a molecular biologist from Texas was visiting.", "hypothesis": "Steve was visiting California to study a new sample.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Yes, Steve was visiting California to study a new sample."}, "gen_args_1": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? Also, Steve was visiting California to study a new sample."}, "gen_args_2": {"arg_0": "", "arg_1": " Steve Harris, a molecular biologist from Texas was visiting., right? No, Steve was visiting California to study a new sample."}}, "resps": [[["-122.0", "False"]], [["-128.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-128.0", "False"], ["-122.5", "False"]], "doc_hash": "6d1b62f99ad559c6d7730f47370ec01b94f5813fe31dafc4d62b734905f2df6b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.6215004  0.00154055 0.37695905]"]}
{"doc_id": 523, "doc": {"premise": "Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network.", "hypothesis": "Convergent flow is influenced by population.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Yes, Convergent flow is influenced by population."}, "gen_args_1": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Also, Convergent flow is influenced by population."}, "gen_args_2": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? No, Convergent flow is influenced by population."}}, "resps": [[["-227.0", "False"]], [["-226.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-227.0", "False"], ["-226.0", "False"], ["-228.0", "False"]], "doc_hash": "adca0e89cf55fca4bd02e67b6fdd2d8ca419483a32a687bc49b42f263234ea08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 531, "doc": {"premise": "And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens.", "hypothesis": "Some private persons denied social rights to black citizens.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Yes, Some private persons denied social rights to black citizens."}, "gen_args_1": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Also, Some private persons denied social rights to black citizens."}, "gen_args_2": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? No, Some private persons denied social rights to black citizens."}}, "resps": [[["-143.0", "False"]], [["-149.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-149.0", "False"], ["-145.0", "False"]], "doc_hash": "869cec794738dc6ee01f88b07a564a4685c79a02d2d78df8fcb7256f5be9febb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 539, "doc": {"premise": "In the postbellum legal order, the same result derived from federal constitutional principles.", "hypothesis": "The prebellum legal order had much different results despite being derived from state constitution principles.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Yes, The prebellum legal order had much different results despite being derived from state constitution principles."}, "gen_args_1": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? Also, The prebellum legal order had much different results despite being derived from state constitution principles."}, "gen_args_2": {"arg_0": "", "arg_1": " In the postbellum legal order, the same result derived from federal constitutional principles., right? No, The prebellum legal order had much different results despite being derived from state constitution principles."}}, "resps": [[["-166.0", "False"]], [["-165.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-165.0", "False"], ["-164.0", "False"]], "doc_hash": "79e07e9a8db160bc30e4e30f294d8f5f534bf3565e00870f37b5a631f9cde563", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 547, "doc": {"premise": "When civil society turns a deaf ear, crazy ideas lose their edge.", "hypothesis": "Crazy ideas become more popular with civil society when they are ignored by civil society.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Yes, Crazy ideas become more popular with civil society when they are ignored by civil society."}, "gen_args_1": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Also, Crazy ideas become more popular with civil society when they are ignored by civil society."}, "gen_args_2": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? No, Crazy ideas become more popular with civil society when they are ignored by civil society."}}, "resps": [[["-130.0", "False"]], [["-137.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-137.0", "False"], ["-129.0", "False"]], "doc_hash": "96cd54be8cd830c8b32770cae4475c70c1c037273d2b032c1aac285cbcb040f8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68875482e-01 2.45182703e-04 7.30879336e-01]"]}
{"doc_id": 555, "doc": {"premise": "Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves.", "hypothesis": "Palomillas allowed young men to express themselves.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Yes, Palomillas allowed young men to express themselves."}, "gen_args_1": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Also, Palomillas allowed young men to express themselves."}, "gen_args_2": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? No, Palomillas allowed young men to express themselves."}}, "resps": [[["-197.0", "False"]], [["-200.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-200.0", "False"], ["-200.0", "False"]], "doc_hash": "4e96d71094bf4742d4891c42bd4881e856e62424dbacf7a0ad92b3213bd65ef7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 563, "doc": {"premise": "Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American.", "hypothesis": "Americans want to protect the flag.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Yes, Americans want to protect the flag."}, "gen_args_1": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? Also, Americans want to protect the flag."}, "gen_args_2": {"arg_0": "", "arg_1": " Two American ideas'protecting the flag and celebrating freedom of speech'would eventually come into focus as contradictory ways of being American., right? No, Americans want to protect the flag."}}, "resps": [[["-166.0", "False"]], [["-171.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-171.0", "False"], ["-170.0", "False"]], "doc_hash": "c766efbcc49f265a4e67e4faed3c6ad9b068e086ae8a3ce72ec849ef149913fe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 571, "doc": {"premise": "As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table.", "hypothesis": "The sand is always flat and smooth.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Yes, The sand is always flat and smooth."}, "gen_args_1": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Also, The sand is always flat and smooth."}, "gen_args_2": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? No, The sand is always flat and smooth."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "a14052bb01bb4e040e1cba66132542b714bcc423fc7cf29e4b632587df3986f0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 579, "doc": {"premise": "Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges.", "hypothesis": "More and more people started trading on online stock exchanges.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Yes, More and more people started trading on online stock exchanges."}, "gen_args_1": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Also, More and more people started trading on online stock exchanges."}, "gen_args_2": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? No, More and more people started trading on online stock exchanges."}}, "resps": [[["-138.0", "False"]], [["-138.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-138.0", "False"], ["-140.0", "False"]], "doc_hash": "786e5c09f77efabbfdfbcd872c2d7f21ee1a8dc703f07e494671f8c8e32071b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 587, "doc": {"premise": "The audience is invisible; each viewer is in his little cubicle, called a living room.", "hypothesis": "You cannot see the audience.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Yes, You cannot see the audience."}, "gen_args_1": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? Also, You cannot see the audience."}, "gen_args_2": {"arg_0": "", "arg_1": " The audience is invisible; each viewer is in his little cubicle, called a living room., right? No, You cannot see the audience."}}, "resps": [[["-122.0", "False"]], [["-126.0", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-126.0", "False"], ["-120.5", "False"]], "doc_hash": "88cc087929f26d56172230df5686f4f691325976d6a9b02e56f7241403573330", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.18181803 0.00333011 0.81485186]"]}
{"doc_id": 595, "doc": {"premise": "Your heart happened to be preadapted to pick up earthquake pretremors.", "hypothesis": "Earthquakes have pretremors.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Yes, Earthquakes have pretremors."}, "gen_args_1": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Also, Earthquakes have pretremors."}, "gen_args_2": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? No, Earthquakes have pretremors."}}, "resps": [[["-139.0", "False"]], [["-141.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-141.0", "False"], ["-141.0", "False"]], "doc_hash": "c21380343befe01759096ab51ef4b257275171bef1332b7ad3d99734db0a8264", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 603, "doc": {"premise": "Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking.", "hypothesis": "The term barbacoa is used to mean roasting vegetables in the oven.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Yes, The term barbacoa is used to mean roasting vegetables in the oven."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Also, The term barbacoa is used to mean roasting vegetables in the oven."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? No, The term barbacoa is used to mean roasting vegetables in the oven."}}, "resps": [[["-133.0", "False"]], [["-134.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-134.0", "False"], ["-131.0", "False"]], "doc_hash": "46e2ec2683bdb085495d8fde692251175365a7a1f739f525f0181125f416c8ef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 611, "doc": {"premise": "For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced.", "hypothesis": "There are voting rights.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Yes, There are voting rights."}, "gen_args_1": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? Also, There are voting rights."}, "gen_args_2": {"arg_0": "", "arg_1": " For the community of nations, so recognized, equality'let us, say, with regard to voting rights in the General Assembly of the United Nations'becomes a norm readily enforced., right? No, There are voting rights."}}, "resps": [[["-195.0", "False"]], [["-200.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-200.0", "False"], ["-197.0", "False"]], "doc_hash": "8321e37a4864f3a7f82b0d9a372e19b3102abda77d0231fe9fe2816e2c66be47", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 619, "doc": {"premise": "The vaquero or buckaroo is a westerner and the cowboy is a southerner.", "hypothesis": "The cowboy is from the south.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Yes, The cowboy is from the south."}, "gen_args_1": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Also, The cowboy is from the south."}, "gen_args_2": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? No, The cowboy is from the south."}}, "resps": [[["-102.5", "False"]], [["-108.0", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-108.0", "False"], ["-103.5", "False"]], "doc_hash": "c2676e1158672f3131fdff1543db96cbb547e1eb1c7fa1f35c44ce4618710ed1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72888092 0.00297877 0.26814031]"]}
{"doc_id": 627, "doc": {"premise": "It would get really big, take us from our beds and never bring us back home  (November 1974).", "hypothesis": "It always brought them back home.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Yes, It always brought them back home."}, "gen_args_1": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Also, It always brought them back home."}, "gen_args_2": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? No, It always brought them back home."}}, "resps": [[["-158.0", "False"]], [["-159.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-159.0", "False"], ["-156.0", "False"]], "doc_hash": "9767f695887525b41dbd50f978925e28b71ec48e4460db2d953f3b478a1f8d08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 635, "doc": {"premise": "I, in turn, happen to have desires such that I would be happier with rather more pears than apples.", "hypothesis": "I would rather have 10 pears than 10 apples.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Yes, I would rather have 10 pears than 10 apples."}, "gen_args_1": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? Also, I would rather have 10 pears than 10 apples."}, "gen_args_2": {"arg_0": "", "arg_1": " I, in turn, happen to have desires such that I would be happier with rather more pears than apples., right? No, I would rather have 10 pears than 10 apples."}}, "resps": [[["-136.0", "False"]], [["-139.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-139.0", "False"], ["-138.0", "False"]], "doc_hash": "1cc5a47d2808d956a081951c25bff3f3c2ef54ace5ffab763ed7999d5f58da10", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 643, "doc": {"premise": "for in the image of God he made Adam.", "hypothesis": "Adam was delighted that he was made in the image of God.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Yes, Adam was delighted that he was made in the image of God."}, "gen_args_1": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Also, Adam was delighted that he was made in the image of God."}, "gen_args_2": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? No, Adam was delighted that he was made in the image of God."}}, "resps": [[["-97.0", "False"]], [["-99.5", "False"]], [["-94.5", "False"]]], "filtered_resps": [["-97.0", "False"], ["-99.5", "False"], ["-94.5", "False"]], "doc_hash": "b793050ebc18c6f6569da0909dcea6cbda53dcb64722abdad397a9df924653d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07538875 0.00618829 0.91842297]"]}
{"doc_id": 651, "doc": {"premise": "22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s.", "hypothesis": "All apparel industries and shops were permanently closed in 1980.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Yes, All apparel industries and shops were permanently closed in 1980."}, "gen_args_1": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Also, All apparel industries and shops were permanently closed in 1980."}, "gen_args_2": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? No, All apparel industries and shops were permanently closed in 1980."}}, "resps": [[["-237.0", "False"]], [["-237.0", "False"]], [["-236.0", "False"]]], "filtered_resps": [["-237.0", "False"], ["-237.0", "False"], ["-236.0", "False"]], "doc_hash": "585b487644024f1010f5a8d321237e3ed953288e9d4068bacb719a448a3664c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 659, "doc": {"premise": "In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913.", "hypothesis": "There are multiple performances per year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Yes, There are multiple performances per year."}, "gen_args_1": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? Also, There are multiple performances per year."}, "gen_args_2": {"arg_0": "", "arg_1": " In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913., right? No, There are multiple performances per year."}}, "resps": [[["-141.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "4f2a2e74fba5a9b22a6c69f79895ef95c02a89824236cbb62cd87b083693b113", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 667, "doc": {"premise": "Economic growth is part and parcel of the creativity of the universe as a whole.", "hypothesis": "Economic growth models many natural systems found in the universe.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Yes, Economic growth models many natural systems found in the universe."}, "gen_args_1": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Also, Economic growth models many natural systems found in the universe."}, "gen_args_2": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? No, Economic growth models many natural systems found in the universe."}}, "resps": [[["-128.0", "False"]], [["-131.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-131.0", "False"], ["-135.0", "False"]], "doc_hash": "a4e9ebca2f5ffbad3e5735724f96763382eac9a2cd07f29d2877da638ff31166", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.51747406e-01 4.73847131e-02 8.67881295e-04]"]}
{"doc_id": 675, "doc": {"premise": "We are literally making our world together, we critters.", "hypothesis": "Every living being affects the world we live in.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Yes, Every living being affects the world we live in."}, "gen_args_1": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Also, Every living being affects the world we live in."}, "gen_args_2": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? No, Every living being affects the world we live in."}}, "resps": [[["-119.5", "False"]], [["-128.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-128.0", "False"], ["-125.0", "False"]], "doc_hash": "9119eb5f83d915ea09d79d55eec6e955d298c588bb8b57fb5a2eae04d5b66417", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.95728088e-01 2.02599170e-04 4.06931311e-03]"]}
{"doc_id": 683, "doc": {"premise": "So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source.", "hypothesis": "Shannon ignored the message.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Yes, Shannon ignored the message."}, "gen_args_1": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? Also, Shannon ignored the message."}, "gen_args_2": {"arg_0": "", "arg_1": " So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source., right? No, Shannon ignored the message."}}, "resps": [[["-165.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "6736bfa9352e212390715964f134207f26b0a26b446e6f20da2539da73dd9462", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00217852 0.11894324 0.87887824]"]}
{"doc_id": 691, "doc": {"premise": "In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness.", "hypothesis": "Many factors work together to pull evolving populations to higher fitness levels.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Yes, Many factors work together to pull evolving populations to higher fitness levels."}, "gen_args_1": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Also, Many factors work together to pull evolving populations to higher fitness levels."}, "gen_args_2": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? No, Many factors work together to pull evolving populations to higher fitness levels."}}, "resps": [[["-194.0", "False"]], [["-200.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-200.0", "False"], ["-196.0", "False"]], "doc_hash": "b936a22283ed2126bb2b46424359d308504b37056ab356aeff4a2731117693de", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 699, "doc": {"premise": "This is not to say that good architecture is merely utilitarian.", "hypothesis": "Good architecture includes aesthetic beauty, as well as economical function.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Yes, Good architecture includes aesthetic beauty, as well as economical function."}, "gen_args_1": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Also, Good architecture includes aesthetic beauty, as well as economical function."}, "gen_args_2": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? No, Good architecture includes aesthetic beauty, as well as economical function."}}, "resps": [[["-112.0", "False"]], [["-116.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-112.0", "False"], ["-116.0", "False"], ["-110.5", "False"]], "doc_hash": "43dd79b3585d5bc9d5aef1a085792ae16ed9fa3ff9f9a874b7f817cb46ddd4a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.18181803 0.00333011 0.81485186]"]}
{"doc_id": 707, "doc": {"premise": "Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits.", "hypothesis": "Today's children have access to TV, and they spend a lot of time watching it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Yes, Today's children have access to TV, and they spend a lot of time watching it."}, "gen_args_1": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? Also, Today's children have access to TV, and they spend a lot of time watching it."}, "gen_args_2": {"arg_0": "", "arg_1": " Clearly today's children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent-child activities, play, reading, and other worthwhile pursuits., right? No, Today's children have access to TV, and they spend a lot of time watching it."}}, "resps": [[["-181.0", "False"]], [["-187.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-187.0", "False"], ["-182.0", "False"]], "doc_hash": "a4b484fbc33450264320588c23ea6f75a4cf0a4a86cb472669cb87d04035d6f8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 715, "doc": {"premise": "Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book.", "hypothesis": "In this book, I'll cover topics that parents and their children can implement while spending time together.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Yes, In this book, I'll cover topics that parents and their children can implement while spending time together."}, "gen_args_1": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Also, In this book, I'll cover topics that parents and their children can implement while spending time together."}, "gen_args_2": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? No, In this book, I'll cover topics that parents and their children can implement while spending time together."}}, "resps": [[["-192.0", "False"]], [["-198.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-198.0", "False"], ["-193.0", "False"]], "doc_hash": "0cda987d57898f4b4fd417bea71a9e8fc8ae7444ed9104b1d90e0ac9ce294993", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 723, "doc": {"premise": "Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment.", "hypothesis": "Relajo is not funny at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Yes, Relajo is not funny at all."}, "gen_args_1": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Also, Relajo is not funny at all."}, "gen_args_2": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? No, Relajo is not funny at all."}}, "resps": [[["-188.0", "False"]], [["-189.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-189.0", "False"], ["-184.0", "False"]], "doc_hash": "eeb82232721432c730ed135e9254bcce090025a61769c536ef055bd82a91f03a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 731, "doc": {"premise": "Should I help her with her homework, and if so, how should I do so?", "hypothesis": "I should not be tempted to help her with homework.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Yes, I should not be tempted to help her with homework."}, "gen_args_1": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? Also, I should not be tempted to help her with homework."}, "gen_args_2": {"arg_0": "", "arg_1": " Should I help her with her homework, and if so, how should I do so?, right? No, I should not be tempted to help her with homework."}}, "resps": [[["-97.0", "False"]], [["-96.5", "False"]], [["-94.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-96.5", "False"], ["-94.0", "False"]], "doc_hash": "0ec41662711a3d1fe9b9c873834b8699e4404a007b6dad445325b48f0b130489", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04398648 0.07252145 0.88349207]"]}
{"doc_id": 739, "doc": {"premise": "The disputes took on the tones of class struggle.", "hypothesis": "They fought about the poor vs the rich.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Yes, They fought about the poor vs the rich."}, "gen_args_1": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Also, They fought about the poor vs the rich."}, "gen_args_2": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? No, They fought about the poor vs the rich."}}, "resps": [[["-110.5", "False"]], [["-115.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-115.0", "False"], ["-110.5", "False"]], "doc_hash": "b5859830404f7fb7619d9a704fe6d91aebe7ac479f62b256de27f7b8baab5f0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 747, "doc": {"premise": "He turned in appeal to Lord Julian.", "hypothesis": "He wanted to ask Lord Julian something.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Yes, He wanted to ask Lord Julian something."}, "gen_args_1": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Also, He wanted to ask Lord Julian something."}, "gen_args_2": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? No, He wanted to ask Lord Julian something."}}, "resps": [[["-104.0", "False"]], [["-108.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-104.0", "False"], ["-108.0", "False"], ["-105.5", "False"]], "doc_hash": "a4bbfbf2619f63c244eebeacceab575890443148eb2cccf060ccb7903463244d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.80551241 0.01475347 0.17973411]"]}
{"doc_id": 755, "doc": {"premise": "Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging.", "hypothesis": "Pitt witnessed how his lordship was serious during the scene.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Yes, Pitt witnessed how his lordship was serious during the scene."}, "gen_args_1": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? Also, Pitt witnessed how his lordship was serious during the scene."}, "gen_args_2": {"arg_0": "", "arg_1": " Pitt, who watched the scene from the quarter-deck rail, tells us that his lordship was as grave as a parson at a hanging., right? No, Pitt witnessed how his lordship was serious during the scene."}}, "resps": [[["-177.0", "False"]], [["-185.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-185.0", "False"], ["-183.0", "False"]], "doc_hash": "2511ed21c5f072d16a7f93c5cae2ac25ef3f1f92864c2195455a04c20b1e7697", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.97193683e-01 3.34521213e-04 2.47179601e-03]"]}
{"doc_id": 763, "doc": {"premise": "He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted.", "hypothesis": "She and Lord Julian Wade shared a kiss last night.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Yes, She and Lord Julian Wade shared a kiss last night."}, "gen_args_1": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Also, She and Lord Julian Wade shared a kiss last night."}, "gen_args_2": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? No, She and Lord Julian Wade shared a kiss last night."}}, "resps": [[["-213.0", "False"]], [["-215.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-215.0", "False"], ["-214.0", "False"]], "doc_hash": "9ad1ee33cdd9b107ffe2c0f1121633e814dc03402dee016c85b6fab3974a6003", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 771, "doc": {"premise": "Mary Traill would tell you of it.", "hypothesis": "Mary Traill can tell you about the donkey.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Yes, Mary Traill can tell you about the donkey."}, "gen_args_1": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Also, Mary Traill can tell you about the donkey."}, "gen_args_2": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? No, Mary Traill can tell you about the donkey."}}, "resps": [[["-103.5", "False"]], [["-106.5", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-103.5", "False"], ["-106.5", "False"], ["-104.0", "False"]], "doc_hash": "dd55e04f555645075c98655784d7951648c90c7c670eca762d6fae65d11bff13", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.6037489  0.03005889 0.36619222]"]}
{"doc_id": 779, "doc": {"premise": "It'll not be Bishop himself,  said Wolverstone, between question and assertion.", "hypothesis": "Wolverstone never said anything about the Bishop.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Yes, Wolverstone never said anything about the Bishop."}, "gen_args_1": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? Also, Wolverstone never said anything about the Bishop."}, "gen_args_2": {"arg_0": "", "arg_1": " It'll not be Bishop himself,  said Wolverstone, between question and assertion., right? No, Wolverstone never said anything about the Bishop."}}, "resps": [[["-161.0", "False"]], [["-161.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-161.0", "False"], ["-157.0", "False"]], "doc_hash": "a52b642142a3402d5e430d922d56f12eb448b1d343b77aae33bea9630ddc9050", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 787, "doc": {"premise": "They are within range,  cried Ogle.", "hypothesis": "Ogle said that they were within earshot.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Yes, Ogle said that they were within earshot."}, "gen_args_1": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Also, Ogle said that they were within earshot."}, "gen_args_2": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? No, Ogle said that they were within earshot."}}, "resps": [[["-118.0", "False"]], [["-119.0", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-118.0", "False"], ["-119.0", "False"], ["-115.5", "False"]], "doc_hash": "cdf65f890dfb3b6334ac3f81df511f0cb6773f78ec18ea32b63350629cb575bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0737987  0.02714903 0.89905227]"]}
{"doc_id": 795, "doc": {"premise": "You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him.", "hypothesis": "Ogle had a crew.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Yes, Ogle had a crew."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Also, Ogle had a crew."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? No, Ogle had a crew."}}, "resps": [[["-191.0", "False"]], [["-193.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-193.0", "False"], ["-193.0", "False"]], "doc_hash": "0fa45ae51e5d7e2797b6f3ba2a54ae479fe7fdbb20df04a0033a5ccd89ae7b2d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 803, "doc": {"premise": "Don't think I accept it willingly.", "hypothesis": "I don't accept it willingly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Yes, I don't accept it willingly."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? Also, I don't accept it willingly."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't think I accept it willingly., right? No, I don't accept it willingly."}}, "resps": [[["-74.0", "False"]], [["-79.0", "False"]], [["-71.0", "False"]]], "filtered_resps": [["-74.0", "False"], ["-79.0", "False"], ["-71.0", "False"]], "doc_hash": "246cc880491bfa48a619030983af5c1c3799df0aab17f0ad9be31724719a757e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 811, "doc": {"premise": "It was she now who was on her defence, her voice quivering with indignation.", "hypothesis": "The woman was angry and defensive.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Yes, The woman was angry and defensive."}, "gen_args_1": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Also, The woman was angry and defensive."}, "gen_args_2": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? No, The woman was angry and defensive."}}, "resps": [[["-121.0", "False"]], [["-125.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-125.0", "False"], ["-121.0", "False"]], "doc_hash": "7ea5cfa61a85b9cb686db55111ca35c3d0f964419462d800a7e67bfd9d55bf5b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 819, "doc": {"premise": "Life can be infernally complex,  he sighed.", "hypothesis": "He let out a sign of resignation.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Yes, He let out a sign of resignation."}, "gen_args_1": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Also, He let out a sign of resignation."}, "gen_args_2": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? No, He let out a sign of resignation."}}, "resps": [[["-113.5", "False"]], [["-116.5", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-116.5", "False"], ["-114.5", "False"]], "doc_hash": "4d9ff97806679008fc937d5fe81b13e6d57ca9de85a6081e5a3dc3c2b057dc3c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 827, "doc": {"premise": "I... I believe that he has,  said Calverley, between doubt and suspicion.", "hypothesis": "Cleverly spoke with clear decisiveness, knowing that he has with certainty.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Yes, Cleverly spoke with clear decisiveness, knowing that he has with certainty."}, "gen_args_1": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? Also, Cleverly spoke with clear decisiveness, knowing that he has with certainty."}, "gen_args_2": {"arg_0": "", "arg_1": " I... I believe that he has,  said Calverley, between doubt and suspicion., right? No, Cleverly spoke with clear decisiveness, knowing that he has with certainty."}}, "resps": [[["-190.0", "False"]], [["-194.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-194.0", "False"], ["-187.0", "False"]], "doc_hash": "65e006ab1678889858dc19a9e6154fb3f6f09b8256f22bba8e08eebe9e81d1cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 835, "doc": {"premise": "It is an honourable service.", "hypothesis": "It is an honorable service because it's about saving lives.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is an honourable service., right? Yes, It is an honorable service because it's about saving lives."}, "gen_args_1": {"arg_0": "", "arg_1": " It is an honourable service., right? Also, It is an honorable service because it's about saving lives."}, "gen_args_2": {"arg_0": "", "arg_1": " It is an honourable service., right? No, It is an honorable service because it's about saving lives."}}, "resps": [[["-85.5", "False"]], [["-90.0", "False"]], [["-87.5", "False"]]], "filtered_resps": [["-85.5", "False"], ["-90.0", "False"], ["-87.5", "False"]], "doc_hash": "ef9e29d8abe893bbd2aad2d6cae7a610f16fb0bc87b14fbc5e3dbb6d950263f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 843, "doc": {"premise": "He looked up in surprise, and then sat conning her with brooding glance.", "hypothesis": "He kept his eyes down looking at the ground.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Yes, He kept his eyes down looking at the ground."}, "gen_args_1": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Also, He kept his eyes down looking at the ground."}, "gen_args_2": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? No, He kept his eyes down looking at the ground."}}, "resps": [[["-139.0", "False"]], [["-141.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-141.0", "False"], ["-137.0", "False"]], "doc_hash": "0afc00530eefefd17dfe1d7445ac7aee8feaec7a42ed415fd62eddcaa830847f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 851, "doc": {"premise": "He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron.", "hypothesis": "He was doing repairs on his ship.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Yes, He was doing repairs on his ship."}, "gen_args_1": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? Also, He was doing repairs on his ship."}, "gen_args_2": {"arg_0": "", "arg_1": " He had been a fortnight in Port Royal, his ship virtually a unit now in the Jamaica squadron., right? No, He was doing repairs on his ship."}}, "resps": [[["-148.0", "False"]], [["-149.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-149.0", "False"], ["-148.0", "False"]], "doc_hash": "5a18046ae8eaba04f750f1aec0e0460c1e4ad047f92f44e36127e19022584edd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 859, "doc": {"premise": "Believe me, I am very grateful.", "hypothesis": "I am grateful because you had done a lot for me.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Yes, I am grateful because you had done a lot for me."}, "gen_args_1": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Also, I am grateful because you had done a lot for me."}, "gen_args_2": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? No, I am grateful because you had done a lot for me."}}, "resps": [[["-81.5", "False"]], [["-87.5", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-81.5", "False"], ["-87.5", "False"], ["-85.0", "False"]], "doc_hash": "d5e0d69edd4f7d6efd2249ad084661e09423e468f31562bc8357c335f131c9fa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96835781 0.00240032 0.02924187]"]}
{"doc_id": 867, "doc": {"premise": "Blood broke the seal, and read.", "hypothesis": "Blood is a man.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Yes, Blood is a man."}, "gen_args_1": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Also, Blood is a man."}, "gen_args_2": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? No, Blood is a man."}}, "resps": [[["-93.5", "False"]], [["-93.5", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-93.5", "False"], ["-92.5", "False"]], "doc_hash": "872ee442658f1b95163c8f4094f6e6ccbbe5284c7ce29c2ecde728d99f0a8fd4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 875, "doc": {"premise": "Mine is the safe and easy way.", "hypothesis": "There is a way that is safe and easy.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Yes, There is a way that is safe and easy."}, "gen_args_1": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? Also, There is a way that is safe and easy."}, "gen_args_2": {"arg_0": "", "arg_1": " Mine is the safe and easy way., right? No, There is a way that is safe and easy."}}, "resps": [[["-86.0", "False"]], [["-93.5", "False"]], [["-86.5", "False"]]], "filtered_resps": [["-86.0", "False"], ["-93.5", "False"], ["-86.5", "False"]], "doc_hash": "ec50ad56dd06c8bc1775c4f0c9a6ad7bd07728e201db7065de7ed85cdd97f7f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22245109e-01 3.44154044e-04 3.77410737e-01]"]}
{"doc_id": 883, "doc": {"premise": "Colder still and more distant than ever grew his lordship's voice.", "hypothesis": "His lordship spoke calmly to all giving the impression of a warm and gentle person.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Yes, His lordship spoke calmly to all giving the impression of a warm and gentle person."}, "gen_args_1": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Also, His lordship spoke calmly to all giving the impression of a warm and gentle person."}, "gen_args_2": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? No, His lordship spoke calmly to all giving the impression of a warm and gentle person."}}, "resps": [[["-162.0", "False"]], [["-166.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-166.0", "False"], ["-164.0", "False"]], "doc_hash": "5ef9e7c677b2d4c7890424a7f11193dfe78c10d49aac69e7accd473e131a7451", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 891, "doc": {"premise": "No.  Blood closed his telescope.", "hypothesis": "The blood came from a person's eye as they had looked into the telescope.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Yes, The blood came from a person's eye as they had looked into the telescope."}, "gen_args_1": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Also, The blood came from a person's eye as they had looked into the telescope."}, "gen_args_2": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? No, The blood came from a person's eye as they had looked into the telescope."}}, "resps": [[["-146.0", "False"]], [["-152.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-152.0", "False"], ["-145.0", "False"]], "doc_hash": "56eb82681a673b4b0d5c136e5d1289b4b2ff7c0c3f1404e461a2c9eb1c5b44f6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[2.68762254e-01 6.66195022e-04 7.30571551e-01]"]}
{"doc_id": 899, "doc": {"premise": "‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?", "hypothesis": "You should explain yourself! What happened to Wolverstone?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Yes, You should explain yourself! What happened to Wolverstone?"}, "gen_args_1": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? Also, You should explain yourself! What happened to Wolverstone?"}, "gen_args_2": {"arg_0": "", "arg_1": " ‘Swounds! Perhaps you'll explain yourself? Whither has Wolverstone gone?, right? No, You should explain yourself! What happened to Wolverstone?"}}, "resps": [[["-158.0", "False"]], [["-163.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-163.0", "False"], ["-159.0", "False"]], "doc_hash": "b9785074bfd98091aece310bb58ca12a9df73611ecd6b465d3fba9e0f8fd2c82", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 907, "doc": {"premise": "But Wolverstone would not stop.", "hypothesis": "The Wolverstone did not come to an end.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Yes, The Wolverstone did not come to an end."}, "gen_args_1": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Also, The Wolverstone did not come to an end."}, "gen_args_2": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? No, The Wolverstone did not come to an end."}}, "resps": [[["-98.5", "False"]], [["-104.0", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-104.0", "False"], ["-96.5", "False"]], "doc_hash": "9777d77be6bf166f6a4b599d9db0833af5437fc0e7a0a8cdd72ac9f3002383bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19144880e-01 4.86917893e-04 8.80368202e-01]"]}
{"doc_id": 915, "doc": {"premise": "Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged.", "hypothesis": "He had moved his shoulders in a sign of acceptance.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Yes, He had moved his shoulders in a sign of acceptance."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Also, He had moved his shoulders in a sign of acceptance."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? No, He had moved his shoulders in a sign of acceptance."}}, "resps": [[["-203.0", "False"]], [["-208.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-208.0", "False"], ["-205.0", "False"]], "doc_hash": "018f22d898501330364d8734187ddf66f1f6b1a6b470c3143097ed8ccfcb8365", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 923, "doc": {"premise": "I can't think that it would make the least difference if he did,  said his lordship gravely.", "hypothesis": "Whether or not he chose to act, his lordship did not believe it would have changed anything.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Yes, Whether or not he chose to act, his lordship did not believe it would have changed anything."}, "gen_args_1": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? Also, Whether or not he chose to act, his lordship did not believe it would have changed anything."}, "gen_args_2": {"arg_0": "", "arg_1": " I can't think that it would make the least difference if he did,  said his lordship gravely., right? No, Whether or not he chose to act, his lordship did not believe it would have changed anything."}}, "resps": [[["-161.0", "False"]], [["-167.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-167.0", "False"], ["-161.0", "False"]], "doc_hash": "640689a2455d9cc81dc491fa6fe6e36630e088b5ca028434e8c6620bcc0d1a89", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 931, "doc": {"premise": "But I suspect this gravity for a mask under which Lord Julian was secretly amused.", "hypothesis": "Julian thought the situation was funny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Yes, Julian thought the situation was funny."}, "gen_args_1": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Also, Julian thought the situation was funny."}, "gen_args_2": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? No, Julian thought the situation was funny."}}, "resps": [[["-151.0", "False"]], [["-155.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-155.0", "False"], ["-153.0", "False"]], "doc_hash": "0d36eb0fa385f8b656f06c7a02990d993886ca7aaf0aee3bef778e142df6d133", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 939, "doc": {"premise": "Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle.", "hypothesis": "People from the forecastle were joining the men in the waist.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Yes, People from the forecastle were joining the men in the waist."}, "gen_args_1": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Also, People from the forecastle were joining the men in the waist."}, "gen_args_2": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? No, People from the forecastle were joining the men in the waist."}}, "resps": [[["-237.0", "False"]], [["-240.0", "False"]], [["-239.0", "False"]]], "filtered_resps": [["-237.0", "False"], ["-240.0", "False"], ["-239.0", "False"]], "doc_hash": "2de67195faaf183f8b0cc0b9765b0a652612c540b2a8777043008ab40108f0ab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 947, "doc": {"premise": "Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after.", "hypothesis": "We will attempt to battle over it, once we begin to sail.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Yes, We will attempt to battle over it, once we begin to sail."}, "gen_args_1": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? Also, We will attempt to battle over it, once we begin to sail."}, "gen_args_2": {"arg_0": "", "arg_1": " Then let them know that if they attempt to hinder our sailing hence, we'll hang the doxy first and fight for it after., right? No, We will attempt to battle over it, once we begin to sail."}}, "resps": [[["-202.0", "False"]], [["-207.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-207.0", "False"], ["-205.0", "False"]], "doc_hash": "0335874b416fa9d04b3a5070c6ab00eea80c00a630ad9fcf28a6c62302097502", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 955, "doc": {"premise": "So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import.", "hypothesis": "The Deputy-Governor was not necessarily expecting him, though greeted him anyways.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Yes, The Deputy-Governor was not necessarily expecting him, though greeted him anyways."}, "gen_args_1": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Also, The Deputy-Governor was not necessarily expecting him, though greeted him anyways."}, "gen_args_2": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? No, The Deputy-Governor was not necessarily expecting him, though greeted him anyways."}}, "resps": [[["-227.0", "False"]], [["-228.0", "False"]], [["-225.0", "False"]]], "filtered_resps": [["-227.0", "False"], ["-228.0", "False"], ["-225.0", "False"]], "doc_hash": "df04e804ab091fb7562ac63d4f816a441e68304eb93a00b3ce9b1a30bbc2c81d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 963, "doc": {"premise": "What I think of you can be a very little matter to you, sir.   This was a disarming stroke.", "hypothesis": "It doesn't matter what I think of you.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Yes, It doesn't matter what I think of you."}, "gen_args_1": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Also, It doesn't matter what I think of you."}, "gen_args_2": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? No, It doesn't matter what I think of you."}}, "resps": [[["-149.0", "False"]], [["-149.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-149.0", "False"], ["-147.0", "False"]], "doc_hash": "be99f7b4255c34636477fdcbdfbbad3387f2710e73089e1a7861ce0b0deee043", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 971, "doc": {"premise": "About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men.", "hypothesis": "This evening was busier than usual because of an event being hosted.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Yes, This evening was busier than usual because of an event being hosted."}, "gen_args_1": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? Also, This evening was busier than usual because of an event being hosted."}, "gen_args_2": {"arg_0": "", "arg_1": " About him in the waist, where all last night had been so peaceful, there was a frenziedly active bustle of some threescore men., right? No, This evening was busier than usual because of an event being hosted."}}, "resps": [[["-212.0", "False"]], [["-215.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-215.0", "False"], ["-214.0", "False"]], "doc_hash": "d890a37195d0f30398dcc1d7ebd712d7820ebe4d1e3a1523e62e6837be7962d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 979, "doc": {"premise": "You'll not go?  he said, between question and assertion.", "hypothesis": "Please do not go! He begged.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Yes, Please do not go! He begged."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Also, Please do not go! He begged."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? No, Please do not go! He begged."}}, "resps": [[["-123.5", "False"]], [["-126.5", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-126.5", "False"], ["-121.0", "False"]], "doc_hash": "d77a7ec8a8999bc655b3cd1fdce5748cca8e26d1064b21a3679066adb94fc455", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 987, "doc": {"premise": "See it manned for me.", "hypothesis": "It should be controlled by someone.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See it manned for me., right? Yes, It should be controlled by someone."}, "gen_args_1": {"arg_0": "", "arg_1": " See it manned for me., right? Also, It should be controlled by someone."}, "gen_args_2": {"arg_0": "", "arg_1": " See it manned for me., right? No, It should be controlled by someone."}}, "resps": [[["-92.5", "False"]], [["-95.5", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-92.5", "False"], ["-95.5", "False"], ["-92.5", "False"]], "doc_hash": "3d2a80554c2deb7c7899a9d687fa1a371e2b6373503dd10a6754acfc923c3d73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 995, "doc": {"premise": "Ha!  Wolverstone vented an ejaculation of sneering mirth.", "hypothesis": "Wolverstone thought that was funny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Yes, Wolverstone thought that was funny."}, "gen_args_1": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? Also, Wolverstone thought that was funny."}, "gen_args_2": {"arg_0": "", "arg_1": " Ha!  Wolverstone vented an ejaculation of sneering mirth., right? No, Wolverstone thought that was funny."}}, "resps": [[["-134.0", "False"]], [["-137.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-137.0", "False"], ["-136.0", "False"]], "doc_hash": "2d0c62b46f6915d4dc18de283ec0a8ece61614381e928f3f1753b414b75e7a88", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1003, "doc": {"premise": "Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance.", "hypothesis": "The Perfume Factory is behind the South African Area.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Yes, The Perfume Factory is behind the South African Area."}, "gen_args_1": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Also, The Perfume Factory is behind the South African Area."}, "gen_args_2": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? No, The Perfume Factory is behind the South African Area."}}, "resps": [[["-136.0", "False"]], [["-139.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-139.0", "False"], ["-134.0", "False"]], "doc_hash": "db7d5f54acf971bd7368db81129a6a78b34e42175a697de71f6694ef208a668d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1011, "doc": {"premise": "The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption.", "hypothesis": "The 2 mile sound could have been caused by many things, including a volcanic eruption.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Yes, The 2 mile sound could have been caused by many things, including a volcanic eruption."}, "gen_args_1": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Also, The 2 mile sound could have been caused by many things, including a volcanic eruption."}, "gen_args_2": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? No, The 2 mile sound could have been caused by many things, including a volcanic eruption."}}, "resps": [[["-157.0", "False"]], [["-159.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-159.0", "False"], ["-158.0", "False"]], "doc_hash": "0969bc3cdd232f664825b4219363d03d231f7b94571f35ecc0e28cd59157b2c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1019, "doc": {"premise": "Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet.", "hypothesis": "The prince's garden is home to the building called the Sailor's House.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Yes, The prince's garden is home to the building called the Sailor's House."}, "gen_args_1": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? Also, The prince's garden is home to the building called the Sailor's House."}, "gen_args_2": {"arg_0": "", "arg_1": " Elsewhere in the prince's garden, in a modern building called the Sailor's House (Casa de Marinos), you can find out what became of the quaint  Tagus squadron  of the royal fleet., right? No, The prince's garden is home to the building called the Sailor's House."}}, "resps": [[["-242.0", "False"]], [["-247.0", "False"]], [["-241.0", "False"]]], "filtered_resps": [["-242.0", "False"], ["-247.0", "False"], ["-241.0", "False"]], "doc_hash": "eaac4ccbb149938d56fbb68549f6e45571e85a511bcff159aee39306b40c1621", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1027, "doc": {"premise": "A flick of a tail or fluke, and it's gone.", "hypothesis": "It is fearless, and will not be moved by anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Yes, It is fearless, and will not be moved by anything."}, "gen_args_1": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Also, It is fearless, and will not be moved by anything."}, "gen_args_2": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? No, It is fearless, and will not be moved by anything."}}, "resps": [[["-132.0", "False"]], [["-131.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-131.0", "False"], ["-128.0", "False"]], "doc_hash": "b468a954bf8ffc227f23b03a23888c49392bf271c3a36024e89214c4cbe58d17", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 1035, "doc": {"premise": "Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web.", "hypothesis": "Singel was a tourist location.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Yes, Singel was a tourist location."}, "gen_args_1": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Also, Singel was a tourist location."}, "gen_args_2": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? No, Singel was a tourist location."}}, "resps": [[["-168.0", "False"]], [["-169.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-169.0", "False"], ["-168.0", "False"]], "doc_hash": "5165baa7645fd50a5ed8b580381e776b8679da86c59d37e01d7af98b482176a6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1043, "doc": {"premise": "The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex.", "hypothesis": "Karl-Marx-Allee is in pristine shape.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Yes, Karl-Marx-Allee is in pristine shape."}, "gen_args_1": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? Also, Karl-Marx-Allee is in pristine shape."}, "gen_args_2": {"arg_0": "", "arg_1": " The crumbling faaades of apartments, hotels, and bargain basement shops line Karl-Marx-Allee leading southeast from Alex., right? No, Karl-Marx-Allee is in pristine shape."}}, "resps": [[["-172.0", "False"]], [["-176.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-176.0", "False"], ["-172.0", "False"]], "doc_hash": "d53af83283c6a6494a112f93d7f6e5c0788c4cd1fad4b21dbe40f12f2ce293cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1051, "doc": {"premise": "Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs.", "hypothesis": "The Saguenay River was part of the fur trade by the French to the Spanish.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Yes, The Saguenay River was part of the fur trade by the French to the Spanish."}, "gen_args_1": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Also, The Saguenay River was part of the fur trade by the French to the Spanish."}, "gen_args_2": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? No, The Saguenay River was part of the fur trade by the French to the Spanish."}}, "resps": [[["-209.0", "False"]], [["-210.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-210.0", "False"], ["-211.0", "False"]], "doc_hash": "9271d829b8c4667e0a72424df6b1c2f2de03414283b6cde5cbfa75f8b3ac2963", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1059, "doc": {"premise": "A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis.", "hypothesis": "The Spartans defeated the Persians at Thermopylae.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Yes, The Spartans defeated the Persians at Thermopylae."}, "gen_args_1": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Also, The Spartans defeated the Persians at Thermopylae."}, "gen_args_2": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? No, The Spartans defeated the Persians at Thermopylae."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-149.0", "False"]], "doc_hash": "c641d14ef0364306ef5efa62f5e8af27283c383eeb5dce88e7e693209d416b71", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1067, "doc": {"premise": "In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling.", "hypothesis": "Weltkugelbrunnen is made of granite.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Yes, Weltkugelbrunnen is made of granite."}, "gen_args_1": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? Also, Weltkugelbrunnen is made of granite."}, "gen_args_2": {"arg_0": "", "arg_1": " In the center of the square is Joachim Schmettau's granite Weltkugelbrunnen (or Fountain of the World), which locals have gaily christened the  aquatic dumpling., right? No, Weltkugelbrunnen is made of granite."}}, "resps": [[["-218.0", "False"]], [["-218.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-218.0", "False"], ["-218.0", "False"], ["-217.0", "False"]], "doc_hash": "676297052ddb6d1294931ac1e7e966b587f614f16502aa1f15630fa9446f8f35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1075, "doc": {"premise": "A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known.", "hypothesis": "Boot is near the La'al Ratty.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Yes, Boot is near the La'al Ratty."}, "gen_args_1": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Also, Boot is near the La'al Ratty."}, "gen_args_2": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? No, Boot is near the La'al Ratty."}}, "resps": [[["-163.0", "False"]], [["-170.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-170.0", "False"], ["-166.0", "False"]], "doc_hash": "a9afcdc7830af56cc74089e0f3d81a2c58cadf4e00d840f05d986c84f210c57a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 1083, "doc": {"premise": "702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory.", "hypothesis": "One Vegas coffee house was built in 1940.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Yes, One Vegas coffee house was built in 1940."}, "gen_args_1": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Also, One Vegas coffee house was built in 1940."}, "gen_args_2": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? No, One Vegas coffee house was built in 1940."}}, "resps": [[["-182.0", "False"]], [["-185.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-185.0", "False"], ["-185.0", "False"]], "doc_hash": "5c62330cebbd750d05e7f0f1469df407f41e58ec7fd10938cf35850596078c59", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1091, "doc": {"premise": "The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans.", "hypothesis": "James Cook went to every Hawaiian island.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Yes, James Cook went to every Hawaiian island."}, "gen_args_1": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? Also, James Cook went to every Hawaiian island."}, "gen_args_2": {"arg_0": "", "arg_1": " The first Westerner to reach Hawaii was Captain James Cook, the British commander whose mission was to disacover the mythic Northwest Passage linking the Atlantic and Pacific oceans., right? No, James Cook went to every Hawaiian island."}}, "resps": [[["-151.0", "False"]], [["-153.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-153.0", "False"], ["-151.0", "False"]], "doc_hash": "ac8fedf0e2dde94ce581b177945f5f7e62520eb9fbf8cf7f867b728c2e4d1628", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1099, "doc": {"premise": "Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time.", "hypothesis": "The a5 coin was British.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Yes, The a5 coin was British."}, "gen_args_1": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Also, The a5 coin was British."}, "gen_args_2": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? No, The a5 coin was British."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-151.0", "False"]], "doc_hash": "c75d6671c5c23f6caf5982aa26903b8b839d6094f41fa7ecbc183470cd3b0033", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1107, "doc": {"premise": "The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality.", "hypothesis": "The faaade was in King Tut's tomb.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Yes, The faaade was in King Tut's tomb."}, "gen_args_1": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Also, The faaade was in King Tut's tomb."}, "gen_args_2": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? No, The faaade was in King Tut's tomb."}}, "resps": [[["-174.0", "False"]], [["-175.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-175.0", "False"], ["-174.0", "False"]], "doc_hash": "50cf06fd27113e6012fa2f71cf6a452c0a7f2f6dcc844dc40a334d9f5596506f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1115, "doc": {"premise": "A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark.", "hypothesis": "People like to drink a lot of beer at the bars after they go fishing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Yes, People like to drink a lot of beer at the bars after they go fishing."}, "gen_args_1": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? Also, People like to drink a lot of beer at the bars after they go fishing."}, "gen_args_2": {"arg_0": "", "arg_1": " A series of fishing competitions make up a  season  for the rich, bright, and beautiful, who descend to fish during the day and enjoy the lively social scene after dark., right? No, People like to drink a lot of beer at the bars after they go fishing."}}, "resps": [[["-223.0", "False"]], [["-222.0", "False"]], [["-222.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-222.0", "False"], ["-222.0", "False"]], "doc_hash": "3bb906aedf3e9858e212ad06438af9822ef29686801b44224c1881fb199b207a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1123, "doc": {"premise": "Also check out Star Computer City in the Star House near the Star Ferry terminal.", "hypothesis": "Computer City is located in the Star House.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Yes, Computer City is located in the Star House."}, "gen_args_1": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Also, Computer City is located in the Star House."}, "gen_args_2": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? No, Computer City is located in the Star House."}}, "resps": [[["-124.0", "False"]], [["-125.5", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-125.5", "False"], ["-126.5", "False"]], "doc_hash": "b358da475a1b8a0a91a91188ac8c110c910451f50bb5d6531595e8e8f0f8587a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.76615721 0.17095278 0.06289001]"]}
{"doc_id": 1131, "doc": {"premise": "The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops.", "hypothesis": "The shops all serve some of the best food in the city.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Yes, The shops all serve some of the best food in the city."}, "gen_args_1": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Also, The shops all serve some of the best food in the city."}, "gen_args_2": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? No, The shops all serve some of the best food in the city."}}, "resps": [[["-156.0", "False"]], [["-157.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-157.0", "False"], ["-158.0", "False"]], "doc_hash": "8d991e8377867ebf3446d4ee707fe8b947ddcce8d7f55dfb624d2eea86d62228", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1139, "doc": {"premise": "Detour to see the mansion designed by McKim Mead", "hypothesis": "The mansion was built by Adam Sandler.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Yes, The mansion was built by Adam Sandler."}, "gen_args_1": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? Also, The mansion was built by Adam Sandler."}, "gen_args_2": {"arg_0": "", "arg_1": " Detour to see the mansion designed by McKim Mead, right? No, The mansion was built by Adam Sandler."}}, "resps": [[["-113.5", "False"]], [["-115.5", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-115.5", "False"], ["-113.0", "False"]], "doc_hash": "8cdc8f3742254165db4a421511f09246125556ba8f4e5c1f5f79138283c5dbf7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.35918811 0.04861082 0.59220107]"]}
{"doc_id": 1147, "doc": {"premise": "The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe.", "hypothesis": "James Wilson Marshall did something special.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Yes, James Wilson Marshall did something special."}, "gen_args_1": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Also, James Wilson Marshall did something special."}, "gen_args_2": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? No, James Wilson Marshall did something special."}}, "resps": [[["-171.0", "False"]], [["-177.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-177.0", "False"], ["-174.0", "False"]], "doc_hash": "500278e00a80d5988a8190929f2eb29b6a9c40b170a9a1003097388e26aef3ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1155, "doc": {"premise": "Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night.", "hypothesis": "Coupons are given out on the beach at night, hoping for customers the next day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Yes, Coupons are given out on the beach at night, hoping for customers the next day."}, "gen_args_1": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Also, Coupons are given out on the beach at night, hoping for customers the next day."}, "gen_args_2": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? No, Coupons are given out on the beach at night, hoping for customers the next day."}}, "resps": [[["-168.0", "False"]], [["-169.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-169.0", "False"], ["-163.0", "False"]], "doc_hash": "f621d202fcee0484c049b4b8aaf3b66a465bbfa7db2d129d53595213f68e7d35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1163, "doc": {"premise": "Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife.", "hypothesis": "Laguna Nichupte is a body of water.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Yes, Laguna Nichupte is a body of water."}, "gen_args_1": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? Also, Laguna Nichupte is a body of water."}, "gen_args_2": {"arg_0": "", "arg_1": " Between the island and the mainland is Laguna Nichupte, a huge seawater lagoon bounded by mangrove swamps that are havens to numerous species of wildlife., right? No, Laguna Nichupte is a body of water."}}, "resps": [[["-147.0", "False"]], [["-152.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-152.0", "False"], ["-149.0", "False"]], "doc_hash": "8e5e6acca6f2eea1b06f5f4ccaf7b17d8a151bf0e48847d3d0ad0378868ad943", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1171, "doc": {"premise": "The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded.", "hypothesis": "There are only 10 people in Gorges d'Apreamont.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Yes, There are only 10 people in Gorges d'Apreamont."}, "gen_args_1": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Also, There are only 10 people in Gorges d'Apreamont."}, "gen_args_2": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? No, There are only 10 people in Gorges d'Apreamont."}}, "resps": [[["-187.0", "False"]], [["-191.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-191.0", "False"], ["-188.0", "False"]], "doc_hash": "738b1b5b39b0b30e54b37bf690bd665fd56218233c74ee224b98b01da2ef6e71", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1179, "doc": {"premise": "Just so long as you don't object to being shown up by the resident ten-year-old experts.", "hypothesis": "The ten year olds are idiots.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Yes, The ten year olds are idiots."}, "gen_args_1": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Also, The ten year olds are idiots."}, "gen_args_2": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? No, The ten year olds are idiots."}}, "resps": [[["-122.5", "False"]], [["-124.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-124.0", "False"], ["-122.5", "False"]], "doc_hash": "0ea2e6fdec4df923146e302629c61d5196934b89f49e37d0b30a527e37d350ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.44981622 0.10036756 0.44981622]"]}
{"doc_id": 1187, "doc": {"premise": "For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures.", "hypothesis": "Old nickelodeons should be owned by film buffs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Yes, Old nickelodeons should be owned by film buffs."}, "gen_args_1": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? Also, Old nickelodeons should be owned by film buffs."}, "gen_args_2": {"arg_0": "", "arg_1": " For film buffs, the most interesting display will be the collection of old nickelodeons, autoscopes, and movieola machines that projected the very first moving pictures., right? No, Old nickelodeons should be owned by film buffs."}}, "resps": [[["-190.0", "False"]], [["-194.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-194.0", "False"], ["-194.0", "False"]], "doc_hash": "2722d818b31e7be753a80b68ab7ba15d5947a455b7b90a75f1150cbfdc6560f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1195, "doc": {"premise": "If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street.", "hypothesis": "Harvard Square is the best at night.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Yes, Harvard Square is the best at night."}, "gen_args_1": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Also, Harvard Square is the best at night."}, "gen_args_2": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? No, Harvard Square is the best at night."}}, "resps": [[["-144.0", "False"]], [["-146.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-146.0", "False"], ["-143.0", "False"]], "doc_hash": "7f1d408488c1b5156650c2f259e59b73d09e063169aa8d9c544a80840d416364", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1203, "doc": {"premise": "Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door.", "hypothesis": "The town is an angry, terrible place.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Yes, The town is an angry, terrible place."}, "gen_args_1": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Also, The town is an angry, terrible place."}, "gen_args_2": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? No, The town is an angry, terrible place."}}, "resps": [[["-217.0", "False"]], [["-220.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-217.0", "False"], ["-220.0", "False"], ["-214.0", "False"]], "doc_hash": "d1b0cf0583c08da4bbb8ac5bd2b61e54b14af9ba0f6db1939095914bfb1e4c39", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1211, "doc": {"premise": "At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades.", "hypothesis": "There is nothing to do there at night.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Yes, There is nothing to do there at night."}, "gen_args_1": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? Also, There is nothing to do there at night."}, "gen_args_2": {"arg_0": "", "arg_1": " At night there are many good restaurants, clubs, and theaters to enjoy, and by day there is the glorious beach, complete with an amusement pier, antique carousel, and the nearby shopping arcades., right? No, There is nothing to do there at night."}}, "resps": [[["-177.0", "False"]], [["-178.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-178.0", "False"], ["-173.0", "False"]], "doc_hash": "2a12273df4ffd51d81716d41fd2e2782cb079e715b4ac384a6f1d077820ebeb8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1219, "doc": {"premise": "Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French.", "hypothesis": "Rocroi saw 1000 Spanish troops killed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Yes, Rocroi saw 1000 Spanish troops killed."}, "gen_args_1": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Also, Rocroi saw 1000 Spanish troops killed."}, "gen_args_2": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? No, Rocroi saw 1000 Spanish troops killed."}}, "resps": [[["-166.0", "False"]], [["-167.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-167.0", "False"], ["-168.0", "False"]], "doc_hash": "c8077466ba0887583e486b9b7d01c6eed0b9f704d79b3337d467b3758e19fa30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1227, "doc": {"premise": "Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible.", "hypothesis": "It's best to book 6 months ahead of your visit.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Yes, It's best to book 6 months ahead of your visit."}, "gen_args_1": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Also, It's best to book 6 months ahead of your visit."}, "gen_args_2": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? No, It's best to book 6 months ahead of your visit."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-140.0", "False"]], "doc_hash": "8e52fdde1822f94c11bafd1d20f6a4fb8dfc353304c4ea4c2502515a7d57b177", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1235, "doc": {"premise": "Later it held courts of law, and justice was dispensed here.", "hypothesis": "It had court held there.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Yes, It had court held there."}, "gen_args_1": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? Also, It had court held there."}, "gen_args_2": {"arg_0": "", "arg_1": " Later it held courts of law, and justice was dispensed here., right? No, It had court held there."}}, "resps": [[["-111.0", "False"]], [["-117.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-111.0", "False"], ["-117.5", "False"], ["-112.0", "False"]], "doc_hash": "1d6400278d7d77ffd630370e033050e041232a9c8aa76c83c79814ab19e72835", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.73025595 0.0010979  0.26864615]"]}
{"doc_id": 1243, "doc": {"premise": "The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla.", "hypothesis": "Shopping prices in these areas are slightly higher than other nearby areas.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Yes, Shopping prices in these areas are slightly higher than other nearby areas."}, "gen_args_1": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Also, Shopping prices in these areas are slightly higher than other nearby areas."}, "gen_args_2": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? No, Shopping prices in these areas are slightly higher than other nearby areas."}}, "resps": [[["-197.0", "False"]], [["-197.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-197.0", "False"], ["-197.0", "False"]], "doc_hash": "eda691eafc977e43e5cf1cdf93b582ef919c757277395f59cb4698271c41e790", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1251, "doc": {"premise": "The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c", "hypothesis": "The statistics in this paper are based on a 2001 report.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Yes, The statistics in this paper are based on a 2001 report."}, "gen_args_1": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Also, The statistics in this paper are based on a 2001 report."}, "gen_args_2": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? No, The statistics in this paper are based on a 2001 report."}}, "resps": [[["-152.0", "False"]], [["-152.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-152.0", "False"], ["-148.0", "False"]], "doc_hash": "7d05d8cd0db9562d9726a1dab5681477514a09b074b951cdedfdfa0ff2120b72", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 1259, "doc": {"premise": "A subject that is discussed during the entry interview is the household's reaction to advertising mail.", "hypothesis": "The entry interview includes a bit about how people react to advertising mail.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Yes, The entry interview includes a bit about how people react to advertising mail."}, "gen_args_1": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? Also, The entry interview includes a bit about how people react to advertising mail."}, "gen_args_2": {"arg_0": "", "arg_1": " A subject that is discussed during the entry interview is the household's reaction to advertising mail., right? No, The entry interview includes a bit about how people react to advertising mail."}}, "resps": [[["-149.0", "False"]], [["-156.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-156.0", "False"], ["-154.0", "False"]], "doc_hash": "854fcf9279e2c78c07b21f878ed3666539075c3bc9d06817cb58820514606b5f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 9.04959183e-04 6.68679417e-03]"]}
{"doc_id": 1267, "doc": {"premise": "All nine responding agencies report participation in a", "hypothesis": "There were nine agencies that responded affirmatively that they participated.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Yes, There were nine agencies that responded affirmatively that they participated."}, "gen_args_1": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Also, There were nine agencies that responded affirmatively that they participated."}, "gen_args_2": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? No, There were nine agencies that responded affirmatively that they participated."}}, "resps": [[["-110.5", "False"]], [["-118.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-118.5", "False"], ["-112.5", "False"]], "doc_hash": "cf2e645f5b9d38430056d1ac883e5995f630fe7dbbc3bd5c603f552d58fc4b2e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 1275, "doc": {"premise": "It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities.", "hypothesis": "The CIO has many duties, including managing expectations and making sure members understand their responsibilities.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Yes, The CIO has many duties, including managing expectations and making sure members understand their responsibilities."}, "gen_args_1": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Also, The CIO has many duties, including managing expectations and making sure members understand their responsibilities."}, "gen_args_2": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? No, The CIO has many duties, including managing expectations and making sure members understand their responsibilities."}}, "resps": [[["-139.0", "False"]], [["-148.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-148.0", "False"], ["-142.0", "False"]], "doc_hash": "f889a08483480f98232ae44f58a4185dd594a29c68bf66630423b4b926293d4b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52462158e-01 1.17543168e-04 4.74202986e-02]"]}
{"doc_id": 1283, "doc": {"premise": "The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource.", "hypothesis": "There aren't enough IT workers to fill the jobs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Yes, There aren't enough IT workers to fill the jobs."}, "gen_args_1": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? Also, There aren't enough IT workers to fill the jobs."}, "gen_args_2": {"arg_0": "", "arg_1": " The shortage of skilled IT workers in the current market environment is often a major reason for leading organizations to outsource., right? No, There aren't enough IT workers to fill the jobs."}}, "resps": [[["-131.0", "False"]], [["-136.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-136.0", "False"], ["-130.0", "False"]], "doc_hash": "a7528c2707ee80f8d487f14a82912473c31f2c6fe28e4c32a90bdc8f6c28715c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1291, "doc": {"premise": "Practice 4: Manage Risk on a Continuing Basis", "hypothesis": "The book contains no information about long term risk management.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Yes, The book contains no information about long term risk management."}, "gen_args_1": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Also, The book contains no information about long term risk management."}, "gen_args_2": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? No, The book contains no information about long term risk management."}}, "resps": [[["-118.5", "False"]], [["-122.0", "False"]], [["-116.5", "False"]]], "filtered_resps": [["-118.5", "False"], ["-122.0", "False"], ["-116.5", "False"]], "doc_hash": "a6f1d541c5e21076dfe3a17ac6ed53b36cb5c2f127a91f6f359c5a6a30898044", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11877538 0.00358671 0.87763792]"]}
{"doc_id": 1299, "doc": {"premise": "In addition, program personnel conduct various workshops for and make educational materials available to new providers.", "hypothesis": "Program personnel cut all the workshops last year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Yes, Program personnel cut all the workshops last year."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Also, Program personnel cut all the workshops last year."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? No, Program personnel cut all the workshops last year."}}, "resps": [[["-159.0", "False"]], [["-165.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-165.0", "False"], ["-152.0", "False"]], "doc_hash": "6f99f06d2f488e909108139ade262840332939d6948349bdb8f99631d25557fb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11049137e-04 2.25826503e-06 9.99086693e-01]"]}
{"doc_id": 1307, "doc": {"premise": "For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs.", "hypothesis": "Employees would need to use the charge card for the hotel.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Yes, Employees would need to use the charge card for the hotel."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? Also, Employees would need to use the charge card for the hotel."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, employees could be required to use the agencydesignated charge card for hotel and certain other costs., right? No, Employees would need to use the charge card for the hotel."}}, "resps": [[["-141.0", "False"]], [["-148.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-148.0", "False"], ["-144.0", "False"]], "doc_hash": "6813b468066360379f297407921582975a9a0975802642ffa0328c6b6a8620c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 1315, "doc": {"premise": "This has been true in primary care settings as well.", "hypothesis": "That only happens in specialists.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Yes, That only happens in specialists."}, "gen_args_1": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Also, That only happens in specialists."}, "gen_args_2": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? No, That only happens in specialists."}}, "resps": [[["-99.5", "False"]], [["-101.5", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-99.5", "False"], ["-101.5", "False"], ["-93.5", "False"]], "doc_hash": "d0fb943e2e6e04484c838df2c28193c7eafb75e8fbf79aae23cf443fb0ef81ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 1323, "doc": {"premise": "For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds.", "hypothesis": "The trust fund borrowed money because it was running at a huge deficit.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Yes, The trust fund borrowed money because it was running at a huge deficit."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Also, The trust fund borrowed money because it was running at a huge deficit."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? No, The trust fund borrowed money because it was running at a huge deficit."}}, "resps": [[["-133.0", "False"]], [["-136.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-136.0", "False"], ["-132.0", "False"]], "doc_hash": "05125251273be33eed2f26540c09ce938dc7736d3c6f86ec88a6c8bb3cd90723", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1331, "doc": {"premise": "The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected.", "hypothesis": "The estimates deal with long-term exposure.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Yes, The estimates deal with long-term exposure."}, "gen_args_1": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? Also, The estimates deal with long-term exposure."}, "gen_args_2": {"arg_0": "", "arg_1": " The estimates derived from the long-term exposure studies, which account for a major share of the benefits in the Base Estimate, are not affected., right? No, The estimates deal with long-term exposure."}}, "resps": [[["-164.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "54c74a812f7fdd5d84a9f8efd362bac8285612c07d52d11f280133c8f65eb15e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1339, "doc": {"premise": "This is a large challenge and a large expectation for any one system of intervention.", "hypothesis": "Most interventions are perfect.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Yes, Most interventions are perfect."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Also, Most interventions are perfect."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? No, Most interventions are perfect."}}, "resps": [[["-126.5", "False"]], [["-129.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-129.0", "False"], ["-127.0", "False"]], "doc_hash": "3fee531070bb5e12926573384bde93e3f40c4eeadaaa171764b8aff4438c8497", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 1347, "doc": {"premise": "12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS).", "hypothesis": "12HEI is on a license plate.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Yes, 12HEI is on a license plate."}, "gen_args_1": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Also, 12HEI is on a license plate."}, "gen_args_2": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? No, 12HEI is on a license plate."}}, "resps": [[["-155.0", "False"]], [["-158.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-158.0", "False"], ["-155.0", "False"]], "doc_hash": "40d9f1a58be67b5e0c1b2e32ad1ec9f56392478276faca31bb48fe2300e1e7f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1355, "doc": {"premise": "The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress.", "hypothesis": "We didn't ask for any money this year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Yes, We didn't ask for any money this year."}, "gen_args_1": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? Also, We didn't ask for any money this year."}, "gen_args_2": {"arg_0": "", "arg_1": " The resources we are requesting for fiscal year 2002 are critical to sustaining our high-level of performance and service to the Congress., right? No, We didn't ask for any money this year."}}, "resps": [[["-138.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "ba9dc5d914398f99f50fbc94e2029c2e1a9c9af26c279208c7a4a6effcb2b868", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1363, "doc": {"premise": "In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements.", "hypothesis": "Corporate CIOs are generally paid less than CEOs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Yes, Corporate CIOs are generally paid less than CEOs."}, "gen_args_1": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Also, Corporate CIOs are generally paid less than CEOs."}, "gen_args_2": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? No, Corporate CIOs are generally paid less than CEOs."}}, "resps": [[["-202.0", "False"]], [["-202.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-202.0", "False"], ["-201.0", "False"]], "doc_hash": "9d9d0f69d693fe05bc4d6d0000f3510fb9edb5aaaeda9895c9561105cd946cbd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1371, "doc": {"premise": "We have already come a long way, and much is left to do.", "hypothesis": "Everything is finally done and we have nothing more to do.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Yes, Everything is finally done and we have nothing more to do."}, "gen_args_1": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Also, Everything is finally done and we have nothing more to do."}, "gen_args_2": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? No, Everything is finally done and we have nothing more to do."}}, "resps": [[["-103.0", "False"]], [["-107.0", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-103.0", "False"], ["-107.0", "False"], ["-98.0", "False"]], "doc_hash": "eaae6032e4b76fd693a65d2fb84fca7c31ebc262b3193640bfe35b8b15efbcba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 1379, "doc": {"premise": "The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes.", "hypothesis": "There was no United States Census conducted in 1990.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Yes, There was no United States Census conducted in 1990."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? Also, There was no United States Census conducted in 1990."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States Bureau of the Census has grouped the 1990 Census of Population and Housing data using 5-Digit ZIP Codes., right? No, There was no United States Census conducted in 1990."}}, "resps": [[["-125.0", "False"]], [["-128.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-128.0", "False"], ["-122.5", "False"]], "doc_hash": "430e9dcfb1fec4903db80b813396540db25cda04ad29d3f303d8fba52fab9460", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 1387, "doc": {"premise": "We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002.", "hypothesis": "We worked closely with seven different employees this year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Yes, We worked closely with seven different employees this year."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Also, We worked closely with seven different employees this year."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? No, We worked closely with seven different employees this year."}}, "resps": [[["-142.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "33f4c92586ba1233912749f37ba5dfb878f5ec7f49466610cc0aeef159fc057f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1395, "doc": {"premise": "This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared.", "hypothesis": "The demand curve depends on the discount being the same.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Yes, The demand curve depends on the discount being the same."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Also, The demand curve depends on the discount being the same."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? No, The demand curve depends on the discount being the same."}}, "resps": [[["-193.0", "False"]], [["-196.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-196.0", "False"], ["-196.0", "False"]], "doc_hash": "c7993be499701a6c7fe4f014a8d1aad8e07dbc1084eea84a1fbd1f6d27b1a6df", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1403, "doc": {"premise": "Employer entity contributions to social insurance programs.", "hypothesis": "Employers keep their money to themselves.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Yes, Employers keep their money to themselves."}, "gen_args_1": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? Also, Employers keep their money to themselves."}, "gen_args_2": {"arg_0": "", "arg_1": " Employer entity contributions to social insurance programs., right? No, Employers keep their money to themselves."}}, "resps": [[["-110.0", "False"]], [["-111.0", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-110.0", "False"], ["-111.0", "False"], ["-105.5", "False"]], "doc_hash": "acf9039049058d3034d505a7bda54ae0883b0763e223a5d06cca517b2063b437", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01094271 0.0040256  0.98503169]"]}
{"doc_id": 1411, "doc": {"premise": "In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes.", "hypothesis": "The impact in France is increasing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Yes, The impact in France is increasing."}, "gen_args_1": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Also, The impact in France is increasing."}, "gen_args_2": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? No, The impact in France is increasing."}}, "resps": [[["-159.0", "False"]], [["-156.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-156.0", "False"], ["-157.0", "False"]], "doc_hash": "6b1dd0a339b0b6e73860cda0b0b3361376dc3853b959eac90c5751e36aff4f09", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.03511903 0.70538451 0.25949646]"]}
{"doc_id": 1419, "doc": {"premise": "The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed.", "hypothesis": "The groups never speak to each other.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Yes, The groups never speak to each other."}, "gen_args_1": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Also, The groups never speak to each other."}, "gen_args_2": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? No, The groups never speak to each other."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-143.0", "False"]], "doc_hash": "4dc83801aefea10420356c20d48ab6c40d7d90bc59f18119d656d179957369a7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1427, "doc": {"premise": "When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage.", "hypothesis": "There was no boiler service outage.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Yes, There was no boiler service outage."}, "gen_args_1": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? Also, There was no boiler service outage."}, "gen_args_2": {"arg_0": "", "arg_1": " When Babcock &amp; Wilcox retrofitted the 675 MWe AES Somerset boiler, the outage began on May 14, and the boiler was returned to service on June 26 - about a six-week outage., right? No, There was no boiler service outage."}}, "resps": [[["-203.0", "False"]], [["-203.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-203.0", "False"], ["-200.0", "False"]], "doc_hash": "c4cc32f563d642d5548ddf7b99e18c58c9fa495540e0ca7473837167accd092c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1435, "doc": {"premise": "In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated.", "hypothesis": "The concentration-response relationship is rarely figured out exactly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Yes, The concentration-response relationship is rarely figured out exactly."}, "gen_args_1": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Also, The concentration-response relationship is rarely figured out exactly."}, "gen_args_2": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? No, The concentration-response relationship is rarely figured out exactly."}}, "resps": [[["-126.0", "False"]], [["-129.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-129.0", "False"], ["-127.0", "False"]], "doc_hash": "ce7352034f72a8124098f29b4eacf696e5119eddba72711aea6d210a097bcb28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1443, "doc": {"premise": "In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target.", "hypothesis": "A household's existing assets have no bearing on the amount of money from income that needs to be saved.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Yes, A household's existing assets have no bearing on the amount of money from income that needs to be saved."}, "gen_args_1": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Also, A household's existing assets have no bearing on the amount of money from income that needs to be saved."}, "gen_args_2": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? No, A household's existing assets have no bearing on the amount of money from income that needs to be saved."}}, "resps": [[["-180.0", "False"]], [["-186.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-186.0", "False"], ["-174.0", "False"]], "doc_hash": "cff4a1b3f11599c0c9e71bbcf579f53e3abc7c0e9633a6d48337aea4b334331b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47260800e-03 6.12898247e-06 9.97521263e-01]"]}
{"doc_id": 1451, "doc": {"premise": "Figure 6 displays the average unit costs generated with the cost function for the USPS.", "hypothesis": "The costs are shown in figure 9 for USPS.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Yes, The costs are shown in figure 9 for USPS."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? Also, The costs are shown in figure 9 for USPS."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 6 displays the average unit costs generated with the cost function for the USPS., right? No, The costs are shown in figure 9 for USPS."}}, "resps": [[["-143.0", "False"]], [["-143.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-143.0", "False"], ["-143.0", "False"]], "doc_hash": "5717709b4285ae3d724c2e5289ec41a8ad83828161d2aac4a9e39eb7e517595d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1459, "doc": {"premise": "This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies.", "hypothesis": "The name of the project is Partners for Justice.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Yes, The name of the project is Partners for Justice."}, "gen_args_1": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Also, The name of the project is Partners for Justice."}, "gen_args_2": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? No, The name of the project is Partners for Justice."}}, "resps": [[["-207.0", "False"]], [["-210.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-210.0", "False"], ["-207.0", "False"]], "doc_hash": "45603c00354f1f6838c86c87587ca2040fda3db2a94678027a763af562d064cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1467, "doc": {"premise": "Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas.", "hypothesis": "Brendan Gill dislikes the merger.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Yes, Brendan Gill dislikes the merger."}, "gen_args_1": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Also, Brendan Gill dislikes the merger."}, "gen_args_2": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? No, Brendan Gill dislikes the merger."}}, "resps": [[["-150.0", "False"]], [["-156.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-156.0", "False"], ["-146.0", "False"]], "doc_hash": "9a58e2edb03f66accb757230408971f1a1639bfe5ddff8bfa9e6b3b0e5f72b43", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79854081e-02 4.45813695e-05 9.81970011e-01]"]}
{"doc_id": 1475, "doc": {"premise": "Case files would have to be copied and provided to the client.", "hypothesis": "The client will be provided with case files.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Yes, The client will be provided with case files."}, "gen_args_1": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? Also, The client will be provided with case files."}, "gen_args_2": {"arg_0": "", "arg_1": " Case files would have to be copied and provided to the client., right? No, The client will be provided with case files."}}, "resps": [[["-96.5", "False"]], [["-105.0", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-105.0", "False"], ["-100.0", "False"]], "doc_hash": "faffacd32afc418917786e38a9718786952ef8322b65a9a9cbd9d13e0c9903c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70496092e-01 1.97465257e-04 2.93064426e-02]"]}
{"doc_id": 1483, "doc": {"premise": "Assets accumulated can generate income in the form of interest and dividends that in turn may be saved.", "hypothesis": "The interest and dividends are a lot of money.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Yes, The interest and dividends are a lot of money."}, "gen_args_1": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Also, The interest and dividends are a lot of money."}, "gen_args_2": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? No, The interest and dividends are a lot of money."}}, "resps": [[["-130.0", "False"]], [["-132.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-132.0", "False"], ["-131.0", "False"]], "doc_hash": "706b3f5f33f0cc05ab98ed1974fcd8f1b2d0e4fea4ec5a5e2a17efa7bee8f445", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1491, "doc": {"premise": "For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability.", "hypothesis": "All assets decline in value by the day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Yes, All assets decline in value by the day."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Also, All assets decline in value by the day."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? No, All assets decline in value by the day."}}, "resps": [[["-146.0", "False"]], [["-149.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-149.0", "False"], ["-146.0", "False"]], "doc_hash": "0bc27a5919ddc631eec037af3e42e0eef0f563c06dce0299ce17f1cc4e2cac49", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1499, "doc": {"premise": "Other advisers have echoed this concern.", "hypothesis": "This concern is shared by several different advisers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Yes, This concern is shared by several different advisers."}, "gen_args_1": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? Also, This concern is shared by several different advisers."}, "gen_args_2": {"arg_0": "", "arg_1": " Other advisers have echoed this concern., right? No, This concern is shared by several different advisers."}}, "resps": [[["-92.5", "False"]], [["-98.5", "False"]], [["-96.0", "False"]]], "filtered_resps": [["-92.5", "False"], ["-98.5", "False"], ["-96.0", "False"]], "doc_hash": "874bbc60bb8d0eccfc8f1b3e762496915c11d1c86686374d0b72bf98feb21cf1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96835781 0.00240032 0.02924187]"]}
{"doc_id": 1507, "doc": {"premise": "It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers.", "hypothesis": "It's not easy to install the system because of security dangers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Yes, It's not easy to install the system because of security dangers."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Also, It's not easy to install the system because of security dangers."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? No, It's not easy to install the system because of security dangers."}}, "resps": [[["-165.0", "False"]], [["-168.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-168.0", "False"], ["-164.0", "False"]], "doc_hash": "a11eba6deccdd7dcc856e9753f232da10b621016fc051c7b0342d2c44a03bb3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1515, "doc": {"premise": "Delivering it repeatedly did not make it more effective.", "hypothesis": "Delivery did not improve how effective it was.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Yes, Delivery did not improve how effective it was."}, "gen_args_1": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Also, Delivery did not improve how effective it was."}, "gen_args_2": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? No, Delivery did not improve how effective it was."}}, "resps": [[["-96.5", "False"]], [["-103.0", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-96.5", "False"], ["-103.0", "False"], ["-95.5", "False"]], "doc_hash": "ede2121edabda07ad175ce3f9f22c7e6a74aa39bbfd83e1871f8816611d58e77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.68832722e-01 4.04173651e-04 7.30763104e-01]"]}
{"doc_id": 1523, "doc": {"premise": "Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993.", "hypothesis": "These plots both met with failure and further efforts were scrapped.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Yes, These plots both met with failure and further efforts were scrapped."}, "gen_args_1": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? Also, These plots both met with failure and further efforts were scrapped."}, "gen_args_2": {"arg_0": "", "arg_1": " Ramzi Yousef and Khalid Sheikh Mohammed masterminded the 1995 Manila air plot, and KSM helped fund Yousef 's attempt to blow up the World Trade Center in 1993., right? No, These plots both met with failure and further efforts were scrapped."}}, "resps": [[["-190.0", "False"]], [["-191.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-191.0", "False"], ["-191.0", "False"]], "doc_hash": "4653672bd4b972d567cd878343ee39c9415581f030cae8cade2ce6c0a93c738f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1531, "doc": {"premise": "He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan).", "hypothesis": "Pakistan and Afghanistan are located very far apart from each other.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Yes, Pakistan and Afghanistan are located very far apart from each other."}, "gen_args_1": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Also, Pakistan and Afghanistan are located very far apart from each other."}, "gen_args_2": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? No, Pakistan and Afghanistan are located very far apart from each other."}}, "resps": [[["-185.0", "False"]], [["-183.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-183.0", "False"], ["-183.0", "False"]], "doc_hash": "9dd01eb421bffb1ea3e647cfab59f699b7b2d2be182c767358b0f7a30785a17b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 1539, "doc": {"premise": "The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later.", "hypothesis": "28 minutes after the fact the Southeast Air Defense Sector received notification.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Yes, 28 minutes after the fact the Southeast Air Defense Sector received notification."}, "gen_args_1": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Also, 28 minutes after the fact the Southeast Air Defense Sector received notification."}, "gen_args_2": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? No, 28 minutes after the fact the Southeast Air Defense Sector received notification."}}, "resps": [[["-129.0", "False"]], [["-140.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-140.0", "False"], ["-131.0", "False"]], "doc_hash": "be66b85969273684bb39988a97c4f6764ec89ed0c21a96c50a68fe2d52b1ea0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80784121e-01 1.47105928e-05 1.19201168e-01]"]}
{"doc_id": 1547, "doc": {"premise": "After Mihdhar left, other students moved into the house.", "hypothesis": "The students protested outside of the house that Mihdhar resided in.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Yes, The students protested outside of the house that Mihdhar resided in."}, "gen_args_1": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? Also, The students protested outside of the house that Mihdhar resided in."}, "gen_args_2": {"arg_0": "", "arg_1": " After Mihdhar left, other students moved into the house., right? No, The students protested outside of the house that Mihdhar resided in."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "f8f3c375db15166b31cddc60c39ef84f3769348f6d767c8edf08f63426e9a6e9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1555, "doc": {"premise": "We ask every nation to join us.", "hypothesis": "We need help from around the world.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Yes, We need help from around the world."}, "gen_args_1": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Also, We need help from around the world."}, "gen_args_2": {"arg_0": "", "arg_1": " We ask every nation to join us., right? No, We need help from around the world."}}, "resps": [[["-85.0", "False"]], [["-89.5", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-85.0", "False"], ["-89.5", "False"], ["-88.5", "False"]], "doc_hash": "76e70d03c312d5285c5692b14f0138cef9a7a1b261244452ea0ec7d40a2aa242", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96033216 0.01066833 0.02899952]"]}
{"doc_id": 1563, "doc": {"premise": "The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags.", "hypothesis": "Police found bottled water in the man's checked bags.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Yes, Police found bottled water in the man's checked bags."}, "gen_args_1": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Also, Police found bottled water in the man's checked bags."}, "gen_args_2": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? No, Police found bottled water in the man's checked bags."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-143.0", "False"]], "doc_hash": "aff355ce12f4875d7fabbf5af6dc017415f375d99631d0441bb46f838a689b19", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1571, "doc": {"premise": "The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat.", "hypothesis": "When the Soviet military threat ended the US cut national security spending.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Yes, When the Soviet military threat ended the US cut national security spending."}, "gen_args_1": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? Also, When the Soviet military threat ended the US cut national security spending."}, "gen_args_2": {"arg_0": "", "arg_1": " The people of the United States hoped to enjoy a peace dividend, as U.S. spending on national security was cut following the end of the Soviet military threat., right? No, When the Soviet military threat ended the US cut national security spending."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-159.0", "False"]], "doc_hash": "fdc8d95c24eeab3dc1ea284b329c214fd7d58d8d2f8d9e48df5968602145ec69", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1579, "doc": {"premise": "Our border screening system should check people efficiently and welcome friends.", "hypothesis": "We do not have time for pleasantries while dealing with border crossings.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Yes, We do not have time for pleasantries while dealing with border crossings."}, "gen_args_1": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Also, We do not have time for pleasantries while dealing with border crossings."}, "gen_args_2": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? No, We do not have time for pleasantries while dealing with border crossings."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-146.0", "False"]], "doc_hash": "b4d05bd95f7455be989c1e7eda201bc53360e2fb6536537027fdbbc405d48165", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1587, "doc": {"premise": "It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role.", "hypothesis": "Many agencies supported the FDNY in its response.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Yes, Many agencies supported the FDNY in its response."}, "gen_args_1": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Also, Many agencies supported the FDNY in its response."}, "gen_args_2": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? No, Many agencies supported the FDNY in its response."}}, "resps": [[["-162.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "32d686f9117b0d83d7dcf6194550eb7712b1fdbe312379d08355abdf8173d65e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1595, "doc": {"premise": "The CTC analyst who drafted the briefing drew on reports over the previous four years.", "hypothesis": "The analyst used multiple reports in order to draft the document.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Yes, The analyst used multiple reports in order to draft the document."}, "gen_args_1": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? Also, The analyst used multiple reports in order to draft the document."}, "gen_args_2": {"arg_0": "", "arg_1": " The CTC analyst who drafted the briefing drew on reports over the previous four years., right? No, The analyst used multiple reports in order to draft the document."}}, "resps": [[["-137.0", "False"]], [["-143.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-143.0", "False"], ["-139.0", "False"]], "doc_hash": "37c2c38f29142ccb7ed46d58fca1cf5bd6de1dbb48721b864995ac1d3e5e8b1d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1603, "doc": {"premise": "Other evidence corroborates her account.", "hypothesis": "There is other information containing evidence that supports what she said.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Yes, There is other information containing evidence that supports what she said."}, "gen_args_1": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Also, There is other information containing evidence that supports what she said."}, "gen_args_2": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? No, There is other information containing evidence that supports what she said."}}, "resps": [[["-102.5", "False"]], [["-106.0", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.0", "False"], ["-105.0", "False"]], "doc_hash": "c0904d7c02044e94f924a6b7ca82784fff68d26e87c0f436a18484d23363a3f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.89905227 0.02714903 0.0737987 ]"]}
{"doc_id": 1611, "doc": {"premise": "But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans.", "hypothesis": "He had plenty of free time to take several long vacations while working on these projects.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Yes, He had plenty of free time to take several long vacations while working on these projects."}, "gen_args_1": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Also, He had plenty of free time to take several long vacations while working on these projects."}, "gen_args_2": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? No, He had plenty of free time to take several long vacations while working on these projects."}}, "resps": [[["-217.0", "False"]], [["-217.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-217.0", "False"], ["-217.0", "False"], ["-212.0", "False"]], "doc_hash": "a12cdbb8695f0a460e70ceecdbeeb91dc65314bf6886e942923a48b75ff005bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1619, "doc": {"premise": "Current security requirements nurture overclassification and excessive compartmentation of information among agencies.", "hypothesis": "The security requirements that are currently in use cause information to be overclassified.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Yes, The security requirements that are currently in use cause information to be overclassified."}, "gen_args_1": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? Also, The security requirements that are currently in use cause information to be overclassified."}, "gen_args_2": {"arg_0": "", "arg_1": " Current security requirements nurture overclassification and excessive compartmentation of information among agencies., right? No, The security requirements that are currently in use cause information to be overclassified."}}, "resps": [[["-142.0", "False"]], [["-148.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-148.0", "False"], ["-142.0", "False"]], "doc_hash": "5686f55ed02dbcb934587e4faa733ecf9a12192570219d5ff2f5a43f60819c7d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1627, "doc": {"premise": "There were numerous technical problems, especially with the Hellfire missiles.", "hypothesis": "The Hellfire missiles worked perfectly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Yes, The Hellfire missiles worked perfectly."}, "gen_args_1": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Also, The Hellfire missiles worked perfectly."}, "gen_args_2": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? No, The Hellfire missiles worked perfectly."}}, "resps": [[["-95.5", "False"]], [["-101.0", "False"]], [["-90.5", "False"]]], "filtered_resps": [["-95.5", "False"], ["-101.0", "False"], ["-90.5", "False"]], "doc_hash": "85b349878f7a718fabce1687b3760c07b429fd7d59c592d7a4e3c84ffab95ffd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69266787e-03 2.73514039e-05 9.93279981e-01]"]}
{"doc_id": 1635, "doc": {"premise": "Secure identification should begin in the United States.", "hypothesis": "Secure Identification should never be used in the US.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Yes, Secure Identification should never be used in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Also, Secure Identification should never be used in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? No, Secure Identification should never be used in the US."}}, "resps": [[["-100.5", "False"]], [["-100.5", "False"]], [["-97.0", "False"]]], "filtered_resps": [["-100.5", "False"], ["-100.5", "False"], ["-97.0", "False"]], "doc_hash": "ce9da970a2dfc4a626ee765dab7b280d74df5464f71d33c7b9e0a7179fae0967", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02847749 0.02847749 0.94304502]"]}
{"doc_id": 1643, "doc": {"premise": "We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press.", "hypothesis": "Yousef was never arrested.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Yes, Yousef was never arrested."}, "gen_args_1": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? Also, Yousef was never arrested."}, "gen_args_2": {"arg_0": "", "arg_1": " We have uncovered no evidence that KSM was present at the guesthouse in Islamabad where Yousef 's arrest took place, as has been suggested in the press., right? No, Yousef was never arrested."}}, "resps": [[["-151.0", "False"]], [["-151.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-151.0", "False"], ["-147.0", "False"]], "doc_hash": "c080bbdfd391b8e305b12eb7f1c087bb742bec648e5bc4c70b6ac021d500291d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 1651, "doc": {"premise": "He also ordered Secretary Rumsfeld to develop a military plan against the Taliban.", "hypothesis": "Nobody ordered the development of a military plan.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Yes, Nobody ordered the development of a military plan."}, "gen_args_1": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Also, Nobody ordered the development of a military plan."}, "gen_args_2": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? No, Nobody ordered the development of a military plan."}}, "resps": [[["-113.5", "False"]], [["-117.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-117.5", "False"], ["-108.0", "False"]], "doc_hash": "51bd0d1e8269af3eb015afd3b812715e114be8b2da74237df07a725815461103", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06983432e-03 7.45416158e-05 9.95855624e-01]"]}
{"doc_id": 1659, "doc": {"premise": "Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11.", "hypothesis": "The Sentencing Order was issued by the seven judges on the Hanseatic Regional High Court.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Yes, The Sentencing Order was issued by the seven judges on the Hanseatic Regional High Court."}, "gen_args_1": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Also, The Sentencing Order was issued by the seven judges on the Hanseatic Regional High Court."}, "gen_args_2": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? No, The Sentencing Order was issued by the seven judges on the Hanseatic Regional High Court."}}, "resps": [[["-206.0", "False"]], [["-212.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-212.0", "False"], ["-206.0", "False"]], "doc_hash": "9b21a2151e7539898632f19557ddb583c554ca71285e786032baf708de9e1495", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1667, "doc": {"premise": "Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005.", "hypothesis": "The entire Patriot Act will remain in force until at least 2010.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Yes, The entire Patriot Act will remain in force until at least 2010."}, "gen_args_1": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? Also, The entire Patriot Act will remain in force until at least 2010."}, "gen_args_2": {"arg_0": "", "arg_1": " Some of the most controversial provisions of the Patriot Act are to sunset at the end of 2005., right? No, The entire Patriot Act will remain in force until at least 2010."}}, "resps": [[["-110.5", "False"]], [["-113.0", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-110.5", "False"], ["-113.0", "False"], ["-101.0", "False"]], "doc_hash": "6b946c7fc126096f8d3dcac58399aaaac24e6e494571d59d0ba729adb1ecf5cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.48457677e-05 6.14371474e-06 9.99919011e-01]"]}
{"doc_id": 1675, "doc": {"premise": "His relationship with her remained close throughout his time in the United States.", "hypothesis": "He had never been to the US.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Yes, He had never been to the US."}, "gen_args_1": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Also, He had never been to the US."}, "gen_args_2": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? No, He had never been to the US."}}, "resps": [[["-104.0", "False"]], [["-104.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-104.0", "False"], ["-104.0", "False"], ["-100.5", "False"]], "doc_hash": "e8dee010d72521aa9d2c31f744e89f7f360d77dd4fd10ca2ab107aad6b7b6da1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02847749 0.02847749 0.94304502]"]}
{"doc_id": 1683, "doc": {"premise": "We will recap it briefly here.", "hypothesis": "The entire incident will now be described in complete detail.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Yes, The entire incident will now be described in complete detail."}, "gen_args_1": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Also, The entire incident will now be described in complete detail."}, "gen_args_2": {"arg_0": "", "arg_1": " We will recap it briefly here., right? No, The entire incident will now be described in complete detail."}}, "resps": [[["-104.5", "False"]], [["-108.0", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-104.5", "False"], ["-108.0", "False"], ["-106.5", "False"]], "doc_hash": "e90235129da5b473d6375b9842ed94da8b037c37a98e641d8bbc068fd023a23b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.85797681 0.02590865 0.11611453]"]}
{"doc_id": 1691, "doc": {"premise": "As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000.", "hypothesis": "His monthly income decreased.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Yes, His monthly income decreased."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? Also, His monthly income decreased."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, his salary was raised and his other allowances stipend increased significantly, from approximately $465 to $3,925 a month, remaining at that level until December 2000., right? No, His monthly income decreased."}}, "resps": [[["-184.0", "False"]], [["-187.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-187.0", "False"], ["-182.0", "False"]], "doc_hash": "c99cc33432960a34f58025156980a4d5a7b7fcf2f2002a78705d690746806713", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1699, "doc": {"premise": "His key personnel shared very little information with the National Security Council and the rest of the national security community.", "hypothesis": "The National Security Council received a full and complete briefing.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Yes, The National Security Council received a full and complete briefing."}, "gen_args_1": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Also, The National Security Council received a full and complete briefing."}, "gen_args_2": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? No, The National Security Council received a full and complete briefing."}}, "resps": [[["-131.0", "False"]], [["-135.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-135.0", "False"], ["-127.0", "False"]], "doc_hash": "926ef9422283b5bc8e7a49e6d338d4d27044b4bda1283b514f1a2c5a2c3680ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 1707, "doc": {"premise": "For units staged at the Brooklyn-Battery tunnel, see ibid.", "hypothesis": "Brooklyn-Battery tunnel was abandoned at this time.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Yes, Brooklyn-Battery tunnel was abandoned at this time."}, "gen_args_1": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Also, Brooklyn-Battery tunnel was abandoned at this time."}, "gen_args_2": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? No, Brooklyn-Battery tunnel was abandoned at this time."}}, "resps": [[["-133.0", "False"]], [["-131.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-131.0", "False"], ["-131.0", "False"]], "doc_hash": "af37acc2edc0ad7c990a2cfc78c856cbcc47b57a4433f741ed1f932a65da58f6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 1715, "doc": {"premise": "The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject.", "hypothesis": "The Director immediately abolished all information sharing barriers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Yes, The Director immediately abolished all information sharing barriers."}, "gen_args_1": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? Also, The Director immediately abolished all information sharing barriers."}, "gen_args_2": {"arg_0": "", "arg_1": " The Director still has no strategy for removing information-sharing barriers and-more than two years since 9/11-has only appointed a working group on the subject., right? No, The Director immediately abolished all information sharing barriers."}}, "resps": [[["-191.0", "False"]], [["-193.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-193.0", "False"], ["-184.0", "False"]], "doc_hash": "9ab7f8615fab01f45c8653ca6719b1c1313cddeeb42cc201c290203b87e0dc0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10938878e-04 1.23282171e-04 9.98965779e-01]"]}
{"doc_id": 1723, "doc": {"premise": "Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted.", "hypothesis": "Several of the attackers were initially flagged for extra inspections.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Yes, Several of the attackers were initially flagged for extra inspections."}, "gen_args_1": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Also, Several of the attackers were initially flagged for extra inspections."}, "gen_args_2": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? No, Several of the attackers were initially flagged for extra inspections."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-151.0", "False"]], "doc_hash": "4522145218b6040d36064235e1aab5cc222bfddafec018a5a1a2d9a5da538c92", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1731, "doc": {"premise": "The U.S. government readily provides copious information about spending on its military forces, including military intelligence.", "hypothesis": "The US government spends $7 billion on military intelligence each year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Yes, The US government spends $7 billion on military intelligence each year."}, "gen_args_1": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Also, The US government spends $7 billion on military intelligence each year."}, "gen_args_2": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? No, The US government spends $7 billion on military intelligence each year."}}, "resps": [[["-137.0", "False"]], [["-141.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-141.0", "False"], ["-138.0", "False"]], "doc_hash": "5978b4e6376d5aba516c00e0beea17ab1e9c77d3b2f096e493337a680d3f6bc1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1739, "doc": {"premise": "The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M.", "hypothesis": "The tower was still standing at 9:15 AM.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Yes, The tower was still standing at 9:15 AM."}, "gen_args_1": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? Also, The tower was still standing at 9:15 AM."}, "gen_args_2": {"arg_0": "", "arg_1": " The first NYPD ESU team entered the West Street-level lobby of the North Tower and prepared to begin climbing at about 9:15 A.M., right? No, The tower was still standing at 9:15 AM."}}, "resps": [[["-164.0", "False"]], [["-166.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-166.0", "False"], ["-162.0", "False"]], "doc_hash": "7a3d7502afb02a70d559f50ccb98caaf80d2e3379c993b9134ef4c389ee3e319", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1747, "doc": {"premise": "It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence.", "hypothesis": "Our law school is supported in part by the Melinda and Bill Gates Foundation.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Yes, Our law school is supported in part by the Melinda and Bill Gates Foundation."}, "gen_args_1": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Also, Our law school is supported in part by the Melinda and Bill Gates Foundation."}, "gen_args_2": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? No, Our law school is supported in part by the Melinda and Bill Gates Foundation."}}, "resps": [[["-140.0", "False"]], [["-146.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-146.0", "False"], ["-143.0", "False"]], "doc_hash": "3f67f15660c796e26030edf4f8f2d590e510b2fe116f7e63235c1050ceabb5a0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1755, "doc": {"premise": "Thank you for supporting the Indianapolis Museum of Art in 1999.", "hypothesis": "Thank you for your $100 donation to the Indianapolis Museum of Art.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Yes, Thank you for your $100 donation to the Indianapolis Museum of Art."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Also, Thank you for your $100 donation to the Indianapolis Museum of Art."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? No, Thank you for your $100 donation to the Indianapolis Museum of Art."}}, "resps": [[["-90.5", "False"]], [["-95.0", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-90.5", "False"], ["-95.0", "False"], ["-95.5", "False"]], "doc_hash": "a0b112134fbb22c0ee85a632ebb9d33c9b611e0af089f0bbbd90d42096768f46", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98246599 0.01091421 0.0066198 ]"]}
{"doc_id": 1763, "doc": {"premise": "It's important that we hear from you during this last fundraising drive of the season.", "hypothesis": "We need $100,000 more to make our fundraising quotas this season.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Yes, We need $100,000 more to make our fundraising quotas this season."}, "gen_args_1": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? Also, We need $100,000 more to make our fundraising quotas this season."}, "gen_args_2": {"arg_0": "", "arg_1": " It's important that we hear from you during this last fundraising drive of the season., right? No, We need $100,000 more to make our fundraising quotas this season."}}, "resps": [[["-125.0", "False"]], [["-129.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-129.0", "False"], ["-129.0", "False"]], "doc_hash": "1eacf4aed7d4aaa8c2576d32838e1eaab74d551526e31505c23c7c1a4a1068ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1771, "doc": {"premise": "(dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling.", "hypothesis": "It is staffed by volunteers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Yes, It is staffed by volunteers."}, "gen_args_1": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Also, It is staffed by volunteers."}, "gen_args_2": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? No, It is staffed by volunteers."}}, "resps": [[["-195.0", "False"]], [["-197.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-197.0", "False"], ["-194.0", "False"]], "doc_hash": "645fcbb341e09d61f2d9e28ed70697681fa884b1d86af72fab1d0984e282d46f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1779, "doc": {"premise": "From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage.", "hypothesis": "Indiana has at least twenty excellent medical schools.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Yes, Indiana has at least twenty excellent medical schools."}, "gen_args_1": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Also, Indiana has at least twenty excellent medical schools."}, "gen_args_2": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? No, Indiana has at least twenty excellent medical schools."}}, "resps": [[["-152.0", "False"]], [["-155.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-155.0", "False"], ["-153.0", "False"]], "doc_hash": "a926e49a4a910e685efb9996e6d357ad2671800f4d4cda2d2efc8ed37fef2f02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1787, "doc": {"premise": "-conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol.", "hypothesis": "The costumes were worked on by hand.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Yes, The costumes were worked on by hand."}, "gen_args_1": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? Also, The costumes were worked on by hand."}, "gen_args_2": {"arg_0": "", "arg_1": " -conceive, design and hand-sew the many beautiful costumes, such as Mary Todd's period dresses in Abe Lincoln in Illinois and the ball gowns in A Christmas Carol., right? No, The costumes were worked on by hand."}}, "resps": [[["-186.0", "False"]], [["-189.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-189.0", "False"], ["-190.0", "False"]], "doc_hash": "881476df686f4645b2efc1f5cbd715cc725ac5b11b37c98af07ce97051af81e3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 1795, "doc": {"premise": "The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable.", "hypothesis": "The homes required resources to be created.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Yes, The homes required resources to be created."}, "gen_args_1": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Also, The homes required resources to be created."}, "gen_args_2": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? No, The homes required resources to be created."}}, "resps": [[["-170.0", "False"]], [["-174.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-174.0", "False"], ["-169.0", "False"]], "doc_hash": "279de3286dffa5221a7f92cf04ca70f63107ca6f2d09bbf5ce3707360fc3de93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1803, "doc": {"premise": "I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year.", "hypothesis": "Please increase your donation amount this year by $25.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Yes, Please increase your donation amount this year by $25."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Also, Please increase your donation amount this year by $25."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? No, Please increase your donation amount this year by $25."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-160.0", "False"]], "doc_hash": "b8507a676eebd058cfe7a3a61ac699e634a4ce5d80f24072d7853984d11b9365", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1811, "doc": {"premise": "The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students.", "hypothesis": "The IRT is involved in the theater.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Yes, The IRT is involved in the theater."}, "gen_args_1": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? Also, The IRT is involved in the theater."}, "gen_args_2": {"arg_0": "", "arg_1": " The one thing I am most proud of is that the IRT is a leader across the country in providing theatre experiences for students., right? No, The IRT is involved in the theater."}}, "resps": [[["-142.0", "False"]], [["-144.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-144.0", "False"], ["-142.0", "False"]], "doc_hash": "8f33420c4ca99452c4ac785efab607193ec3718ec4a3f7bd9c37943c9478e94e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1819, "doc": {"premise": "Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs.", "hypothesis": "You could help us expand into seven states.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Yes, You could help us expand into seven states."}, "gen_args_1": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Also, You could help us expand into seven states."}, "gen_args_2": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? No, You could help us expand into seven states."}}, "resps": [[["-176.0", "False"]], [["-182.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-182.0", "False"], ["-178.0", "False"]], "doc_hash": "87901644a0f0c2969dfbe5775b601b084f76c8fe21f6af335458b4b1c844b774", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1827, "doc": {"premise": "What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now", "hypothesis": "No actors were in Indiana in the 70's.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Yes, No actors were in Indiana in the 70's."}, "gen_args_1": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Also, No actors were in Indiana in the 70's."}, "gen_args_2": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? No, No actors were in Indiana in the 70's."}}, "resps": [[["-211.0", "False"]], [["-216.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-216.0", "False"], ["-212.0", "False"]], "doc_hash": "616425a0978a791329512cb1c4b51d33d4a222fd9502f4c245a957fee0fc3615", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1835, "doc": {"premise": "The law school's 5,539 alumni form a distinguished group.", "hypothesis": "There are over 5,000 alumni from the law school.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Yes, There are over 5,000 alumni from the law school."}, "gen_args_1": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? Also, There are over 5,000 alumni from the law school."}, "gen_args_2": {"arg_0": "", "arg_1": " The law school's 5,539 alumni form a distinguished group., right? No, There are over 5,000 alumni from the law school."}}, "resps": [[["-112.0", "False"]], [["-118.0", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-118.0", "False"], ["-116.0", "False"]], "doc_hash": "5a8982a7e92cd49e785737e2ed98889cdf08630470c2942366aff05a6db75d38", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 1843, "doc": {"premise": "Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school.", "hypothesis": "The Maennerchor Society got $1m in donations last year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Yes, The Maennerchor Society got $1m in donations last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Also, The Maennerchor Society got $1m in donations last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? No, The Maennerchor Society got $1m in donations last year."}}, "resps": [[["-160.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "fceea2117e081fad3ddec6f054f347d2d52102006b015bc11ad7a907b3aab070", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1851, "doc": {"premise": "Others continue to notice our success.", "hypothesis": "We are failing and everyone can see it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Yes, We are failing and everyone can see it."}, "gen_args_1": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Also, We are failing and everyone can see it."}, "gen_args_2": {"arg_0": "", "arg_1": " Others continue to notice our success., right? No, We are failing and everyone can see it."}}, "resps": [[["-96.5", "False"]], [["-100.5", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-96.5", "False"], ["-100.5", "False"], ["-93.5", "False"]], "doc_hash": "6b08c757e1384962f4b165bb9e3e7e5596fe9df953265fe366f870562e90cfb7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1859, "doc": {"premise": "In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole.", "hypothesis": "They supported the organization because they knew it would benefit the city.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Yes, They supported the organization because they knew it would benefit the city."}, "gen_args_1": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? Also, They supported the organization because they knew it would benefit the city."}, "gen_args_2": {"arg_0": "", "arg_1": " In their enlightened self-interest, they supported this fledgling organization, knowing it would benefit the city as a whole., right? No, They supported the organization because they knew it would benefit the city."}}, "resps": [[["-126.5", "False"]], [["-134.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-134.0", "False"], ["-127.0", "False"]], "doc_hash": "a8363eae859259cb8d683d3a667b1f600670960b0edfcbba1b3439d6ad8be916", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22245109e-01 3.44154044e-04 3.77410737e-01]"]}
{"doc_id": 1867, "doc": {"premise": "Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age.", "hypothesis": "There are programs that encourage kids to go to the library twice a week.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Yes, There are programs that encourage kids to go to the library twice a week."}, "gen_args_1": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Also, There are programs that encourage kids to go to the library twice a week."}, "gen_args_2": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? No, There are programs that encourage kids to go to the library twice a week."}}, "resps": [[["-185.0", "False"]], [["-186.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-186.0", "False"], ["-187.0", "False"]], "doc_hash": "3b116bb392337e25cb7590ac2c89a4e54135992676694b04c6b86467d7692b26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1875, "doc": {"premise": "The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars.", "hypothesis": "The rug bears the Presidential Seal.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Yes, The rug bears the Presidential Seal."}, "gen_args_1": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Also, The rug bears the Presidential Seal."}, "gen_args_2": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? No, The rug bears the Presidential Seal."}}, "resps": [[["-129.0", "False"]], [["-132.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-132.0", "False"], ["-132.0", "False"]], "doc_hash": "1331c6493dd943080ff2f051cddf8b9b362b3e78b76d9518761c212ef3dfd199", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1883, "doc": {"premise": "To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext.", "hypothesis": "Please call Kathy Dannels if you would like to discuss your contribution.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Yes, Please call Kathy Dannels if you would like to discuss your contribution."}, "gen_args_1": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? Also, Please call Kathy Dannels if you would like to discuss your contribution."}, "gen_args_2": {"arg_0": "", "arg_1": " To assist you with your contribution, please feel free to call Kathy Dannels, Director of Development, at 924-6770 ext., right? No, Please call Kathy Dannels if you would like to discuss your contribution."}}, "resps": [[["-153.0", "False"]], [["-160.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-160.0", "False"], ["-159.0", "False"]], "doc_hash": "aa5259eacca352ef95677ad2c6131f24f5c6a8f352efdf7f9bb6a98b7123cd5b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.96620823e-01 9.08800555e-04 2.47037604e-03]"]}
{"doc_id": 1891, "doc": {"premise": "When Urban left for Vietnam, we'd only been married a short time, JoAnn said.", "hypothesis": "JoAnn and Urban were married for one month when he left for Vietnam.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Yes, JoAnn and Urban were married for one month when he left for Vietnam."}, "gen_args_1": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Also, JoAnn and Urban were married for one month when he left for Vietnam."}, "gen_args_2": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? No, JoAnn and Urban were married for one month when he left for Vietnam."}}, "resps": [[["-134.0", "False"]], [["-140.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-140.0", "False"], ["-137.0", "False"]], "doc_hash": "8d77f3527d9442b7f685d4edc2ed863ea84e2609cf78b95dd32f960f4edc1efc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1899, "doc": {"premise": "00 invested in a job-training program for a person on welfare saves $3.", "hypothesis": "Anyone who invests in a job-training program loses $5.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Yes, Anyone who invests in a job-training program loses $5."}, "gen_args_1": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Also, Anyone who invests in a job-training program loses $5."}, "gen_args_2": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? No, Anyone who invests in a job-training program loses $5."}}, "resps": [[["-133.0", "False"]], [["-134.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-134.0", "False"], ["-129.0", "False"]], "doc_hash": "48ea688c82f42b0d31e9c4d449170f326a3d5ea501a8d6ee80f6ae60b9efe31a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1907, "doc": {"premise": "This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design.", "hypothesis": "The space is full of tropical flowers and beautiful trees.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Yes, The space is full of tropical flowers and beautiful trees."}, "gen_args_1": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? Also, The space is full of tropical flowers and beautiful trees."}, "gen_args_2": {"arg_0": "", "arg_1": " This stunnngly beautiful 3.3 -acre landmark botanical attraction combines the best of gardening ideas, plant information and inspiring landscape design., right? No, The space is full of tropical flowers and beautiful trees."}}, "resps": [[["-195.0", "False"]], [["-197.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-195.0", "False"], ["-197.0", "False"], ["-198.0", "False"]], "doc_hash": "7dff203df50a409545107a550f68770c92b4cc608b4f43a2f8e516baa817d504", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1915, "doc": {"premise": "Many see philanthropy as no more than the grand gestures of the rich.", "hypothesis": "Some people think donating is just something rich people do.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Yes, Some people think donating is just something rich people do."}, "gen_args_1": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Also, Some people think donating is just something rich people do."}, "gen_args_2": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? No, Some people think donating is just something rich people do."}}, "resps": [[["-112.5", "False"]], [["-113.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-113.5", "False"], ["-115.5", "False"]], "doc_hash": "94629a86d7eb41e6c336542e6e1423cd82202ad166153d522d948157ca7ff86b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 1923, "doc": {"premise": "McCoy invites the support of The __ Company Foundation in the amount of $10,000.", "hypothesis": "McCoy is asking for $250,000.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Yes, McCoy is asking for $250,000."}, "gen_args_1": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Also, McCoy is asking for $250,000."}, "gen_args_2": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? No, McCoy is asking for $250,000."}}, "resps": [[["-139.0", "False"]], [["-137.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-137.0", "False"], ["-130.0", "False"]], "doc_hash": "34f2a843a2e8e6a95034e2f2502dc7fe606dfdc77183c3da6b9e89456c3d6cef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.23282171e-04 9.10938878e-04 9.98965779e-01]"]}
{"doc_id": 1931, "doc": {"premise": "learn to walk in someone else's shoes", "hypothesis": "To selfishly mind your own life and your own business.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Yes, To selfishly mind your own life and your own business."}, "gen_args_1": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? Also, To selfishly mind your own life and your own business."}, "gen_args_2": {"arg_0": "", "arg_1": " learn to walk in someone else's shoes, right? No, To selfishly mind your own life and your own business."}}, "resps": [[["-99.0", "False"]], [["-99.5", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-99.0", "False"], ["-99.5", "False"], ["-99.0", "False"]], "doc_hash": "b701e4c40f5957e4fd72753f2c0b5d87a2e219600c9149003e686636192e4342", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.38365173 0.23269654 0.38365173]"]}
{"doc_id": 1939, "doc": {"premise": "These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state.", "hypothesis": "Students can benefit from campus visits.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Yes, Students can benefit from campus visits."}, "gen_args_1": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Also, Students can benefit from campus visits."}, "gen_args_2": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? No, Students can benefit from campus visits."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-172.0", "False"]], "doc_hash": "0073a8823a3bea93039d693b0028bf127438db7637a852255582ce0d267d5b6a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1947, "doc": {"premise": "As with all gifts to the Institute, 100% of your contribution will be used directly for research.", "hypothesis": "Every penny goes towards cancer research.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Yes, Every penny goes towards cancer research."}, "gen_args_1": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Also, Every penny goes towards cancer research."}, "gen_args_2": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? No, Every penny goes towards cancer research."}}, "resps": [[["-104.5", "False"]], [["-111.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-104.5", "False"], ["-111.0", "False"], ["-109.0", "False"]], "doc_hash": "20b7dcb1fb975844f337daf17bc22ec17218003595fe8d1e34777782bbf982f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98754466 0.00148471 0.01097063]"]}
{"doc_id": 1955, "doc": {"premise": "It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo.", "hypothesis": "The animals at the zoo get $100,000 a year in funding for care and feeding.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Yes, The animals at the zoo get $100,000 a year in funding for care and feeding."}, "gen_args_1": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? Also, The animals at the zoo get $100,000 a year in funding for care and feeding."}, "gen_args_2": {"arg_0": "", "arg_1": " It pays for the care, feeding, and housing of the thousands of plants and animals at the Zoo., right? No, The animals at the zoo get $100,000 a year in funding for care and feeding."}}, "resps": [[["-134.0", "False"]], [["-139.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-139.0", "False"], ["-133.0", "False"]], "doc_hash": "0945422eb10fe6d76633aa5a475e852f19283b881e731e09190ae6cc1de0d017", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1963, "doc": {"premise": "Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre.", "hypothesis": "The Civic Theater is in Indianapolis.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Yes, The Civic Theater is in Indianapolis."}, "gen_args_1": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Also, The Civic Theater is in Indianapolis."}, "gen_args_2": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? No, The Civic Theater is in Indianapolis."}}, "resps": [[["-130.0", "False"]], [["-137.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-137.0", "False"], ["-134.0", "False"]], "doc_hash": "b0ac93b97455eedda561eefce3269cb90728e02ae7043e34c8d364757a3f1250", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1971, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations.", "hypothesis": "The Society contributes a lot to the connections that are made.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Yes, The Society contributes a lot to the connections that are made."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Also, The Society contributes a lot to the connections that are made."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? No, The Society contributes a lot to the connections that are made."}}, "resps": [[["-136.0", "False"]], [["-146.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-146.0", "False"], ["-140.0", "False"]], "doc_hash": "4f2450bb819c64aec20f11f997133c18b343f121503881135f86cde1d3d7a341", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81970011e-01 4.45813695e-05 1.79854081e-02]"]}
{"doc_id": 1979, "doc": {"premise": "Technology, although seemingly indispensable, has caused us to go into hyperspeed.", "hypothesis": "Technology hasn't done anything to help us.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Yes, Technology hasn't done anything to help us."}, "gen_args_1": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? Also, Technology hasn't done anything to help us."}, "gen_args_2": {"arg_0": "", "arg_1": " Technology, although seemingly indispensable, has caused us to go into hyperspeed., right? No, Technology hasn't done anything to help us."}}, "resps": [[["-123.0", "False"]], [["-123.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-123.0", "False"], ["-123.0", "False"], ["-121.0", "False"]], "doc_hash": "1caba665fb61eca7d0d8ffe352a2ded614130a96acfe569a5caa6139b798fbb1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1987, "doc": {"premise": "For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000.", "hypothesis": "The law school is getting $1million more than normal.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Yes, The law school is getting $1million more than normal."}, "gen_args_1": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Also, The law school is getting $1million more than normal."}, "gen_args_2": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? No, The law school is getting $1million more than normal."}}, "resps": [[["-171.0", "False"]], [["-170.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-170.0", "False"], ["-166.0", "False"]], "doc_hash": "a4fbf6c971bdb847f63b32173647a7efd890d1d3fdeedfea6b999434fde9f9ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00657326 0.01786798 0.97555875]"]}
{"doc_id": 1995, "doc": {"premise": "The newsweeklies' cover packages pander to anxious parents.", "hypothesis": "Anxious parents are one marketing target of the newsweeklies.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Yes, Anxious parents are one marketing target of the newsweeklies."}, "gen_args_1": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Also, Anxious parents are one marketing target of the newsweeklies."}, "gen_args_2": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? No, Anxious parents are one marketing target of the newsweeklies."}}, "resps": [[["-134.0", "False"]], [["-139.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-139.0", "False"], ["-135.0", "False"]], "doc_hash": "27c1f97594bd1a59a727520f90c705ab5a4e675e7cd8a71cb780e2a4ac0b1e75", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2003, "doc": {"premise": "The main point, though, is that there aren't actually all that many Milosevics in the world.", "hypothesis": "There are not many Milosevics.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Yes, There are not many Milosevics."}, "gen_args_1": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? Also, There are not many Milosevics."}, "gen_args_2": {"arg_0": "", "arg_1": " The main point, though, is that there aren't actually all that many Milosevics in the world., right? No, There are not many Milosevics."}}, "resps": [[["-109.5", "False"]], [["-115.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-109.5", "False"], ["-115.0", "False"], ["-109.0", "False"]], "doc_hash": "a37364a26407c7e7cdccdce115b649091fccda23c04b12b8cdfc52ea10a2bb10", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37695905 0.00154055 0.6215004 ]"]}
{"doc_id": 2011, "doc": {"premise": "Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory.", "hypothesis": "Paul has never heard of Alan Greenspan or his economic theories.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Yes, Paul has never heard of Alan Greenspan or his economic theories."}, "gen_args_1": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Also, Paul has never heard of Alan Greenspan or his economic theories."}, "gen_args_2": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? No, Paul has never heard of Alan Greenspan or his economic theories."}}, "resps": [[["-164.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "3e4c57faa538b5ecf30227e1b869aff6d49df685cc08761d8e80dad05531fec5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 2019, "doc": {"premise": "The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position.", "hypothesis": "The Nerds are hopeless.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Yes, The Nerds are hopeless."}, "gen_args_1": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Also, The Nerds are hopeless."}, "gen_args_2": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? No, The Nerds are hopeless."}}, "resps": [[["-139.0", "False"]], [["-146.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-146.0", "False"], ["-141.0", "False"]], "doc_hash": "32786a9d507933131e263f217cef35126970bc905184903a2dae4e0dba0beb40", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 2027, "doc": {"premise": "Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters.", "hypothesis": "The Slate Table of Contents includes a photograph of President Clinton.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Yes, The Slate Table of Contents includes a photograph of President Clinton."}, "gen_args_1": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? Also, The Slate Table of Contents includes a photograph of President Clinton."}, "gen_args_2": {"arg_0": "", "arg_1": " Photograph of Bill Clinton on the Slate Table of Contents by Kevin Lamarque/Reuters., right? No, The Slate Table of Contents includes a photograph of President Clinton."}}, "resps": [[["-117.0", "False"]], [["-120.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-120.5", "False"], ["-119.0", "False"]], "doc_hash": "b7aea398b7387ebcd551f54c8899f39c43fb5c4eb7f939dca9b34ec31fe347d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.85797681 0.02590865 0.11611453]"]}
{"doc_id": 2035, "doc": {"premise": "Population growth is like pollution in reverse.", "hypothesis": "Population growth is similar to inverse pollution.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Yes, Population growth is similar to inverse pollution."}, "gen_args_1": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Also, Population growth is similar to inverse pollution."}, "gen_args_2": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? No, Population growth is similar to inverse pollution."}}, "resps": [[["-95.5", "False"]], [["-99.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-95.5", "False"], ["-99.5", "False"], ["-95.0", "False"]], "doc_hash": "fdde0ef4fa5c609ae72dbbf5b292f3656752d03753de1b26a10e2e732e877d88", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 2043, "doc": {"premise": "The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history.", "hypothesis": "First Wives Club is a happily-ever-after, romance movie about the enduring love of marrying your first boyfriend.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Yes, First Wives Club is a happily-ever-after, romance movie about the enduring love of marrying your first boyfriend."}, "gen_args_1": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Also, First Wives Club is a happily-ever-after, romance movie about the enduring love of marrying your first boyfriend."}, "gen_args_2": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? No, First Wives Club is a happily-ever-after, romance movie about the enduring love of marrying your first boyfriend."}}, "resps": [[["-185.0", "False"]], [["-184.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-184.0", "False"], ["-180.0", "False"]], "doc_hash": "ba518a2a2d48104653a1310a0b3dba8a7ff0c05bd8b540c8f7a5a15fbdcf264f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00657326 0.01786798 0.97555875]"]}
{"doc_id": 2051, "doc": {"premise": "The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority.", "hypothesis": "The USDA says they need looser enforcement.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Yes, The USDA says they need looser enforcement."}, "gen_args_1": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? Also, The USDA says they need looser enforcement."}, "gen_args_2": {"arg_0": "", "arg_1": " The USDA argues, however, that what is needed is more enforcement power, and to that end, it is advancing a bill designed to expand its authority., right? No, The USDA says they need looser enforcement."}}, "resps": [[["-160.0", "False"]], [["-161.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-161.0", "False"], ["-154.0", "False"]], "doc_hash": "49d0c5bf589c872e15cf47bcd1c064526afe4e81a8a3be6a44613931ff0a53e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 2059, "doc": {"premise": "The junk yards of history are strewn with wreckage.", "hypothesis": "Sometimes precious items that evoke strong memories of past historical events are found in the wreckage of the junk yards.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Yes, Sometimes precious items that evoke strong memories of past historical events are found in the wreckage of the junk yards."}, "gen_args_1": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Also, Sometimes precious items that evoke strong memories of past historical events are found in the wreckage of the junk yards."}, "gen_args_2": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? No, Sometimes precious items that evoke strong memories of past historical events are found in the wreckage of the junk yards."}}, "resps": [[["-148.0", "False"]], [["-155.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-155.0", "False"], ["-147.0", "False"]], "doc_hash": "636bc20d3f775ce66ecd142ce87bb5b8ad2e504802f8310bd78e340f3e9e4b11", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[2.68875482e-01 2.45182703e-04 7.30879336e-01]"]}
{"doc_id": 2067, "doc": {"premise": "Pundits often say history is written by the winners.", "hypothesis": "Pundits say losers write history.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Yes, Pundits say losers write history."}, "gen_args_1": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Also, Pundits say losers write history."}, "gen_args_2": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? No, Pundits say losers write history."}}, "resps": [[["-90.5", "False"]], [["-87.0", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-90.5", "False"], ["-87.0", "False"], ["-85.0", "False"]], "doc_hash": "db2534dd318e3a0a94adfddf2fc9aeaac48f74d086c4497665b1708424c9fbb6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00358671 0.11877538 0.87763792]"]}
{"doc_id": 2075, "doc": {"premise": "Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system.", "hypothesis": "Our immune system was kept busy in the past.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Yes, Our immune system was kept busy in the past."}, "gen_args_1": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? Also, Our immune system was kept busy in the past."}, "gen_args_2": {"arg_0": "", "arg_1": " Theory of the Leisure  Modern medicine and hygiene have licked most of the major problems that used to preoccupy our immune system., right? No, Our immune system was kept busy in the past."}}, "resps": [[["-165.0", "False"]], [["-173.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-173.0", "False"], ["-168.0", "False"]], "doc_hash": "7f70e2735a53503e1c56a6f3f5c6c558f69939cedfa0e7f49edd6a14d16a0b46", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 2083, "doc": {"premise": "Prudie agrees there is something tacky about being seen chewing gum.", "hypothesis": "Prudie thinks highly of people who chew bubble gum.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Yes, Prudie thinks highly of people who chew bubble gum."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Also, Prudie thinks highly of people who chew bubble gum."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? No, Prudie thinks highly of people who chew bubble gum."}}, "resps": [[["-124.0", "False"]], [["-124.5", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-124.0", "False"], ["-124.5", "False"], ["-123.0", "False"]], "doc_hash": "139c45414ea4f22defa81cbe09f4f1b8b1a1a850caf6952bc65df43b2936f44f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.2312239  0.14024438 0.62853172]"]}
{"doc_id": 2091, "doc": {"premise": "TV dinners carry a terrible stigma.", "hypothesis": "Breakfast and lunch are the only meals that appear on TV.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Yes, Breakfast and lunch are the only meals that appear on TV."}, "gen_args_1": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Also, Breakfast and lunch are the only meals that appear on TV."}, "gen_args_2": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? No, Breakfast and lunch are the only meals that appear on TV."}}, "resps": [[["-105.5", "False"]], [["-105.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-105.5", "False"], ["-105.5", "False"], ["-104.5", "False"]], "doc_hash": "7cd637dc2fda4dee9817a32b162c18f48dcc7f0b3c15bcf08af1f82a87b795b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2099, "doc": {"premise": "Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private.", "hypothesis": "There is a popular TV show about Pynchon's private life, starring Pynchon himself.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Yes, There is a popular TV show about Pynchon's private life, starring Pynchon himself."}, "gen_args_1": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? Also, There is a popular TV show about Pynchon's private life, starring Pynchon himself."}, "gen_args_2": {"arg_0": "", "arg_1": " Pynchon : As befits a man guarding, as opposed to flaunting, his privacy, Pynchon has kept his private life private., right? No, There is a popular TV show about Pynchon's private life, starring Pynchon himself."}}, "resps": [[["-179.0", "False"]], [["-182.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-182.0", "False"], ["-179.0", "False"]], "doc_hash": "773c568294ff072a751ab7766e00c3b78428d436bc294d630b9c00b5c12e075b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2107, "doc": {"premise": "Let me show you how the American people in the end viewed your performance as independent counsel.", "hypothesis": "The American people have no idea that you were independent counsel.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Yes, The American people have no idea that you were independent counsel."}, "gen_args_1": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Also, The American people have no idea that you were independent counsel."}, "gen_args_2": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? No, The American people have no idea that you were independent counsel."}}, "resps": [[["-131.0", "False"]], [["-136.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-136.0", "False"], ["-128.0", "False"]], "doc_hash": "0fe385510c87ac39a45f80e458ccef10d007cbe0c0367b25faa79a704ddd7768", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 2115, "doc": {"premise": "The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers.", "hypothesis": "The trip helped make sense of the Republic of Texas believers' motivations.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Yes, The trip helped make sense of the Republic of Texas believers' motivations."}, "gen_args_1": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Also, The trip helped make sense of the Republic of Texas believers' motivations."}, "gen_args_2": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? No, The trip helped make sense of the Republic of Texas believers' motivations."}}, "resps": [[["-144.0", "False"]], [["-155.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-155.0", "False"], ["-151.0", "False"]], "doc_hash": "c86fa149fef0408e86e1b1b314813c8ed3c4b593ed19059036869c10b8c877b7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.99072278e-01 1.66862063e-05 9.11035992e-04]"]}
{"doc_id": 2123, "doc": {"premise": "Three Japanese banks will merge to create the world's largest financial institution.", "hypothesis": "The three respective banks are already large.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Yes, The three respective banks are already large."}, "gen_args_1": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? Also, The three respective banks are already large."}, "gen_args_2": {"arg_0": "", "arg_1": " Three Japanese banks will merge to create the world's largest financial institution., right? No, The three respective banks are already large."}}, "resps": [[["-108.5", "False"]], [["-110.0", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-108.5", "False"], ["-110.0", "False"], ["-105.0", "False"]], "doc_hash": "17b90f105efd209bfda30155d37b1af09985b2c8b1feb7d9c6b3d9b92425bdb4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.02912176 0.00649794 0.9643803 ]"]}
{"doc_id": 2131, "doc": {"premise": "Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done.", "hypothesis": "Prudie thinks life is better when you laugh at everything.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Yes, Prudie thinks life is better when you laugh at everything."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Also, Prudie thinks life is better when you laugh at everything."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? No, Prudie thinks life is better when you laugh at everything."}}, "resps": [[["-169.0", "False"]], [["-169.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-169.0", "False"], ["-169.0", "False"]], "doc_hash": "564013e4eb30e04635120af54fc0dc6f0aa10c07c433fea289fefe374bfb47f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2139, "doc": {"premise": "The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people.", "hypothesis": "Bugsy Siegel and Kid Twist are a part of our history and that means we're tough.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Yes, Bugsy Siegel and Kid Twist are a part of our history and that means we're tough."}, "gen_args_1": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Also, Bugsy Siegel and Kid Twist are a part of our history and that means we're tough."}, "gen_args_2": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? No, Bugsy Siegel and Kid Twist are a part of our history and that means we're tough."}}, "resps": [[["-150.0", "False"]], [["-154.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-154.0", "False"], ["-148.0", "False"]], "doc_hash": "45c8b5f69ad29c40ecf95d4f3580f47a709296d06a211273a66c7b4d58f45e38", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 2147, "doc": {"premise": "Soderbergh is one of those rare filmmakers who learn on the job.", "hypothesis": "Soderbergh is a filmmaker with the skill of learning on the job.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Yes, Soderbergh is a filmmaker with the skill of learning on the job."}, "gen_args_1": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? Also, Soderbergh is a filmmaker with the skill of learning on the job."}, "gen_args_2": {"arg_0": "", "arg_1": " Soderbergh is one of those rare filmmakers who learn on the job., right? No, Soderbergh is a filmmaker with the skill of learning on the job."}}, "resps": [[["-104.0", "False"]], [["-110.0", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-110.0", "False"], ["-103.0", "False"]], "doc_hash": "ad80cd4b679b02b7f4d2c51fe78e74df5719596f5e1c51e1a046c8d4402208b9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.68762254e-01 6.66195022e-04 7.30571551e-01]"]}
{"doc_id": 2155, "doc": {"premise": "Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah.", "hypothesis": "Bush warned on a weekday that his party often painted an image on social issues.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Yes, Bush warned on a weekday that his party often painted an image on social issues."}, "gen_args_1": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Also, Bush warned on a weekday that his party often painted an image on social issues."}, "gen_args_2": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? No, Bush warned on a weekday that his party often painted an image on social issues."}}, "resps": [[["-178.0", "False"]], [["-179.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-179.0", "False"], ["-179.0", "False"]], "doc_hash": "dc4e9a9a624c96bee9d9ecaf435730f3e00de787c54b0e66ca0d235cc6656af2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2163, "doc": {"premise": "Time runs two anti-emotion articles.", "hypothesis": "Newsweek ran four very emotional articles.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Yes, Newsweek ran four very emotional articles."}, "gen_args_1": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Also, Newsweek ran four very emotional articles."}, "gen_args_2": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? No, Newsweek ran four very emotional articles."}}, "resps": [[["-118.0", "False"]], [["-117.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-117.0", "False"], ["-115.0", "False"]], "doc_hash": "e8981db3d741b237364f897dbb06df0e641d543ebcf6733d9389daed96f01725", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 2171, "doc": {"premise": "One measure of attachment to ordinary  Does the president carry a wallet?", "hypothesis": "The president might carry a wallet.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Yes, The president might carry a wallet."}, "gen_args_1": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? Also, The president might carry a wallet."}, "gen_args_2": {"arg_0": "", "arg_1": " One measure of attachment to ordinary  Does the president carry a wallet?, right? No, The president might carry a wallet."}}, "resps": [[["-133.0", "False"]], [["-138.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-138.0", "False"], ["-135.0", "False"]], "doc_hash": "4c374a07cf41b5321adeda6ec17ea7c41d9feb59a886e5bd008bf50d56ede267", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2179, "doc": {"premise": "Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill.", "hypothesis": "New York state has no senators.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Yes, New York state has no senators."}, "gen_args_1": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Also, New York state has no senators."}, "gen_args_2": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? No, New York state has no senators."}}, "resps": [[["-165.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "5f47715b1dc3758f928be7cac35fa5b8ecf44f73c38cf735488ab0548e64eeae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[8.94679497e-04 1.79701181e-02 9.81135202e-01]"]}
{"doc_id": 2187, "doc": {"premise": "So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb.", "hypothesis": "Cuba is in the arctic.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Yes, Cuba is in the arctic."}, "gen_args_1": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Also, Cuba is in the arctic."}, "gen_args_2": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? No, Cuba is in the arctic."}}, "resps": [[["-163.0", "False"]], [["-164.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-164.0", "False"], ["-162.0", "False"]], "doc_hash": "82216a418cb7732f8d1674acfd7a57a873e7e59e7908ccc27836bc412f114709", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2195, "doc": {"premise": "The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies.", "hypothesis": "There are no good ideas from the Eurocats.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Yes, There are no good ideas from the Eurocats."}, "gen_args_1": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? Also, There are no good ideas from the Eurocats."}, "gen_args_2": {"arg_0": "", "arg_1": " The European Union's Eurocrats have worthy ideas, such as persuading the continent's governments to agree on harmonious environmental and immigration policies., right? No, There are no good ideas from the Eurocats."}}, "resps": [[["-171.0", "False"]], [["-173.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-173.0", "False"], ["-166.0", "False"]], "doc_hash": "53b62ea5f12270e2d2d57f1b82ce2b80d805731b9c287e7dc99093147bc54bad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 2203, "doc": {"premise": "So why does Gates produce at such a frantic pace?", "hypothesis": "The President was wondering why machines in the Gates factory produce at such a high rate.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Yes, The President was wondering why machines in the Gates factory produce at such a high rate."}, "gen_args_1": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Also, The President was wondering why machines in the Gates factory produce at such a high rate."}, "gen_args_2": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? No, The President was wondering why machines in the Gates factory produce at such a high rate."}}, "resps": [[["-143.0", "False"]], [["-146.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-146.0", "False"], ["-141.0", "False"]], "doc_hash": "8ad0956950ee1dcd16cf5d15152466093f14c7f6df638749d3f5692a15a76e64", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2211, "doc": {"premise": "The MCI Web site spells out the intended method of measuring these home runs.", "hypothesis": "The MCI Web site has guidelines that are easy to understand regarding measuring home runs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Yes, The MCI Web site has guidelines that are easy to understand regarding measuring home runs."}, "gen_args_1": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Also, The MCI Web site has guidelines that are easy to understand regarding measuring home runs."}, "gen_args_2": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? No, The MCI Web site has guidelines that are easy to understand regarding measuring home runs."}}, "resps": [[["-153.0", "False"]], [["-158.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-158.0", "False"], ["-158.0", "False"]], "doc_hash": "c72db439e038837f6549afd49cc01380f03cc93bcad22aaf579bd4c34f33607d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 2219, "doc": {"premise": "While I'm not writing you from the United States, that's where I normally am, so sign me...", "hypothesis": "I'm usually in the United States, but I'm not writing to you from there right now.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Yes, I'm usually in the United States, but I'm not writing to you from there right now."}, "gen_args_1": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? Also, I'm usually in the United States, but I'm not writing to you from there right now."}, "gen_args_2": {"arg_0": "", "arg_1": " While I'm not writing you from the United States, that's where I normally am, so sign me..., right? No, I'm usually in the United States, but I'm not writing to you from there right now."}}, "resps": [[["-138.0", "False"]], [["-144.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-144.0", "False"], ["-141.0", "False"]], "doc_hash": "a5c169d89c8043822a941bf897a87503e38f55d68e14ca536cf20a1fdf5841c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2227, "doc": {"premise": "There are two evolutionary advantages to looking average.", "hypothesis": "It's best to look very fancy.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Yes, It's best to look very fancy."}, "gen_args_1": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Also, It's best to look very fancy."}, "gen_args_2": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? No, It's best to look very fancy."}}, "resps": [[["-112.5", "False"]], [["-113.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-113.5", "False"], ["-108.5", "False"]], "doc_hash": "5795d6be0eda80d2726b3819551a338fa122681b68abc1ebf9b34a5919175afc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 2235, "doc": {"premise": "The Feminization of Culture Answer", "hypothesis": "Culture cannot relate to feminism.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Yes, Culture cannot relate to feminism."}, "gen_args_1": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Also, Culture cannot relate to feminism."}, "gen_args_2": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? No, Culture cannot relate to feminism."}}, "resps": [[["-97.5", "False"]], [["-101.5", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-101.5", "False"], ["-95.5", "False"]], "doc_hash": "d0acb180d47a1c5af9b2eaec51a5de98d72c1c7ab4ab44f5485dbb09b7ab7025", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 2243, "doc": {"premise": "Alternative should not be used in place of alternate.", "hypothesis": "Lots of people do not know how to correctly use alternative and alternate.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Yes, Lots of people do not know how to correctly use alternative and alternate."}, "gen_args_1": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? Also, Lots of people do not know how to correctly use alternative and alternate."}, "gen_args_2": {"arg_0": "", "arg_1": " Alternative should not be used in place of alternate., right? No, Lots of people do not know how to correctly use alternative and alternate."}}, "resps": [[["-106.0", "False"]], [["-107.0", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-107.0", "False"], ["-107.0", "False"]], "doc_hash": "3e742a8efcee1a881349cf503d5e1b17629b6e43b6bc25cb177d67b6d465d028", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2251, "doc": {"premise": "The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator.", "hypothesis": "Dr. Spooner was a part of New College for decades.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Yes, Dr. Spooner was a part of New College for decades."}, "gen_args_1": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Also, Dr. Spooner was a part of New College for decades."}, "gen_args_2": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? No, Dr. Spooner was a part of New College for decades."}}, "resps": [[["-178.0", "False"]], [["-185.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-185.0", "False"], ["-182.0", "False"]], "doc_hash": "c8922caf2b1908345abe7d453a0ee4831793dc6f538332707a904a439ee88735", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 2259, "doc": {"premise": "Given time and improved technology, all non-radio phones may be branded as wire phones .", "hypothesis": "Non radio phones will all end up as wire phones.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Yes, Non radio phones will all end up as wire phones."}, "gen_args_1": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Also, Non radio phones will all end up as wire phones."}, "gen_args_2": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? No, Non radio phones will all end up as wire phones."}}, "resps": [[["-156.0", "False"]], [["-162.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-162.0", "False"], ["-161.0", "False"]], "doc_hash": "8b13adc41a21027b66cc7cc131ff019056b44675451b55e75e2926699b12797e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 2267, "doc": {"premise": "A cavalier is tied to his steed through Latin caballus `horse.", "hypothesis": "There are three different breeds of horses popular among cavaliers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Yes, There are three different breeds of horses popular among cavaliers."}, "gen_args_1": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? Also, There are three different breeds of horses popular among cavaliers."}, "gen_args_2": {"arg_0": "", "arg_1": " A cavalier is tied to his steed through Latin caballus `horse., right? No, There are three different breeds of horses popular among cavaliers."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-158.0", "False"]], "doc_hash": "aa60bf9b868f53ae5ca342ce3d50a9ef4c2cc338eda2041d499f7fae2a01f45b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2275, "doc": {"premise": "If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published.", "hypothesis": "This edition is the same as the previous edition.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Yes, This edition is the same as the previous edition."}, "gen_args_1": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Also, This edition is the same as the previous edition."}, "gen_args_2": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? No, This edition is the same as the previous edition."}}, "resps": [[["-153.0", "False"]], [["-156.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-156.0", "False"], ["-150.0", "False"]], "doc_hash": "fef2511e11e6c6ba5e3df82531bacaf3a0d2b1b0c48f1b91c377717d62fa777b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 2283, "doc": {"premise": "Today these Germanisms do not even stay put in the United States.", "hypothesis": "Nowadays these Germanisms do not even stay in the same location in the United states.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Yes, Nowadays these Germanisms do not even stay in the same location in the United states."}, "gen_args_1": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Also, Nowadays these Germanisms do not even stay in the same location in the United states."}, "gen_args_2": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? No, Nowadays these Germanisms do not even stay in the same location in the United states."}}, "resps": [[["-136.0", "False"]], [["-141.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-141.0", "False"], ["-137.0", "False"]], "doc_hash": "a72c65adf2c717ee3209ef85472869683bd47cf5bc643f72e43d78d9bcc0a0d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2291, "doc": {"premise": "Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events.", "hypothesis": "They celebrate seasonal events because they believe time is s loop.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Yes, They celebrate seasonal events because they believe time is s loop."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? Also, They celebrate seasonal events because they believe time is s loop."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, their concept of time is circular, not linear, so marking the passage of time is not as important as celebrating the return of seasonal events., right? No, They celebrate seasonal events because they believe time is s loop."}}, "resps": [[["-169.0", "False"]], [["-173.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-173.0", "False"], ["-171.0", "False"]], "doc_hash": "162891f81ad69667fed9c8cea2f43f1e359dfa3acf5e25b1025be4a660841f7e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2299, "doc": {"premise": "To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing.", "hypothesis": "I could write a book titled The Perils of Literacy or one named A little Literacy is a dangerous Thing", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Yes, I could write a book titled The Perils of Literacy or one named A little Literacy is a dangerous Thing"}, "gen_args_1": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Also, I could write a book titled The Perils of Literacy or one named A little Literacy is a dangerous Thing"}, "gen_args_2": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? No, I could write a book titled The Perils of Literacy or one named A little Literacy is a dangerous Thing"}}, "resps": [[["-170.0", "False"]], [["-170.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-170.0", "False"], ["-172.0", "False"]], "doc_hash": "47013b97792db1bec3900a20b151d46055773f42e3b2d9ef880d8f3ca4e5f32a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 2307, "doc": {"premise": "I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?", "hypothesis": "I thought that the lyrics of this song were very strange.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Yes, I thought that the lyrics of this song were very strange."}, "gen_args_1": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Also, I thought that the lyrics of this song were very strange."}, "gen_args_2": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? No, I thought that the lyrics of this song were very strange."}}, "resps": [[["-243.0", "False"]], [["-244.0", "False"]], [["-249.0", "False"]]], "filtered_resps": [["-243.0", "False"], ["-244.0", "False"], ["-249.0", "False"]], "doc_hash": "6f75224e2e597744a6e440bdc5d9a20eda08bf61df06caaf1863ae52da43736c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.26845495 0.00180884]"]}
{"doc_id": 2315, "doc": {"premise": "The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores .", "hypothesis": "The King James Bible has many old words and phrases.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Yes, The King James Bible has many old words and phrases."}, "gen_args_1": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? Also, The King James Bible has many old words and phrases."}, "gen_args_2": {"arg_0": "", "arg_1": " The King James Bible, which contains many such archaisms, has preserved them for modern English; wherefore more commonly appears in the tautology whys and wherefores ., right? No, The King James Bible has many old words and phrases."}}, "resps": [[["-200.0", "False"]], [["-203.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-203.0", "False"], ["-204.0", "False"]], "doc_hash": "363b7036c632864816a6fe13dccadff12fcb570d82c9bbb9b0811473f707ee9e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2323, "doc": {"premise": "Make my coat look new, dear, sew it!", "hypothesis": "My coat is in perfect condition, I will not need you to touch it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Yes, My coat is in perfect condition, I will not need you to touch it."}, "gen_args_1": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Also, My coat is in perfect condition, I will not need you to touch it."}, "gen_args_2": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? No, My coat is in perfect condition, I will not need you to touch it."}}, "resps": [[["-125.5", "False"]], [["-127.5", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-125.5", "False"], ["-127.5", "False"], ["-121.0", "False"]], "doc_hash": "54d7da0882b8de976e5d9f2cffc01559c10f23a870aa0a7a14a3c1a034db4a9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01097063 0.00148471 0.98754466]"]}
{"doc_id": 2331, "doc": {"premise": "Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins.", "hypothesis": "It can be difficult to decide exactly where emotional appeals begin.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Yes, It can be difficult to decide exactly where emotional appeals begin."}, "gen_args_1": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Also, It can be difficult to decide exactly where emotional appeals begin."}, "gen_args_2": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? No, It can be difficult to decide exactly where emotional appeals begin."}}, "resps": [[["-165.0", "False"]], [["-169.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-169.0", "False"], ["-169.0", "False"]], "doc_hash": "7bdd9636672fccb229cd19a17b70224421a40ef1b4b024df2cdb3e3359907b0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2339, "doc": {"premise": "Words are, generally speaking, old.", "hypothesis": "The average word is more than one hundred years old.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Yes, The average word is more than one hundred years old."}, "gen_args_1": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? Also, The average word is more than one hundred years old."}, "gen_args_2": {"arg_0": "", "arg_1": " Words are, generally speaking, old., right? No, The average word is more than one hundred years old."}}, "resps": [[["-96.5", "False"]], [["-102.5", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-102.5", "False"], ["-99.0", "False"]], "doc_hash": "599e8d34ecb6ba46efcb7d2b78f632f45a5a078f6608be981c69edda50ee7815", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.92202971 0.00228548 0.07568481]"]}
{"doc_id": 2347, "doc": {"premise": "Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account.", "hypothesis": "Even in a noisy environment, you can learn the most important information by looking at facial expressions, gestures, and contextual signs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Yes, Even in a noisy environment, you can learn the most important information by looking at facial expressions, gestures, and contextual signs."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Also, Even in a noisy environment, you can learn the most important information by looking at facial expressions, gestures, and contextual signs."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? No, Even in a noisy environment, you can learn the most important information by looking at facial expressions, gestures, and contextual signs."}}, "resps": [[["-183.0", "False"]], [["-187.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-187.0", "False"], ["-187.0", "False"]], "doc_hash": "390ae909dd10b963482a1e4d6bfa25af44a58ae5780fcf7798c42d8eeb17b981", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2355, "doc": {"premise": "What are you doing becomes  Watch a dune.", "hypothesis": "They change the phrases to confuse people.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Yes, They change the phrases to confuse people."}, "gen_args_1": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Also, They change the phrases to confuse people."}, "gen_args_2": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? No, They change the phrases to confuse people."}}, "resps": [[["-140.0", "False"]], [["-141.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-141.0", "False"], ["-138.0", "False"]], "doc_hash": "0f99110fdc049570d745101f045f844dcb56d54145c7804a33a78ecf6611bbf8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 2363, "doc": {"premise": "From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research.", "hypothesis": "This dictionary documents in the personal acknowledgments that its contents relies largely on original research.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Yes, This dictionary documents in the personal acknowledgments that its contents relies largely on original research."}, "gen_args_1": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? Also, This dictionary documents in the personal acknowledgments that its contents relies largely on original research."}, "gen_args_2": {"arg_0": "", "arg_1": " From the five pages of personal acknowledgments (as opposed to a mere two pages of bibliography), it should be clear that the dictionary rests largely on original research., right? No, This dictionary documents in the personal acknowledgments that its contents relies largely on original research."}}, "resps": [[["-200.0", "False"]], [["-205.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-205.0", "False"], ["-204.0", "False"]], "doc_hash": "47ccd74bd60230c824ae84c780e078a595c30e2127be726547bd15174629dbd9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 2371, "doc": {"premise": "And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings.", "hypothesis": "Xerography is related to word meaning.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Yes, Xerography is related to word meaning."}, "gen_args_1": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Also, Xerography is related to word meaning."}, "gen_args_2": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? No, Xerography is related to word meaning."}}, "resps": [[["-249.0", "False"]], [["-252.0", "False"]], [["-252.0", "False"]]], "filtered_resps": [["-249.0", "False"], ["-252.0", "False"], ["-252.0", "False"]], "doc_hash": "522ff1a77e107127d6289c0a8c3f515b5651b466bbb46a45430f39743eb82bdc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 2379, "doc": {"premise": "Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included.", "hypothesis": "I'm in total agreement with Hendrickson.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Yes, I'm in total agreement with Hendrickson."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Also, I'm in total agreement with Hendrickson."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? No, I'm in total agreement with Hendrickson."}}, "resps": [[["-192.0", "False"]], [["-194.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-194.0", "False"], ["-192.0", "False"]], "doc_hash": "97219ac7d17b477ae7a60f8d0e7a7f1312866c1576968c26b8b0eb0ca64287e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2387, "doc": {"premise": "But the question cannot even be asked when the details are mislaid.", "hypothesis": "You can't answer the question when the details are not laid out properly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Yes, You can't answer the question when the details are not laid out properly."}, "gen_args_1": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? Also, You can't answer the question when the details are not laid out properly."}, "gen_args_2": {"arg_0": "", "arg_1": " But the question cannot even be asked when the details are mislaid., right? No, You can't answer the question when the details are not laid out properly."}}, "resps": [[["-118.5", "False"]], [["-120.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-118.5", "False"], ["-120.5", "False"], ["-119.0", "False"]], "doc_hash": "dfb0d32b5f25551cec946655323cecfedb568bd5c8bc8684fa24222ba5e481cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57409699 0.07769558 0.34820743]"]}
{"doc_id": 2395, "doc": {"premise": "In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson.", "hypothesis": "Most of the people in Santa Fe have Hispanic names.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Yes, Most of the people in Santa Fe have Hispanic names."}, "gen_args_1": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Also, Most of the people in Santa Fe have Hispanic names."}, "gen_args_2": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? No, Most of the people in Santa Fe have Hispanic names."}}, "resps": [[["-182.0", "False"]], [["-181.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-181.0", "False"], ["-183.0", "False"]], "doc_hash": "5df5e0df58d51d14309d1a89cd0cd15f2c0cd0e0bcaf4d3c6b454f0466044350", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2403, "doc": {"premise": "One can also find some definitions here and there that are not entirely wrong yet with which one might disagree.", "hypothesis": "A definition may be technically correct yet have two or more interpretations that people would argue about.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Yes, A definition may be technically correct yet have two or more interpretations that people would argue about."}, "gen_args_1": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Also, A definition may be technically correct yet have two or more interpretations that people would argue about."}, "gen_args_2": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? No, A definition may be technically correct yet have two or more interpretations that people would argue about."}}, "resps": [[["-166.0", "False"]], [["-171.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-171.0", "False"], ["-171.0", "False"]], "doc_hash": "dcc4d14f1679885a5e70bdd4664ae320ad35363965bf8a04a6b483963cf58c4b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 2411, "doc": {"premise": "Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha", "hypothesis": "We were handed a long list of strange terms.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Yes, We were handed a long list of strange terms."}, "gen_args_1": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? Also, We were handed a long list of strange terms."}, "gen_args_2": {"arg_0": "", "arg_1": " Governmental/legal  batta, begar, chaprasi, dakoit, dakoity, dhan, dharna, kotwal, kotwali, panchayat, pottah, sabha, right? No, We were handed a long list of strange terms."}}, "resps": [[["-235.0", "False"]], [["-239.0", "False"]], [["-237.0", "False"]]], "filtered_resps": [["-235.0", "False"], ["-239.0", "False"], ["-237.0", "False"]], "doc_hash": "6f4f6119d6b2f3b191a47ae402439389c073d1e5de7e73f71f39074dd9f0fbfb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2419, "doc": {"premise": "The flashes of wisdom should not be overlooked,", "hypothesis": "The flashes of wisdom are of great significance.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Yes, The flashes of wisdom are of great significance."}, "gen_args_1": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Also, The flashes of wisdom are of great significance."}, "gen_args_2": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? No, The flashes of wisdom are of great significance."}}, "resps": [[["-96.5", "False"]], [["-102.5", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-102.5", "False"], ["-99.0", "False"]], "doc_hash": "418aa54d34c353b452080254ccae9b5e193c8633b1428d5f816db72d9a717344", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.92202971 0.00228548 0.07568481]"]}
{"doc_id": 2427, "doc": {"premise": "Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops.", "hypothesis": "Hogwash is defined as that which is nonsensical and worthless.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Yes, Hogwash is defined as that which is nonsensical and worthless."}, "gen_args_1": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Also, Hogwash is defined as that which is nonsensical and worthless."}, "gen_args_2": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? No, Hogwash is defined as that which is nonsensical and worthless."}}, "resps": [[["-166.0", "False"]], [["-170.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-170.0", "False"], ["-164.0", "False"]], "doc_hash": "1175d0d2d48b4c5b3e2aa2605693bcdd3166c5c4eb4308f0557490ff57e5d844", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 2435, "doc": {"premise": "Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one.", "hypothesis": "The Omni Gazetteer of the United States is comprehensive.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Yes, The Omni Gazetteer of the United States is comprehensive."}, "gen_args_1": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? Also, The Omni Gazetteer of the United States is comprehensive."}, "gen_args_2": {"arg_0": "", "arg_1": " Taken in this context, the recent publication of the Omni Gazetteer of the United States of America , despite its 1,500,000 entries, may properly be seen as only a first step, albeit an ambitious one., right? No, The Omni Gazetteer of the United States is comprehensive."}}, "resps": [[["-182.0", "False"]], [["-187.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-187.0", "False"], ["-184.0", "False"]], "doc_hash": "ff560f50352ee28d9337e04f1504e3683c93cd8df50ffb107e33c797968464a6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2443, "doc": {"premise": "The difference between a president and a king is that a king has no vice .", "hypothesis": "A president has a vice-president, but a king does not have a vice-king.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Yes, A president has a vice-president, but a king does not have a vice-king."}, "gen_args_1": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Also, A president has a vice-president, but a king does not have a vice-king."}, "gen_args_2": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? No, A president has a vice-president, but a king does not have a vice-king."}}, "resps": [[["-97.5", "False"]], [["-101.0", "False"]], [["-99.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-101.0", "False"], ["-99.5", "False"]], "doc_hash": "769ee5c7c97e44fd196b7e3afaf9de002552fa97eb83717ac38d1b5ba6523ace", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.85797681 0.02590865 0.11611453]"]}
{"doc_id": 2451, "doc": {"premise": "A virgin forest is a forest in which the hand of man has never set foot .", "hypothesis": "A forest that has never been marred by man's presence is called a virgin forest.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Yes, A forest that has never been marred by man's presence is called a virgin forest."}, "gen_args_1": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Also, A forest that has never been marred by man's presence is called a virgin forest."}, "gen_args_2": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? No, A forest that has never been marred by man's presence is called a virgin forest."}}, "resps": [[["-113.5", "False"]], [["-116.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-113.5", "False"], ["-116.5", "False"], ["-116.0", "False"]], "doc_hash": "ca0c8f41d95e771197535b21d89e394323fad3dbeb5a174c9146fb5338fd304a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.88349207 0.04398648 0.07252145]"]}
{"doc_id": 2459, "doc": {"premise": "Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians.", "hypothesis": "The Indians showed Sir William Johnson how to plant a garden.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Yes, The Indians showed Sir William Johnson how to plant a garden."}, "gen_args_1": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? Also, The Indians showed Sir William Johnson how to plant a garden."}, "gen_args_2": {"arg_0": "", "arg_1": " Jones, referring to Sir William Johnson, commented,  He was loved, caressed, and almost adored by the Indians., right? No, The Indians showed Sir William Johnson how to plant a garden."}}, "resps": [[["-164.0", "False"]], [["-167.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-167.0", "False"], ["-163.0", "False"]], "doc_hash": "d3915392f11d56546cb694cf5200600a57731acbae521fa0d1f3bcfb12ece890", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2467, "doc": {"premise": "It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him.", "hypothesis": "Lover was on the run from the law who wanted him dead.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Yes, Lover was on the run from the law who wanted him dead."}, "gen_args_1": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Also, Lover was on the run from the law who wanted him dead."}, "gen_args_2": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? No, Lover was on the run from the law who wanted him dead."}}, "resps": [[["-150.0", "False"]], [["-156.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-156.0", "False"], ["-153.0", "False"]], "doc_hash": "b8a25ac77d2df3bc1c0e42062fe15f7638b5aa8a64ec4df7e40c1504e9e8b206", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2475, "doc": {"premise": "The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out.", "hypothesis": "English is badly in need of additional exotic words.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Yes, English is badly in need of additional exotic words."}, "gen_args_1": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Also, English is badly in need of additional exotic words."}, "gen_args_2": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? No, English is badly in need of additional exotic words."}}, "resps": [[["-165.0", "False"]], [["-171.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-171.0", "False"], ["-162.0", "False"]], "doc_hash": "d219c72209221a99fc6fa480910300378a7a05142b87f0a1239c9e0c59f41241", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 2483, "doc": {"premise": "A month has passed since the election and still Republicans and Democrats are high-fiving.", "hypothesis": "It has been only a week since the election.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Yes, It has been only a week since the election."}, "gen_args_1": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? Also, It has been only a week since the election."}, "gen_args_2": {"arg_0": "", "arg_1": " A month has passed since the election and still Republicans and Democrats are high-fiving., right? No, It has been only a week since the election."}}, "resps": [[["-114.5", "False"]], [["-115.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-114.5", "False"], ["-115.0", "False"], ["-111.0", "False"]], "doc_hash": "e068a568e60ec4474c79e3bbfd52841f306c36f5bf66244e7f5731dffb441060", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0288002 0.0174682 0.9537316]"]}
{"doc_id": 4, "doc": {"premise": "I didn't know what I was going for or anything, so was to report to a designated place in Washington.", "hypothesis": "I knew exactly what I needed to do as I marched to Washington.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Yes, I knew exactly what I needed to do as I marched to Washington."}, "gen_args_1": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Also, I knew exactly what I needed to do as I marched to Washington."}, "gen_args_2": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? No, I knew exactly what I needed to do as I marched to Washington."}}, "resps": [[["-152.0", "False"]], [["-156.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-156.0", "False"], ["-149.0", "False"]], "doc_hash": "553bffb9ee54fa7e5e6bd999ce41ca3e9c58478e23105850c8e3b242bb808bcc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 12, "doc": {"premise": "I was just there just trying to figure it out.", "hypothesis": "I understood it well from the beginning.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Yes, I understood it well from the beginning."}, "gen_args_1": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Also, I understood it well from the beginning."}, "gen_args_2": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? No, I understood it well from the beginning."}}, "resps": [[["-91.5", "False"]], [["-94.0", "False"]], [["-88.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-94.0", "False"], ["-88.0", "False"]], "doc_hash": "832605dcbf0e3aaacc4b9e58dd331730468b2ac0b472e62a4377dfd9f32640f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 20, "doc": {"premise": "And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white.", "hypothesis": "Granny's sister wasn't white but she wanted to be so she could go to school.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Yes, Granny's sister wasn't white but she wanted to be so she could go to school."}, "gen_args_1": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? Also, Granny's sister wasn't white but she wanted to be so she could go to school."}, "gen_args_2": {"arg_0": "", "arg_1": " And Granny used to tell the story about how her sister and her sister's husband decided that they were going to move to the city, to Augusta, and pass for white., right? No, Granny's sister wasn't white but she wanted to be so she could go to school."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-169.0", "False"]], "doc_hash": "1eabb6347c66071b69c69a1208399621b4d6220f5e61a976e66b08cec05237e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 28, "doc": {"premise": "But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location.", "hypothesis": "I shipped the boxes to Japan.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Yes, I shipped the boxes to Japan."}, "gen_args_1": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Also, I shipped the boxes to Japan."}, "gen_args_2": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? No, I shipped the boxes to Japan."}}, "resps": [[["-169.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "0c3525dd04f263eb17a4c474d0aa3d4c9ba2e89220bd4938b8bb57255e90f341", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 36, "doc": {"premise": "When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight.", "hypothesis": "All of the instruments in the aircraft were intact.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Yes, All of the instruments in the aircraft were intact."}, "gen_args_1": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Also, All of the instruments in the aircraft were intact."}, "gen_args_2": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? No, All of the instruments in the aircraft were intact."}}, "resps": [[["-205.0", "False"]], [["-205.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-205.0", "False"], ["-200.0", "False"]], "doc_hash": "c1bdbd35926661e7264ad3bf8bb5c670671494dc25cd76bfbfe570681bdbacea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 44, "doc": {"premise": "Maybe she told everyone else and I wasn't paying attention at that particular time.", "hypothesis": "I was talking to someone else at the time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Yes, I was talking to someone else at the time."}, "gen_args_1": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? Also, I was talking to someone else at the time."}, "gen_args_2": {"arg_0": "", "arg_1": " Maybe she told everyone else and I wasn't paying attention at that particular time., right? No, I was talking to someone else at the time."}}, "resps": [[["-100.5", "False"]], [["-101.0", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-100.5", "False"], ["-101.0", "False"], ["-98.0", "False"]], "doc_hash": "89bca793bcfa051304712fd4458bfa2f62fc6e3766a1d1115814f51f5fb84918", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07252145 0.04398648 0.88349207]"]}
{"doc_id": 52, "doc": {"premise": "Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour.", "hypothesis": "It only travels 10,000 miles an hour.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Yes, It only travels 10,000 miles an hour."}, "gen_args_1": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Also, It only travels 10,000 miles an hour."}, "gen_args_2": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? No, It only travels 10,000 miles an hour."}}, "resps": [[["-186.0", "False"]], [["-190.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-190.0", "False"], ["-184.0", "False"]], "doc_hash": "379e8682205df024e3059490c52f8cb1f7d4c753b1b7f02b84a1c8c894c866f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 60, "doc": {"premise": "Also, oh, let me go through this.", "hypothesis": "I don't need to deal with that.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Yes, I don't need to deal with that."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Also, I don't need to deal with that."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? No, I don't need to deal with that."}}, "resps": [[["-91.5", "False"]], [["-91.0", "False"]], [["-88.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-91.0", "False"], ["-88.0", "False"]], "doc_hash": "1257369cc5c9113436283246fae42d44d98a025e4bab78a55cd12db6838af628", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02796094 0.0460998  0.92593926]"]}
{"doc_id": 68, "doc": {"premise": "He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that.", "hypothesis": "He would write a dream on the paper and then burn it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Yes, He would write a dream on the paper and then burn it."}, "gen_args_1": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? Also, He would write a dream on the paper and then burn it."}, "gen_args_2": {"arg_0": "", "arg_1": " He would tear the, the paper up and put it in the sand, ashtray sand, set it on a fire and burn it, and then stir the ashes up like that., right? No, He would write a dream on the paper and then burn it."}}, "resps": [[["-194.0", "False"]], [["-194.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-194.0", "False"], ["-195.0", "False"]], "doc_hash": "4cdd67c62eeef54f47c6382a9f3bb94a0ea4ef867e2f8b4973fc30ad36dc8acc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 76, "doc": {"premise": "I think that's why I remember that.", "hypothesis": "That's probably the reason I remembered his name.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Yes, That's probably the reason I remembered his name."}, "gen_args_1": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Also, That's probably the reason I remembered his name."}, "gen_args_2": {"arg_0": "", "arg_1": " I think that's why I remember that., right? No, That's probably the reason I remembered his name."}}, "resps": [[["-89.0", "False"]], [["-89.5", "False"]], [["-91.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-89.5", "False"], ["-91.0", "False"]], "doc_hash": "cd7f001ce0c3e32ffc90153eca4758bb7e411d620755ea71cebbee6a5a07dd8d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57409699 0.34820743 0.07769558]"]}
{"doc_id": 84, "doc": {"premise": "That was, that was a pretty scary day.", "hypothesis": "It was a relaxing day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Yes, It was a relaxing day."}, "gen_args_1": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Also, It was a relaxing day."}, "gen_args_2": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? No, It was a relaxing day."}}, "resps": [[["-82.0", "False"]], [["-83.5", "False"]], [["-77.5", "False"]]], "filtered_resps": [["-82.0", "False"], ["-83.5", "False"], ["-77.5", "False"]], "doc_hash": "516f1934af0ff9a3bf065552f52c12c675bc02adaec27b00f66511910ebb0dc8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01096007 0.00244552 0.9865944 ]"]}
{"doc_id": 92, "doc": {"premise": "So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May.", "hypothesis": "This is General May and three U2 pilots at President Kennedy's office.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Yes, This is General May and three U2 pilots at President Kennedy's office."}, "gen_args_1": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? Also, This is General May and three U2 pilots at President Kennedy's office."}, "gen_args_2": {"arg_0": "", "arg_1": " So, well I, uh, anyway, uh, uh, this is the three, uh, U2 pilots that, uh, President Kennedy's office in Washington with General May., right? No, This is General May and three U2 pilots at President Kennedy's office."}}, "resps": [[["-209.0", "False"]], [["-216.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-216.0", "False"], ["-211.0", "False"]], "doc_hash": "426f313b3c79477ac6f35bffe7be2aaaa9b4e86a41e34f288095ade8ff7d3678", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 100, "doc": {"premise": "But uh, think about it.", "hypothesis": "It's nothing you would want to think about.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But uh, think about it., right? Yes, It's nothing you would want to think about."}, "gen_args_1": {"arg_0": "", "arg_1": " But uh, think about it., right? Also, It's nothing you would want to think about."}, "gen_args_2": {"arg_0": "", "arg_1": " But uh, think about it., right? No, It's nothing you would want to think about."}}, "resps": [[["-86.5", "False"]], [["-87.5", "False"]], [["-81.0", "False"]]], "filtered_resps": [["-86.5", "False"], ["-87.5", "False"], ["-81.0", "False"]], "doc_hash": "5833a31f8968f24c6305cdb8bc48b37313d2e8522fa53a0fff1a311255a8ca4e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00406405 0.00149508 0.99444087]"]}
{"doc_id": 108, "doc": {"premise": "I don't want to go into the Third SS that's Third Strategic Support Squadron.", "hypothesis": "I couldn't wait to go into the Third SS.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Yes, I couldn't wait to go into the Third SS."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Also, I couldn't wait to go into the Third SS."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? No, I couldn't wait to go into the Third SS."}}, "resps": [[["-131.0", "False"]], [["-136.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-136.0", "False"], ["-128.0", "False"]], "doc_hash": "cf75b6e90a5930d6431d1c1a93cdbc760218df870ee95eaaf5407b749fa1265e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 116, "doc": {"premise": "He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed.", "hypothesis": "I wasn't worried at all, it would happen when it happened.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Yes, I wasn't worried at all, it would happen when it happened."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? Also, I wasn't worried at all, it would happen when it happened."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't say a time again, so he just got me over there stressing out, and I really don't even know when it's needed., right? No, I wasn't worried at all, it would happen when it happened."}}, "resps": [[["-180.0", "False"]], [["-178.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-178.0", "False"], ["-177.0", "False"]], "doc_hash": "50bc86aed3a37488e7151971c1b049a782f2f175a023d3114aa0281ba784c2aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.03511903 0.25949646 0.70538451]"]}
{"doc_id": 124, "doc": {"premise": "Little things like that made a big difference in what I was trying to do.", "hypothesis": "I was trying to accomplish something.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Yes, I was trying to accomplish something."}, "gen_args_1": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Also, I was trying to accomplish something."}, "gen_args_2": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? No, I was trying to accomplish something."}}, "resps": [[["-88.5", "False"]], [["-92.5", "False"]], [["-89.5", "False"]]], "filtered_resps": [["-88.5", "False"], ["-92.5", "False"], ["-89.5", "False"]], "doc_hash": "0a73aac2379395dd1cd9ede4a7e28f7fbc762b614e0a4748d2d4e1d11dddddfc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 132, "doc": {"premise": "I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed.", "hypothesis": "I told him I didn't want to hear anything else.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Yes, I told him I didn't want to hear anything else."}, "gen_args_1": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Also, I told him I didn't want to hear anything else."}, "gen_args_2": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? No, I told him I didn't want to hear anything else."}}, "resps": [[["-118.0", "False"]], [["-117.5", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-117.5", "False"], ["-115.0", "False"]], "doc_hash": "a17605dd60278bfe3b19aa96adc26a16a441e1c16c93a4ac210b67557674e532", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04398648 0.07252145 0.88349207]"]}
{"doc_id": 140, "doc": {"premise": "Um, and so they just left town, and she, she never did see her sister again, never saw her sister again.", "hypothesis": "She saw her sister every day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Yes, She saw her sister every day."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? Also, She saw her sister every day."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, and so they just left town, and she, she never did see her sister again, never saw her sister again., right? No, She saw her sister every day."}}, "resps": [[["-127.5", "False"]], [["-134.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-134.0", "False"], ["-124.0", "False"]], "doc_hash": "d799a485473fa57381bd259ce352a089d7bbe67fcc724bac405147ac34f6112e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93109390e-02 4.40672145e-05 9.70644994e-01]"]}
{"doc_id": 148, "doc": {"premise": "It was still cultural area but suburbs was still the dominant form.", "hypothesis": "Most of the area was full of cheap houses.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Yes, Most of the area was full of cheap houses."}, "gen_args_1": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Also, Most of the area was full of cheap houses."}, "gen_args_2": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? No, Most of the area was full of cheap houses."}}, "resps": [[["-141.0", "False"]], [["-139.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-139.0", "False"], ["-140.0", "False"]], "doc_hash": "86a2c7e808495d2aa40dcd1bd326a95d9abac4cfa5e964a5ebabd08c063fcdca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 156, "doc": {"premise": "It would not explode without the trigger.", "hypothesis": "The trigger makes it explode.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Yes, The trigger makes it explode."}, "gen_args_1": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Also, The trigger makes it explode."}, "gen_args_2": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? No, The trigger makes it explode."}}, "resps": [[["-79.0", "False"]], [["-83.5", "False"]], [["-78.5", "False"]]], "filtered_resps": [["-79.0", "False"], ["-83.5", "False"], ["-78.5", "False"]], "doc_hash": "0bd3b03fccb3169a17ad98f58e247d5d524aa354937ed890b0f07279472b8d3d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 164, "doc": {"premise": "And our father always told us not to say they are animals.", "hypothesis": "Our dad said they were creatures, not animals.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Yes, Our dad said they were creatures, not animals."}, "gen_args_1": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? Also, Our dad said they were creatures, not animals."}, "gen_args_2": {"arg_0": "", "arg_1": " And our father always told us not to say they are animals., right? No, Our dad said they were creatures, not animals."}}, "resps": [[["-109.0", "False"]], [["-115.5", "False"]], [["-107.5", "False"]]], "filtered_resps": [["-109.0", "False"], ["-115.5", "False"], ["-107.5", "False"]], "doc_hash": "9b2a03efa4301b0e58d53834c8ac32f261df966c0dbdd9eadeca272058ab48c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[1.82375504e-01 2.74190481e-04 8.17350305e-01]"]}
{"doc_id": 172, "doc": {"premise": "I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever.", "hypothesis": "I didn't see what the person was doing on Monday.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Yes, I didn't see what the person was doing on Monday."}, "gen_args_1": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Also, I didn't see what the person was doing on Monday."}, "gen_args_2": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? No, I didn't see what the person was doing on Monday."}}, "resps": [[["-214.0", "False"]], [["-215.0", "False"]], [["-210.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-215.0", "False"], ["-210.0", "False"]], "doc_hash": "85a9073bea340949f395a9002aa042aeeb41a6f8e42ec9862e6e51d95b7d0720", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 180, "doc": {"premise": "If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression.", "hypothesis": "No changes would occur in your skin.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Yes, No changes would occur in your skin."}, "gen_args_1": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Also, No changes would occur in your skin."}, "gen_args_2": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? No, No changes would occur in your skin."}}, "resps": [[["-180.0", "False"]], [["-185.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-185.0", "False"], ["-181.0", "False"]], "doc_hash": "ef8ea21b8cb07ccc09d19f3bb62c1f3c14d313e8e4beb3ba861822b5b81e71ff", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 188, "doc": {"premise": "They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them.", "hypothesis": "He stayed with them in New York.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Yes, He stayed with them in New York."}, "gen_args_1": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? Also, He stayed with them in New York."}, "gen_args_2": {"arg_0": "", "arg_1": " They had wound up starting out to New York to visit some relatives of this, this cousin, and they just stayed and he didn't know how to get back, so he just stayed with them., right? No, He stayed with them in New York."}}, "resps": [[["-173.0", "False"]], [["-180.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-180.0", "False"], ["-177.0", "False"]], "doc_hash": "488a57c5dc99cfd8726eec6418f03e1d65dd90aa429d5304d8d990394bd29f39", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 196, "doc": {"premise": "My grandmother was born in 1910, she was a little girl.", "hypothesis": "My grandma was born in 1899.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Yes, My grandma was born in 1899."}, "gen_args_1": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Also, My grandma was born in 1899."}, "gen_args_2": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? No, My grandma was born in 1899."}}, "resps": [[["-87.0", "False"]], [["-88.0", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-87.0", "False"], ["-88.0", "False"], ["-84.0", "False"]], "doc_hash": "36db7eb4684d0f8113297923d548e97685b58b7e097c3111aceece933e5128f0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 204, "doc": {"premise": "Anyhow, so I finished came home at 6:30 today and that was my day.", "hypothesis": "I decided to come home at lunch and take the rest of the day off.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Yes, I decided to come home at lunch and take the rest of the day off."}, "gen_args_1": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Also, I decided to come home at lunch and take the rest of the day off."}, "gen_args_2": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? No, I decided to come home at lunch and take the rest of the day off."}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-125.5", "False"]], "doc_hash": "dc4db62d6d41f88c610d8f4d830e0b3eda6ecc5c5c1f3d8267251989ebdf7a37", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.92965023e-02 5.36584156e-04 9.70166914e-01]"]}
{"doc_id": 212, "doc": {"premise": "And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off.", "hypothesis": "It will only surge once.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Yes, It will only surge once."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? Also, It will only surge once."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, if it surged and just kept surging it would go 'whish,' and, like it was going to pull your head off., right? No, It will only surge once."}}, "resps": [[["-175.0", "False"]], [["-177.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-177.0", "False"], ["-172.0", "False"]], "doc_hash": "5d9122b4d283ce1030347dbcf6f9b974216d9fb1716b06c6b962bd2c1fd30e56", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 220, "doc": {"premise": "Of course, they questioned me there, why I went.", "hypothesis": "They asked why I went to the store.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Yes, They asked why I went to the store."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Also, They asked why I went to the store."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? No, They asked why I went to the store."}}, "resps": [[["-102.5", "False"]], [["-107.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-107.5", "False"], ["-105.0", "False"]], "doc_hash": "3df8801fe567ec9cd40b2b993c8b4742da462b3c599f268768d0f420a0162ab3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.91842297 0.00618829 0.07538875]"]}
{"doc_id": 228, "doc": {"premise": "Now that's how classified it was.", "hypothesis": "If anyone learned the information, they'd be jailed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Yes, If anyone learned the information, they'd be jailed."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Also, If anyone learned the information, they'd be jailed."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how classified it was., right? No, If anyone learned the information, they'd be jailed."}}, "resps": [[["-111.5", "False"]], [["-114.0", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-111.5", "False"], ["-114.0", "False"], ["-114.0", "False"]], "doc_hash": "3417d2eb9895fd9f1fb277df84443cedaad1b46c96cd66ad15572850c4c3d9ff", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.85898108 0.07050946 0.07050946]"]}
{"doc_id": 236, "doc": {"premise": "So it took me like, an hour to two hours just to find what I needed.", "hypothesis": "It took me a while to find it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Yes, It took me a while to find it."}, "gen_args_1": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? Also, It took me a while to find it."}, "gen_args_2": {"arg_0": "", "arg_1": " So it took me like, an hour to two hours just to find what I needed., right? No, It took me a while to find it."}}, "resps": [[["-99.0", "False"]], [["-104.5", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-99.0", "False"], ["-104.5", "False"], ["-100.5", "False"]], "doc_hash": "8e22f79ca37cd77150240312f39222621b293b6c053583639fbafa7bcd1dc8e4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81485186 0.00333011 0.18181803]"]}
{"doc_id": 244, "doc": {"premise": "That was my messed up.", "hypothesis": "I made a mistake when i sent in the forms.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was my messed up., right? Yes, I made a mistake when i sent in the forms."}, "gen_args_1": {"arg_0": "", "arg_1": " That was my messed up., right? Also, I made a mistake when i sent in the forms."}, "gen_args_2": {"arg_0": "", "arg_1": " That was my messed up., right? No, I made a mistake when i sent in the forms."}}, "resps": [[["-93.5", "False"]], [["-92.0", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-92.0", "False"], ["-93.5", "False"]], "doc_hash": "5a30d023572531195a4dacc6a392a2c08b7c2e5938b8dd38e5b9d0ec1a0f170c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.15428077 0.69143845 0.15428077]"]}
{"doc_id": 252, "doc": {"premise": "yeah i have a credit union", "hypothesis": "I do have a credit union I go to.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Yes, I do have a credit union I go to."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Also, I do have a credit union I go to."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i have a credit union, right? No, I do have a credit union I go to."}}, "resps": [[["-74.0", "False"]], [["-83.0", "False"]], [["-77.5", "False"]]], "filtered_resps": [["-74.0", "False"], ["-83.0", "False"], ["-77.5", "False"]], "doc_hash": "6af1053b2473b813e2c907fcf349d06fbc3ae5262a25ddca551d3ef4deda5e53", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70571502e-01 1.19778039e-04 2.93087198e-02]"]}
{"doc_id": 260, "doc": {"premise": "and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us", "hypothesis": "We have to make changes to those that represent us.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Yes, We have to make changes to those that represent us."}, "gen_args_1": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? Also, We have to make changes to those that represent us."}, "gen_args_2": {"arg_0": "", "arg_1": " and that what i think is gonna be really interesting is what we do about it i mean we are gonna have to change the people who represent us, right? No, We have to make changes to those that represent us."}}, "resps": [[["-143.0", "False"]], [["-151.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-151.0", "False"], ["-145.0", "False"]], "doc_hash": "90d40a30289791b36e40ead12b1cee52eace1069b3c4c49e0c5d7e6c918caa78", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 268, "doc": {"premise": "yeah you you must've had a cordless", "hypothesis": "The one you had was definitely a corded version only.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Yes, The one you had was definitely a corded version only."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Also, The one you had was definitely a corded version only."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? No, The one you had was definitely a corded version only."}}, "resps": [[["-111.0", "False"]], [["-116.5", "False"]], [["-108.0", "False"]]], "filtered_resps": [["-111.0", "False"], ["-116.5", "False"], ["-108.0", "False"]], "doc_hash": "e03be20845987ec753713cecff748c7d913dfdaac90279a671b5540ade54d676", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74166829e-02 1.93781146e-04 9.52389536e-01]"]}
{"doc_id": 276, "doc": {"premise": "well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs", "hypothesis": "I am strongly against drug testing, there is no doubt in my mind about it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Yes, I am strongly against drug testing, there is no doubt in my mind about it."}, "gen_args_1": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Also, I am strongly against drug testing, there is no doubt in my mind about it."}, "gen_args_2": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? No, I am strongly against drug testing, there is no doubt in my mind about it."}}, "resps": [[["-207.0", "False"]], [["-212.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-212.0", "False"], ["-212.0", "False"]], "doc_hash": "43899180459e9023b81dd200067903fdfe7bf3794fe58f2ea4ce2916d83e28af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 284, "doc": {"premise": "but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants", "hypothesis": "I still wear dresses when I'm working at home because I feel fancier.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Yes, I still wear dresses when I'm working at home because I feel fancier."}, "gen_args_1": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? Also, I still wear dresses when I'm working at home because I feel fancier."}, "gen_args_2": {"arg_0": "", "arg_1": " but no we usually you know skirt and skirt and blouse or suit or dress is is what you see down here so it's nice with me working at home because i can wear pants, right? No, I still wear dresses when I'm working at home because I feel fancier."}}, "resps": [[["-210.0", "False"]], [["-216.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-210.0", "False"], ["-216.0", "False"], ["-207.0", "False"]], "doc_hash": "2fb99cf65094cfdfcf6b77e7472a41c93916c4635f9aba83f0550cf8b058e45d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 292, "doc": {"premise": "yeah it's ours up here we have our rural connections are real bad", "hypothesis": "We do not get good connections here.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Yes, We do not get good connections here."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Also, We do not get good connections here."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? No, We do not get good connections here."}}, "resps": [[["-130.0", "False"]], [["-138.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-138.0", "False"], ["-130.0", "False"]], "doc_hash": "769946cf72cdaf2b6be3ace24e06662328774a3d8a295cee8422d144c269fcb0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99916148e-01 1.67703185e-04 4.99916148e-01]"]}
{"doc_id": 300, "doc": {"premise": "one of the benefits we get of course is travel", "hypothesis": "Traveling is my favorite part of it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Yes, Traveling is my favorite part of it."}, "gen_args_1": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Also, Traveling is my favorite part of it."}, "gen_args_2": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? No, Traveling is my favorite part of it."}}, "resps": [[["-88.0", "False"]], [["-94.5", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-88.0", "False"], ["-94.5", "False"], ["-91.5", "False"]], "doc_hash": "e9cc0a90009d23a99b1e642b6b06238181aded588eacfcd310bc7b095b9f7ec1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 308, "doc": {"premise": "yeah it was pretty reasonable", "hypothesis": "Yes, we acknowledge that it was difficult but nonetheless came out pretty well in the end.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Yes, Yes, we acknowledge that it was difficult but nonetheless came out pretty well in the end."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? Also, Yes, we acknowledge that it was difficult but nonetheless came out pretty well in the end."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it was pretty reasonable, right? No, Yes, we acknowledge that it was difficult but nonetheless came out pretty well in the end."}}, "resps": [[["-106.5", "False"]], [["-110.0", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-110.0", "False"], ["-111.5", "False"]], "doc_hash": "986012c1c2b5051f1663603d958e2fa214f1a90cf8db8f2a0bd3c47f8dbb93f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.9643803  0.02912176 0.00649794]"]}
{"doc_id": 316, "doc": {"premise": "have you read The Firm", "hypothesis": "Have you read The Soft?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " have you read The Firm, right? Yes, Have you read The Soft?"}, "gen_args_1": {"arg_0": "", "arg_1": " have you read The Firm, right? Also, Have you read The Soft?"}, "gen_args_2": {"arg_0": "", "arg_1": " have you read The Firm, right? No, Have you read The Soft?"}}, "resps": [[["-84.0", "False"]], [["-82.5", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-84.0", "False"], ["-82.5", "False"], ["-84.0", "False"]], "doc_hash": "fa8e0d2da5faacf2bec8f7ea196eb5623a63edc7d9e7eef145b9c9661f5459af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.15428077 0.69143845 0.15428077]"]}
{"doc_id": 324, "doc": {"premise": "uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody", "hypothesis": "She is willing to sit or play with anybody.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Yes, She is willing to sit or play with anybody."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Also, She is willing to sit or play with anybody."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? No, She is willing to sit or play with anybody."}}, "resps": [[["-130.0", "False"]], [["-137.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-137.0", "False"], ["-131.0", "False"]], "doc_hash": "ebd32d9081a01c4b81ad0306b5b01795391eeff638717d0a6f9717d679907919", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 332, "doc": {"premise": "yeah they had a whole bunch of things that that sort of broke at the same time", "hypothesis": "Some of the broken stuff was valuable.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Yes, Some of the broken stuff was valuable."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? Also, Some of the broken stuff was valuable."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah they had a whole bunch of things that that sort of broke at the same time, right? No, Some of the broken stuff was valuable."}}, "resps": [[["-115.0", "False"]], [["-117.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-117.0", "False"], ["-117.5", "False"]], "doc_hash": "7e5b7734233da22f5dc1af23855b646f1dc958378a9f6f2b95107c618a135d57", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.82140902 0.11116562 0.06742536]"]}
{"doc_id": 340, "doc": {"premise": "you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education", "hypothesis": "No companies help with education costs no matter how large or small.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Yes, No companies help with education costs no matter how large or small."}, "gen_args_1": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Also, No companies help with education costs no matter how large or small."}, "gen_args_2": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? No, No companies help with education costs no matter how large or small."}}, "resps": [[["-229.0", "False"]], [["-236.0", "False"]], [["-227.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-236.0", "False"], ["-227.0", "False"]], "doc_hash": "0f34247485e58d3b0f073425c471a43b83ce69df63f71d7f12cc6aad894d9903", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19189966e-01 1.08687181e-04 8.80701347e-01]"]}
{"doc_id": 348, "doc": {"premise": "yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes", "hypothesis": "It got voted down because people didn't want to get out and vote.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Yes, It got voted down because people didn't want to get out and vote."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Also, It got voted down because people didn't want to get out and vote."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? No, It got voted down because people didn't want to get out and vote."}}, "resps": [[["-203.0", "False"]], [["-206.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-206.0", "False"], ["-203.0", "False"]], "doc_hash": "070763b42c24b185f116545bb2a4560605f76f6884185557155df3291c598dad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 356, "doc": {"premise": "but i know that in some i know in a lot of rural areas they're not that good", "hypothesis": "They are very good in both urban and rural areas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Yes, They are very good in both urban and rural areas."}, "gen_args_1": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? Also, They are very good in both urban and rural areas."}, "gen_args_2": {"arg_0": "", "arg_1": " but i know that in some i know in a lot of rural areas they're not that good, right? No, They are very good in both urban and rural areas."}}, "resps": [[["-119.0", "False"]], [["-129.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-119.0", "False"], ["-129.0", "False"], ["-119.5", "False"]], "doc_hash": "58697a25f50eb1194788b1da282a864eb1ce5b4de153765b93bfe280c9f4b258", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.22441741e-01 2.82588113e-05 3.77530000e-01]"]}
{"doc_id": 364, "doc": {"premise": "now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark", "hypothesis": "Robbers don't like dogs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Yes, Robbers don't like dogs."}, "gen_args_1": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Also, Robbers don't like dogs."}, "gen_args_2": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? No, Robbers don't like dogs."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-153.0", "False"]], "doc_hash": "8a41543cd1bed81ebf300edfae097ae7d573f3ad12f18af44d9b3097840e9419", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 372, "doc": {"premise": "came back from uh uh Grand Rapids where we saw one of our sons graduate", "hypothesis": "Grand Rapids is a beautiful place.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Yes, Grand Rapids is a beautiful place."}, "gen_args_1": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Also, Grand Rapids is a beautiful place."}, "gen_args_2": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? No, Grand Rapids is a beautiful place."}}, "resps": [[["-108.0", "False"]], [["-111.5", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-108.0", "False"], ["-111.5", "False"], ["-110.5", "False"]], "doc_hash": "97dc9f3a8913dbc0bc7dc32e9b749cf7d0d0fbaa5ced3a8d5a1a995f7382ed6c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.89905227 0.02714903 0.0737987 ]"]}
{"doc_id": 380, "doc": {"premise": "it's only getting worse exponentially it seems um", "hypothesis": "It's getting better.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Yes, It's getting better."}, "gen_args_1": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? Also, It's getting better."}, "gen_args_2": {"arg_0": "", "arg_1": " it's only getting worse exponentially it seems um, right? No, It's getting better."}}, "resps": [[["-88.5", "False"]], [["-95.5", "False"]], [["-85.5", "False"]]], "filtered_resps": [["-88.5", "False"], ["-95.5", "False"], ["-85.5", "False"]], "doc_hash": "c2fa2627288d08c1e8455aa8259bc5f37723ffbbbd0ae65d2aa0437ee8183601", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74238222e-02 4.32449282e-05 9.52532933e-01]"]}
{"doc_id": 388, "doc": {"premise": "not just lawyers but police officers and judges and the whole legal profession in general", "hypothesis": "It's everyone involved in the legal system.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Yes, It's everyone involved in the legal system."}, "gen_args_1": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Also, It's everyone involved in the legal system."}, "gen_args_2": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? No, It's everyone involved in the legal system."}}, "resps": [[["-102.0", "False"]], [["-106.5", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-102.0", "False"], ["-106.5", "False"], ["-100.0", "False"]], "doc_hash": "1353f9f472abd793fd47ad4e12e6993524c44e9c4629dfa0e800027737d5f457", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11904528 0.00132247 0.87963225]"]}
{"doc_id": 396, "doc": {"premise": "yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in", "hypothesis": "The price is pretty good.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Yes, The price is pretty good."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Also, The price is pretty good."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? No, The price is pretty good."}}, "resps": [[["-155.0", "False"]], [["-154.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-154.0", "False"], ["-154.0", "False"]], "doc_hash": "59e932d813205c0c86bd4a0ecd9babbff26272ec3552cdc67b1ba678c3e94382", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 404, "doc": {"premise": "yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas", "hypothesis": "They are also the best looking cars around.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Yes, They are also the best looking cars around."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? Also, They are also the best looking cars around."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i think there's so much more economicable too just like with gas and everything i mean i can go forever on a tank of gas, right? No, They are also the best looking cars around."}}, "resps": [[["-173.0", "False"]], [["-177.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-177.0", "False"], ["-176.0", "False"]], "doc_hash": "212208edbfe77e8c2dd08dc4ec95c86853dd9e70c840a3d6ff89d48e6a354065", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 412, "doc": {"premise": "i never have can't do anything with cakes so", "hypothesis": "I could never run out of ideas for cake!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Yes, I could never run out of ideas for cake!"}, "gen_args_1": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Also, I could never run out of ideas for cake!"}, "gen_args_2": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? No, I could never run out of ideas for cake!"}}, "resps": [[["-115.0", "False"]], [["-114.0", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-114.0", "False"], ["-112.5", "False"]], "doc_hash": "659671170aa2819000feb54bf47f8ae096c58b2206de2cc8f87f8ae93716b7eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06289001 0.17095278 0.76615721]"]}
{"doc_id": 420, "doc": {"premise": "yeah because it's uh it had definitely been through the mill but uh", "hypothesis": "I wish that this did not have to happen since it was so discouraging.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Yes, I wish that this did not have to happen since it was so discouraging."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Also, I wish that this did not have to happen since it was so discouraging."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? No, I wish that this did not have to happen since it was so discouraging."}}, "resps": [[["-144.0", "False"]], [["-146.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-146.0", "False"], ["-145.0", "False"]], "doc_hash": "f2eb7acfb4560be0232f51694a197b7ff84435bf588062d8af1da6445be9ac0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 428, "doc": {"premise": "with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns", "hypothesis": "Some friends took turns hosting Mother's Day brunch.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Yes, Some friends took turns hosting Mother's Day brunch."}, "gen_args_1": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? Also, Some friends took turns hosting Mother's Day brunch."}, "gen_args_2": {"arg_0": "", "arg_1": " with the others we've either with some friends done a a sort of Mother's Day out kind of thing where they took turns, right? No, Some friends took turns hosting Mother's Day brunch."}}, "resps": [[["-172.0", "False"]], [["-174.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-174.0", "False"], ["-176.0", "False"]], "doc_hash": "dba6e8077150d31b8394a18e31290dc43f9f2b214d4761943f548b58444e3cb6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 436, "doc": {"premise": "uh-huh all right bye now", "hypothesis": "It was great talking to you and I'll talk to you tomorrow.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Yes, It was great talking to you and I'll talk to you tomorrow."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Also, It was great talking to you and I'll talk to you tomorrow."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? No, It was great talking to you and I'll talk to you tomorrow."}}, "resps": [[["-87.5", "False"]], [["-93.5", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-87.5", "False"], ["-93.5", "False"], ["-89.0", "False"]], "doc_hash": "8e2290276fbd19599e376d73473986f05b6d34f8d55aae60c7ce6930882f182b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.81592096 0.00202247 0.18205657]"]}
{"doc_id": 444, "doc": {"premise": "yeah some special interest group", "hypothesis": "The group is interested in a lot of different topics.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah some special interest group, right? Yes, The group is interested in a lot of different topics."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah some special interest group, right? Also, The group is interested in a lot of different topics."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah some special interest group, right? No, The group is interested in a lot of different topics."}}, "resps": [[["-91.5", "False"]], [["-91.5", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-91.5", "False"], ["-91.5", "False"], ["-88.5", "False"]], "doc_hash": "1f6f6ce5f8a36925a0d8f026b6f62ac0ea6b930b974302fcdca0afaa08e9acca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 452, "doc": {"premise": "Texas only had fifty five thousand when i was there", "hypothesis": "I used to be in Texas.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Yes, I used to be in Texas."}, "gen_args_1": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? Also, I used to be in Texas."}, "gen_args_2": {"arg_0": "", "arg_1": " Texas only had fifty five thousand when i was there, right? No, I used to be in Texas."}}, "resps": [[["-93.5", "False"]], [["-93.5", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-93.5", "False"], ["-93.5", "False"], ["-92.0", "False"]], "doc_hash": "3b992b57debb28c4735289ab83fbec17bdf699a2f2b9dc10b6fae8d2f0d67cf9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.15428077 0.15428077 0.69143845]"]}
{"doc_id": 460, "doc": {"premise": "um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line", "hypothesis": "The alarm company gives you signs to put in each window.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Yes, The alarm company gives you signs to put in each window."}, "gen_args_1": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Also, The alarm company gives you signs to put in each window."}, "gen_args_2": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? No, The alarm company gives you signs to put in each window."}}, "resps": [[["-188.0", "False"]], [["-186.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-186.0", "False"], ["-189.0", "False"]], "doc_hash": "729e1862faf7ed04b320b257174a40eda4c7d6c9c73652472a3b19d9ed82255a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.84379473 0.04201007]"]}
{"doc_id": 468, "doc": {"premise": "um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and", "hypothesis": "I don't own any electronics.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Yes, I don't own any electronics."}, "gen_args_1": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Also, I don't own any electronics."}, "gen_args_2": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? No, I don't own any electronics."}}, "resps": [[["-192.0", "False"]], [["-192.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-192.0", "False"], ["-187.0", "False"]], "doc_hash": "fc5748c92cd82d394682ee53455c3337bd609980b24cb4ddfcb98393cb6e951a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 476, "doc": {"premise": "and uh so i really enjoyed that", "hypothesis": "That was beyond disgusting!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Yes, That was beyond disgusting!"}, "gen_args_1": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? Also, That was beyond disgusting!"}, "gen_args_2": {"arg_0": "", "arg_1": " and uh so i really enjoyed that, right? No, That was beyond disgusting!"}}, "resps": [[["-87.0", "False"]], [["-91.0", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-87.0", "False"], ["-91.0", "False"], ["-87.0", "False"]], "doc_hash": "2f11857c5f0bb959b97ac340ab6f18f696502c1ddfd955aededaad7758594fa8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 484, "doc": {"premise": "well we're definitely keeping them poor and down trodden and helpless", "hypothesis": "We are encouraging them and uplifting them every day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Yes, We are encouraging them and uplifting them every day."}, "gen_args_1": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Also, We are encouraging them and uplifting them every day."}, "gen_args_2": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? No, We are encouraging them and uplifting them every day."}}, "resps": [[["-113.0", "False"]], [["-118.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-113.0", "False"], ["-118.5", "False"], ["-112.5", "False"]], "doc_hash": "51f97e5c56c77be7b6f079acf719f0b5ef30663f65091ad29351f18fd78b8861", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37695905 0.00154055 0.6215004 ]"]}
{"doc_id": 492, "doc": {"premise": "um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there", "hypothesis": "I thought they should cut the food expenditures and not books.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Yes, I thought they should cut the food expenditures and not books."}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Also, I thought they should cut the food expenditures and not books."}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? No, I thought they should cut the food expenditures and not books."}}, "resps": [[["-188.0", "False"]], [["-194.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-194.0", "False"], ["-189.0", "False"]], "doc_hash": "f709a90cec074916ad8abb7e7c006ee7d79928d3d9d14f3f6823d0be7e63ed7e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 500, "doc": {"premise": "Espinosa collected many romances from Californios in the 1920s.", "hypothesis": "Esponosa died in 1900.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Yes, Esponosa died in 1900."}, "gen_args_1": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? Also, Esponosa died in 1900."}, "gen_args_2": {"arg_0": "", "arg_1": " Espinosa collected many romances from Californios in the 1920s., right? No, Esponosa died in 1900."}}, "resps": [[["-143.0", "False"]], [["-140.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-140.0", "False"], ["-141.0", "False"]], "doc_hash": "a9c73113bd9628d42c8d14fe417d98c387b1ad03b6c07cd1d30456eb6d37d8e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.03511903 0.70538451 0.25949646]"]}
{"doc_id": 508, "doc": {"premise": "The law redeems not the individual but the community or the nation as a whole.", "hypothesis": "The law will redeem America.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Yes, The law will redeem America."}, "gen_args_1": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Also, The law will redeem America."}, "gen_args_2": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? No, The law will redeem America."}}, "resps": [[["-109.5", "False"]], [["-112.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-109.5", "False"], ["-112.0", "False"], ["-109.5", "False"]], "doc_hash": "3fe48490978fba45ea827615deb2fefdb9fe62942ac93a75063182567502e75e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48028779 0.03942442 0.48028779]"]}
{"doc_id": 516, "doc": {"premise": "Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light).", "hypothesis": "Most than one hundred officers served in each chapter.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Yes, Most than one hundred officers served in each chapter."}, "gen_args_1": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Also, Most than one hundred officers served in each chapter."}, "gen_args_2": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? No, Most than one hundred officers served in each chapter."}}, "resps": [[["-268.0", "False"]], [["-266.0", "False"]], [["-268.0", "False"]]], "filtered_resps": [["-268.0", "False"], ["-266.0", "False"], ["-268.0", "False"]], "doc_hash": "389da7885e07b38d726c77082be3ea16a2cd8d89eae71fc6e9c0432ebd275189", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 524, "doc": {"premise": "Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network.", "hypothesis": "Convergent flow prevents classification.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Yes, Convergent flow prevents classification."}, "gen_args_1": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? Also, Convergent flow prevents classification."}, "gen_args_2": {"arg_0": "", "arg_1": " Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as  equivalent  by the network., right? No, Convergent flow prevents classification."}}, "resps": [[["-215.0", "False"]], [["-216.0", "False"]], [["-213.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-216.0", "False"], ["-213.0", "False"]], "doc_hash": "d38d0dc447a9304ee90e258af3ce0615ef3c5872269306f140731f59b2cfb614", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 532, "doc": {"premise": "And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens.", "hypothesis": "The private persons were white.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Yes, The private persons were white."}, "gen_args_1": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Also, The private persons were white."}, "gen_args_2": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? No, The private persons were white."}}, "resps": [[["-153.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "8f573d1a12ea0f55ff42224d78581d632e2094d988ac72cbc63faebb580b586c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 540, "doc": {"premise": "Darwin starts with life already here.", "hypothesis": "Darwin started by focusing on fish.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Yes, Darwin started by focusing on fish."}, "gen_args_1": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Also, Darwin started by focusing on fish."}, "gen_args_2": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? No, Darwin started by focusing on fish."}}, "resps": [[["-97.0", "False"]], [["-97.0", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-97.0", "False"], ["-97.0", "False"], ["-96.5", "False"]], "doc_hash": "dcf7fcb46a021fa42cce9ef698e101760f69429c8482caf8e8cddefc5e199bb8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.27406862 0.27406862 0.45186276]"]}
{"doc_id": 548, "doc": {"premise": "When civil society turns a deaf ear, crazy ideas lose their edge.", "hypothesis": "Most crazy ideas are ignored by civil society.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Yes, Most crazy ideas are ignored by civil society."}, "gen_args_1": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? Also, Most crazy ideas are ignored by civil society."}, "gen_args_2": {"arg_0": "", "arg_1": " When civil society turns a deaf ear, crazy ideas lose their edge., right? No, Most crazy ideas are ignored by civil society."}}, "resps": [[["-117.0", "False"]], [["-123.5", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-123.5", "False"], ["-118.0", "False"]], "doc_hash": "190e130dc9f7554d12d851c3fdd7ee56539e8f9388f858e8460cfaff2d548ed6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.73025595 0.0010979  0.26864615]"]}
{"doc_id": 556, "doc": {"premise": "Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves.", "hypothesis": "Palomillas consisted solely of several old women who told sad stories about frying pans.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Yes, Palomillas consisted solely of several old women who told sad stories about frying pans."}, "gen_args_1": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Also, Palomillas consisted solely of several old women who told sad stories about frying pans."}, "gen_args_2": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? No, Palomillas consisted solely of several old women who told sad stories about frying pans."}}, "resps": [[["-247.0", "False"]], [["-249.0", "False"]], [["-244.0", "False"]]], "filtered_resps": [["-247.0", "False"], ["-249.0", "False"], ["-244.0", "False"]], "doc_hash": "6d7a513b310b92a9a6229ed500cbe136788bf7f4bc773e0ef0163936b157a379", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 564, "doc": {"premise": "Bato is a word centuries old that can be translated as  guy  or  dude.", "hypothesis": "Vato is the preferred spelling.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Yes, Vato is the preferred spelling."}, "gen_args_1": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Also, Vato is the preferred spelling."}, "gen_args_2": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? No, Vato is the preferred spelling."}}, "resps": [[["-141.0", "False"]], [["-143.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-143.0", "False"], ["-140.0", "False"]], "doc_hash": "eb4c7d50567f24f17237f42e23df969913ca65208ad99d24d3d96c0a9f249be1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 572, "doc": {"premise": "As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table.", "hypothesis": "The sand is scooped by a bulldozer.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Yes, The sand is scooped by a bulldozer."}, "gen_args_1": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? Also, The sand is scooped by a bulldozer."}, "gen_args_2": {"arg_0": "", "arg_1": " As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table., right? No, The sand is scooped by a bulldozer."}}, "resps": [[["-165.0", "False"]], [["-166.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-166.0", "False"], ["-164.0", "False"]], "doc_hash": "e0e5d7ab8a00eca952aadb289f989fd7bc3afa66d1d8b23b997ce269be71b078", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 580, "doc": {"premise": "Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges.", "hypothesis": "No one was interested in actual trading on stock exchanges.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Yes, No one was interested in actual trading on stock exchanges."}, "gen_args_1": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Also, No one was interested in actual trading on stock exchanges."}, "gen_args_2": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? No, No one was interested in actual trading on stock exchanges."}}, "resps": [[["-133.0", "False"]], [["-133.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-133.0", "False"], ["-127.0", "False"]], "doc_hash": "b74a12ae924d3ae67e17e685c4ba960888c49bc56a66a511d3cd062b198eb287", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 588, "doc": {"premise": "The end of plantation capitalism might have come as safely as the demise of communism in Europe.", "hypothesis": "Plantation capitalism has ended.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Yes, Plantation capitalism has ended."}, "gen_args_1": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Also, Plantation capitalism has ended."}, "gen_args_2": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? No, Plantation capitalism has ended."}}, "resps": [[["-123.0", "False"]], [["-131.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-123.0", "False"], ["-131.0", "False"], ["-127.5", "False"]], "doc_hash": "294f403e95f7cba6bd202199ed24c0394529caf69bab6d7d73cd521e0b97fef1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.88685034e-01 3.31666880e-04 1.09832986e-02]"]}
{"doc_id": 596, "doc": {"premise": "Your heart happened to be preadapted to pick up earthquake pretremors.", "hypothesis": "Your heart cannot pick up earthquake pretremors.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Yes, Your heart cannot pick up earthquake pretremors."}, "gen_args_1": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? Also, Your heart cannot pick up earthquake pretremors."}, "gen_args_2": {"arg_0": "", "arg_1": " Your heart happened to be preadapted to pick up earthquake pretremors., right? No, Your heart cannot pick up earthquake pretremors."}}, "resps": [[["-144.0", "False"]], [["-147.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-147.0", "False"], ["-137.0", "False"]], "doc_hash": "e1f7d2458bb13adc76d973a22e01d89f0e9b71939c70f0cd2062ec2f6495cd70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11009872e-04 4.53565108e-05 9.99043634e-01]"]}
{"doc_id": 604, "doc": {"premise": "Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking.", "hypothesis": "The term barbacoa was first used in ancient Egypt.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Yes, The term barbacoa was first used in ancient Egypt."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Also, The term barbacoa was first used in ancient Egypt."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? No, The term barbacoa was first used in ancient Egypt."}}, "resps": [[["-126.5", "False"]], [["-128.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-126.5", "False"], ["-128.0", "False"], ["-124.5", "False"]], "doc_hash": "3adc97c3834abab7c66fca083d51133ca370c877e676c38237d1c164d2446575", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11611453 0.02590865 0.85797681]"]}
{"doc_id": 612, "doc": {"premise": "The problem of exploitation in apparently voluntary sexual relations has long been with us.", "hypothesis": "The problem of exploitation is getting better.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Yes, The problem of exploitation is getting better."}, "gen_args_1": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Also, The problem of exploitation is getting better."}, "gen_args_2": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? No, The problem of exploitation is getting better."}}, "resps": [[["-118.5", "False"]], [["-120.5", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-118.5", "False"], ["-120.5", "False"], ["-115.0", "False"]], "doc_hash": "91db5365609ce4d7be1456561c0612da90c0f5b4b1c7ba0af9df5ba89b41e35e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.02919641 0.0039513  0.96685229]"]}
{"doc_id": 620, "doc": {"premise": "The vaquero or buckaroo is a westerner and the cowboy is a southerner.", "hypothesis": "The cowboy is from the southern US.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Yes, The cowboy is from the southern US."}, "gen_args_1": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? Also, The cowboy is from the southern US."}, "gen_args_2": {"arg_0": "", "arg_1": " The vaquero or buckaroo is a westerner and the cowboy is a southerner., right? No, The cowboy is from the southern US."}}, "resps": [[["-106.0", "False"]], [["-111.0", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-111.0", "False"], ["-107.0", "False"]], "doc_hash": "7e11d4a34fdab4d35111795e1cb56309c6b47b6a18019522351182be42ce4fa5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 628, "doc": {"premise": "It would get really big, take us from our beds and never bring us back home  (November 1974).", "hypothesis": "It was scary when it got really big.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Yes, It was scary when it got really big."}, "gen_args_1": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Also, It was scary when it got really big."}, "gen_args_2": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? No, It was scary when it got really big."}}, "resps": [[["-159.0", "False"]], [["-160.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-160.0", "False"], ["-160.0", "False"]], "doc_hash": "e678910960ffd2f55d39ebfd5cf308c8e27a6878c818a1a9f2c34f5126bdd530", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 636, "doc": {"premise": "Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all.", "hypothesis": "New laws are original.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Yes, New laws are original."}, "gen_args_1": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Also, New laws are original."}, "gen_args_2": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? No, New laws are original."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-147.0", "False"]], "doc_hash": "b5b6c557620c86d4b44df6971a869e4e2220ad6d515f635a77e088083e367d86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 644, "doc": {"premise": "for in the image of God he made Adam.", "hypothesis": "Eve made Adam using her own beautiful image.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Yes, Eve made Adam using her own beautiful image."}, "gen_args_1": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? Also, Eve made Adam using her own beautiful image."}, "gen_args_2": {"arg_0": "", "arg_1": " for in the image of God he made Adam., right? No, Eve made Adam using her own beautiful image."}}, "resps": [[["-109.0", "False"]], [["-110.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-110.5", "False"], ["-106.0", "False"]], "doc_hash": "e57e0036064cd59d24de7ef8cae5509e063f1986ba7974cbe2f545538074a6bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04692926 0.01047133 0.94259941]"]}
{"doc_id": 652, "doc": {"premise": "22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s.", "hypothesis": "There are not enough inspectors to monitor violations in apparel workplaces.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Yes, There are not enough inspectors to monitor violations in apparel workplaces."}, "gen_args_1": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Also, There are not enough inspectors to monitor violations in apparel workplaces."}, "gen_args_2": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? No, There are not enough inspectors to monitor violations in apparel workplaces."}}, "resps": [[["-218.0", "False"]], [["-219.0", "False"]], [["-219.0", "False"]]], "filtered_resps": [["-218.0", "False"], ["-219.0", "False"], ["-219.0", "False"]], "doc_hash": "3e58ce293ab2f4028904c6fc20b30b3f416168342ac38d100d715897887d33c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 660, "doc": {"premise": "Of course, if we could not solve our chosen ways to make livings, we would be dead.", "hypothesis": "Figuring how to make a living is not a piece of cake.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Yes, Figuring how to make a living is not a piece of cake."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Also, Figuring how to make a living is not a piece of cake."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? No, Figuring how to make a living is not a piece of cake."}}, "resps": [[["-142.0", "False"]], [["-144.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-144.0", "False"], ["-143.0", "False"]], "doc_hash": "6a6254ed6f6a69cd370fc36d46ae29f483095e0b9d8646c7b322365448d8282f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 668, "doc": {"premise": "Economic growth is part and parcel of the creativity of the universe as a whole.", "hypothesis": "One cannot separate economic growth from the universe.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Yes, One cannot separate economic growth from the universe."}, "gen_args_1": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? Also, One cannot separate economic growth from the universe."}, "gen_args_2": {"arg_0": "", "arg_1": " Economic growth is part and parcel of the creativity of the universe as a whole., right? No, One cannot separate economic growth from the universe."}}, "resps": [[["-111.0", "False"]], [["-117.0", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-111.0", "False"], ["-117.0", "False"], ["-114.0", "False"]], "doc_hash": "29b84491d89fd081dd17dea4060c39e5ca0786540f38492858abf33a42a71bf0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 676, "doc": {"premise": "We are literally making our world together, we critters.", "hypothesis": "Living beings make up the world as do plants and trees. But we can change out the effects we cause.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Yes, Living beings make up the world as do plants and trees. But we can change out the effects we cause."}, "gen_args_1": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Also, Living beings make up the world as do plants and trees. But we can change out the effects we cause."}, "gen_args_2": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? No, Living beings make up the world as do plants and trees. But we can change out the effects we cause."}}, "resps": [[["-181.0", "False"]], [["-187.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-187.0", "False"], ["-182.0", "False"]], "doc_hash": "e86fab831926082d675a545e3d70a158d6c63aca05e07b9bb3cc64c2d0908ed5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 684, "doc": {"premise": "As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable.", "hypothesis": "It looks as though something profound in going on in the universe.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Yes, It looks as though something profound in going on in the universe."}, "gen_args_1": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Also, It looks as though something profound in going on in the universe."}, "gen_args_2": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? No, It looks as though something profound in going on in the universe."}}, "resps": [[["-165.0", "False"]], [["-172.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-172.0", "False"], ["-167.0", "False"]], "doc_hash": "e9981f86a67256197d5f3e4923beccfb219dcbb34139c44e7ed0be0bdb8f8423", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 692, "doc": {"premise": "In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness.", "hypothesis": "There are no factors that help evolving populations reach higher fitness levels.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Yes, There are no factors that help evolving populations reach higher fitness levels."}, "gen_args_1": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? Also, There are no factors that help evolving populations reach higher fitness levels."}, "gen_args_2": {"arg_0": "", "arg_1": " In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness., right? No, There are no factors that help evolving populations reach higher fitness levels."}}, "resps": [[["-201.0", "False"]], [["-203.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-203.0", "False"], ["-196.0", "False"]], "doc_hash": "0ecefe79d2826f3013a4cf09b805631196d4bf650f916c74e87a442a3b9aa4d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 700, "doc": {"premise": "This is not to say that good architecture is merely utilitarian.", "hypothesis": "That does not conclude that good architecture is only designed for functionality.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Yes, That does not conclude that good architecture is only designed for functionality."}, "gen_args_1": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Also, That does not conclude that good architecture is only designed for functionality."}, "gen_args_2": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? No, That does not conclude that good architecture is only designed for functionality."}}, "resps": [[["-113.0", "False"]], [["-116.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-113.0", "False"], ["-116.5", "False"], ["-109.5", "False"]], "doc_hash": "a305dce418b2d0a9ffb7a42e22415670d383087ce8547ae927533e13edb83aa9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.92863079e-02 8.84369869e-04 9.69829322e-01]"]}
{"doc_id": 708, "doc": {"premise": "Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship.", "hypothesis": "Lipstadt was a cook.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Yes, Lipstadt was a cook."}, "gen_args_1": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Also, Lipstadt was a cook."}, "gen_args_2": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? No, Lipstadt was a cook."}}, "resps": [[["-198.0", "False"]], [["-199.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-198.0", "False"], ["-199.0", "False"], ["-194.0", "False"]], "doc_hash": "ebc8fd30ef28c6efa8e14b962cd8c92032f070903993d44dcb61459529c66817", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 716, "doc": {"premise": "Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book.", "hypothesis": "This parenting book is on the New York Times bestseller's list.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Yes, This parenting book is on the New York Times bestseller's list."}, "gen_args_1": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? Also, This parenting book is on the New York Times bestseller's list."}, "gen_args_2": {"arg_0": "", "arg_1": " Fashioning time for parents and children to be together is the  rst step toward implementing the ideas and practices I'll discuss in this book., right? No, This parenting book is on the New York Times bestseller's list."}}, "resps": [[["-188.0", "False"]], [["-188.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-188.0", "False"], ["-188.0", "False"]], "doc_hash": "55f8ea63020e3fab6f0141e817f08bffd3f473b2603ad98ae1cedc0938c75d2a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 724, "doc": {"premise": "Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment.", "hypothesis": "Relajo makes jokes about the economy.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Yes, Relajo makes jokes about the economy."}, "gen_args_1": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Also, Relajo makes jokes about the economy."}, "gen_args_2": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? No, Relajo makes jokes about the economy."}}, "resps": [[["-200.0", "False"]], [["-200.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-200.0", "False"], ["-200.0", "False"]], "doc_hash": "03a1832e8b26fb92e1a775817f4fbfb61eecb9e75d5356728409763f24018e44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 732, "doc": {"premise": "See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico.", "hypothesis": "Ancient moradas can be found in the northern part of New Mexico.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Yes, Ancient moradas can be found in the northern part of New Mexico."}, "gen_args_1": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Also, Ancient moradas can be found in the northern part of New Mexico."}, "gen_args_2": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? No, Ancient moradas can be found in the northern part of New Mexico."}}, "resps": [[["-173.0", "False"]], [["-178.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-178.0", "False"], ["-180.0", "False"]], "doc_hash": "f514faa627a9c506301cb11e8139ef46e900fa4bb880a9ddfe6451064b256fef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 6.68679417e-03 9.04959183e-04]"]}
{"doc_id": 740, "doc": {"premise": "The disputes took on the tones of class struggle.", "hypothesis": "They fought about the weather.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Yes, They fought about the weather."}, "gen_args_1": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? Also, They fought about the weather."}, "gen_args_2": {"arg_0": "", "arg_1": " The disputes took on the tones of class struggle., right? No, They fought about the weather."}}, "resps": [[["-108.5", "False"]], [["-111.5", "False"]], [["-102.5", "False"]]], "filtered_resps": [["-108.5", "False"], ["-111.5", "False"], ["-102.5", "False"]], "doc_hash": "5fb8e1dce5c7410c06230097681b70266af53c1de401df629438e51c6a43ff86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47231880e-03 1.23089505e-04 9.97404592e-01]"]}
{"doc_id": 748, "doc": {"premise": "He turned in appeal to Lord Julian.", "hypothesis": "He wanted to ask Lord Julian to spare his wife.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Yes, He wanted to ask Lord Julian to spare his wife."}, "gen_args_1": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Also, He wanted to ask Lord Julian to spare his wife."}, "gen_args_2": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? No, He wanted to ask Lord Julian to spare his wife."}}, "resps": [[["-110.5", "False"]], [["-115.5", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-115.5", "False"], ["-114.5", "False"]], "doc_hash": "2afda9517b9288aaea74ed855094f9a0a80fe99926b56a2ff3179643a276355b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 756, "doc": {"premise": "The Colonel accepted it, and belatedly bowed, removing his broad hat.", "hypothesis": "The Colonel accepted a medal from the mayor of New York City.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Yes, The Colonel accepted a medal from the mayor of New York City."}, "gen_args_1": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Also, The Colonel accepted a medal from the mayor of New York City."}, "gen_args_2": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? No, The Colonel accepted a medal from the mayor of New York City."}}, "resps": [[["-136.0", "False"]], [["-139.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-139.0", "False"], ["-137.0", "False"]], "doc_hash": "93e44ab0f26f46e3ae1dc9e192a2ac7961a32fb4f39558d6aad68faa25afb0d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 764, "doc": {"premise": "He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted.", "hypothesis": "She is infatuated with Lord Julian Wade, despite his bumbling nature.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Yes, She is infatuated with Lord Julian Wade, despite his bumbling nature."}, "gen_args_1": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? Also, She is infatuated with Lord Julian Wade, despite his bumbling nature."}, "gen_args_2": {"arg_0": "", "arg_1": " He was allowed plainly to perceive that it was the graceful, elegant young trifler from St. James's, Lord Julian Wade, to whom her every moment was devoted., right? No, She is infatuated with Lord Julian Wade, despite his bumbling nature."}}, "resps": [[["-224.0", "False"]], [["-225.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-225.0", "False"], ["-224.0", "False"]], "doc_hash": "3879e5f25029e6c5a62426459191a6d678edd861e88958d1a3612e9ffcf876c2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 772, "doc": {"premise": "Mary Traill would tell you of it.", "hypothesis": "Mary Traill knows about it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Yes, Mary Traill knows about it."}, "gen_args_1": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Also, Mary Traill knows about it."}, "gen_args_2": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? No, Mary Traill knows about it."}}, "resps": [[["-91.5", "False"]], [["-96.5", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-96.5", "False"], ["-93.0", "False"]], "doc_hash": "49e53e5d0ec1bc549c0a7b3854b01f0664ab890be9373ef2a0cb858a32f3c19c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81309532 0.00547859 0.18142609]"]}
{"doc_id": 780, "doc": {"premise": "Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden.", "hypothesis": "Blood had a hat that he wore before sitting down.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Yes, Blood had a hat that he wore before sitting down."}, "gen_args_1": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Also, Blood had a hat that he wore before sitting down."}, "gen_args_2": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? No, Blood had a hat that he wore before sitting down."}}, "resps": [[["-208.0", "False"]], [["-210.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-208.0", "False"], ["-210.0", "False"], ["-209.0", "False"]], "doc_hash": "ad015e03961acbe8ee97a3b7aa7b4deba2c5b49def767f7f5452ba1a6e100b6a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 788, "doc": {"premise": "They are within range,  cried Ogle.", "hypothesis": "Though he knew that they were within range, Ogle kept it to himself.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Yes, Though he knew that they were within range, Ogle kept it to himself."}, "gen_args_1": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? Also, Though he knew that they were within range, Ogle kept it to himself."}, "gen_args_2": {"arg_0": "", "arg_1": " They are within range,  cried Ogle., right? No, Though he knew that they were within range, Ogle kept it to himself."}}, "resps": [[["-135.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "0fb827281d357c13695ad493d2b7c918c2fa090638310fcc892c78e4832388dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 796, "doc": {"premise": "You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him.", "hypothesis": "Ogle let him continue to speak.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Yes, Ogle let him continue to speak."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Also, Ogle let him continue to speak."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? No, Ogle let him continue to speak."}}, "resps": [[["-200.0", "False"]], [["-204.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-204.0", "False"], ["-197.0", "False"]], "doc_hash": "98d6ef1a3af6e24011cc5f998357ab993738e639d6a50f20352d82c2e24de53f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 804, "doc": {"premise": "A murderer--I?  he said at last.", "hypothesis": "After a pause he said a murderer, I.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Yes, After a pause he said a murderer, I."}, "gen_args_1": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Also, After a pause he said a murderer, I."}, "gen_args_2": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? No, After a pause he said a murderer, I."}}, "resps": [[["-126.5", "False"]], [["-134.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-134.0", "False"], ["-127.0", "False"]], "doc_hash": "270b98656c4ecbe471e114132dff466ffc34b15abf376e6dfc64442205fc150a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22245109e-01 3.44154044e-04 3.77410737e-01]"]}
{"doc_id": 812, "doc": {"premise": "It was she now who was on her defence, her voice quivering with indignation.", "hypothesis": "The woman was so delighted that she was speechless!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Yes, The woman was so delighted that she was speechless!"}, "gen_args_1": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? Also, The woman was so delighted that she was speechless!"}, "gen_args_2": {"arg_0": "", "arg_1": " It was she now who was on her defence, her voice quivering with indignation., right? No, The woman was so delighted that she was speechless!"}}, "resps": [[["-134.0", "False"]], [["-138.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-138.0", "False"], ["-134.0", "False"]], "doc_hash": "1603cbb416a88dddb5d9c7bb612037814022ea9c73993608073a112e81e390d9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 820, "doc": {"premise": "Life can be infernally complex,  he sighed.", "hypothesis": "He remained silent as he complained about the simplicity of life.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Yes, He remained silent as he complained about the simplicity of life."}, "gen_args_1": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Also, He remained silent as he complained about the simplicity of life."}, "gen_args_2": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? No, He remained silent as he complained about the simplicity of life."}}, "resps": [[["-130.0", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "4a415c893dad77bcc465b3ddb132f19007c979e4b2bfb6af3fe07f4498981c83", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 828, "doc": {"premise": "And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him.", "hypothesis": "He has his own officers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Yes, He has his own officers."}, "gen_args_1": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Also, He has his own officers."}, "gen_args_2": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? No, He has his own officers."}}, "resps": [[["-140.0", "False"]], [["-144.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-144.0", "False"], ["-142.0", "False"]], "doc_hash": "f77d00803d95002f0658173433f39d9d707ed219a2155b681c7b9ca079fbffbd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 836, "doc": {"premise": "It is an honourable service.", "hypothesis": "It isn't an honorable service at all, it's very embarrassing!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is an honourable service., right? Yes, It isn't an honorable service at all, it's very embarrassing!"}, "gen_args_1": {"arg_0": "", "arg_1": " It is an honourable service., right? Also, It isn't an honorable service at all, it's very embarrassing!"}, "gen_args_2": {"arg_0": "", "arg_1": " It is an honourable service., right? No, It isn't an honorable service at all, it's very embarrassing!"}}, "resps": [[["-97.0", "False"]], [["-104.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-104.5", "False"], ["-95.0", "False"]], "doc_hash": "40fd793e53c694815c42ccbcd28043a5318b51c37213cfbcdb2b11b85068a245", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19195064e-01 6.59249267e-05 8.80739011e-01]"]}
{"doc_id": 844, "doc": {"premise": "He looked up in surprise, and then sat conning her with brooding glance.", "hypothesis": "He was surprised by her.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Yes, He was surprised by her."}, "gen_args_1": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Also, He was surprised by her."}, "gen_args_2": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? No, He was surprised by her."}}, "resps": [[["-129.0", "False"]], [["-132.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-132.0", "False"], ["-128.0", "False"]], "doc_hash": "4de3d6c096d46b86954fea19b24b676323f11bae47300cd2c04c61942a889182", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 852, "doc": {"premise": "If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke.", "hypothesis": "The man was the captain of one of the ships.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Yes, The man was the captain of one of the ships."}, "gen_args_1": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Also, The man was the captain of one of the ships."}, "gen_args_2": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? No, The man was the captain of one of the ships."}}, "resps": [[["-188.0", "False"]], [["-192.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-192.0", "False"], ["-189.0", "False"]], "doc_hash": "b81a9adbfc79506ad3321ede142ea5016fc60ba33b76d1143b1f2497f6f222a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 860, "doc": {"premise": "Believe me, I am very grateful.", "hypothesis": "One is certainly grateful.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Yes, One is certainly grateful."}, "gen_args_1": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? Also, One is certainly grateful."}, "gen_args_2": {"arg_0": "", "arg_1": " Believe me, I am very grateful., right? No, One is certainly grateful."}}, "resps": [[["-79.5", "False"]], [["-87.5", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-79.5", "False"], ["-87.5", "False"], ["-84.5", "False"]], "doc_hash": "4de8e5127c64e7a130d27a5f3c832307e90d7a9738cd2d976c7ba4e56e5f34eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92976272e-01 3.33106430e-04 6.69062149e-03]"]}
{"doc_id": 868, "doc": {"premise": "Blood broke the seal, and read.", "hypothesis": "The seal remained unbroken.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Yes, The seal remained unbroken."}, "gen_args_1": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Also, The seal remained unbroken."}, "gen_args_2": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? No, The seal remained unbroken."}}, "resps": [[["-100.0", "False"]], [["-101.5", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-101.5", "False"], ["-96.5", "False"]], "doc_hash": "8bff6ac4a33cf688dbad7dbdd72b2b214e6963816d4ca65740cb1822f990e2f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02912176 0.00649794 0.9643803 ]"]}
{"doc_id": 876, "doc": {"premise": "Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing.", "hypothesis": "She quickly fled the scene in order to avoid further scrutiny.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Yes, She quickly fled the scene in order to avoid further scrutiny."}, "gen_args_1": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Also, She quickly fled the scene in order to avoid further scrutiny."}, "gen_args_2": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? No, She quickly fled the scene in order to avoid further scrutiny."}}, "resps": [[["-164.0", "False"]], [["-166.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-166.0", "False"], ["-166.0", "False"]], "doc_hash": "0dcbea5d705e559e1666dfda8b98551e3ae337658928b5415431070567641f56", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 884, "doc": {"premise": "Colder still and more distant than ever grew his lordship's voice.", "hypothesis": "The Lord's voice felt both distant and chilling", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Yes, The Lord's voice felt both distant and chilling"}, "gen_args_1": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? Also, The Lord's voice felt both distant and chilling"}, "gen_args_2": {"arg_0": "", "arg_1": " Colder still and more distant than ever grew his lordship's voice., right? No, The Lord's voice felt both distant and chilling"}}, "resps": [[["-134.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "198a5d709d0a058eb15c943ff5788f7e515bdfab73a99d1643f1793e35dc59ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 892, "doc": {"premise": "No.  Blood closed his telescope.", "hypothesis": "There was blood around the telescope.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Yes, There was blood around the telescope."}, "gen_args_1": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Also, There was blood around the telescope."}, "gen_args_2": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? No, There was blood around the telescope."}}, "resps": [[["-113.0", "False"]], [["-120.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-113.0", "False"], ["-120.5", "False"], ["-112.5", "False"]], "doc_hash": "ef81288ab0a83cdf3fb62c296dee81cb0d99544b3bab2464c67f8d59ef48a34f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[3.77461850e-01 2.08768250e-04 6.22329381e-01]"]}
{"doc_id": 900, "doc": {"premise": "Since when have you commanded on the main deck, Ogle? I take my orders from the Captain.", "hypothesis": "Ogle had attempted to give orders as though he were the Captain.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Yes, Ogle had attempted to give orders as though he were the Captain."}, "gen_args_1": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Also, Ogle had attempted to give orders as though he were the Captain."}, "gen_args_2": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? No, Ogle had attempted to give orders as though he were the Captain."}}, "resps": [[["-154.0", "False"]], [["-157.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-157.0", "False"], ["-153.0", "False"]], "doc_hash": "18b23573b11af3d86e2d55744cc921688f7299dc02119ff58746d94046f66ff6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 908, "doc": {"premise": "But Wolverstone would not stop.", "hypothesis": "The Wolverstone was part of an elaborate ploy.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Yes, The Wolverstone was part of an elaborate ploy."}, "gen_args_1": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? Also, The Wolverstone was part of an elaborate ploy."}, "gen_args_2": {"arg_0": "", "arg_1": " But Wolverstone would not stop., right? No, The Wolverstone was part of an elaborate ploy."}}, "resps": [[["-106.0", "False"]], [["-111.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-111.5", "False"], ["-105.0", "False"]], "doc_hash": "1bb1d801acf7f0ea0fa3f0e8856a8008c5997ad14d0c3666171e5b01e323271b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26864615 0.0010979  0.73025595]"]}
{"doc_id": 916, "doc": {"premise": "Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged.", "hypothesis": "He told them that he could see it but it was not a big deal in the end.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Yes, He told them that he could see it but it was not a big deal in the end."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Also, He told them that he could see it but it was not a big deal in the end."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? No, He told them that he could see it but it was not a big deal in the end."}}, "resps": [[["-224.0", "False"]], [["-225.0", "False"]], [["-225.0", "False"]]], "filtered_resps": [["-224.0", "False"], ["-225.0", "False"], ["-225.0", "False"]], "doc_hash": "53554df6c72db87ab4e35e90852488068db62ed6d73fce6a7e40957c87243301", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 924, "doc": {"premise": "Your words have rankled with him.", "hypothesis": "He did not like what you said.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Yes, He did not like what you said."}, "gen_args_1": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Also, He did not like what you said."}, "gen_args_2": {"arg_0": "", "arg_1": " Your words have rankled with him., right? No, He did not like what you said."}}, "resps": [[["-86.0", "False"]], [["-92.5", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-86.0", "False"], ["-92.5", "False"], ["-88.5", "False"]], "doc_hash": "2fc73f64c9916626981fb6cfabc03c65bc0c35c2afc43e4ee6f223a0f87c4a9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92285961 0.00138746 0.07575293]"]}
{"doc_id": 932, "doc": {"premise": "But I suspect this gravity for a mask under which Lord Julian was secretly amused.", "hypothesis": "Julian was being clear about his feelings.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Yes, Julian was being clear about his feelings."}, "gen_args_1": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? Also, Julian was being clear about his feelings."}, "gen_args_2": {"arg_0": "", "arg_1": " But I suspect this gravity for a mask under which Lord Julian was secretly amused., right? No, Julian was being clear about his feelings."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-158.0", "False"]], "doc_hash": "814ec30dd10df45e561ad23a1d797316e40d4ef7c68a558092d5ff0bcc693bcd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 940, "doc": {"premise": "Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle.", "hypothesis": "Some people believed the tale that the princess had been eaten by a dragon.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Yes, Some people believed the tale that the princess had been eaten by a dragon."}, "gen_args_1": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Also, Some people believed the tale that the princess had been eaten by a dragon."}, "gen_args_2": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? No, Some people believed the tale that the princess had been eaten by a dragon."}}, "resps": [[["-254.0", "False"]], [["-254.0", "False"]], [["-255.0", "False"]]], "filtered_resps": [["-254.0", "False"], ["-254.0", "False"], ["-255.0", "False"]], "doc_hash": "79de8eb45c5e962ce4af4139f9a39e24ed73465be0f9a248679e31d1510ef47e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 948, "doc": {"premise": "Good-day to you, sir,  Blood hailed him pleasantly.", "hypothesis": "Blood said nothing to the man he encountered.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Yes, Blood said nothing to the man he encountered."}, "gen_args_1": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Also, Blood said nothing to the man he encountered."}, "gen_args_2": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? No, Blood said nothing to the man he encountered."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-129.0", "False"]], "doc_hash": "6c01a2e0a2c8b0b05bdb62b624ef17268679c256862a87be37ff6774a4f02822", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 956, "doc": {"premise": "So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import.", "hypothesis": "There was some remorse when the Deputy-Governor had waved hello.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Yes, There was some remorse when the Deputy-Governor had waved hello."}, "gen_args_1": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? Also, There was some remorse when the Deputy-Governor had waved hello."}, "gen_args_2": {"arg_0": "", "arg_1": " So ye've come,  the Deputy-Governor hailed him, and followed the greeting by a series of grunts of vague but apparently ill-humoured import., right? No, There was some remorse when the Deputy-Governor had waved hello."}}, "resps": [[["-235.0", "False"]], [["-237.0", "False"]], [["-235.0", "False"]]], "filtered_resps": [["-235.0", "False"], ["-237.0", "False"], ["-235.0", "False"]], "doc_hash": "2de563156301aa2f96bcf133ab8518dfb5b790dad59f07157c24027782968e7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 964, "doc": {"premise": "What I think of you can be a very little matter to you, sir.   This was a disarming stroke.", "hypothesis": "You might care what I think about you.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Yes, You might care what I think about you."}, "gen_args_1": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Also, You might care what I think about you."}, "gen_args_2": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? No, You might care what I think about you."}}, "resps": [[["-159.0", "False"]], [["-161.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-161.0", "False"], ["-160.0", "False"]], "doc_hash": "93b35f700a45e79c013487610ebf2c9e49febd8b6bd0629441ce86c181394fd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 972, "doc": {"premise": "I cannot think why you should trouble to put yourself on your defence,   she discouraged him.", "hypothesis": "Encouraging this, she had found many reasons as to why one would trouble themselves to defend you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Yes, Encouraging this, she had found many reasons as to why one would trouble themselves to defend you."}, "gen_args_1": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Also, Encouraging this, she had found many reasons as to why one would trouble themselves to defend you."}, "gen_args_2": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? No, Encouraging this, she had found many reasons as to why one would trouble themselves to defend you."}}, "resps": [[["-203.0", "False"]], [["-208.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-208.0", "False"], ["-207.0", "False"]], "doc_hash": "22aaa9e9be325540c70cceb35166d1a30047ce7e24c9bfc7dcfb60b20103e54c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 980, "doc": {"premise": "You'll not go?  he said, between question and assertion.", "hypothesis": "Why are you not leaving right now? He grunted.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Yes, Why are you not leaving right now? He grunted."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? Also, Why are you not leaving right now? He grunted."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll not go?  he said, between question and assertion., right? No, Why are you not leaving right now? He grunted."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-134.0", "False"]], "doc_hash": "f839324ff887c631e99b9785af36fd1ea272e242db63704ff42bc643eb590589", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 988, "doc": {"premise": "See it manned for me.", "hypothesis": "See that no one mans it for me.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See it manned for me., right? Yes, See that no one mans it for me."}, "gen_args_1": {"arg_0": "", "arg_1": " See it manned for me., right? Also, See that no one mans it for me."}, "gen_args_2": {"arg_0": "", "arg_1": " See it manned for me., right? No, See that no one mans it for me."}}, "resps": [[["-94.5", "False"]], [["-99.0", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-94.5", "False"], ["-99.0", "False"], ["-93.0", "False"]], "doc_hash": "cfeb3155cdb4fce2eacea7db48baa4e19bfd8e9661c10d904d810e2eb59f95c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18205657 0.00202247 0.81592096]"]}
{"doc_id": 996, "doc": {"premise": "After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex.", "hypothesis": "You can see boats at the top of the hill.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Yes, You can see boats at the top of the hill."}, "gen_args_1": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Also, You can see boats at the top of the hill."}, "gen_args_2": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? No, You can see boats at the top of the hill."}}, "resps": [[["-181.0", "False"]], [["-182.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-182.0", "False"], ["-184.0", "False"]], "doc_hash": "860d6fae29b917dbb049d6b5761d76bb500a922d88cdf6d5a9031b0328f31c65", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 1004, "doc": {"premise": "Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance.", "hypothesis": "`The Perfume Factory is in front of the South African area.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Yes, `The Perfume Factory is in front of the South African area."}, "gen_args_1": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? Also, `The Perfume Factory is in front of the South African area."}, "gen_args_2": {"arg_0": "", "arg_1": " Behind the South American area you'll find the Perfume Factory, where you can create your own personal fragrance., right? No, `The Perfume Factory is in front of the South African area."}}, "resps": [[["-151.0", "False"]], [["-157.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-157.0", "False"], ["-150.0", "False"]], "doc_hash": "3b4ef41f20431dc5313ae3073f84a5da9492b0a8e04f721e3b92b771b52c1466", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68762254e-01 6.66195022e-04 7.30571551e-01]"]}
{"doc_id": 1012, "doc": {"premise": "The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption.", "hypothesis": "The 2 mile sound was definitely not caused by a volcanic eruption.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Yes, The 2 mile sound was definitely not caused by a volcanic eruption."}, "gen_args_1": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Also, The 2 mile sound was definitely not caused by a volcanic eruption."}, "gen_args_2": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? No, The 2 mile sound was definitely not caused by a volcanic eruption."}}, "resps": [[["-152.0", "False"]], [["-152.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-152.0", "False"], ["-146.0", "False"]], "doc_hash": "ca6acae6b9dabd71acd43d31c13ed68ec23e4a3cacd1d9b5d402a8ec506306ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1020, "doc": {"premise": "Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940.", "hypothesis": "Greece has never been ruled by a military dictator.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Yes, Greece has never been ruled by a military dictator."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Also, Greece has never been ruled by a military dictator."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? No, Greece has never been ruled by a military dictator."}}, "resps": [[["-183.0", "False"]], [["-183.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-183.0", "False"], ["-178.0", "False"]], "doc_hash": "6ebf55f75044fe0b53341bae44053d43a3ee3bf7702a574f4c3c07b02bd3db93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1028, "doc": {"premise": "A flick of a tail or fluke, and it's gone.", "hypothesis": "The slightest movement and that's it; it is gone.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Yes, The slightest movement and that's it; it is gone."}, "gen_args_1": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? Also, The slightest movement and that's it; it is gone."}, "gen_args_2": {"arg_0": "", "arg_1": " A flick of a tail or fluke, and it's gone., right? No, The slightest movement and that's it; it is gone."}}, "resps": [[["-121.0", "False"]], [["-126.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-126.5", "False"], ["-122.0", "False"]], "doc_hash": "60f0d16a961c6c48132297b1ca7fb4b2a366519fc747b1971ac5199ea6667ed3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72888092 0.00297877 0.26814031]"]}
{"doc_id": 1036, "doc": {"premise": "Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web.", "hypothesis": "Singel was an inner city.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Yes, Singel was an inner city."}, "gen_args_1": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Also, Singel was an inner city."}, "gen_args_2": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? No, Singel was an inner city."}}, "resps": [[["-162.0", "False"]], [["-166.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-166.0", "False"], ["-162.0", "False"]], "doc_hash": "2d7cefa8a9fcfc7c74d5719100f5340d7cb0d299e1f7cfdccc1b2de7c52f033f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1044, "doc": {"premise": "Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands.", "hypothesis": "Culebra is halfway between Puerto Rico and St. Thomas in the US Virgin Islands.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Yes, Culebra is halfway between Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_1": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Also, Culebra is halfway between Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_2": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? No, Culebra is halfway between Puerto Rico and St. Thomas in the US Virgin Islands."}}, "resps": [[["-125.5", "False"]], [["-134.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-125.5", "False"], ["-134.0", "False"], ["-129.0", "False"]], "doc_hash": "c4bb33f7e06fcdec52bac046116a443b6c0c15e56f7da14d9466812cfa62bb26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70496092e-01 1.97465257e-04 2.93064426e-02]"]}
{"doc_id": 1052, "doc": {"premise": "Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs.", "hypothesis": "The Saguenay River was part of the fur trade.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Yes, The Saguenay River was part of the fur trade."}, "gen_args_1": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? Also, The Saguenay River was part of the fur trade."}, "gen_args_2": {"arg_0": "", "arg_1": " Cete de Charlevoix is part of the Laurentian heights, reaching to the Saguenay River where the coureurs de bois turned off in search of furs., right? No, The Saguenay River was part of the fur trade."}}, "resps": [[["-186.0", "False"]], [["-189.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-189.0", "False"], ["-188.0", "False"]], "doc_hash": "83f98f423804a34e2a365f4c0f71df55480f397a34af1e58e0e4e4dd85754592", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1060, "doc": {"premise": "A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis.", "hypothesis": "The Spartans delayed the Persian army at Thermopylae.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Yes, The Spartans delayed the Persian army at Thermopylae."}, "gen_args_1": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Also, The Spartans delayed the Persian army at Thermopylae."}, "gen_args_2": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? No, The Spartans delayed the Persian army at Thermopylae."}}, "resps": [[["-150.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "7270dbc01fe25867c38cc6fb686f2674acce11e3e3892320703634a48b27b14d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1068, "doc": {"premise": "Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith.", "hypothesis": "The Zenith hosts 1000 concerts a year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Yes, The Zenith hosts 1000 concerts a year."}, "gen_args_1": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Also, The Zenith hosts 1000 concerts a year."}, "gen_args_2": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? No, The Zenith hosts 1000 concerts a year."}}, "resps": [[["-139.0", "False"]], [["-142.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-142.0", "False"], ["-143.0", "False"]], "doc_hash": "19496f6e057c2e522b0b0460dfe84457f33e0a7e7eec53df938dacdb2f4d0c3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 1076, "doc": {"premise": "A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known.", "hypothesis": "Boot is very far from all of the railways.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Yes, Boot is very far from all of the railways."}, "gen_args_1": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? Also, Boot is very far from all of the railways."}, "gen_args_2": {"arg_0": "", "arg_1": " A little way along from Boot you'll find the terminus of the Ravenglass and Eskdale Railway, or  La'al Ratty,  as it's affectionately known., right? No, Boot is very far from all of the railways."}}, "resps": [[["-178.0", "False"]], [["-182.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-182.0", "False"], ["-179.0", "False"]], "doc_hash": "be1102157e906ed1bb09c104b595579248ac4fdb7afe5745a4d40b63c647bf72", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1084, "doc": {"premise": "702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory.", "hypothesis": "There's one coffee house in Vegas that's older than the rest.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Yes, There's one coffee house in Vegas that's older than the rest."}, "gen_args_1": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Also, There's one coffee house in Vegas that's older than the rest."}, "gen_args_2": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? No, There's one coffee house in Vegas that's older than the rest."}}, "resps": [[["-179.0", "False"]], [["-186.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-186.0", "False"], ["-180.0", "False"]], "doc_hash": "a9192b55cb06fd023da3daaab3432acb2c30264f1979ae6784978cc90435179d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 1092, "doc": {"premise": "Several small temples can be found here.", "hypothesis": "There are no temples in the areas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Yes, There are no temples in the areas."}, "gen_args_1": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Also, There are no temples in the areas."}, "gen_args_2": {"arg_0": "", "arg_1": " Several small temples can be found here., right? No, There are no temples in the areas."}}, "resps": [[["-96.5", "False"]], [["-97.5", "False"]], [["-92.5", "False"]]], "filtered_resps": [["-96.5", "False"], ["-97.5", "False"], ["-92.5", "False"]], "doc_hash": "62c42d41348ea05cfe4d4e295769437d71f9187d40e8bc4fb19a1cfd3398dacf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1100, "doc": {"premise": "Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time.", "hypothesis": "The a5 coin was from China.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Yes, The a5 coin was from China."}, "gen_args_1": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? Also, The a5 coin was from China."}, "gen_args_2": {"arg_0": "", "arg_1": " Be sure to see the 1887 a5 coin, which caused consternation among British subjects of the time., right? No, The a5 coin was from China."}}, "resps": [[["-157.0", "False"]], [["-159.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-159.0", "False"], ["-155.0", "False"]], "doc_hash": "1d0757b6bb743c0e2f07893a3e1ec810d910fb21b40c4b2333a0893544362901", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1108, "doc": {"premise": "The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality.", "hypothesis": "The faaade was in the Temple of Ramses II and is made of solid gold.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Yes, The faaade was in the Temple of Ramses II and is made of solid gold."}, "gen_args_1": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Also, The faaade was in the Temple of Ramses II and is made of solid gold."}, "gen_args_2": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? No, The faaade was in the Temple of Ramses II and is made of solid gold."}}, "resps": [[["-187.0", "False"]], [["-189.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-189.0", "False"], ["-187.0", "False"]], "doc_hash": "9d155909386d1c95d260df0435bb5a41e825c329585ae53684724ffe06795523", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1116, "doc": {"premise": "Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times.", "hypothesis": "The National Historical Museum has a lot of artifacts from post-Classical times.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Yes, The National Historical Museum has a lot of artifacts from post-Classical times."}, "gen_args_1": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Also, The National Historical Museum has a lot of artifacts from post-Classical times."}, "gen_args_2": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? No, The National Historical Museum has a lot of artifacts from post-Classical times."}}, "resps": [[["-155.0", "False"]], [["-159.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-159.0", "False"], ["-160.0", "False"]], "doc_hash": "0261d757d7969e12412d8b2ee13d93495b0ebebde3a40db43a05cc044f02795f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1124, "doc": {"premise": "Also check out Star Computer City in the Star House near the Star Ferry terminal.", "hypothesis": "Computer City is the most impressive thing in the Star House.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Yes, Computer City is the most impressive thing in the Star House."}, "gen_args_1": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? Also, Computer City is the most impressive thing in the Star House."}, "gen_args_2": {"arg_0": "", "arg_1": " Also check out Star Computer City in the Star House near the Star Ferry terminal., right? No, Computer City is the most impressive thing in the Star House."}}, "resps": [[["-139.0", "False"]], [["-139.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-139.0", "False"], ["-140.0", "False"]], "doc_hash": "fcf04f0f08fa599bf5e42f1c089859b2e2fb763d43629331302123cd27d4a3d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1132, "doc": {"premise": "The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops.", "hypothesis": "The shops in the nearby streets are interesting.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Yes, The shops in the nearby streets are interesting."}, "gen_args_1": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Also, The shops in the nearby streets are interesting."}, "gen_args_2": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? No, The shops in the nearby streets are interesting."}}, "resps": [[["-143.0", "False"]], [["-148.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-148.0", "False"], ["-145.0", "False"]], "doc_hash": "c7e6709f4723d72a1e6700e5fc8e5ac686d80783a2d71cea5e24a4dc69dc8d4b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1140, "doc": {"premise": "You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum.", "hypothesis": "The museum is across the street from the Egyptian museum.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Yes, The museum is across the street from the Egyptian museum."}, "gen_args_1": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Also, The museum is across the street from the Egyptian museum."}, "gen_args_2": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? No, The museum is across the street from the Egyptian museum."}}, "resps": [[["-158.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "b3a074cda22df9549276a50477d3bd0d9515e34e09a8ffac589d4ffad596a1dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1148, "doc": {"premise": "The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe.", "hypothesis": "James Wilson Marshall invented something.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Yes, James Wilson Marshall invented something."}, "gen_args_1": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? Also, James Wilson Marshall invented something."}, "gen_args_2": {"arg_0": "", "arg_1": " The find that caught the whole world's imagination was made by one James Wilson Marshall, a carpenter, at John Sutter's sawmill on the American River at Coloma, which lies midway between Sacramento and Lake Tahoe., right? No, James Wilson Marshall invented something."}}, "resps": [[["-171.0", "False"]], [["-174.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-174.0", "False"], ["-172.0", "False"]], "doc_hash": "f29e69afc3d6eae2451bd4964cf13bcbe7eeb28088444a12e6ac6ce8a859fa3c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1156, "doc": {"premise": "Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night.", "hypothesis": "Coupons are given out on the beach, hoping for long term customers.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Yes, Coupons are given out on the beach, hoping for long term customers."}, "gen_args_1": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Also, Coupons are given out on the beach, hoping for long term customers."}, "gen_args_2": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? No, Coupons are given out on the beach, hoping for long term customers."}}, "resps": [[["-170.0", "False"]], [["-174.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-174.0", "False"], ["-167.0", "False"]], "doc_hash": "216c953525d107454d2ace8bf7a926ddccb6a8e40f595afbe3b75c6eb7e5faca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1164, "doc": {"premise": "The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village.", "hypothesis": "Alaior has 100 white houses.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Yes, Alaior has 100 white houses."}, "gen_args_1": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Also, Alaior has 100 white houses."}, "gen_args_2": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? No, Alaior has 100 white houses."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-153.0", "False"]], "doc_hash": "543fe7a8ada7e402f13ad20b1d1fa6a95864c78b7ec567f0960d10bb7f8012dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1172, "doc": {"premise": "The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded.", "hypothesis": "There aren't as many people in the towns near Barbizon.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Yes, There aren't as many people in the towns near Barbizon."}, "gen_args_1": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? Also, There aren't as many people in the towns near Barbizon."}, "gen_args_2": {"arg_0": "", "arg_1": " The Gorges d'Apreamont (near the little town of Barbizon, famed as a haunt of 19th-century landscape painters) tend to be less crowded., right? No, There aren't as many people in the towns near Barbizon."}}, "resps": [[["-191.0", "False"]], [["-194.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-194.0", "False"], ["-194.0", "False"]], "doc_hash": "6739b4a23767b678971332411d72eb645ce5671925cfd6456f6abc57c6e6b2e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1180, "doc": {"premise": "Just so long as you don't object to being shown up by the resident ten-year-old experts.", "hypothesis": "The ten year olds know all about science.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Yes, The ten year olds know all about science."}, "gen_args_1": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Also, The ten year olds know all about science."}, "gen_args_2": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? No, The ten year olds know all about science."}}, "resps": [[["-126.0", "False"]], [["-131.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-131.0", "False"], ["-129.0", "False"]], "doc_hash": "985b882f02897ba9226960730022d6bd5aa034c4844b3859efa72889387a6daa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1188, "doc": {"premise": "Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies.", "hypothesis": "The Komische Oper is in Australia.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Yes, The Komische Oper is in Australia."}, "gen_args_1": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Also, The Komische Oper is in Australia."}, "gen_args_2": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? No, The Komische Oper is in Australia."}}, "resps": [[["-166.0", "False"]], [["-172.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-172.0", "False"], ["-164.0", "False"]], "doc_hash": "92bef439ae173725e23e22d730e04ad1364f8f7acf057ae2be2e59c186017c99", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 1196, "doc": {"premise": "If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street.", "hypothesis": "Harvard Square isn't great at night.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Yes, Harvard Square isn't great at night."}, "gen_args_1": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? Also, Harvard Square isn't great at night."}, "gen_args_2": {"arg_0": "", "arg_1": " If you're looking for an evening alternative to Harvard Square, head to Hispanic-flavored Inman Square, located down Cambridge Street., right? No, Harvard Square isn't great at night."}}, "resps": [[["-143.0", "False"]], [["-143.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-143.0", "False"], ["-141.0", "False"]], "doc_hash": "dc572fadd6c974b15ebbbf6cbeef1366de0f1553ff308fce18ec441c54193479", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1204, "doc": {"premise": "Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door.", "hypothesis": "The town is friendly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Yes, The town is friendly."}, "gen_args_1": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Also, The town is friendly."}, "gen_args_2": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? No, The town is friendly."}}, "resps": [[["-200.0", "False"]], [["-202.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-202.0", "False"], ["-203.0", "False"]], "doc_hash": "fc5c9197e7ccb04eec589379d355a03692c05d49abdb83fb82d884ab9d9623fb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1212, "doc": {"premise": "Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level.", "hypothesis": "Flag Hill his very high compared to the rest of town.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Yes, Flag Hill his very high compared to the rest of town."}, "gen_args_1": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Also, Flag Hill his very high compared to the rest of town."}, "gen_args_2": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? No, Flag Hill his very high compared to the rest of town."}}, "resps": [[["-143.0", "False"]], [["-148.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-148.0", "False"], ["-149.0", "False"]], "doc_hash": "1a45904e026bba52177f8b99b9b0509e7c567fde4a7b3fc4d2d9c522b2700adc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.99086747 0.00667641 0.00245611]"]}
{"doc_id": 1220, "doc": {"premise": "Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French.", "hypothesis": "Rocroi was where the Spanish were beaten.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Yes, Rocroi was where the Spanish were beaten."}, "gen_args_1": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? Also, Rocroi was where the Spanish were beaten."}, "gen_args_2": {"arg_0": "", "arg_1": " Another important defeat took place at Rocroi, in Flanders, in 1643, when Spanish troops, never to regain their former glory, were routed by the French., right? No, Rocroi was where the Spanish were beaten."}}, "resps": [[["-154.0", "False"]], [["-157.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-157.0", "False"], ["-154.0", "False"]], "doc_hash": "79842c1a429c42fe93ed977648b11f694702adf74262ed9264dcfefe4f186b5c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1228, "doc": {"premise": "Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible.", "hypothesis": "It's best to book early.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Yes, It's best to book early."}, "gen_args_1": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Also, It's best to book early."}, "gen_args_2": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? No, It's best to book early."}}, "resps": [[["-128.0", "False"]], [["-132.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-132.0", "False"], ["-130.0", "False"]], "doc_hash": "9d0b703838e813e693cfdc5ee681d63196d024e8b20d7757e8a38711e8c4d942", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1236, "doc": {"premise": "Just east of the Star Ferry terminal, you'll come to City Hall.", "hypothesis": "City Hall is 2 blocks east of the terminal.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Yes, City Hall is 2 blocks east of the terminal."}, "gen_args_1": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Also, City Hall is 2 blocks east of the terminal."}, "gen_args_2": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? No, City Hall is 2 blocks east of the terminal."}}, "resps": [[["-110.0", "False"]], [["-121.5", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-110.0", "False"], ["-121.5", "False"], ["-107.0", "False"]], "doc_hash": "de4701bec8f18efeb0908000d6f023e60ab6097e3c3b77c1af4d80df1013b0c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.74258504e-02 4.80428303e-07 9.52573669e-01]"]}
{"doc_id": 1244, "doc": {"premise": "The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla.", "hypothesis": "There are shopping areas in the uptown segment of La Rambla.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Yes, There are shopping areas in the uptown segment of La Rambla."}, "gen_args_1": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? Also, There are shopping areas in the uptown segment of La Rambla."}, "gen_args_2": {"arg_0": "", "arg_1": " The principal shopping and strolling avenues are the elegant Passeig de Gracia, Barcelona's version of the Champs d'Elysee, and pedestrian-only Rambla de Catalunya, an uptown segment of La Rambla., right? No, There are shopping areas in the uptown segment of La Rambla."}}, "resps": [[["-185.0", "False"]], [["-186.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-186.0", "False"], ["-186.0", "False"]], "doc_hash": "4d371953985c80a8b10f8f5e6fa6ee07ad72494ee997a6315f6fe45f80d93a86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1252, "doc": {"premise": "The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c", "hypothesis": "The statistics in this paper are outdated.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Yes, The statistics in this paper are outdated."}, "gen_args_1": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Also, The statistics in this paper are outdated."}, "gen_args_2": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? No, The statistics in this paper are outdated."}}, "resps": [[["-144.0", "False"]], [["-142.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-142.0", "False"], ["-140.0", "False"]], "doc_hash": "2eff3707e499fa8f85fcc46005d917a2a9d810d359780ea6e04212d653c011b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 1260, "doc": {"premise": "189 and the user costs are estimated in the same way.", "hypothesis": "They guessed about the user cost.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Yes, They guessed about the user cost."}, "gen_args_1": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Also, They guessed about the user cost."}, "gen_args_2": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? No, They guessed about the user cost."}}, "resps": [[["-120.5", "False"]], [["-122.0", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-120.5", "False"], ["-122.0", "False"], ["-120.0", "False"]], "doc_hash": "c613951451a90c43ec24a25b96542ee5e928a02e224eeaf9279653d28ff1ff7c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.34820743 0.07769558 0.57409699]"]}
{"doc_id": 1268, "doc": {"premise": "All nine responding agencies report participation in a", "hypothesis": "These nine agencies are pleased that they had such a high participation level.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Yes, These nine agencies are pleased that they had such a high participation level."}, "gen_args_1": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? Also, These nine agencies are pleased that they had such a high participation level."}, "gen_args_2": {"arg_0": "", "arg_1": " All nine responding agencies report participation in a, right? No, These nine agencies are pleased that they had such a high participation level."}}, "resps": [[["-131.0", "False"]], [["-136.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-136.0", "False"], ["-131.0", "False"]], "doc_hash": "583ab243effbbe835303f7c4611264a0e0fde2ac960dcf1073a9e20e40ca76a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1276, "doc": {"premise": "It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities.", "hypothesis": "The CIO has no idea what the responsibilities of members are and isn't responsible for informing them.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Yes, The CIO has no idea what the responsibilities of members are and isn't responsible for informing them."}, "gen_args_1": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Also, The CIO has no idea what the responsibilities of members are and isn't responsible for informing them."}, "gen_args_2": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? No, The CIO has no idea what the responsibilities of members are and isn't responsible for informing them."}}, "resps": [[["-162.0", "False"]], [["-164.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-164.0", "False"], ["-159.0", "False"]], "doc_hash": "c46c1ae20316cf09e6979b38a729e737cb60ee7b4ed3bde84c64007532aa9559", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1284, "doc": {"premise": "It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere.", "hypothesis": "It's obvious how much bias there is.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Yes, It's obvious how much bias there is."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Also, It's obvious how much bias there is."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? No, It's obvious how much bias there is."}}, "resps": [[["-197.0", "False"]], [["-197.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-197.0", "False"], ["-195.0", "False"]], "doc_hash": "bd51a3cc73fe91d58da2c235909a54ff194b2114d8cfcb3c46b3fcecb0b6b0d4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1292, "doc": {"premise": "Practice 4: Manage Risk on a Continuing Basis", "hypothesis": "This exercise must be completed and turned in by the end of the week.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Yes, This exercise must be completed and turned in by the end of the week."}, "gen_args_1": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? Also, This exercise must be completed and turned in by the end of the week."}, "gen_args_2": {"arg_0": "", "arg_1": " Practice 4: Manage Risk on a Continuing Basis, right? No, This exercise must be completed and turned in by the end of the week."}}, "resps": [[["-113.0", "False"]], [["-114.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-113.0", "False"], ["-114.0", "False"], ["-115.0", "False"]], "doc_hash": "bd9a3cbe6580314a13143814b6c87e2f673246a5337d09fb6decf74afbf2de85", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1300, "doc": {"premise": "In addition, program personnel conduct various workshops for and make educational materials available to new providers.", "hypothesis": "Program personnel host workshops for ELL students.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Yes, Program personnel host workshops for ELL students."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Also, Program personnel host workshops for ELL students."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? No, Program personnel host workshops for ELL students."}}, "resps": [[["-151.0", "False"]], [["-155.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-155.0", "False"], ["-152.0", "False"]], "doc_hash": "dad280f498283eadfa39dbb7a63f932efb3c790365ad72a5dc5756272f1a4a4f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1308, "doc": {"premise": "LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States.", "hypothesis": "Attorneys get paid by the LSC if they are working in terrorism.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Yes, Attorneys get paid by the LSC if they are working in terrorism."}, "gen_args_1": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Also, Attorneys get paid by the LSC if they are working in terrorism."}, "gen_args_2": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? No, Attorneys get paid by the LSC if they are working in terrorism."}}, "resps": [[["-190.0", "False"]], [["-191.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-191.0", "False"], ["-191.0", "False"]], "doc_hash": "74cefac759cd250f1e1dc095c169068acd47a27f052b4b2d78a5200f40db5020", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1316, "doc": {"premise": "This has been true in primary care settings as well.", "hypothesis": "There were unpaid bills in primary care as well.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Yes, There were unpaid bills in primary care as well."}, "gen_args_1": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? Also, There were unpaid bills in primary care as well."}, "gen_args_2": {"arg_0": "", "arg_1": " This has been true in primary care settings as well., right? No, There were unpaid bills in primary care as well."}}, "resps": [[["-103.0", "False"]], [["-108.5", "False"]], [["-102.5", "False"]]], "filtered_resps": [["-103.0", "False"], ["-108.5", "False"], ["-102.5", "False"]], "doc_hash": "2bcac49cac8247a4f45240295e8c3aad1b232197dd391d6c858c98c9d92f7193", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37695905 0.00154055 0.6215004 ]"]}
{"doc_id": 1324, "doc": {"premise": "For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds.", "hypothesis": "The trust fund has never needed to borrow.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Yes, The trust fund has never needed to borrow."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Also, The trust fund has never needed to borrow."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? No, The trust fund has never needed to borrow."}}, "resps": [[["-126.0", "False"]], [["-128.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-128.0", "False"], ["-122.0", "False"]], "doc_hash": "e02f434372b547debd5bb9459928499796d7d965df95a86b947bedeb0fa5ec8c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1332, "doc": {"premise": "Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process.", "hypothesis": "First you do an efficacy trial.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Yes, First you do an efficacy trial."}, "gen_args_1": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Also, First you do an efficacy trial."}, "gen_args_2": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? No, First you do an efficacy trial."}}, "resps": [[["-157.0", "False"]], [["-163.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-163.0", "False"], ["-158.0", "False"]], "doc_hash": "f356ff6e7aec11e34814dc9f33073ee8cebfc7ad0d895ba97b842e7f19f47501", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 1340, "doc": {"premise": "This is a large challenge and a large expectation for any one system of intervention.", "hypothesis": "One kind of intervention has a big challenge, no matter what.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Yes, One kind of intervention has a big challenge, no matter what."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? Also, One kind of intervention has a big challenge, no matter what."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a large challenge and a large expectation for any one system of intervention., right? No, One kind of intervention has a big challenge, no matter what."}}, "resps": [[["-144.0", "False"]], [["-147.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-147.0", "False"], ["-145.0", "False"]], "doc_hash": "da7c5ff667a3a4d309950640f31354367925d5a8f7d178b868d3d91b1252545a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1348, "doc": {"premise": "12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS).", "hypothesis": "12HEI is related directly to air pollution.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Yes, 12HEI is related directly to air pollution."}, "gen_args_1": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Also, 12HEI is related directly to air pollution."}, "gen_args_2": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? No, 12HEI is related directly to air pollution."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-149.0", "False"]], "doc_hash": "6338366534c542a817ee247a429aaf87503f7e784935b0fbc1928fb8f31f9f56", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1356, "doc": {"premise": "TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS", "hypothesis": "Mercury can't be above 10 ppm.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Yes, Mercury can't be above 10 ppm."}, "gen_args_1": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Also, Mercury can't be above 10 ppm."}, "gen_args_2": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? No, Mercury can't be above 10 ppm."}}, "resps": [[["-159.0", "False"]], [["-158.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-158.0", "False"], ["-156.0", "False"]], "doc_hash": "fcd4c6ef71e593c2d304719df1e9234dcda10a524af0d493e67d8cfb8cdc06b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 1364, "doc": {"premise": "In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements.", "hypothesis": "In hybrid organizations the CEO maintains direct central control of the organization.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Yes, In hybrid organizations the CEO maintains direct central control of the organization."}, "gen_args_1": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? Also, In hybrid organizations the CEO maintains direct central control of the organization."}, "gen_args_2": {"arg_0": "", "arg_1": " In this hybrid, the CEO assigns central control to a corporate CIO and supporting CIO organization, while delegating specific authority to each business unit for managing its own unique information management requirements., right? No, In hybrid organizations the CEO maintains direct central control of the organization."}}, "resps": [[["-213.0", "False"]], [["-214.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-214.0", "False"], ["-207.0", "False"]], "doc_hash": "53737e6eea1a0c33ad2ee71260541ca55a93f351773bbd7a1051b8f9f61ae868", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 1372, "doc": {"premise": "We have already come a long way, and much is left to do.", "hypothesis": "There are exactly five more tasks that must still be accomplished.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Yes, There are exactly five more tasks that must still be accomplished."}, "gen_args_1": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Also, There are exactly five more tasks that must still be accomplished."}, "gen_args_2": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? No, There are exactly five more tasks that must still be accomplished."}}, "resps": [[["-110.5", "False"]], [["-116.5", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-110.5", "False"], ["-116.5", "False"], ["-111.0", "False"]], "doc_hash": "b230f282bf97cc3320030075033411b7e00513e9e78f4681d6141b667f542e39", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.6215004  0.00154055 0.37695905]"]}
{"doc_id": 1380, "doc": {"premise": "Significant differences were noted, however, as", "hypothesis": "The differences were so significant that they were written down.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Yes, The differences were so significant that they were written down."}, "gen_args_1": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Also, The differences were so significant that they were written down."}, "gen_args_2": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? No, The differences were so significant that they were written down."}}, "resps": [[["-109.0", "False"]], [["-112.0", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-109.0", "False"], ["-112.0", "False"], ["-108.5", "False"]], "doc_hash": "1ecd774460dbf84dcf1081bdc592564874018a6719e50af4e3727aecfd2d016a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.3705751  0.01844985 0.61097505]"]}
{"doc_id": 1388, "doc": {"premise": "We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002.", "hypothesis": "You have done something to support us in this past year.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Yes, You have done something to support us in this past year."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? Also, You have done something to support us in this past year."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to your continued support and working even more closely with you and your staff this year and in fiscal year 2002., right? No, You have done something to support us in this past year."}}, "resps": [[["-139.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "c3fa687313c18c5850a197731bf6ae35448c968658dc784182a1498ba8dd5213", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1396, "doc": {"premise": "This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared.", "hypothesis": "The demand curve isn't dependent on anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Yes, The demand curve isn't dependent on anything."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Also, The demand curve isn't dependent on anything."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? No, The demand curve isn't dependent on anything."}}, "resps": [[["-198.0", "False"]], [["-198.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-198.0", "False"], ["-198.0", "False"], ["-195.0", "False"]], "doc_hash": "b66ce822e996b762f02088fcfb8c1a2c217b7202ab11aa7b3362afd5ec7aa43b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1404, "doc": {"premise": "change are staff downsizing, changes in contract methods, and business", "hypothesis": "They're firing half the employees.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Yes, They're firing half the employees."}, "gen_args_1": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Also, They're firing half the employees."}, "gen_args_2": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? No, They're firing half the employees."}}, "resps": [[["-130.0", "False"]], [["-131.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-130.0", "False"], ["-131.0", "False"], ["-127.5", "False"]], "doc_hash": "9b7130f2f5b58bedbacdf74cc8890574dc38959e7180b3dca52bef03cd4532b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0737987  0.02714903 0.89905227]"]}
{"doc_id": 1412, "doc": {"premise": "In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes.", "hypothesis": "There is a much greater impact of volume in the United States.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Yes, There is a much greater impact of volume in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? Also, There is a much greater impact of volume in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " In contrast, the impact of volume is greater in the U.S. than in France because the U.S. has lower postal densities and a greater variation in volumes., right? No, There is a much greater impact of volume in the United States."}}, "resps": [[["-152.0", "False"]], [["-158.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-158.0", "False"], ["-154.0", "False"]], "doc_hash": "6b36d085d03c75a9fb0ec6b8415d30e080f88596e0fae039f9a21584587d22e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1420, "doc": {"premise": "The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed.", "hypothesis": "The two groups work together to make sure they aren't missing any important pieces.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Yes, The two groups work together to make sure they aren't missing any important pieces."}, "gen_args_1": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Also, The two groups work together to make sure they aren't missing any important pieces."}, "gen_args_2": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? No, The two groups work together to make sure they aren't missing any important pieces."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-161.0", "False"]], "doc_hash": "ca1aa4c3323cca95b4b4a5ccab522d9b7aa99c5f9914b560b27b95400af33209", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1428, "doc": {"premise": "We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world.", "hypothesis": "We want to make GAO fall apart.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Yes, We want to make GAO fall apart."}, "gen_args_1": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Also, We want to make GAO fall apart."}, "gen_args_2": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? No, We want to make GAO fall apart."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-167.0", "False"]], "doc_hash": "b8452f46ae42416202eaeb9b28014916acbf625c6b969a0b6a67b650b19ecb04", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1436, "doc": {"premise": "In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated.", "hypothesis": "The effects of the concentration-response relationship are rarely overestimated.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Yes, The effects of the concentration-response relationship are rarely overestimated."}, "gen_args_1": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? Also, The effects of the concentration-response relationship are rarely overestimated."}, "gen_args_2": {"arg_0": "", "arg_1": " In most cases, the concentration-response relationship may be overestimated; in other cases, it may be underestimated., right? No, The effects of the concentration-response relationship are rarely overestimated."}}, "resps": [[["-129.0", "False"]], [["-134.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-134.0", "False"], ["-126.0", "False"]], "doc_hash": "c639d85ff90e4914d13e0d9ec114bec7d007533bd5dfcccdac2b0a6b312d63fa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 1444, "doc": {"premise": "In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target.", "hypothesis": "Increased value in existing assets can lower the amount of savings from income that is needed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Yes, Increased value in existing assets can lower the amount of savings from income that is needed."}, "gen_args_1": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Also, Increased value in existing assets can lower the amount of savings from income that is needed."}, "gen_args_2": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? No, Increased value in existing assets can lower the amount of savings from income that is needed."}}, "resps": [[["-176.0", "False"]], [["-182.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-182.0", "False"], ["-182.0", "False"]], "doc_hash": "6b7e1237fe453ac6439e5aacc819caba0b18f31c74efcd6e8ae2fdd007d166ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99506695 0.00246652 0.00246652]"]}
{"doc_id": 1452, "doc": {"premise": "It made sense for the state to outsource tactical functions such as help desks and mainframe management.", "hypothesis": "The state does not outsource any functions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Yes, The state does not outsource any functions."}, "gen_args_1": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Also, The state does not outsource any functions."}, "gen_args_2": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? No, The state does not outsource any functions."}}, "resps": [[["-130.0", "False"]], [["-131.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-130.0", "False"], ["-131.0", "False"], ["-124.5", "False"]], "doc_hash": "8301753edac60897e44fc8763522e175ab02dfbbf6c933c813e6cc8da74b74e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00406405 0.00149508 0.99444087]"]}
{"doc_id": 1460, "doc": {"premise": "This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies.", "hypothesis": "This project has not been very successful.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Yes, This project has not been very successful."}, "gen_args_1": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? Also, This project has not been very successful."}, "gen_args_2": {"arg_0": "", "arg_1": " This project, called Partners for Justice is a cooperative venture among the five LSC programs, LATIS, the Appleseed Justice Center, the South Carolina Bar Pro Bono Program, and 46 human services agencies., right? No, This project has not been very successful."}}, "resps": [[["-219.0", "False"]], [["-220.0", "False"]], [["-215.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-220.0", "False"], ["-215.0", "False"]], "doc_hash": "bb367c7abcc00a5e6bae70505dc7f6bcdd31953dd19933533012f2418d12a43b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1468, "doc": {"premise": "Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas.", "hypothesis": "Brendan Gill likes the merger", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Yes, Brendan Gill likes the merger"}, "gen_args_1": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Also, Brendan Gill likes the merger"}, "gen_args_2": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? No, Brendan Gill likes the merger"}}, "resps": [[["-142.0", "False"]], [["-149.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-149.0", "False"], ["-142.0", "False"]], "doc_hash": "ec6dfbcf242926f023bba767576ff09017582d40eac41c1f88531a68dc1204b7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 1476, "doc": {"premise": "If households' existing assets lose value, people have to save more to attain their wealth-income target.", "hypothesis": "Assets will lose value sometimes due to the market.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Yes, Assets will lose value sometimes due to the market."}, "gen_args_1": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Also, Assets will lose value sometimes due to the market."}, "gen_args_2": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? No, Assets will lose value sometimes due to the market."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-162.0", "False"]], "doc_hash": "d83f9cd496db93c9eeb659d720d03f2c2c130151c2aa31ee3e8310207eb527ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1484, "doc": {"premise": "Assets accumulated can generate income in the form of interest and dividends that in turn may be saved.", "hypothesis": "You can generate income with assets.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Yes, You can generate income with assets."}, "gen_args_1": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? Also, You can generate income with assets."}, "gen_args_2": {"arg_0": "", "arg_1": " Assets accumulated can generate income in the form of interest and dividends that in turn may be saved., right? No, You can generate income with assets."}}, "resps": [[["-117.5", "False"]], [["-124.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-117.5", "False"], ["-124.0", "False"], ["-119.5", "False"]], "doc_hash": "b5f065dbd6b682996c29678adc94abb546db2c576bcb7fc0323a7ecc1d6822ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87963225 0.00132247 0.11904528]"]}
{"doc_id": 1492, "doc": {"premise": "For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability.", "hypothesis": "Assets such as real estate properties gain value by the year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Yes, Assets such as real estate properties gain value by the year."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Also, Assets such as real estate properties gain value by the year."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? No, Assets such as real estate properties gain value by the year."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-154.0", "False"]], "doc_hash": "d16685222b4342911424eef64857ee8f39ccc0c9d1cac4cae95b371380cd1abb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1500, "doc": {"premise": "The system also chose passengers at random to receive additional security scrutiny.", "hypothesis": "All passengers just get to walk through without an issue.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Yes, All passengers just get to walk through without an issue."}, "gen_args_1": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Also, All passengers just get to walk through without an issue."}, "gen_args_2": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? No, All passengers just get to walk through without an issue."}}, "resps": [[["-133.0", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "fd2e03e68f78c7aa85c638e08e3aeacec9a03a0a8874cec6b0880b01eded3b32", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 1508, "doc": {"premise": "It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers.", "hypothesis": "The security system will be installed in 6 weeks, i promise.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Yes, The security system will be installed in 6 weeks, i promise."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? Also, The security system will be installed in 6 weeks, i promise."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not clear the system can be installed before 2010, but even this timetable may be too slow, given the possible security dangers., right? No, The security system will be installed in 6 weeks, i promise."}}, "resps": [[["-183.0", "False"]], [["-184.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-184.0", "False"], ["-181.0", "False"]], "doc_hash": "2bc6b6cbae796dd18172b9a45ef448b323ba84c95ee5e009b12ac1e78175a2b3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1516, "doc": {"premise": "Delivering it repeatedly did not make it more effective.", "hypothesis": "Delivery made it incredible effective.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Yes, Delivery made it incredible effective."}, "gen_args_1": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Also, Delivery made it incredible effective."}, "gen_args_2": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? No, Delivery made it incredible effective."}}, "resps": [[["-100.0", "False"]], [["-105.5", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-105.5", "False"], ["-97.5", "False"]], "doc_hash": "e59cfaded26eaf8b18462efa40ac2d33412923a08ef5c0f7488b1f17164f0884", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58346701e-02 3.09918964e-04 9.23855411e-01]"]}
{"doc_id": 1524, "doc": {"premise": "According to both KSM and Khallad, Abu Bara never applied for a U.S. visa.", "hypothesis": "Abu Bara didn't want a visa.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Yes, Abu Bara didn't want a visa."}, "gen_args_1": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Also, Abu Bara didn't want a visa."}, "gen_args_2": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? No, Abu Bara didn't want a visa."}}, "resps": [[["-126.0", "False"]], [["-126.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-126.0", "False"], ["-126.0", "False"], ["-124.5", "False"]], "doc_hash": "0e8fbea8284ae1a91232008744eee01f90d759ab79b2a7771ae70b16a26c7d3a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.15428077 0.15428077 0.69143845]"]}
{"doc_id": 1532, "doc": {"premise": "He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan).", "hypothesis": "Training provided in Afghanistan included hand to hand combat.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Yes, Training provided in Afghanistan included hand to hand combat."}, "gen_args_1": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? Also, Training provided in Afghanistan included hand to hand combat."}, "gen_args_2": {"arg_0": "", "arg_1": " He had traveled to Pakistan but became agitated when asked if he had traveled to nearby countries while in Pakistan (Pakistan was the customary route to the training camps in Afghanistan)., right? No, Training provided in Afghanistan included hand to hand combat."}}, "resps": [[["-197.0", "False"]], [["-196.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-196.0", "False"], ["-198.0", "False"]], "doc_hash": "4e52412c76991980be3edbc986353d294f7235eceda46821e9b580428f57dbb9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 1540, "doc": {"premise": "The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later.", "hypothesis": "The Sector did not receive the notifications in time due to a delay in communications.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Yes, The Sector did not receive the notifications in time due to a delay in communications."}, "gen_args_1": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Also, The Sector did not receive the notifications in time due to a delay in communications."}, "gen_args_2": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? No, The Sector did not receive the notifications in time due to a delay in communications."}}, "resps": [[["-151.0", "False"]], [["-158.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-158.0", "False"], ["-151.0", "False"]], "doc_hash": "dc8161137eb58df6278c1d985b0c4d83fe0cd2ca55e07cc682b395d77bfc6108", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 1548, "doc": {"premise": "According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation.", "hypothesis": "Bin Ladin didn't know that moussaoui had been detained.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Yes, Bin Ladin didn't know that moussaoui had been detained."}, "gen_args_1": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Also, Bin Ladin didn't know that moussaoui had been detained."}, "gen_args_2": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? No, Bin Ladin didn't know that moussaoui had been detained."}}, "resps": [[["-151.0", "False"]], [["-151.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-151.0", "False"], ["-149.0", "False"]], "doc_hash": "160f3e4bd7bad536ed8641f22b0730bd6ce7b6d9c8842b2cfccd8c056ce27266", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1556, "doc": {"premise": "We ask every nation to join us.", "hypothesis": "We will do this alone!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Yes, We will do this alone!"}, "gen_args_1": {"arg_0": "", "arg_1": " We ask every nation to join us., right? Also, We will do this alone!"}, "gen_args_2": {"arg_0": "", "arg_1": " We ask every nation to join us., right? No, We will do this alone!"}}, "resps": [[["-90.0", "False"]], [["-94.0", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-90.0", "False"], ["-94.0", "False"], ["-84.0", "False"]], "doc_hash": "d29a108db27579562a06dea4712c1328606428a3f2399cbfd218983f47071f41", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47251118e-03 4.52856220e-05 9.97482203e-01]"]}
{"doc_id": 1564, "doc": {"premise": "The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags.", "hypothesis": "Police found various items in the man's checked bags after the terminal was evacuated.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Yes, Police found various items in the man's checked bags after the terminal was evacuated."}, "gen_args_1": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Also, Police found various items in the man's checked bags after the terminal was evacuated."}, "gen_args_2": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? No, Police found various items in the man's checked bags after the terminal was evacuated."}}, "resps": [[["-147.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "64b3acf16bdaa28d5c811dea43f2aff90f6d37938abec7747f37175cbdc64b7d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 1572, "doc": {"premise": "While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average.", "hypothesis": "Physical searches were more likely to find contraband.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Yes, Physical searches were more likely to find contraband."}, "gen_args_1": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Also, Physical searches were more likely to find contraband."}, "gen_args_2": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? No, Physical searches were more likely to find contraband."}}, "resps": [[["-148.0", "False"]], [["-149.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-149.0", "False"], ["-150.0", "False"]], "doc_hash": "d8a10d8b72a8fc49e2839b7486864928a4fd2cb5450b27db4ce278d0969ad41d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1580, "doc": {"premise": "Our border screening system should check people efficiently and welcome friends.", "hypothesis": "We have to screen everyone equally and thus treat all with the respect that they deserve.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Yes, We have to screen everyone equally and thus treat all with the respect that they deserve."}, "gen_args_1": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? Also, We have to screen everyone equally and thus treat all with the respect that they deserve."}, "gen_args_2": {"arg_0": "", "arg_1": " Our border screening system should check people efficiently and welcome friends., right? No, We have to screen everyone equally and thus treat all with the respect that they deserve."}}, "resps": [[["-155.0", "False"]], [["-160.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-160.0", "False"], ["-152.0", "False"]], "doc_hash": "f3dd7188ca63b0db8665356454abfbd94d5911bb02e02d995a9e9c800fffadd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 1588, "doc": {"premise": "It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role.", "hypothesis": "The FDNY did not want local, federal, bistate, and state agencies to help.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Yes, The FDNY did not want local, federal, bistate, and state agencies to help."}, "gen_args_1": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Also, The FDNY did not want local, federal, bistate, and state agencies to help."}, "gen_args_2": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? No, The FDNY did not want local, federal, bistate, and state agencies to help."}}, "resps": [[["-176.0", "False"]], [["-176.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-176.0", "False"], ["-171.0", "False"]], "doc_hash": "7d196f4d971d4e79dc3e7d4e951b5cf36d0a4837ca6cbec989029e784d0fbe57", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1596, "doc": {"premise": "On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda.", "hypothesis": "President Bush had no contact with President Musharraf.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Yes, President Bush had no contact with President Musharraf."}, "gen_args_1": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Also, President Bush had no contact with President Musharraf."}, "gen_args_2": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? No, President Bush had no contact with President Musharraf."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-144.0", "False"]], "doc_hash": "b5d948d53bbc0ffcd6d77120c61f0f24c20188a6f079df266ef7add0d395cc2a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 1604, "doc": {"premise": "Other evidence corroborates her account.", "hypothesis": "We have absolutely no reason to believe her account.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Yes, We have absolutely no reason to believe her account."}, "gen_args_1": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? Also, We have absolutely no reason to believe her account."}, "gen_args_2": {"arg_0": "", "arg_1": " Other evidence corroborates her account., right? No, We have absolutely no reason to believe her account."}}, "resps": [[["-89.0", "False"]], [["-91.5", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-91.5", "False"], ["-87.0", "False"]], "doc_hash": "3938fb698a1cb26edb4c58e2be6d5ddf7deff5cb6c3707c9235541b4d1de9d8f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11804785 0.00968996 0.87226219]"]}
{"doc_id": 1612, "doc": {"premise": "But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans.", "hypothesis": "Placing new officials in office and working on a defense policy were time consuming projects.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Yes, Placing new officials in office and working on a defense policy were time consuming projects."}, "gen_args_1": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Also, Placing new officials in office and working on a defense policy were time consuming projects."}, "gen_args_2": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? No, Placing new officials in office and working on a defense policy were time consuming projects."}}, "resps": [[["-211.0", "False"]], [["-218.0", "False"]], [["-215.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-218.0", "False"], ["-215.0", "False"]], "doc_hash": "f3d20cc4f58207a7cdefc806a271bd6c61d71db9445419d60a2164d91e52a1e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1620, "doc": {"premise": "Boston  A second one just hit the Trade Center.", "hypothesis": "The Trade Center was hit by a train.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Yes, The Trade Center was hit by a train."}, "gen_args_1": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Also, The Trade Center was hit by a train."}, "gen_args_2": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? No, The Trade Center was hit by a train."}}, "resps": [[["-117.0", "False"]], [["-119.5", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-117.0", "False"], ["-119.5", "False"], ["-114.5", "False"]], "doc_hash": "4a75bfc3a9e12d76cb9dc5751ed2af61ec1c75259049f0f80d36ce4ec494d8d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07538875 0.00618829 0.91842297]"]}
{"doc_id": 1628, "doc": {"premise": "There were numerous technical problems, especially with the Hellfire missiles.", "hypothesis": "There were also technical errors with other types of missiles.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Yes, There were also technical errors with other types of missiles."}, "gen_args_1": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? Also, There were also technical errors with other types of missiles."}, "gen_args_2": {"arg_0": "", "arg_1": " There were numerous technical problems, especially with the Hellfire missiles., right? No, There were also technical errors with other types of missiles."}}, "resps": [[["-110.5", "False"]], [["-114.0", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-114.0", "False"], ["-111.5", "False"]], "doc_hash": "01891575fe913e99d83940cb64441d7000e5356485ac99246c119aa2e67fc4b3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 1636, "doc": {"premise": "Secure identification should begin in the United States.", "hypothesis": "Secure id would make things safer in the US.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Yes, Secure id would make things safer in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Also, Secure id would make things safer in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? No, Secure id would make things safer in the US."}}, "resps": [[["-112.0", "False"]], [["-113.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-113.0", "False"], ["-117.0", "False"]], "doc_hash": "8a9beceaf3aead34053c5155302eb8256a5307da6123a5be45d59de0e6bbe283", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.26762315 0.00490169]"]}
{"doc_id": 1644, "doc": {"premise": "At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed.", "hypothesis": "The FDNY Chief of Department saw the South Tower collapse.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Yes, The FDNY Chief of Department saw the South Tower collapse."}, "gen_args_1": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Also, The FDNY Chief of Department saw the South Tower collapse."}, "gen_args_2": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? No, The FDNY Chief of Department saw the South Tower collapse."}}, "resps": [[["-163.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "877a72ad8ce890f4f84b527da09f06bb00c51484bc4c3e610452e2d14cc9baa9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1652, "doc": {"premise": "He also ordered Secretary Rumsfeld to develop a military plan against the Taliban.", "hypothesis": "Secretary Rumsfeld developed a military plan right away.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Yes, Secretary Rumsfeld developed a military plan right away."}, "gen_args_1": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? Also, Secretary Rumsfeld developed a military plan right away."}, "gen_args_2": {"arg_0": "", "arg_1": " He also ordered Secretary Rumsfeld to develop a military plan against the Taliban., right? No, Secretary Rumsfeld developed a military plan right away."}}, "resps": [[["-102.0", "False"]], [["-108.5", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-102.0", "False"], ["-108.5", "False"], ["-105.5", "False"]], "doc_hash": "87e6deabf67f9063e17b4ac1156d30ff2a6a1831ff48e67a62bd450999aecb33", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 1660, "doc": {"premise": "Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11.", "hypothesis": "The Sentencing Order was issued in 2003.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Yes, The Sentencing Order was issued in 2003."}, "gen_args_1": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Also, The Sentencing Order was issued in 2003."}, "gen_args_2": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? No, The Sentencing Order was issued in 2003."}}, "resps": [[["-189.0", "False"]], [["-194.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-194.0", "False"], ["-189.0", "False"]], "doc_hash": "e05fa093372950bcd2845316dd06202cd6c9c551a874aec7f1351fea0f0af664", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 1668, "doc": {"premise": "The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq.", "hypothesis": "Muslims in Somalia are sometimes threatened by tyrants.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Yes, Muslims in Somalia are sometimes threatened by tyrants."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Also, Muslims in Somalia are sometimes threatened by tyrants."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? No, Muslims in Somalia are sometimes threatened by tyrants."}}, "resps": [[["-134.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "45ad923ea62a85b05460c876b57186f442a8c936e6ed7e74f84eca2be305b524", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.99541338e-01 1.23353201e-04 3.35308764e-04]"]}
{"doc_id": 1676, "doc": {"premise": "His relationship with her remained close throughout his time in the United States.", "hypothesis": "He spent time in the United States.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Yes, He spent time in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? Also, He spent time in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " His relationship with her remained close throughout his time in the United States., right? No, He spent time in the United States."}}, "resps": [[["-98.0", "False"]], [["-101.5", "False"]], [["-99.5", "False"]]], "filtered_resps": [["-98.0", "False"], ["-101.5", "False"], ["-99.5", "False"]], "doc_hash": "3b1707bd1b2f51b5d24e2a4e884ada759694759c84b15561ba01dc5c686d5ab0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 1684, "doc": {"premise": "We will recap it briefly here.", "hypothesis": "This summary will not take much time.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Yes, This summary will not take much time."}, "gen_args_1": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Also, This summary will not take much time."}, "gen_args_2": {"arg_0": "", "arg_1": " We will recap it briefly here., right? No, This summary will not take much time."}}, "resps": [[["-92.5", "False"]], [["-97.0", "False"]], [["-94.0", "False"]]], "filtered_resps": [["-92.5", "False"], ["-97.0", "False"], ["-94.0", "False"]], "doc_hash": "626754f1d2e4346b34a309e41c9f90a045eec12bfc5daa71839c866ffc640c5b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81021575 0.00900068 0.18078357]"]}
{"doc_id": 1692, "doc": {"premise": "After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism.", "hypothesis": "Sudan supported terrorists with cash payments and training.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Yes, Sudan supported terrorists with cash payments and training."}, "gen_args_1": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Also, Sudan supported terrorists with cash payments and training."}, "gen_args_2": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? No, Sudan supported terrorists with cash payments and training."}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-138.0", "False"]], "doc_hash": "0368f9ea2d27cd484e97bb9b5c9c385c4002e4e56250b0ecb7c2f3086b369957", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1700, "doc": {"premise": "His key personnel shared very little information with the National Security Council and the rest of the national security community.", "hypothesis": "The National Security Council wished they had received more information about any threats to air travel.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Yes, The National Security Council wished they had received more information about any threats to air travel."}, "gen_args_1": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? Also, The National Security Council wished they had received more information about any threats to air travel."}, "gen_args_2": {"arg_0": "", "arg_1": " His key personnel shared very little information with the National Security Council and the rest of the national security community., right? No, The National Security Council wished they had received more information about any threats to air travel."}}, "resps": [[["-156.0", "False"]], [["-158.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-158.0", "False"], ["-156.0", "False"]], "doc_hash": "759588e5b8b972c2890b3052ced14d19b04ae62099660e8461b9175131648da7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1708, "doc": {"premise": "For units staged at the Brooklyn-Battery tunnel, see ibid.", "hypothesis": "There were several units at the tunnel.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Yes, There were several units at the tunnel."}, "gen_args_1": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Also, There were several units at the tunnel."}, "gen_args_2": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? No, There were several units at the tunnel."}}, "resps": [[["-127.0", "False"]], [["-131.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-131.0", "False"], ["-128.0", "False"]], "doc_hash": "dd2645cda1088f33a231286ee385d02b7884674c9ed2116ca2f6a1e0cc21af36", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1716, "doc": {"premise": "A jet fuel fireball erupted upon impact and shot down at least one bank of elevators.", "hypothesis": "The fire was hot enough to melt some of the glass windows in the area.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Yes, The fire was hot enough to melt some of the glass windows in the area."}, "gen_args_1": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Also, The fire was hot enough to melt some of the glass windows in the area."}, "gen_args_2": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? No, The fire was hot enough to melt some of the glass windows in the area."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-141.0", "False"]], "doc_hash": "91a098e36c395ddfb524f0890bb757008633f446e5b2f1d1239e08d96fa40a4f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1724, "doc": {"premise": "Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted.", "hypothesis": "They received extra inspections because they wore funny looking hats.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Yes, They received extra inspections because they wore funny looking hats."}, "gen_args_1": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? Also, They received extra inspections because they wore funny looking hats."}, "gen_args_2": {"arg_0": "", "arg_1": " Four of the 9/11 attackers were pulled into secondary border inspection, but then admitted., right? No, They received extra inspections because they wore funny looking hats."}}, "resps": [[["-159.0", "False"]], [["-159.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-159.0", "False"], ["-158.0", "False"]], "doc_hash": "111408c5651db6a67865ba94187c3a3513c8ea0e89579d95afe6147db1e4a2ce", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1732, "doc": {"premise": "The U.S. government readily provides copious information about spending on its military forces, including military intelligence.", "hypothesis": "The US government spends money on their military intelligence.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Yes, The US government spends money on their military intelligence."}, "gen_args_1": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Also, The US government spends money on their military intelligence."}, "gen_args_2": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? No, The US government spends money on their military intelligence."}}, "resps": [[["-135.0", "False"]], [["-140.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-140.0", "False"], ["-138.0", "False"]], "doc_hash": "6edc7e072c5460e08e30cc8ceec59e720f60d94b4357d1b5c9e5c0bd8cd08a20", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1740, "doc": {"premise": "For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr.", "hypothesis": "Nobody knows what the instructor's reaction was.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Yes, Nobody knows what the instructor's reaction was."}, "gen_args_1": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Also, Nobody knows what the instructor's reaction was."}, "gen_args_2": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? No, Nobody knows what the instructor's reaction was."}}, "resps": [[["-170.0", "False"]], [["-171.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-171.0", "False"], ["-166.0", "False"]], "doc_hash": "e61fbbd55c6875fa7e61cdd8885a82c33ac72ecdca7eed495c7147533dd790a7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1748, "doc": {"premise": "It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence.", "hypothesis": "Our law school needs money to continue to grow.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Yes, Our law school needs money to continue to grow."}, "gen_args_1": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? Also, Our law school needs money to continue to grow."}, "gen_args_2": {"arg_0": "", "arg_1": " It takes a partnership of private support and University funding for our law school to continue to grow in stature and influence., right? No, Our law school needs money to continue to grow."}}, "resps": [[["-129.0", "False"]], [["-135.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-135.0", "False"], ["-132.0", "False"]], "doc_hash": "4db483b4ddd315762cfa8397c9ec46c33666831465785dda9aba31649cdcaef6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1756, "doc": {"premise": "Thank you for supporting the Indianapolis Museum of Art in 1999.", "hypothesis": "Thanks but no thanks for lapsing on your donations in 1999.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Yes, Thanks but no thanks for lapsing on your donations in 1999."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Also, Thanks but no thanks for lapsing on your donations in 1999."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? No, Thanks but no thanks for lapsing on your donations in 1999."}}, "resps": [[["-124.0", "False"]], [["-119.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-119.5", "False"], ["-122.5", "False"]], "doc_hash": "4e730b39810319a3248bba1f89b5b4c881754a47b80f184ffa1485971b7840f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01047133 0.94259941 0.04692926]"]}
{"doc_id": 1764, "doc": {"premise": "P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country.", "hypothesis": "There was another theater that recently celebrated its 84th anniversary, but then it burned down.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Yes, There was another theater that recently celebrated its 84th anniversary, but then it burned down."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Also, There was another theater that recently celebrated its 84th anniversary, but then it burned down."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? No, There was another theater that recently celebrated its 84th anniversary, but then it burned down."}}, "resps": [[["-181.0", "False"]], [["-183.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-183.0", "False"], ["-182.0", "False"]], "doc_hash": "71873a86d9ae182e8a7b23691469b83c0655b0bb591bbf4af50daa9de256ca2e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1772, "doc": {"premise": "(dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling.", "hypothesis": "It's staffed by 20 volunteers each day.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Yes, It's staffed by 20 volunteers each day."}, "gen_args_1": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? Also, It's staffed by 20 volunteers each day."}, "gen_args_2": {"arg_0": "", "arg_1": " (dba), a charitable, all-volunteer, nonprofit membership organization, provides free self-employment and business information and assistance to enterprising individuals with disabilities, and for professionals in vocational rehabilitation, career and business counseling., right? No, It's staffed by 20 volunteers each day."}}, "resps": [[["-216.0", "False"]], [["-217.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-216.0", "False"], ["-217.0", "False"], ["-214.0", "False"]], "doc_hash": "fe2b03bae72ce8b157e5335d907094941b1a74218e7cda360bd93b7685db53e0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1780, "doc": {"premise": "From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage.", "hypothesis": "The state of Indiana has only one medical school.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Yes, The state of Indiana has only one medical school."}, "gen_args_1": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Also, The state of Indiana has only one medical school."}, "gen_args_2": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? No, The state of Indiana has only one medical school."}}, "resps": [[["-140.0", "False"]], [["-145.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-145.0", "False"], ["-141.0", "False"]], "doc_hash": "d3ba8e89cdf075506fe35d2133dcd7d2701e7e790e08294ed8a821ece6e33080", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1788, "doc": {"premise": "We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th.", "hypothesis": "We have no intention of ever contacting those who have not donated this fiscal year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Yes, We have no intention of ever contacting those who have not donated this fiscal year."}, "gen_args_1": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Also, We have no intention of ever contacting those who have not donated this fiscal year."}, "gen_args_2": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? No, We have no intention of ever contacting those who have not donated this fiscal year."}}, "resps": [[["-172.0", "False"]], [["-176.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-176.0", "False"], ["-168.0", "False"]], "doc_hash": "085529dc70d1c551a91c481a6d5547d705bdd4f853b6c2d2790dbe0ce780c6cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 1796, "doc": {"premise": "The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable.", "hypothesis": "The homes were more expensive to create than expected.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Yes, The homes were more expensive to create than expected."}, "gen_args_1": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? Also, The homes were more expensive to create than expected."}, "gen_args_2": {"arg_0": "", "arg_1": " The cost of creating these homes far exceeds what our buyers cm pay, so we rely on grants and individual donations to keep them affordable., right? No, The homes were more expensive to create than expected."}}, "resps": [[["-167.0", "False"]], [["-169.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-169.0", "False"], ["-164.0", "False"]], "doc_hash": "56b49b715ac35d4800e46984aae9faea12e2cdfe401783c9041426b1171bf8ae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1804, "doc": {"premise": "I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year.", "hypothesis": "You gave enough last year, so please reduce it by $25 this time around.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Yes, You gave enough last year, so please reduce it by $25 this time around."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Also, You gave enough last year, so please reduce it by $25 this time around."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? No, You gave enough last year, so please reduce it by $25 this time around."}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-180.0", "False"]], "doc_hash": "d83edb283ba84b9ccf5d64b3eed8c736b424a24954e94772cafeb961ffdffc86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1812, "doc": {"premise": "Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan.", "hypothesis": "The Society cares for animals that are almost extinct in Africa.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Yes, The Society cares for animals that are almost extinct in Africa."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Also, The Society cares for animals that are almost extinct in Africa."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? No, The Society cares for animals that are almost extinct in Africa."}}, "resps": [[["-171.0", "False"]], [["-175.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-175.0", "False"], ["-174.0", "False"]], "doc_hash": "9e05309b290586a02b35a146802fd5ef501875594fe6bcee542452eb02ff74e9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1820, "doc": {"premise": "Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs.", "hypothesis": "You could help us expand our outreach programs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Yes, You could help us expand our outreach programs."}, "gen_args_1": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? Also, You could help us expand our outreach programs."}, "gen_args_2": {"arg_0": "", "arg_1": " Your help today will enable us to strengthen further America's philanthropic heritage by expanding the Center's crucial educational, leadership and outreach programs., right? No, You could help us expand our outreach programs."}}, "resps": [[["-162.0", "False"]], [["-169.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-169.0", "False"], ["-164.0", "False"]], "doc_hash": "91f731a464f95031d13f8c325d68e6bf5d916b2e7df5a1ab18ce6b31a95c93bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 1828, "doc": {"premise": "What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now", "hypothesis": "Some Oscar-winning actors toured Indiana in 1973.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Yes, Some Oscar-winning actors toured Indiana in 1973."}, "gen_args_1": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Also, Some Oscar-winning actors toured Indiana in 1973."}, "gen_args_2": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? No, Some Oscar-winning actors toured Indiana in 1973."}}, "resps": [[["-219.0", "False"]], [["-224.0", "False"]], [["-220.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-224.0", "False"], ["-220.0", "False"]], "doc_hash": "ec6c0240d7e8ee77a82171cfe7ad40f5fa3cbd0aaaa988296196702e34870150", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1836, "doc": {"premise": "Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves.", "hypothesis": "Goldfish, snakes, and nothing else are on the rug's border.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Yes, Goldfish, snakes, and nothing else are on the rug's border."}, "gen_args_1": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Also, Goldfish, snakes, and nothing else are on the rug's border."}, "gen_args_2": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? No, Goldfish, snakes, and nothing else are on the rug's border."}}, "resps": [[["-170.0", "False"]], [["-174.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-174.0", "False"], ["-168.0", "False"]], "doc_hash": "2bcc47885ec18b6ccc2130ed8ab688fa695baed57e57c50a0ea97bc11017403c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1844, "doc": {"premise": "Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school.", "hypothesis": "The Maennerchor Society is privately funded by Bill Gates.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Yes, The Maennerchor Society is privately funded by Bill Gates."}, "gen_args_1": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? Also, The Maennerchor Society is privately funded by Bill Gates."}, "gen_args_2": {"arg_0": "", "arg_1": " Your contributions to the Annual Fund at the Maennerchor Society level have provided significant assistance to the school., right? No, The Maennerchor Society is privately funded by Bill Gates."}}, "resps": [[["-163.0", "False"]], [["-164.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-164.0", "False"], ["-163.0", "False"]], "doc_hash": "bf5e9178b2226ccb68edcb66227376921cbf6d7176e802b9e0d9d93350dbadef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1852, "doc": {"premise": "Others continue to notice our success.", "hypothesis": "We are succeeding when it comes to raising capital.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Yes, We are succeeding when it comes to raising capital."}, "gen_args_1": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Also, We are succeeding when it comes to raising capital."}, "gen_args_2": {"arg_0": "", "arg_1": " Others continue to notice our success., right? No, We are succeeding when it comes to raising capital."}}, "resps": [[["-98.0", "False"]], [["-105.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-98.0", "False"], ["-105.0", "False"], ["-104.5", "False"]], "doc_hash": "304a2672663701360e0412551c07c13e90023d439d9f4f4c641786629640edc1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.97590499e-01 9.09684785e-04 1.49981665e-03]"]}
{"doc_id": 1860, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!", "hypothesis": "Organizations just like yours are what help form fantastic connections each and every day.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Yes, Organizations just like yours are what help form fantastic connections each and every day."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Also, Organizations just like yours are what help form fantastic connections each and every day."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? No, Organizations just like yours are what help form fantastic connections each and every day."}}, "resps": [[["-167.0", "False"]], [["-172.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-172.0", "False"], ["-165.0", "False"]], "doc_hash": "c0c7b96e0f04c6f9bed24ee2dbbe847ee7c5c4b988d4548f036881efeeb80da1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19107257e-01 8.02538386e-04 8.80090205e-01]"]}
{"doc_id": 1868, "doc": {"premise": "Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age.", "hypothesis": "There are programs to make kids interested in the library.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Yes, There are programs to make kids interested in the library."}, "gen_args_1": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? Also, There are programs to make kids interested in the library."}, "gen_args_2": {"arg_0": "", "arg_1": " Friends' programs such as Young Library Leaders and the Love is Reading Together Week target young people and instill library habits at an early age., right? No, There are programs to make kids interested in the library."}}, "resps": [[["-179.0", "False"]], [["-182.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-182.0", "False"], ["-183.0", "False"]], "doc_hash": "e78cc131fadb5708be9c410e32a838c513766b10b9499f5b496622228191f37b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 1876, "doc": {"premise": "The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars.", "hypothesis": "The rug is neon green and has a picture of Bart Simpson on it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Yes, The rug is neon green and has a picture of Bart Simpson on it."}, "gen_args_1": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Also, The rug is neon green and has a picture of Bart Simpson on it."}, "gen_args_2": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? No, The rug is neon green and has a picture of Bart Simpson on it."}}, "resps": [[["-155.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "a75be8e3aabce696579e9c82d60e830e7089694e4d5b6115c8431127f95998e4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 1884, "doc": {"premise": "It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!", "hypothesis": "Don't visit the school, just send money.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Yes, Don't visit the school, just send money."}, "gen_args_1": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Also, Don't visit the school, just send money."}, "gen_args_2": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? No, Don't visit the school, just send money."}}, "resps": [[["-153.0", "False"]], [["-158.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-158.0", "False"], ["-149.0", "False"]], "doc_hash": "eedc121fd2427ba22e809e03d6e44f29b20a8cf1e00b34c801e8c53aa0cb7a16", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 1892, "doc": {"premise": "When Urban left for Vietnam, we'd only been married a short time, JoAnn said.", "hypothesis": "JoAnn said that she and Urban hadn't been married long when he left for Vietnam.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Yes, JoAnn said that she and Urban hadn't been married long when he left for Vietnam."}, "gen_args_1": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? Also, JoAnn said that she and Urban hadn't been married long when he left for Vietnam."}, "gen_args_2": {"arg_0": "", "arg_1": " When Urban left for Vietnam, we'd only been married a short time, JoAnn said., right? No, JoAnn said that she and Urban hadn't been married long when he left for Vietnam."}}, "resps": [[["-131.0", "False"]], [["-137.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-137.0", "False"], ["-134.0", "False"]], "doc_hash": "5feff3d8253d2acaf2c8170deda2ea471ab7a7abaeb7cc9748431ca3847c6a95", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1900, "doc": {"premise": "00 invested in a job-training program for a person on welfare saves $3.", "hypothesis": "Five percent of the nation's population above twenty-five years of age is on welfare.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Yes, Five percent of the nation's population above twenty-five years of age is on welfare."}, "gen_args_1": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Also, Five percent of the nation's population above twenty-five years of age is on welfare."}, "gen_args_2": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? No, Five percent of the nation's population above twenty-five years of age is on welfare."}}, "resps": [[["-147.0", "False"]], [["-147.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-147.0", "False"], ["-149.0", "False"]], "doc_hash": "8fff67dbea6839fe203852fdbab812371c0e52e002978b6447ee8f358a7e79a4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 1908, "doc": {"premise": "If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed.", "hypothesis": "The Salvation Army does not handle medical needs.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Yes, The Salvation Army does not handle medical needs."}, "gen_args_1": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Also, The Salvation Army does not handle medical needs."}, "gen_args_2": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? No, The Salvation Army does not handle medical needs."}}, "resps": [[["-134.0", "False"]], [["-137.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-137.0", "False"], ["-130.0", "False"]], "doc_hash": "a4067ea92e98637b2d5c3e086754a76ed083a6a8ca4a9853236649b288a8dacc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1916, "doc": {"premise": "Many see philanthropy as no more than the grand gestures of the rich.", "hypothesis": "Some people think they're too poor to give any money, so they ignore our calls.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Yes, Some people think they're too poor to give any money, so they ignore our calls."}, "gen_args_1": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? Also, Some people think they're too poor to give any money, so they ignore our calls."}, "gen_args_2": {"arg_0": "", "arg_1": " Many see philanthropy as no more than the grand gestures of the rich., right? No, Some people think they're too poor to give any money, so they ignore our calls."}}, "resps": [[["-139.0", "False"]], [["-137.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-137.0", "False"], ["-139.0", "False"]], "doc_hash": "affafdb8c425293af856242bdd8709634c334c5bcce797b2981c37d0b3124bc5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 1924, "doc": {"premise": "McCoy invites the support of The __ Company Foundation in the amount of $10,000.", "hypothesis": "McCoy is requesting $10,000 worth of support.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Yes, McCoy is requesting $10,000 worth of support."}, "gen_args_1": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Also, McCoy is requesting $10,000 worth of support."}, "gen_args_2": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? No, McCoy is requesting $10,000 worth of support."}}, "resps": [[["-136.0", "False"]], [["-143.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-143.0", "False"], ["-132.0", "False"]], "doc_hash": "6e39d7fdcff7a87a75130009911f987e4ecba47a7d9fddea795b17a77ad60f02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.79859150e-02 1.64010315e-05 9.81997684e-01]"]}
{"doc_id": 1932, "doc": {"premise": "The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school.", "hypothesis": "Indiana is the first state dental association to work with a dental school in such a way.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Yes, Indiana is the first state dental association to work with a dental school in such a way."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Also, Indiana is the first state dental association to work with a dental school in such a way."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? No, Indiana is the first state dental association to work with a dental school in such a way."}}, "resps": [[["-158.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "4007cbb8d6c5b61fb0aaa9f79fcfb5153b366ca64d6754e5590cab51522f63de", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1940, "doc": {"premise": "These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state.", "hypothesis": "Students don't learn anything from visiting campus.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Yes, Students don't learn anything from visiting campus."}, "gen_args_1": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? Also, Students don't learn anything from visiting campus."}, "gen_args_2": {"arg_0": "", "arg_1": " These can include unforeseen chances to enhance student and faculty learning by inviting special visitors and scholars to the campus when they happen to be in the state., right? No, Students don't learn anything from visiting campus."}}, "resps": [[["-182.0", "False"]], [["-182.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-182.0", "False"], ["-175.0", "False"]], "doc_hash": "36d49059588c4bce91c3ee188d7866b0bc8f52ffa374d61f2ccb76bb452c4d19", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10221936e-04 9.10221936e-04 9.98179556e-01]"]}
{"doc_id": 1948, "doc": {"premise": "As with all gifts to the Institute, 100% of your contribution will be used directly for research.", "hypothesis": "Every penny you donate helps research.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Yes, Every penny you donate helps research."}, "gen_args_1": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Also, Every penny you donate helps research."}, "gen_args_2": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? No, Every penny you donate helps research."}}, "resps": [[["-109.5", "False"]], [["-114.0", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-109.5", "False"], ["-114.0", "False"], ["-111.5", "False"]], "doc_hash": "ae62b14ee4655670d35accd4b6448c41d82cbb5b3533fb51cb476575aa2039bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 1956, "doc": {"premise": "If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today.", "hypothesis": "Bob Lovell can answer questions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Yes, Bob Lovell can answer questions."}, "gen_args_1": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Also, Bob Lovell can answer questions."}, "gen_args_2": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? No, Bob Lovell can answer questions."}}, "resps": [[["-149.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "6e4ce2103d4df23f67257064b359ce9994205b046d0d59f69939f7f631d4f25e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1964, "doc": {"premise": "Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre.", "hypothesis": "The Civic Theater is located in Tampa.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Yes, The Civic Theater is located in Tampa."}, "gen_args_1": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? Also, The Civic Theater is located in Tampa."}, "gen_args_2": {"arg_0": "", "arg_1": " Many more arts and cultural opportunities exist in Indianapolis, yet none finer than Civic Theatre., right? No, The Civic Theater is located in Tampa."}}, "resps": [[["-141.0", "False"]], [["-145.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-145.0", "False"], ["-141.0", "False"]], "doc_hash": "fb998a93d901a505d581cf3dd763713d9de47a4a0e22b509dee777d8f4121342", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1972, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations.", "hypothesis": "The Society doesn't have anything to do with people.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Yes, The Society doesn't have anything to do with people."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Also, The Society doesn't have anything to do with people."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? No, The Society doesn't have anything to do with people."}}, "resps": [[["-141.0", "False"]], [["-141.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-141.0", "False"], ["-138.0", "False"]], "doc_hash": "bf1ee45addacf670474d580a0b662325e5e2b8ab5ee7a3d731718609e0df0f38", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1980, "doc": {"premise": "Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education.", "hypothesis": "The IU School of Law has 1000 students.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Yes, The IU School of Law has 1000 students."}, "gen_args_1": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Also, The IU School of Law has 1000 students."}, "gen_args_2": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? No, The IU School of Law has 1000 students."}}, "resps": [[["-167.0", "False"]], [["-169.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-169.0", "False"], ["-168.0", "False"]], "doc_hash": "928b38bbdb552581b23678041c3ba8e1909e5362a9f3b429cc4bdd22fdf6d560", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1988, "doc": {"premise": "For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000.", "hypothesis": "The law school was the first program to face budget cuts.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Yes, The law school was the first program to face budget cuts."}, "gen_args_1": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? Also, The law school was the first program to face budget cuts."}, "gen_args_2": {"arg_0": "", "arg_1": " For this fiscal year and next, the law school is required to absorb reductions in its state appropriation and increased health costs totaling more than $400,000., right? No, The law school was the first program to face budget cuts."}}, "resps": [[["-168.0", "False"]], [["-172.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-172.0", "False"], ["-167.0", "False"]], "doc_hash": "af4c72f622bfe1e6c7596115cde8ecca0b06edd0ac6acc21de6fd7befa9a6671", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1996, "doc": {"premise": "The newsweeklies' cover packages pander to anxious parents.", "hypothesis": "Newsweeklies design their cover packages to appeal to small children or the elderly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Yes, Newsweeklies design their cover packages to appeal to small children or the elderly."}, "gen_args_1": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Also, Newsweeklies design their cover packages to appeal to small children or the elderly."}, "gen_args_2": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? No, Newsweeklies design their cover packages to appeal to small children or the elderly."}}, "resps": [[["-143.0", "False"]], [["-143.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-143.0", "False"], ["-140.0", "False"]], "doc_hash": "4fe5314b2bc934df7f0276572b19a4c0e44678d3608f38b281747206d5d828af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 2004, "doc": {"premise": "Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age.", "hypothesis": "Kim Kardashian wrote the cover story for Time magazine about the 12 steps needed for success in the digital age.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Yes, Kim Kardashian wrote the cover story for Time magazine about the 12 steps needed for success in the digital age."}, "gen_args_1": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Also, Kim Kardashian wrote the cover story for Time magazine about the 12 steps needed for success in the digital age."}, "gen_args_2": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? No, Kim Kardashian wrote the cover story for Time magazine about the 12 steps needed for success in the digital age."}}, "resps": [[["-142.0", "False"]], [["-147.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-147.0", "False"], ["-143.0", "False"]], "doc_hash": "3af015373a52f6a4eb55ec2005d36fd164a78a8385d85855a4d11470a63bf15b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2012, "doc": {"premise": "Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory.", "hypothesis": "Paul thinks Alan Greenspan is the smartest economist he knows.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Yes, Paul thinks Alan Greenspan is the smartest economist he knows."}, "gen_args_1": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? Also, Paul thinks Alan Greenspan is the smartest economist he knows."}, "gen_args_2": {"arg_0": "", "arg_1": " Paul seems to regard Alan Greenspan as an ideologue who actually does control the unemployment rate according to the dictates of some economic theory., right? No, Paul thinks Alan Greenspan is the smartest economist he knows."}}, "resps": [[["-163.0", "False"]], [["-165.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-165.0", "False"], ["-162.0", "False"]], "doc_hash": "99368f5fb68105804cdeb351214a1bb942f7d42d35f21d3e928cda73f3a4258c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2020, "doc": {"premise": "The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position.", "hypothesis": "The Nerds are not good with social interaction.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Yes, The Nerds are not good with social interaction."}, "gen_args_1": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Also, The Nerds are not good with social interaction."}, "gen_args_2": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? No, The Nerds are not good with social interaction."}}, "resps": [[["-153.0", "False"]], [["-156.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-156.0", "False"], ["-156.0", "False"]], "doc_hash": "3975a7cf254a98494c65caf38555ffe5ffc89cc42352619cfd1a40774b1ad16e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 2028, "doc": {"premise": "Which is more than the News Quiz can promise about Fox.", "hypothesis": "It's less than News Quiz can promise about Fox.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Yes, It's less than News Quiz can promise about Fox."}, "gen_args_1": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Also, It's less than News Quiz can promise about Fox."}, "gen_args_2": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? No, It's less than News Quiz can promise about Fox."}}, "resps": [[["-115.5", "False"]], [["-118.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-115.5", "False"], ["-118.0", "False"], ["-115.0", "False"]], "doc_hash": "7bccb30817217195f287999722b3f197ccc7211bfdca7106a840928aa1f605cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.36619222 0.03005889 0.6037489 ]"]}
{"doc_id": 2036, "doc": {"premise": "Population growth is like pollution in reverse.", "hypothesis": "There is no relation between population growth and pollution.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Yes, There is no relation between population growth and pollution."}, "gen_args_1": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? Also, There is no relation between population growth and pollution."}, "gen_args_2": {"arg_0": "", "arg_1": " Population growth is like pollution in reverse., right? No, There is no relation between population growth and pollution."}}, "resps": [[["-89.5", "False"]], [["-94.0", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-89.5", "False"], ["-94.0", "False"], ["-86.0", "False"]], "doc_hash": "c11b8857acccaa56cd7c934cdc6ec3ebd0bb3f78c5ba5c455298cd75e200fec7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93026889e-02 3.25523470e-04 9.70371788e-01]"]}
{"doc_id": 2044, "doc": {"premise": "The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history.", "hypothesis": "The movie, First Wives Club, set film industry records as the highest grossing women's film on it's first weekend.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Yes, The movie, First Wives Club, set film industry records as the highest grossing women's film on it's first weekend."}, "gen_args_1": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Also, The movie, First Wives Club, set film industry records as the highest grossing women's film on it's first weekend."}, "gen_args_2": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? No, The movie, First Wives Club, set film industry records as the highest grossing women's film on it's first weekend."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-170.0", "False"]], "doc_hash": "1427a449554f24fcb31a9d1c3cbc543d49512507b929c17cdd99f3e545e27505", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 2052, "doc": {"premise": "Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed.", "hypothesis": "Jon Benet Ramsey's half-brother was not in town when the murder was committed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Yes, Jon Benet Ramsey's half-brother was not in town when the murder was committed."}, "gen_args_1": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Also, Jon Benet Ramsey's half-brother was not in town when the murder was committed."}, "gen_args_2": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? No, Jon Benet Ramsey's half-brother was not in town when the murder was committed."}}, "resps": [[["-150.0", "False"]], [["-151.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-151.0", "False"], ["-149.0", "False"]], "doc_hash": "ff3873d09a41008461f5f5bcdec86022c43ca12aa4a0f9d777d1e3b220f35e2f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2060, "doc": {"premise": "The junk yards of history are strewn with wreckage.", "hypothesis": "The evidence is the wreckage in the junk yards of history.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Yes, The evidence is the wreckage in the junk yards of history."}, "gen_args_1": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? Also, The evidence is the wreckage in the junk yards of history."}, "gen_args_2": {"arg_0": "", "arg_1": " The junk yards of history are strewn with wreckage., right? No, The evidence is the wreckage in the junk yards of history."}}, "resps": [[["-116.0", "False"]], [["-119.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-119.5", "False"], ["-116.0", "False"]], "doc_hash": "392b34bf4a3403a9bb73d32b520ac8056414e96a931a64961be9209ca4c8727d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49256294 0.01487411 0.49256294]"]}
{"doc_id": 2068, "doc": {"premise": "Pundits often say history is written by the winners.", "hypothesis": "Pundits say people who win the lottery tell history.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Yes, Pundits say people who win the lottery tell history."}, "gen_args_1": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Also, Pundits say people who win the lottery tell history."}, "gen_args_2": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? No, Pundits say people who win the lottery tell history."}}, "resps": [[["-105.5", "False"]], [["-104.5", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-105.5", "False"], ["-104.5", "False"], ["-100.0", "False"]], "doc_hash": "c956a5dde9c6c3f2c79d1daa6619668df38f0afc0f39b4134cef5a2a8e960fef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0040256  0.01094271 0.98503169]"]}
{"doc_id": 2076, "doc": {"premise": "Thank You, Sir, Could I Have Another Answer", "hypothesis": "I appreciate that, Sir; may I get another answer.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Yes, I appreciate that, Sir; may I get another answer."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Also, I appreciate that, Sir; may I get another answer."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? No, I appreciate that, Sir; may I get another answer."}}, "resps": [[["-108.0", "False"]], [["-116.0", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-116.0", "False"], ["-110.0", "False"]], "doc_hash": "a554752e64142a44d7e29748ad2aa18b6dcc0d72b8cdec0bf58316896a31ed7e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 2084, "doc": {"premise": "Prudie agrees there is something tacky about being seen chewing gum.", "hypothesis": "Prudie thinks that it is not a good thing to be seen chewing gum.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Yes, Prudie thinks that it is not a good thing to be seen chewing gum."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? Also, Prudie thinks that it is not a good thing to be seen chewing gum."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie agrees there is something tacky about being seen chewing gum., right? No, Prudie thinks that it is not a good thing to be seen chewing gum."}}, "resps": [[["-118.0", "False"]], [["-123.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-118.0", "False"], ["-123.5", "False"], ["-122.5", "False"]], "doc_hash": "1b28181a03f198f1c294de01c5de6e8c24271d891ed257f214cff1a23082a190", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98503169 0.0040256  0.01094271]"]}
{"doc_id": 2092, "doc": {"premise": "TV dinners carry a terrible stigma.", "hypothesis": "People can watch dinners on TV.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Yes, People can watch dinners on TV."}, "gen_args_1": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Also, People can watch dinners on TV."}, "gen_args_2": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? No, People can watch dinners on TV."}}, "resps": [[["-104.5", "False"]], [["-105.5", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-104.5", "False"], ["-105.5", "False"], ["-104.0", "False"]], "doc_hash": "b26e8cd5d3e7282cee1d5e45b9ad32105e3ed22039d611d2834ea0d5f6d02ee5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.33149896 0.12195165 0.54654939]"]}
{"doc_id": 2100, "doc": {"premise": "Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason.", "hypothesis": "Faith and reason can be reconciled using some controversial approaches.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Yes, Faith and reason can be reconciled using some controversial approaches."}, "gen_args_1": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Also, Faith and reason can be reconciled using some controversial approaches."}, "gen_args_2": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? No, Faith and reason can be reconciled using some controversial approaches."}}, "resps": [[["-143.0", "False"]], [["-150.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-150.0", "False"], ["-148.0", "False"]], "doc_hash": "d711fde48d4f91a71afe281186a2ee31457c2e24c69aa7029e881fd41cab5916", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 9.04959183e-04 6.68679417e-03]"]}
{"doc_id": 2108, "doc": {"premise": "Let me show you how the American people in the end viewed your performance as independent counsel.", "hypothesis": "The American people were not pleased with your performance as independent counsel.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Yes, The American people were not pleased with your performance as independent counsel."}, "gen_args_1": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? Also, The American people were not pleased with your performance as independent counsel."}, "gen_args_2": {"arg_0": "", "arg_1": " Let me show you how the American people in the end viewed your performance as independent counsel., right? No, The American people were not pleased with your performance as independent counsel."}}, "resps": [[["-127.0", "False"]], [["-131.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-131.0", "False"], ["-127.0", "False"]], "doc_hash": "ad2a28418902d988b0eb9499b551b477fd8fd164d61c0b4ad37d766cef077ac8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 2116, "doc": {"premise": "The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers.", "hypothesis": "The trip to Texas was fun getting to learn about Christian's beliefs and motivations.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Yes, The trip to Texas was fun getting to learn about Christian's beliefs and motivations."}, "gen_args_1": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Also, The trip to Texas was fun getting to learn about Christian's beliefs and motivations."}, "gen_args_2": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? No, The trip to Texas was fun getting to learn about Christian's beliefs and motivations."}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-176.0", "False"]], "doc_hash": "4f8cb9fe801d6f91ee3d10416122672d1497ea27a9d0c63366a3798b4105c0ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2124, "doc": {"premise": "On the other hand, he's got Mark Twain between him and daylight.", "hypothesis": "He has not seen daylight in years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Yes, He has not seen daylight in years."}, "gen_args_1": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Also, He has not seen daylight in years."}, "gen_args_2": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? No, He has not seen daylight in years."}}, "resps": [[["-114.0", "False"]], [["-116.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-116.5", "False"], ["-115.5", "False"]], "doc_hash": "c89e98c2462bff556e8693328db8f0128187de571b100be3ea60fbb13c63097c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.76615721 0.06289001 0.17095278]"]}
{"doc_id": 2132, "doc": {"premise": "Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done.", "hypothesis": "Prudie wants you to laugh.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Yes, Prudie wants you to laugh."}, "gen_args_1": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? Also, Prudie wants you to laugh."}, "gen_args_2": {"arg_0": "", "arg_1": " Prudie wants you to immediately regain your sense of humor and be grateful that your pal stepped in before any, uh, harm was done., right? No, Prudie wants you to laugh."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "0d9cc41432199406001dc4bd5ce72587b9ac6134522ec124dfb018dedda51c6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2140, "doc": {"premise": "The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people.", "hypothesis": "Just because Bugsy Siegel and Kid Twist are a part of our history doesn't mean we're automatically tough.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Yes, Just because Bugsy Siegel and Kid Twist are a part of our history doesn't mean we're automatically tough."}, "gen_args_1": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Also, Just because Bugsy Siegel and Kid Twist are a part of our history doesn't mean we're automatically tough."}, "gen_args_2": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? No, Just because Bugsy Siegel and Kid Twist are a part of our history doesn't mean we're automatically tough."}}, "resps": [[["-154.0", "False"]], [["-156.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-156.0", "False"], ["-152.0", "False"]], "doc_hash": "1de4a661febf63155166b4ec17de12f15fd2cac61e8701a88786fcc10787e394", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2148, "doc": {"premise": "Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?", "hypothesis": "Clarke has worries about how we will respond to the recent violence.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Yes, Clarke has worries about how we will respond to the recent violence."}, "gen_args_1": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Also, Clarke has worries about how we will respond to the recent violence."}, "gen_args_2": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? No, Clarke has worries about how we will respond to the recent violence."}}, "resps": [[["-191.0", "False"]], [["-194.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-194.0", "False"], ["-191.0", "False"]], "doc_hash": "07f28a5e86c3160cf4e888d723599971170d31b4a226458f5c3e4c70cccd7bc2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2156, "doc": {"premise": "Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah.", "hypothesis": "On Thursday Bush complimented his party on painting a picture of America heading towards sunshine.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Yes, On Thursday Bush complimented his party on painting a picture of America heading towards sunshine."}, "gen_args_1": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? Also, On Thursday Bush complimented his party on painting a picture of America heading towards sunshine."}, "gen_args_2": {"arg_0": "", "arg_1": " Tuesday, Bush warned, Too often, on social issues, my party has painted an image of America slouching toward Gomorrah., right? No, On Thursday Bush complimented his party on painting a picture of America heading towards sunshine."}}, "resps": [[["-201.0", "False"]], [["-203.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-203.0", "False"], ["-199.0", "False"]], "doc_hash": "35d7ffd2fa23b910e281d08dc4a5e4fec05ea4d70b2e2ddbfdc25c03438c877e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2164, "doc": {"premise": "Time runs two anti-emotion articles.", "hypothesis": "Time magazine includes two articles against emotion.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Yes, Time magazine includes two articles against emotion."}, "gen_args_1": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Also, Time magazine includes two articles against emotion."}, "gen_args_2": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? No, Time magazine includes two articles against emotion."}}, "resps": [[["-108.5", "False"]], [["-113.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-108.5", "False"], ["-113.0", "False"], ["-110.5", "False"]], "doc_hash": "d8f8acb1aa9655a1c363aaa2546a9cc3e494ac6a401979539cdb5ec45c576566", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87226219 0.00968996 0.11804785]"]}
{"doc_id": 2172, "doc": {"premise": "Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals.", "hypothesis": "Catholics and Christians have some things in common.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Yes, Catholics and Christians have some things in common."}, "gen_args_1": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Also, Catholics and Christians have some things in common."}, "gen_args_2": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? No, Catholics and Christians have some things in common."}}, "resps": [[["-191.0", "False"]], [["-196.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-196.0", "False"], ["-197.0", "False"]], "doc_hash": "34970de52d08095b2ca47ed442580eb17be0f82d5b1d57a39180eae5cb39f4cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00667641 0.00245611]"]}
{"doc_id": 2180, "doc": {"premise": "Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill.", "hypothesis": "New York state has the more senators than other states.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Yes, New York state has the more senators than other states."}, "gen_args_1": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? Also, New York state has the more senators than other states."}, "gen_args_2": {"arg_0": "", "arg_1": " Yet New York state senators and legislators privately admit they assented to the legislation because they were impressed with the ferocity of the support for the bill., right? No, New York state has the more senators than other states."}}, "resps": [[["-180.0", "False"]], [["-177.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-177.0", "False"], ["-183.0", "False"]], "doc_hash": "b3b804eaff4008621f5992f08e4484cd88d596cf1b0bcfee9c8a67b845524e14", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04731416 0.95033021 0.00235563]"]}
{"doc_id": 2188, "doc": {"premise": "So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb.", "hypothesis": "Cuba is in the tropics.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Yes, Cuba is in the tropics."}, "gen_args_1": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Also, Cuba is in the tropics."}, "gen_args_2": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? No, Cuba is in the tropics."}}, "resps": [[["-155.0", "False"]], [["-155.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-155.0", "False"], ["-154.0", "False"]], "doc_hash": "ed836183efd5f5e0357eef1fe3a807534c2f27b67b36a1440a2d8a636a707701", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2196, "doc": {"premise": "This is no secret to music retailers.", "hypothesis": "Music retailers are completely in the dark about this.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Yes, Music retailers are completely in the dark about this."}, "gen_args_1": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Also, Music retailers are completely in the dark about this."}, "gen_args_2": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? No, Music retailers are completely in the dark about this."}}, "resps": [[["-97.0", "False"]], [["-101.5", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-97.0", "False"], ["-101.5", "False"], ["-91.5", "False"]], "doc_hash": "f4290dcdcc7fb68ed4553f034a9b3a6a575ad9efca67a8e479b7f7470fbd8c81", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.06995369e-03 4.52131015e-05 9.95884833e-01]"]}
{"doc_id": 2204, "doc": {"premise": "So why does Gates produce at such a frantic pace?", "hypothesis": "Why does Gates produce at such a slow pace?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Yes, Why does Gates produce at such a slow pace?"}, "gen_args_1": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? Also, Why does Gates produce at such a slow pace?"}, "gen_args_2": {"arg_0": "", "arg_1": " So why does Gates produce at such a frantic pace?, right? No, Why does Gates produce at such a slow pace?"}}, "resps": [[["-104.0", "False"]], [["-102.0", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-102.0", "False"], ["-99.0", "False"]], "doc_hash": "6cebbaf46aa1f799629205cca2d2b46eeaa595e27c4afeb2739731e2cb000eed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00637746 0.04712342 0.94649912]"]}
{"doc_id": 2212, "doc": {"premise": "The MCI Web site spells out the intended method of measuring these home runs.", "hypothesis": "There are established guidelines on the MCI Web site that explain how to measure home runs.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Yes, There are established guidelines on the MCI Web site that explain how to measure home runs."}, "gen_args_1": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Also, There are established guidelines on the MCI Web site that explain how to measure home runs."}, "gen_args_2": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? No, There are established guidelines on the MCI Web site that explain how to measure home runs."}}, "resps": [[["-155.0", "False"]], [["-163.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-163.0", "False"], ["-160.0", "False"]], "doc_hash": "eb8dac385e605dfb1eace498534a1c0c80ad5524c0e9c78ee58f9857a3676553", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92976272e-01 3.33106430e-04 6.69062149e-03]"]}
{"doc_id": 2220, "doc": {"premise": "What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence.", "hypothesis": "Hernstein and Murray used educated and intelligence to determine IQ.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Yes, Hernstein and Murray used educated and intelligence to determine IQ."}, "gen_args_1": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Also, Hernstein and Murray used educated and intelligence to determine IQ."}, "gen_args_2": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? No, Hernstein and Murray used educated and intelligence to determine IQ."}}, "resps": [[["-139.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "dc45fd1b5d6991ad5442ef24d63e05f4d863a6daeaec2ab46281df24afb6a79a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 2228, "doc": {"premise": "There are two evolutionary advantages to looking average.", "hypothesis": "It's ok to look average.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Yes, It's ok to look average."}, "gen_args_1": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? Also, It's ok to look average."}, "gen_args_2": {"arg_0": "", "arg_1": " There are two evolutionary advantages to looking average., right? No, It's ok to look average."}}, "resps": [[["-95.0", "False"]], [["-96.0", "False"]], [["-96.0", "False"]]], "filtered_resps": [["-95.0", "False"], ["-96.0", "False"], ["-96.0", "False"]], "doc_hash": "d0666ca5fc2d0f4b43d8e7c66ec958c16971c4e363248e25c81d116448105b5a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2236, "doc": {"premise": "The Feminization of Culture Answer", "hypothesis": "Culture was feminized.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Yes, Culture was feminized."}, "gen_args_1": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Also, Culture was feminized."}, "gen_args_2": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? No, Culture was feminized."}}, "resps": [[["-82.5", "False"]], [["-92.5", "False"]], [["-89.5", "False"]]], "filtered_resps": [["-82.5", "False"], ["-92.5", "False"], ["-89.5", "False"]], "doc_hash": "9780abce77033b147886cb23607cce5ef8993a6c52acaaf71166a47c75c88ea2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.99043634e-01 4.53565108e-05 9.11009872e-04]"]}
{"doc_id": 2244, "doc": {"premise": "By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less", "hypothesis": "As Skeat entered his sixties he gave off no indication that he was thinking about anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Yes, As Skeat entered his sixties he gave off no indication that he was thinking about anything."}, "gen_args_1": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Also, As Skeat entered his sixties he gave off no indication that he was thinking about anything."}, "gen_args_2": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? No, As Skeat entered his sixties he gave off no indication that he was thinking about anything."}}, "resps": [[["-177.0", "False"]], [["-182.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-182.0", "False"], ["-176.0", "False"]], "doc_hash": "468c294db4ede68d1b27fb0158ecc6567e5c9250dc9236e22233211f794e54fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 2252, "doc": {"premise": "The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator.", "hypothesis": "Dr. Spooner was the longest serving member of New College.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Yes, Dr. Spooner was the longest serving member of New College."}, "gen_args_1": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? Also, Dr. Spooner was the longest serving member of New College."}, "gen_args_2": {"arg_0": "", "arg_1": " The good Dr. Spooner, a kind man with white hair and cherubic face, served New College for a half century as distinguished scholar and able administrator., right? No, Dr. Spooner was the longest serving member of New College."}}, "resps": [[["-176.0", "False"]], [["-182.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-182.0", "False"], ["-181.0", "False"]], "doc_hash": "de34d4405bfdaa7bf4a606503c885c3c9197095bb66fec9490c7d05b429c1f9a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 2260, "doc": {"premise": "Given time and improved technology, all non-radio phones may be branded as wire phones .", "hypothesis": "Phones will improve with technology.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Yes, Phones will improve with technology."}, "gen_args_1": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Also, Phones will improve with technology."}, "gen_args_2": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? No, Phones will improve with technology."}}, "resps": [[["-151.0", "False"]], [["-153.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-153.0", "False"], ["-155.0", "False"]], "doc_hash": "7a2bd528a766e481c9159de1d3877493c8224f5397ee4a3a75c814d208cd4458", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 2268, "doc": {"premise": "Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096.", "hypothesis": "According to Lingua France was spoken after the first Crusade.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Yes, According to Lingua France was spoken after the first Crusade."}, "gen_args_1": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Also, According to Lingua France was spoken after the first Crusade."}, "gen_args_2": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? No, According to Lingua France was spoken after the first Crusade."}}, "resps": [[["-188.0", "False"]], [["-189.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-189.0", "False"], ["-183.0", "False"]], "doc_hash": "19cd7952a2a8913e8f8cb63e6519bbacd1793119fe6b8f2f84d8e1d5288100e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 2276, "doc": {"premise": "If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published.", "hypothesis": "This edition sold more than five hundred thousand copies in its first year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Yes, This edition sold more than five hundred thousand copies in its first year."}, "gen_args_1": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? Also, This edition sold more than five hundred thousand copies in its first year."}, "gen_args_2": {"arg_0": "", "arg_1": " If so, they might be induced to buy this edition because it contains 55 pages of words, definitions, and citations not previously published., right? No, This edition sold more than five hundred thousand copies in its first year."}}, "resps": [[["-168.0", "False"]], [["-170.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-170.0", "False"], ["-169.0", "False"]], "doc_hash": "15eb567c42970b1f060351aa78135da58e2fa9bf56f6b061f187c07ee924b37a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2284, "doc": {"premise": "Today these Germanisms do not even stay put in the United States.", "hypothesis": "These Germanisms are no longer used within the United states.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Yes, These Germanisms are no longer used within the United states."}, "gen_args_1": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Also, These Germanisms are no longer used within the United states."}, "gen_args_2": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? No, These Germanisms are no longer used within the United states."}}, "resps": [[["-127.0", "False"]], [["-132.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-132.0", "False"], ["-127.0", "False"]], "doc_hash": "565642eb54082fc3a89fa477f58ed2fc6e3aa49bce34d27ff5cffa7b406bccc1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 2292, "doc": {"premise": "For example, some have derivations distinctly removed from the equipment used or the court on which the game is played.", "hypothesis": "All sports are named after a piece of equipment used in the sport.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Yes, All sports are named after a piece of equipment used in the sport."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Also, All sports are named after a piece of equipment used in the sport."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? No, All sports are named after a piece of equipment used in the sport."}}, "resps": [[["-166.0", "False"]], [["-165.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-165.0", "False"], ["-164.0", "False"]], "doc_hash": "0e810354afbc38a3360bc1a36f82c8926bd02b23e71c09d94c1b24289705a280", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 2300, "doc": {"premise": "To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing.", "hypothesis": "There could be other titles for a book I could write about the dangers of literacy.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Yes, There could be other titles for a book I could write about the dangers of literacy."}, "gen_args_1": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? Also, There could be other titles for a book I could write about the dangers of literacy."}, "gen_args_2": {"arg_0": "", "arg_1": " To put the matter differently, I could write an essay called  The Perils of Literacy  or  A Little Literacy Is a Dangerous Thing., right? No, There could be other titles for a book I could write about the dangers of literacy."}}, "resps": [[["-171.0", "False"]], [["-172.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-172.0", "False"], ["-172.0", "False"]], "doc_hash": "63649f58b2877fcf69e6888695fe76bc0ecf7f929dc4f552c81694be6cbb8f96", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2308, "doc": {"premise": "I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?", "hypothesis": "I thought that the song lyrics were disappointingly obvious.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Yes, I thought that the song lyrics were disappointingly obvious."}, "gen_args_1": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Also, I thought that the song lyrics were disappointingly obvious."}, "gen_args_2": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? No, I thought that the song lyrics were disappointingly obvious."}}, "resps": [[["-252.0", "False"]], [["-255.0", "False"]], [["-258.0", "False"]]], "filtered_resps": [["-252.0", "False"], ["-255.0", "False"], ["-258.0", "False"]], "doc_hash": "9c4030e98eb264d10ac8267324981fead0a574987ee22c8a86f8acca0e613963", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.95033021 0.04731416 0.00235563]"]}
{"doc_id": 2316, "doc": {"premise": "But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular.", "hypothesis": "The acknowledgements are dedications.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Yes, The acknowledgements are dedications."}, "gen_args_1": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Also, The acknowledgements are dedications."}, "gen_args_2": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? No, The acknowledgements are dedications."}}, "resps": [[["-152.0", "False"]], [["-156.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-156.0", "False"], ["-150.0", "False"]], "doc_hash": "4ba42bf058c0bed0d363e7fc965dc95eef6db64da32ef5ca7631dc0f3fe24736", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 2324, "doc": {"premise": "Make my coat look new, dear, sew it!", "hypothesis": "There are several loose stitches on the lapel of my coat.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Yes, There are several loose stitches on the lapel of my coat."}, "gen_args_1": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? Also, There are several loose stitches on the lapel of my coat."}, "gen_args_2": {"arg_0": "", "arg_1": " Make my coat look new, dear, sew it!, right? No, There are several loose stitches on the lapel of my coat."}}, "resps": [[["-120.5", "False"]], [["-123.0", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-120.5", "False"], ["-123.0", "False"], ["-121.5", "False"]], "doc_hash": "08203cc9cb37c1dd9719c1678f283f12a34438425b7b98e35132a6fa3843e583", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 2332, "doc": {"premise": "Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins.", "hypothesis": "This piece is nothing but a dry analytical analysis.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Yes, This piece is nothing but a dry analytical analysis."}, "gen_args_1": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Also, This piece is nothing but a dry analytical analysis."}, "gen_args_2": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? No, This piece is nothing but a dry analytical analysis."}}, "resps": [[["-164.0", "False"]], [["-167.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-167.0", "False"], ["-166.0", "False"]], "doc_hash": "c9830bffbfefaca89d7280750106a72fb12f0e7eb4b1aec363f83d22d29a8ffb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2340, "doc": {"premise": "The equally whimsical nature of the  definitions' defies description.", "hypothesis": "The definitions are actually quite dry and non descriptive.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Yes, The definitions are actually quite dry and non descriptive."}, "gen_args_1": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Also, The definitions are actually quite dry and non descriptive."}, "gen_args_2": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? No, The definitions are actually quite dry and non descriptive."}}, "resps": [[["-148.0", "False"]], [["-149.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-149.0", "False"], ["-148.0", "False"]], "doc_hash": "6c628e29d0f9d828520287036a776eea37a6d3a4c2c54bc6a608e0b43d0dd7ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2348, "doc": {"premise": "Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account.", "hypothesis": "You can understand what is being communicated by facial expressions and hand gestures even when you can't hear what is being said.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Yes, You can understand what is being communicated by facial expressions and hand gestures even when you can't hear what is being said."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? Also, You can understand what is being communicated by facial expressions and hand gestures even when you can't hear what is being said."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, it is possible to pick out the necessary morsels of information in noisy surroundings, if facial expressions, gestures and other contextual clues are taken into account., right? No, You can understand what is being communicated by facial expressions and hand gestures even when you can't hear what is being said."}}, "resps": [[["-183.0", "False"]], [["-185.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-185.0", "False"], ["-184.0", "False"]], "doc_hash": "f4199e38065432f033a04d140dafd7e6334a21397f1958d52a66febda1f91dbe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2356, "doc": {"premise": "What are you doing becomes  Watch a dune.", "hypothesis": "They say it just as they always have.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Yes, They say it just as they always have."}, "gen_args_1": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Also, They say it just as they always have."}, "gen_args_2": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? No, They say it just as they always have."}}, "resps": [[["-138.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "d81e566deecd2837eebea7170ac6463fd55c9ba7c749ae256e209334fd0719e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2364, "doc": {"premise": "Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth.", "hypothesis": "Even if they can't speak the language, they should be able to answer the questions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Yes, Even if they can't speak the language, they should be able to answer the questions."}, "gen_args_1": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Also, Even if they can't speak the language, they should be able to answer the questions."}, "gen_args_2": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? No, Even if they can't speak the language, they should be able to answer the questions."}}, "resps": [[["-186.0", "False"]], [["-186.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-186.0", "False"], ["-183.0", "False"]], "doc_hash": "695b87605664bbe4e60cc3c290e6f8be0ada678d26b531a9350b2506fae1abc2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 2372, "doc": {"premise": "And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings.", "hypothesis": "Xerography is related to word meanings of technical terms.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Yes, Xerography is related to word meanings of technical terms."}, "gen_args_1": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? Also, Xerography is related to word meanings of technical terms."}, "gen_args_2": {"arg_0": "", "arg_1": " And while xerography has provided both noun and verb newances for the word copy , Horace's ut pictura poesis reminds one that picture , too, has newances coexisting with its age-old meanings., right? No, Xerography is related to word meanings of technical terms."}}, "resps": [[["-264.0", "False"]], [["-268.0", "False"]], [["-268.0", "False"]]], "filtered_resps": [["-264.0", "False"], ["-268.0", "False"], ["-268.0", "False"]], "doc_hash": "6b64060fc56987951ed10df812c94217de930b4ffb72616e7f4a1eeffc9ff235", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2380, "doc": {"premise": "Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included.", "hypothesis": "I'm not in agreement with Hendrickson about the origin of the horse latitudes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Yes, I'm not in agreement with Hendrickson about the origin of the horse latitudes."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Also, I'm not in agreement with Hendrickson about the origin of the horse latitudes."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? No, I'm not in agreement with Hendrickson about the origin of the horse latitudes."}}, "resps": [[["-197.0", "False"]], [["-200.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-200.0", "False"], ["-195.0", "False"]], "doc_hash": "6b61cd271f9e5ee819f8336a24dd66e8e3e126e5023218454bfdfe33211909e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2388, "doc": {"premise": "And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?", "hypothesis": "Kermit is the name for a certain type of telecommunications protocol.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Yes, Kermit is the name for a certain type of telecommunications protocol."}, "gen_args_1": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Also, Kermit is the name for a certain type of telecommunications protocol."}, "gen_args_2": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? No, Kermit is the name for a certain type of telecommunications protocol."}}, "resps": [[["-168.0", "False"]], [["-175.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-175.0", "False"], ["-170.0", "False"]], "doc_hash": "6c3f80b7224827e311334b38f43ed16be92b30448612ec3ee30bf3885271f642", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 2396, "doc": {"premise": "In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson.", "hypothesis": "There are a lot of Spanish names in Santa Fe.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Yes, There are a lot of Spanish names in Santa Fe."}, "gen_args_1": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? Also, There are a lot of Spanish names in Santa Fe."}, "gen_args_2": {"arg_0": "", "arg_1": " In Santa Fe, where the Hispanic heritage and population remain considerable, the new pseudo-Spanish names are more apt to be correct than in, say, California or Tucson., right? No, There are a lot of Spanish names in Santa Fe."}}, "resps": [[["-174.0", "False"]], [["-177.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-177.0", "False"], ["-177.0", "False"]], "doc_hash": "feaba59a3f4b1eb23e51a7a74fea0bc53e772a40db8d2ca912d642b7fc3a28d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 2404, "doc": {"premise": "One can also find some definitions here and there that are not entirely wrong yet with which one might disagree.", "hypothesis": "All of the definitions have been agreed upon by all parties.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Yes, All of the definitions have been agreed upon by all parties."}, "gen_args_1": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Also, All of the definitions have been agreed upon by all parties."}, "gen_args_2": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? No, All of the definitions have been agreed upon by all parties."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-147.0", "False"]], "doc_hash": "94c15de2920f6f8a7e7379fe6172d146ccd96a855976a18a47326dafc3bb4486", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2412, "doc": {"premise": "The teacher explained, in terms that she hoped were appropriate to her audience.", "hypothesis": "She explained the theory of evolution to her audience.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Yes, She explained the theory of evolution to her audience."}, "gen_args_1": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Also, She explained the theory of evolution to her audience."}, "gen_args_2": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? No, She explained the theory of evolution to her audience."}}, "resps": [[["-113.5", "False"]], [["-117.0", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-117.0", "False"], ["-112.5", "False"]], "doc_hash": "3e3a990ce08d0b9fbe5e78f9abc93affd775503ce8b5fd3f70bdd5f5aa2f2418", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26677486 0.0080559  0.72516924]"]}
{"doc_id": 2420, "doc": {"premise": "The flashes of wisdom should not be overlooked,", "hypothesis": "The flashes of wisdom should always be considered.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Yes, The flashes of wisdom should always be considered."}, "gen_args_1": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? Also, The flashes of wisdom should always be considered."}, "gen_args_2": {"arg_0": "", "arg_1": " The flashes of wisdom should not be overlooked,, right? No, The flashes of wisdom should always be considered."}}, "resps": [[["-93.0", "False"]], [["-99.5", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-93.0", "False"], ["-99.5", "False"], ["-93.5", "False"]], "doc_hash": "f5416995b644d898204b106b4ffc834c8e9daa7aa82af352444c9970349985ae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.62187736 0.00093495 0.37718769]"]}
{"doc_id": 2428, "doc": {"premise": "Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops.", "hypothesis": "Hogwash is most commonly used to describe the most important and sensible things.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Yes, Hogwash is most commonly used to describe the most important and sensible things."}, "gen_args_1": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Also, Hogwash is most commonly used to describe the most important and sensible things."}, "gen_args_2": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? No, Hogwash is most commonly used to describe the most important and sensible things."}}, "resps": [[["-183.0", "False"]], [["-185.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-185.0", "False"], ["-181.0", "False"]], "doc_hash": "1203b15023899b46e31bb35c29f56674f5a109ec3c57eddd72d8f423c4fe4879", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2436, "doc": {"premise": "'  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist.", "hypothesis": "A dictionary has a lot to offer.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Yes, A dictionary has a lot to offer."}, "gen_args_1": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Also, A dictionary has a lot to offer."}, "gen_args_2": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? No, A dictionary has a lot to offer."}}, "resps": [[["-178.0", "False"]], [["-183.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-183.0", "False"], ["-181.0", "False"]], "doc_hash": "33b5afaac6ea95c00741abac9125611c18b33be173a8f0c2f34aecf698558abf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 2444, "doc": {"premise": "The difference between a president and a king is that a king has no vice .", "hypothesis": "It is never obvious who will take over for a king in the event of his death, but it is obvious for a president.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Yes, It is never obvious who will take over for a king in the event of his death, but it is obvious for a president."}, "gen_args_1": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? Also, It is never obvious who will take over for a king in the event of his death, but it is obvious for a president."}, "gen_args_2": {"arg_0": "", "arg_1": " The difference between a president and a king is that a king has no vice ., right? No, It is never obvious who will take over for a king in the event of his death, but it is obvious for a president."}}, "resps": [[["-135.0", "False"]], [["-129.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-129.0", "False"], ["-134.0", "False"]], "doc_hash": "3304cdae7f3ee34e9cad5ed226cefd88d88100597272e1fd54b11a72fd35d726", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00245611 0.99086747 0.00667641]"]}
{"doc_id": 2452, "doc": {"premise": "A virgin forest is a forest in which the hand of man has never set foot .", "hypothesis": "Due to our population, there are few virgin forests still left in the United States.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Yes, Due to our population, there are few virgin forests still left in the United States."}, "gen_args_1": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Also, Due to our population, there are few virgin forests still left in the United States."}, "gen_args_2": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? No, Due to our population, there are few virgin forests still left in the United States."}}, "resps": [[["-131.0", "False"]], [["-131.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-131.0", "False"], ["-131.0", "False"]], "doc_hash": "7bede9f28a594f458667ed5bc1da1332c3ee62b65e929929b8fbccddb7c7e90b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2460, "doc": {"premise": "I have yet Room for six scotches more.", "hypothesis": "I can still consume six more scotches.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Yes, I can still consume six more scotches."}, "gen_args_1": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Also, I can still consume six more scotches."}, "gen_args_2": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? No, I can still consume six more scotches."}}, "resps": [[["-112.0", "False"]], [["-120.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-120.0", "False"], ["-115.0", "False"]], "doc_hash": "9c876ac3b5ccfa73e44ace67520beb9ae2a56e258f6f6d1f2515d92e83f25328", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 2468, "doc": {"premise": "It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him.", "hypothesis": "The rancher named Lover hid in a grassy area while planning his murder rampage.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Yes, The rancher named Lover hid in a grassy area while planning his murder rampage."}, "gen_args_1": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? Also, The rancher named Lover hid in a grassy area while planning his murder rampage."}, "gen_args_2": {"arg_0": "", "arg_1": " It is a rocky area where a rancher named Lover hid among the boulders from people intent on killing him., right? No, The rancher named Lover hid in a grassy area while planning his murder rampage."}}, "resps": [[["-183.0", "False"]], [["-184.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-184.0", "False"], ["-180.0", "False"]], "doc_hash": "65067ba891046315b1cca186c50c23865d20b65fb253f0ebab2b4c79a2061100", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 2476, "doc": {"premise": "The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out.", "hypothesis": "Experts have identified fifty different words that should not be part of the language.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Yes, Experts have identified fifty different words that should not be part of the language."}, "gen_args_1": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Also, Experts have identified fifty different words that should not be part of the language."}, "gen_args_2": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? No, Experts have identified fifty different words that should not be part of the language."}}, "resps": [[["-182.0", "False"]], [["-187.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-187.0", "False"], ["-183.0", "False"]], "doc_hash": "cb9bb0c2b073c985b18200802e03786e19a9058dbe28e1cd3aa5124a3bbf3bf5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2484, "doc": {"premise": "Feisty, like fizzle, began as Middle English fysten, fisten `to fart.", "hypothesis": "Fiesty began as fisten.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Yes, Fiesty began as fisten."}, "gen_args_1": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Also, Fiesty began as fisten."}, "gen_args_2": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? No, Fiesty began as fisten."}}, "resps": [[["-160.0", "False"]], [["-164.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-164.0", "False"], ["-161.0", "False"]], "doc_hash": "531ac9bb019a6cffc8e6fed25cd74bce1b7ac6c54072f8d0e16b7e89c5e4d20e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 5, "doc": {"premise": "I didn't know what I was going for or anything, so was to report to a designated place in Washington.", "hypothesis": "I was not quite certain what I was going to do so I went to Washington where I was assigned to report.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Yes, I was not quite certain what I was going to do so I went to Washington where I was assigned to report."}, "gen_args_1": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? Also, I was not quite certain what I was going to do so I went to Washington where I was assigned to report."}, "gen_args_2": {"arg_0": "", "arg_1": " I didn't know what I was going for or anything, so was to report to a designated place in Washington., right? No, I was not quite certain what I was going to do so I went to Washington where I was assigned to report."}}, "resps": [[["-159.0", "False"]], [["-169.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-169.0", "False"], ["-164.0", "False"]], "doc_hash": "25f956cf17e32106ad84c2e1093e6d99d20e58b970098f75f237f8be3ad5e43c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.93262357e-01 4.50940412e-05 6.69254912e-03]"]}
{"doc_id": 13, "doc": {"premise": "I was just there just trying to figure it out.", "hypothesis": "I was trying to understand where the money went.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Yes, I was trying to understand where the money went."}, "gen_args_1": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Also, I was trying to understand where the money went."}, "gen_args_2": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? No, I was trying to understand where the money went."}}, "resps": [[["-88.5", "False"]], [["-91.5", "False"]], [["-88.0", "False"]]], "filtered_resps": [["-88.5", "False"], ["-91.5", "False"], ["-88.0", "False"]], "doc_hash": "656e80fb2e3a901bdf9517f640c9174a4cc79dfe9dd3e698f7be08830c13032f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.3705751  0.01844985 0.61097505]"]}
{"doc_id": 21, "doc": {"premise": "Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well.", "hypothesis": "Santo lived in New York and worked on the high O2 regulator.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Yes, Santo lived in New York and worked on the high O2 regulator."}, "gen_args_1": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Also, Santo lived in New York and worked on the high O2 regulator."}, "gen_args_2": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? No, Santo lived in New York and worked on the high O2 regulator."}}, "resps": [[["-298.0", "False"]], [["-300.0", "False"]], [["-298.0", "False"]]], "filtered_resps": [["-298.0", "False"], ["-300.0", "False"], ["-298.0", "False"]], "doc_hash": "f17776af8a948c7374ea0b3bb3dd272af2d2a603fb462f0ea1789cb8c3385ecf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 29, "doc": {"premise": "But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location.", "hypothesis": "I shipped them out.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Yes, I shipped them out."}, "gen_args_1": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? Also, I shipped them out."}, "gen_args_2": {"arg_0": "", "arg_1": " But my job was to put parachutes on it and life preservers when we would load it and start to an overseas location., right? No, I shipped them out."}}, "resps": [[["-157.0", "False"]], [["-160.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-160.0", "False"], ["-155.0", "False"]], "doc_hash": "c8c2045c72b313d8a0be25cf58228c75561f9d1266ce8a88a679efbcfd0532d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 37, "doc": {"premise": "When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight.", "hypothesis": "It was difficult to get him out.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Yes, It was difficult to get him out."}, "gen_args_1": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Also, It was difficult to get him out."}, "gen_args_2": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? No, It was difficult to get him out."}}, "resps": [[["-196.0", "False"]], [["-197.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-197.0", "False"], ["-197.0", "False"]], "doc_hash": "382d135fc679074ac023c30860802d5aa52b41e26bb85313cefa5dffcecdcd23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 45, "doc": {"premise": "Only lost two, three aircraft while we was there, and, uh, test phase.", "hypothesis": "A couple of aircraft got lost because of the weather.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Yes, A couple of aircraft got lost because of the weather."}, "gen_args_1": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Also, A couple of aircraft got lost because of the weather."}, "gen_args_2": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? No, A couple of aircraft got lost because of the weather."}}, "resps": [[["-153.0", "False"]], [["-156.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-156.0", "False"], ["-153.0", "False"]], "doc_hash": "769f76a922f7468fe76140b6df2cf1768d34b956bb8ddc25e9c2facc98500473", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 53, "doc": {"premise": "Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour.", "hypothesis": "The jet flies 20,000 miles an hour.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Yes, The jet flies 20,000 miles an hour."}, "gen_args_1": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? Also, The jet flies 20,000 miles an hour."}, "gen_args_2": {"arg_0": "", "arg_1": " Different, totally different types parachutes and in an bird that flies, uh, three times the speed of sound, over 22,000 miles an hour., right? No, The jet flies 20,000 miles an hour."}}, "resps": [[["-185.0", "False"]], [["-189.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-189.0", "False"], ["-185.0", "False"]], "doc_hash": "0487a0d8655421562b77ac9bd745ebf933da0020226522e9ab2b659dd2231d83", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 61, "doc": {"premise": "Also, oh, let me go through this.", "hypothesis": "I will look through this.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Yes, I will look through this."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Also, I will look through this."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? No, I will look through this."}}, "resps": [[["-84.0", "False"]], [["-85.5", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-84.0", "False"], ["-85.5", "False"], ["-86.0", "False"]], "doc_hash": "b0a7d7c28867dc5e1c8c5b9a725b2ebedecd5b03fc160dd84542650adb331695", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.73612472 0.16425163 0.09962365]"]}
{"doc_id": 69, "doc": {"premise": "Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord.", "hypothesis": "Ramona has lived in Concord all her life.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Yes, Ramona has lived in Concord all her life."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Also, Ramona has lived in Concord all her life."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? No, Ramona has lived in Concord all her life."}}, "resps": [[["-211.0", "False"]], [["-212.0", "False"]], [["-212.0", "False"]]], "filtered_resps": [["-211.0", "False"], ["-212.0", "False"], ["-212.0", "False"]], "doc_hash": "e0809d56be57bf64696de3e06aaa3bb7a6e933771b78d15884567965bbb53e28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 77, "doc": {"premise": "I think that's why I remember that.", "hypothesis": "That's probably why I recalled that.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Yes, That's probably why I recalled that."}, "gen_args_1": {"arg_0": "", "arg_1": " I think that's why I remember that., right? Also, That's probably why I recalled that."}, "gen_args_2": {"arg_0": "", "arg_1": " I think that's why I remember that., right? No, That's probably why I recalled that."}}, "resps": [[["-83.5", "False"]], [["-86.5", "False"]], [["-85.5", "False"]]], "filtered_resps": [["-83.5", "False"], ["-86.5", "False"], ["-85.5", "False"]], "doc_hash": "668eb72f15bb867e73137f278d646d026a34f16940c6b6f5390eba46d88c7754", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 85, "doc": {"premise": "That was, that was a pretty scary day.", "hypothesis": "It was really scary when the tornado came into town.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Yes, It was really scary when the tornado came into town."}, "gen_args_1": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Also, It was really scary when the tornado came into town."}, "gen_args_2": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? No, It was really scary when the tornado came into town."}}, "resps": [[["-88.5", "False"]], [["-95.0", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-88.5", "False"], ["-95.0", "False"], ["-92.0", "False"]], "doc_hash": "5a82a21156ffd349bd36616ac1bcb54a1985e912a3a70c747486649e2133bf6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 93, "doc": {"premise": "Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?", "hypothesis": "I can't drink milk.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Yes, I can't drink milk."}, "gen_args_1": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Also, I can't drink milk."}, "gen_args_2": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? No, I can't drink milk."}}, "resps": [[["-112.5", "False"]], [["-112.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-112.0", "False"], ["-109.5", "False"]], "doc_hash": "a071a9f34f7f323b281ab90f524d016df19c532de4c32a90bee3fd28855ff0f3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04398648 0.07252145 0.88349207]"]}
{"doc_id": 101, "doc": {"premise": "But uh, think about it.", "hypothesis": "It's something to think about.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But uh, think about it., right? Yes, It's something to think about."}, "gen_args_1": {"arg_0": "", "arg_1": " But uh, think about it., right? Also, It's something to think about."}, "gen_args_2": {"arg_0": "", "arg_1": " But uh, think about it., right? No, It's something to think about."}}, "resps": [[["-72.5", "False"]], [["-76.0", "False"]], [["-74.0", "False"]]], "filtered_resps": [["-72.5", "False"], ["-76.0", "False"], ["-74.0", "False"]], "doc_hash": "9279d4238f9ef5f2c8d255ed496a186f852d1ade203babb07ca3b961ceb669fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 109, "doc": {"premise": "I don't want to go into the Third SS that's Third Strategic Support Squadron.", "hypothesis": "I don't want to be part of the Third SS.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Yes, I don't want to be part of the Third SS."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Also, I don't want to be part of the Third SS."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? No, I don't want to be part of the Third SS."}}, "resps": [[["-125.0", "False"]], [["-129.0", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-129.0", "False"], ["-121.5", "False"]], "doc_hash": "ccede9dfbab8e3b5ec33b868368615b51fffff83e36e127e5aa42d34622ec67e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[2.92965023e-02 5.36584156e-04 9.70166914e-01]"]}
{"doc_id": 117, "doc": {"premise": "He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married.", "hypothesis": "He is a Greek man who speaks no English.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Yes, He is a Greek man who speaks no English."}, "gen_args_1": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Also, He is a Greek man who speaks no English."}, "gen_args_2": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? No, He is a Greek man who speaks no English."}}, "resps": [[["-186.0", "False"]], [["-189.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-189.0", "False"], ["-188.0", "False"]], "doc_hash": "2d9d8b35b76cdf43f15e12584261179c742facac1cf0dcce897e61ee7c2fe814", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 125, "doc": {"premise": "Little things like that made a big difference in what I was trying to do.", "hypothesis": "I was trying to finish my poster for class and the new markers helped.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Yes, I was trying to finish my poster for class and the new markers helped."}, "gen_args_1": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? Also, I was trying to finish my poster for class and the new markers helped."}, "gen_args_2": {"arg_0": "", "arg_1": " Little things like that made a big difference in what I was trying to do., right? No, I was trying to finish my poster for class and the new markers helped."}}, "resps": [[["-129.0", "False"]], [["-134.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-134.0", "False"], ["-133.0", "False"]], "doc_hash": "6b6b784bb1a21cbc4922e98e6c7ce29ccffb4aabd0a759fbec3c21e01c149a38", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 133, "doc": {"premise": "I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed.", "hypothesis": "I told him I needed more info to decide what to do with the job.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Yes, I told him I needed more info to decide what to do with the job."}, "gen_args_1": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Also, I told him I needed more info to decide what to do with the job."}, "gen_args_2": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? No, I told him I needed more info to decide what to do with the job."}}, "resps": [[["-128.0", "False"]], [["-129.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-129.0", "False"], ["-130.0", "False"]], "doc_hash": "2ea41970c0b6295e50efcf56d80725516d0310dffb48d5e6515908b95a4f59d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 141, "doc": {"premise": "So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there.", "hypothesis": "Granny stayed on the porch.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Yes, Granny stayed on the porch."}, "gen_args_1": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Also, Granny stayed on the porch."}, "gen_args_2": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? No, Granny stayed on the porch."}}, "resps": [[["-144.0", "False"]], [["-151.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-151.0", "False"], ["-141.0", "False"]], "doc_hash": "30273f8401bd438b9d67406579f6d5c991dcecb84b7cf27591d1ba128c86714a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74238222e-02 4.32449282e-05 9.52532933e-01]"]}
{"doc_id": 149, "doc": {"premise": "It was still cultural area but suburbs was still the dominant form.", "hypothesis": "Most of the area was suburbia.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Yes, Most of the area was suburbia."}, "gen_args_1": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? Also, Most of the area was suburbia."}, "gen_args_2": {"arg_0": "", "arg_1": " It was still cultural area but suburbs was still the dominant form., right? No, Most of the area was suburbia."}}, "resps": [[["-127.5", "False"]], [["-133.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-133.0", "False"], ["-128.0", "False"]], "doc_hash": "c3afa6e93b143e2b46d1fa7e11917a277599662bac47c144551277cfba9d78bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.62087991 0.00253739 0.3765827 ]"]}
{"doc_id": 157, "doc": {"premise": "It would not explode without the trigger.", "hypothesis": "The trigger makes the bomb explode..", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Yes, The trigger makes the bomb explode.."}, "gen_args_1": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Also, The trigger makes the bomb explode.."}, "gen_args_2": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? No, The trigger makes the bomb explode.."}}, "resps": [[["-88.0", "False"]], [["-93.0", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-88.0", "False"], ["-93.0", "False"], ["-88.5", "False"]], "doc_hash": "25f7786792aaa5d89c2015f21724b6e742dabf37b99644f1a52bca0907db444a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61985958 0.00417658 0.37596384]"]}
{"doc_id": 165, "doc": {"premise": "I don't care if you don't know anything about it.", "hypothesis": "I know you aren't obsessed with it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Yes, I know you aren't obsessed with it."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Also, I know you aren't obsessed with it."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? No, I know you aren't obsessed with it."}}, "resps": [[["-79.0", "False"]], [["-79.0", "False"]], [["-80.5", "False"]]], "filtered_resps": [["-79.0", "False"], ["-79.0", "False"], ["-80.5", "False"]], "doc_hash": "24ee5f97b15d9ba15acf6212f93537cedaed1a3584c89aa746f5d334382fffdc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.44981622 0.44981622 0.10036756]"]}
{"doc_id": 173, "doc": {"premise": "I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever.", "hypothesis": "I saw every bit of it!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Yes, I saw every bit of it!"}, "gen_args_1": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? Also, I saw every bit of it!"}, "gen_args_2": {"arg_0": "", "arg_1": " I never did see, and don't know yet why, unless it was just ex, ex, expressing the, the, the need to know what you was a doing and whatever., right? No, I saw every bit of it!"}}, "resps": [[["-204.0", "False"]], [["-208.0", "False"]], [["-202.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-208.0", "False"], ["-202.0", "False"]], "doc_hash": "be0c18d98647e961dd325edf6ab9e501cff6baac36a9444bf4eb606d6402a7b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 181, "doc": {"premise": "If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression.", "hypothesis": "your hand could change size if it was exposed outside of the suit.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Yes, your hand could change size if it was exposed outside of the suit."}, "gen_args_1": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Also, your hand could change size if it was exposed outside of the suit."}, "gen_args_2": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? No, your hand could change size if it was exposed outside of the suit."}}, "resps": [[["-178.0", "False"]], [["-186.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-186.0", "False"], ["-181.0", "False"]], "doc_hash": "5fd83bdca799ee0389ee7b805f738f5e59004882062387e3c24bc214e03cf993", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 189, "doc": {"premise": "No, it was just that one time in the morning, and she said that she was going to come back to the office.", "hypothesis": "She didn't mention if she was going to return or not.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Yes, She didn't mention if she was going to return or not."}, "gen_args_1": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Also, She didn't mention if she was going to return or not."}, "gen_args_2": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? No, She didn't mention if she was going to return or not."}}, "resps": [[["-128.0", "False"]], [["-131.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-131.0", "False"], ["-126.0", "False"]], "doc_hash": "09299e04c866b870b326dbeb0aa03dbd6d63aff074765d3be11708fba51a9305", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 197, "doc": {"premise": "My grandmother was born in 1910, she was a little girl.", "hypothesis": "My grandma was born on july 1, 1910.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Yes, My grandma was born on july 1, 1910."}, "gen_args_1": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? Also, My grandma was born on july 1, 1910."}, "gen_args_2": {"arg_0": "", "arg_1": " My grandmother was born in 1910, she was a little girl., right? No, My grandma was born on july 1, 1910."}}, "resps": [[["-93.5", "False"]], [["-96.5", "False"]], [["-94.5", "False"]]], "filtered_resps": [["-93.5", "False"], ["-96.5", "False"], ["-94.5", "False"]], "doc_hash": "2b90cf2fe62f9122d5706b10b4e78a6ee4ef5f266d55e3269f71ed816ef982c0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 205, "doc": {"premise": "Anyhow, so I finished came home at 6:30 today and that was my day.", "hypothesis": "I didnt do anything significant after 6:30 today.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Yes, I didnt do anything significant after 6:30 today."}, "gen_args_1": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Also, I didnt do anything significant after 6:30 today."}, "gen_args_2": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? No, I didnt do anything significant after 6:30 today."}}, "resps": [[["-132.0", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "f43ff06722b0fd038daedf54fad1481b14a6f84fc691b86fba7b35e3e9b4e4a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 213, "doc": {"premise": "I don't have enough information.", "hypothesis": "I have all the information I could ever need.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't have enough information., right? Yes, I have all the information I could ever need."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't have enough information., right? Also, I have all the information I could ever need."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't have enough information., right? No, I have all the information I could ever need."}}, "resps": [[["-66.5", "False"]], [["-72.0", "False"]], [["-62.0", "False"]]], "filtered_resps": [["-66.5", "False"], ["-72.0", "False"], ["-62.0", "False"]], "doc_hash": "6b2b8b4155252d92c7d0d500cc2cd767fa576ea5e1dee661153e661897beba9a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.09864493e-02 4.48991073e-05 9.88968652e-01]"]}
{"doc_id": 221, "doc": {"premise": "Of course, they questioned me there, why I went.", "hypothesis": "They asked why I'd stayed home.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Yes, They asked why I'd stayed home."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? Also, They asked why I'd stayed home."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, they questioned me there, why I went., right? No, They asked why I'd stayed home."}}, "resps": [[["-112.0", "False"]], [["-114.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-114.0", "False"], ["-112.0", "False"]], "doc_hash": "d400d228d878278933e14d7aa2d52f73babb51d16ea41b6a48cad7c164cec538", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 229, "doc": {"premise": "Now that's how classified it was.", "hypothesis": "It was public information.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Yes, It was public information."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Also, It was public information."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how classified it was., right? No, It was public information."}}, "resps": [[["-89.5", "False"]], [["-92.0", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-89.5", "False"], ["-92.0", "False"], ["-86.0", "False"]], "doc_hash": "0fa1bbfc9f9258e732e4eef47e2216e20836b2c63e7820ce9d865e5bae73f076", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 237, "doc": {"premise": "Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down.", "hypothesis": "Pilots get tested in altitude chambers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Yes, Pilots get tested in altitude chambers."}, "gen_args_1": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Also, Pilots get tested in altitude chambers."}, "gen_args_2": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? No, Pilots get tested in altitude chambers."}}, "resps": [[["-205.0", "False"]], [["-210.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-210.0", "False"], ["-209.0", "False"]], "doc_hash": "8ba0645ca1c530bde1819a7e518224392b29ec38c12479656ec61cf32c6a00e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 245, "doc": {"premise": "That was my messed up.", "hypothesis": "I made a mistake.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was my messed up., right? Yes, I made a mistake."}, "gen_args_1": {"arg_0": "", "arg_1": " That was my messed up., right? Also, I made a mistake."}, "gen_args_2": {"arg_0": "", "arg_1": " That was my messed up., right? No, I made a mistake."}}, "resps": [[["-68.5", "False"]], [["-70.5", "False"]], [["-68.5", "False"]]], "filtered_resps": [["-68.5", "False"], ["-70.5", "False"], ["-68.5", "False"]], "doc_hash": "052541b80f2ba2278c24c98cd4f3b3e93e9bcb53f9c3b20b64680abf42f34055", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 253, "doc": {"premise": "yeah i have a credit union", "hypothesis": "I visit my credit union frequently.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Yes, I visit my credit union frequently."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Also, I visit my credit union frequently."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i have a credit union, right? No, I visit my credit union frequently."}}, "resps": [[["-76.0", "False"]], [["-79.5", "False"]], [["-79.5", "False"]]], "filtered_resps": [["-76.0", "False"], ["-79.5", "False"], ["-79.5", "False"]], "doc_hash": "adb26ed14df9bf852daab236d0c46c27ba9b1830f7dead78c2d26322b5096a02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94304502 0.02847749 0.02847749]"]}
{"doc_id": 261, "doc": {"premise": "and they can be very nice too after after they've been trained", "hypothesis": "They become hardened and cold once they complete the training.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Yes, They become hardened and cold once they complete the training."}, "gen_args_1": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Also, They become hardened and cold once they complete the training."}, "gen_args_2": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? No, They become hardened and cold once they complete the training."}}, "resps": [[["-126.5", "False"]], [["-128.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-128.0", "False"], ["-125.0", "False"]], "doc_hash": "f6106c2eea71b75d935e1c9a09760023e28c7cd9b42d3e962e5257f2dbf9a63f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17529039 0.03911257 0.78559703]"]}
{"doc_id": 269, "doc": {"premise": "yeah you you must've had a cordless", "hypothesis": "You might have had one with an optional cord.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Yes, You might have had one with an optional cord."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? Also, You might have had one with an optional cord."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah you you must've had a cordless, right? No, You might have had one with an optional cord."}}, "resps": [[["-108.0", "False"]], [["-109.5", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-108.0", "False"], ["-109.5", "False"], ["-104.5", "False"]], "doc_hash": "ef734d6ceb544d2830294ab9a480a256837c7a7bc04e2f9ac0524c2d99d35b33", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.02912176 0.00649794 0.9643803 ]"]}
{"doc_id": 277, "doc": {"premise": "well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs", "hypothesis": "I guess I would be fine with being drug tested.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Yes, I guess I would be fine with being drug tested."}, "gen_args_1": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Also, I guess I would be fine with being drug tested."}, "gen_args_2": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? No, I guess I would be fine with being drug tested."}}, "resps": [[["-193.0", "False"]], [["-199.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-199.0", "False"], ["-195.0", "False"]], "doc_hash": "98ade09ceecd05feefbb98c6a0fbe275d0c4feda6b75f1ada8f54453a28f0fa6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 285, "doc": {"premise": "yeah there there's something about having a place to live i don't know", "hypothesis": "Having a place to live is a dream come true.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Yes, Having a place to live is a dream come true."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Also, Having a place to live is a dream come true."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? No, Having a place to live is a dream come true."}}, "resps": [[["-102.5", "False"]], [["-110.0", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-110.0", "False"], ["-105.0", "False"]], "doc_hash": "d3b7445621602a956f1e7beb2b1a911c20522ab18ac2bb77e5306ee876820593", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.23669706e-01 5.10867278e-04 7.58194266e-02]"]}
{"doc_id": 293, "doc": {"premise": "yeah it's ours up here we have our rural connections are real bad", "hypothesis": "We have the best connections around here.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Yes, We have the best connections around here."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? Also, We have the best connections around here."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah it's ours up here we have our rural connections are real bad, right? No, We have the best connections around here."}}, "resps": [[["-128.0", "False"]], [["-135.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-135.0", "False"], ["-125.0", "False"]], "doc_hash": "a6a80b5060d57f389da42205c8ecc8c46326166c2aa67947c52b2ec8ce61a39b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74238222e-02 4.32449282e-05 9.52532933e-01]"]}
{"doc_id": 301, "doc": {"premise": "one of the benefits we get of course is travel", "hypothesis": "Traveling is one perk we get.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Yes, Traveling is one perk we get."}, "gen_args_1": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Also, Traveling is one perk we get."}, "gen_args_2": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? No, Traveling is one perk we get."}}, "resps": [[["-88.5", "False"]], [["-98.0", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-88.5", "False"], ["-98.0", "False"], ["-92.0", "False"]], "doc_hash": "d109b6f64773edbd1ef4692089044492f0e884d348d5d00a0f2e13438c29630c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70617246e-01 7.26524770e-05 2.93101011e-02]"]}
{"doc_id": 309, "doc": {"premise": "so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it", "hypothesis": "We go to the cottage for a couple of days.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Yes, We go to the cottage for a couple of days."}, "gen_args_1": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Also, We go to the cottage for a couple of days."}, "gen_args_2": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? No, We go to the cottage for a couple of days."}}, "resps": [[["-155.0", "False"]], [["-164.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-164.0", "False"], ["-158.0", "False"]], "doc_hash": "d642c2f8cdd40cd5d9772e7afbc37cd13adcf2270c87218506e756c4aecb9e4e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52462158e-01 1.17543168e-04 4.74202986e-02]"]}
{"doc_id": 317, "doc": {"premise": "have you read The Firm", "hypothesis": "Would you like to borrow my copy of The Firm to read?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " have you read The Firm, right? Yes, Would you like to borrow my copy of The Firm to read?"}, "gen_args_1": {"arg_0": "", "arg_1": " have you read The Firm, right? Also, Would you like to borrow my copy of The Firm to read?"}, "gen_args_2": {"arg_0": "", "arg_1": " have you read The Firm, right? No, Would you like to borrow my copy of The Firm to read?"}}, "resps": [[["-80.5", "False"]], [["-80.5", "False"]], [["-80.5", "False"]]], "filtered_resps": [["-80.5", "False"], ["-80.5", "False"], ["-80.5", "False"]], "doc_hash": "52689e1cc4820acab0a88ce25ab5f25cfb02f5fe6724193d71ea2a003c94eed7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 325, "doc": {"premise": "uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody", "hypothesis": "She normally plays poker or blackjack, but will sometimes play scrabble.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Yes, She normally plays poker or blackjack, but will sometimes play scrabble."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Also, She normally plays poker or blackjack, but will sometimes play scrabble."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? No, She normally plays poker or blackjack, but will sometimes play scrabble."}}, "resps": [[["-161.0", "False"]], [["-162.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-162.0", "False"], ["-162.0", "False"]], "doc_hash": "36878d39f7abafd48a2f1dee368f59d20a3f6e7447d8216a67be58b5a4287ae1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 333, "doc": {"premise": "but uh so you like different foods huh", "hypothesis": "Do you like different types of food?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Yes, Do you like different types of food?"}, "gen_args_1": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Also, Do you like different types of food?"}, "gen_args_2": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? No, Do you like different types of food?"}}, "resps": [[["-89.0", "False"]], [["-92.5", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-92.5", "False"], ["-90.0", "False"]], "doc_hash": "ccc8d9f08556404eb40bd42078cc40158753cbfdce007820f57b5b541e650d4f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 341, "doc": {"premise": "you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education", "hypothesis": "Sometimes larger companies help you pay for education.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Yes, Sometimes larger companies help you pay for education."}, "gen_args_1": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? Also, Sometimes larger companies help you pay for education."}, "gen_args_2": {"arg_0": "", "arg_1": " you know one other benefit that that just occurred to me i didn't take it as much advantage of it at least not yet in  sometimes big companies will pay for like education, right? No, Sometimes larger companies help you pay for education."}}, "resps": [[["-207.0", "False"]], [["-213.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-213.0", "False"], ["-211.0", "False"]], "doc_hash": "fd178934179a1c874a8baca975e32bdd4943d204a8b2d14a62d3487ec6bc065c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 349, "doc": {"premise": "yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes", "hypothesis": "It lost by not very many votes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Yes, It lost by not very many votes."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Also, It lost by not very many votes."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? No, It lost by not very many votes."}}, "resps": [[["-185.0", "False"]], [["-192.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-192.0", "False"], ["-186.0", "False"]], "doc_hash": "ad7c93891e2b6ae4213dff137483bf84a4a3311fe08bda0416eb40fb9fef3411", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 357, "doc": {"premise": "right they will go through the slot", "hypothesis": "They are easy to slide through.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " right they will go through the slot, right? Yes, They are easy to slide through."}, "gen_args_1": {"arg_0": "", "arg_1": " right they will go through the slot, right? Also, They are easy to slide through."}, "gen_args_2": {"arg_0": "", "arg_1": " right they will go through the slot, right? No, They are easy to slide through."}}, "resps": [[["-82.5", "False"]], [["-87.5", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-82.5", "False"], ["-87.5", "False"], ["-85.0", "False"]], "doc_hash": "b635466a4dd7ca80bae6a603c0bccc1f874da4c9a89feba4e65edc062b647f30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.91842297 0.00618829 0.07538875]"]}
{"doc_id": 365, "doc": {"premise": "now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark", "hypothesis": "Robbers know dogs will be quiet soon.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Yes, Robbers know dogs will be quiet soon."}, "gen_args_1": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? Also, Robbers know dogs will be quiet soon."}, "gen_args_2": {"arg_0": "", "arg_1": " now that's one of the best deterrents for a robber is a noisy neighbor even if the neighbor's got a noisy dog that's a deterrent because they know that that dog's going to bark, right? No, Robbers know dogs will be quiet soon."}}, "resps": [[["-177.0", "False"]], [["-182.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-182.0", "False"], ["-176.0", "False"]], "doc_hash": "8477adac8bb7fdcbb8e3b1fae433152145752aef071e054e6c22c3efcebcebfb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 373, "doc": {"premise": "came back from uh uh Grand Rapids where we saw one of our sons graduate", "hypothesis": "We don't have a son.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Yes, We don't have a son."}, "gen_args_1": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Also, We don't have a son."}, "gen_args_2": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? No, We don't have a son."}}, "resps": [[["-115.0", "False"]], [["-121.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-115.0", "False"], ["-121.5", "False"], ["-113.5", "False"]], "doc_hash": "e9751865e7cf8ceff5d8d2e0f9fca1e93a139c82d47e23d65cd1507cfa9a7f96", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.82375504e-01 2.74190481e-04 8.17350305e-01]"]}
{"doc_id": 381, "doc": {"premise": "and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i", "hypothesis": "Having a yard is not all fun and games but I do enjoy it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Yes, Having a yard is not all fun and games but I do enjoy it."}, "gen_args_1": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Also, Having a yard is not all fun and games but I do enjoy it."}, "gen_args_2": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? No, Having a yard is not all fun and games but I do enjoy it."}}, "resps": [[["-160.0", "False"]], [["-166.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-166.0", "False"], ["-164.0", "False"]], "doc_hash": "dde8e7d7ba358528e134f6753b6a46b46249aa721f814e1ca7cedebad7510792", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 389, "doc": {"premise": "not just lawyers but police officers and judges and the whole legal profession in general", "hypothesis": "Most of the legal system is involved, a majority being that of police.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Yes, Most of the legal system is involved, a majority being that of police."}, "gen_args_1": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? Also, Most of the legal system is involved, a majority being that of police."}, "gen_args_2": {"arg_0": "", "arg_1": " not just lawyers but police officers and judges and the whole legal profession in general, right? No, Most of the legal system is involved, a majority being that of police."}}, "resps": [[["-136.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "05abaed4469e1586861929ded484a8ac84fde310bf2d28c6453c86b12c3b42d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 397, "doc": {"premise": "yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in", "hypothesis": "We are definitely going to get it to watch our local news.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Yes, We are definitely going to get it to watch our local news."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Also, We are definitely going to get it to watch our local news."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? No, We are definitely going to get it to watch our local news."}}, "resps": [[["-170.0", "False"]], [["-178.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-178.0", "False"], ["-171.0", "False"]], "doc_hash": "3d8d360bea67477f6696d4307fe7e6387ec6c0642a3441c103c76df58b00bad7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 405, "doc": {"premise": "a few years ago i was a student there and spent um a semester studying abroad in London", "hypothesis": "A couple years ago I studied in London for a semester.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Yes, A couple years ago I studied in London for a semester."}, "gen_args_1": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Also, A couple years ago I studied in London for a semester."}, "gen_args_2": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? No, A couple years ago I studied in London for a semester."}}, "resps": [[["-119.5", "False"]], [["-125.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-125.0", "False"], ["-122.0", "False"]], "doc_hash": "149a1a7e2eb53f1b579a145fa8697314b9ff81e06a34a3ab7fdae693ca8b4dba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92066469 0.00376255 0.07557276]"]}
{"doc_id": 413, "doc": {"premise": "i never have can't do anything with cakes so", "hypothesis": "I wish I could do something with the cakes but I have no use for them.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Yes, I wish I could do something with the cakes but I have no use for them."}, "gen_args_1": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? Also, I wish I could do something with the cakes but I have no use for them."}, "gen_args_2": {"arg_0": "", "arg_1": " i never have can't do anything with cakes so, right? No, I wish I could do something with the cakes but I have no use for them."}}, "resps": [[["-116.0", "False"]], [["-119.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-119.0", "False"], ["-117.0", "False"]], "doc_hash": "2348b79d7485f1fdc3d9e66b9b0298bf33a255a1915a103b2fdd54805cedb528", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 421, "doc": {"premise": "yeah because it's uh it had definitely been through the mill but uh", "hypothesis": "Yeah it made it without a single scratch!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Yes, Yeah it made it without a single scratch!"}, "gen_args_1": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Also, Yeah it made it without a single scratch!"}, "gen_args_2": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? No, Yeah it made it without a single scratch!"}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-128.0", "False"]], "doc_hash": "6f66ba007cda560eab99aa2b1d143143ec7c3cc0c067b3436b22f15a13b00506", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 429, "doc": {"premise": "do we know what we're going to say", "hypothesis": "Do you know what script they're going to give us to read?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Yes, Do you know what script they're going to give us to read?"}, "gen_args_1": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Also, Do you know what script they're going to give us to read?"}, "gen_args_2": {"arg_0": "", "arg_1": " do we know what we're going to say, right? No, Do you know what script they're going to give us to read?"}}, "resps": [[["-87.5", "False"]], [["-87.0", "False"]], [["-87.5", "False"]]], "filtered_resps": [["-87.5", "False"], ["-87.0", "False"], ["-87.5", "False"]], "doc_hash": "74883b4ce7f7582f096c83f3e25b7da186dc699011273ec67b5f8bd0fb4d31db", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.27406862 0.45186276 0.27406862]"]}
{"doc_id": 437, "doc": {"premise": "uh-huh all right bye now", "hypothesis": "Let's keep talking.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Yes, Let's keep talking."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? Also, Let's keep talking."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh all right bye now, right? No, Let's keep talking."}}, "resps": [[["-78.5", "False"]], [["-83.5", "False"]], [["-75.0", "False"]]], "filtered_resps": [["-78.5", "False"], ["-83.5", "False"], ["-75.0", "False"]], "doc_hash": "6e6f670f8331ee907615b8074ce1f0a72fbb18377eca21bbb68664e360e1623e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93064426e-02 1.97465257e-04 9.70496092e-01]"]}
{"doc_id": 445, "doc": {"premise": "yeah some special interest group", "hypothesis": "The group is interested in environmental issues.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah some special interest group, right? Yes, The group is interested in environmental issues."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah some special interest group, right? Also, The group is interested in environmental issues."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah some special interest group, right? No, The group is interested in environmental issues."}}, "resps": [[["-85.5", "False"]], [["-86.0", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-85.5", "False"], ["-86.0", "False"], ["-83.0", "False"]], "doc_hash": "b857114f549d38a94778a80807396c0e9e1cebecd4ba60207ba1ca954bac7c4e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07252145 0.04398648 0.88349207]"]}
{"doc_id": 453, "doc": {"premise": "expensive you can get a lot of money in that kind of stuff especially the good stuff", "hypothesis": "It's not worth anything because it's junk.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Yes, It's not worth anything because it's junk."}, "gen_args_1": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Also, It's not worth anything because it's junk."}, "gen_args_2": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? No, It's not worth anything because it's junk."}}, "resps": [[["-118.0", "False"]], [["-117.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-117.0", "False"], ["-111.0", "False"]], "doc_hash": "8752d7b8e36a6da8b0c7dca6c638e9bdce403f6f1abcbba01d98397855bfdece", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.08800555e-04 2.47037604e-03 9.96620823e-01]"]}
{"doc_id": 461, "doc": {"premise": "um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line", "hypothesis": "There is a sign to say you have an alarm.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Yes, There is a sign to say you have an alarm."}, "gen_args_1": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? Also, There is a sign to say you have an alarm."}, "gen_args_2": {"arg_0": "", "arg_1": " um hum yeah so so so you got a sign up there that says you got this alarm system and what if a burglar comes along and cuts your phone line, right? No, There is a sign to say you have an alarm."}}, "resps": [[["-176.0", "False"]], [["-177.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-177.0", "False"], ["-178.0", "False"]], "doc_hash": "419cfa7f4e0b9fc278e43dea689ccc4b281c9604576b5366ac14dc7a04c23f29", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 469, "doc": {"premise": "um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and", "hypothesis": "I have an Apple and an HP computer at home.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Yes, I have an Apple and an HP computer at home."}, "gen_args_1": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Also, I have an Apple and an HP computer at home."}, "gen_args_2": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? No, I have an Apple and an HP computer at home."}}, "resps": [[["-196.0", "False"]], [["-204.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-204.0", "False"], ["-199.0", "False"]], "doc_hash": "1adc4bb26ec18ba66c6597e30b863700b4e4ac44cdd52cbb0e5a2a21d94e9b89", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 477, "doc": {"premise": "wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it", "hypothesis": "I don't want to go see that movie at all!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Yes, I don't want to go see that movie at all!"}, "gen_args_1": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Also, I don't want to go see that movie at all!"}, "gen_args_2": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? No, I don't want to go see that movie at all!"}}, "resps": [[["-129.0", "False"]], [["-128.0", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-129.0", "False"], ["-128.0", "False"], ["-121.5", "False"]], "doc_hash": "e467beac6719d791237483796bec1fd30a2c9fc9ea02c30592ec31e71e0718eb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[5.51949273e-04 1.50035368e-03 9.97947697e-01]"]}
{"doc_id": 485, "doc": {"premise": "well we're definitely keeping them poor and down trodden and helpless", "hypothesis": "We make it so poor people can't succeed in our society.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Yes, We make it so poor people can't succeed in our society."}, "gen_args_1": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? Also, We make it so poor people can't succeed in our society."}, "gen_args_2": {"arg_0": "", "arg_1": " well we're definitely keeping them poor and down trodden and helpless, right? No, We make it so poor people can't succeed in our society."}}, "resps": [[["-117.0", "False"]], [["-120.5", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-117.0", "False"], ["-120.5", "False"], ["-118.5", "False"]], "doc_hash": "1fab231a4836df761e55e371bdda0a933192717699fe369551f1458909b907b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.79787603 0.02409377 0.17803021]"]}
{"doc_id": 493, "doc": {"premise": "um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there", "hypothesis": "I was going to suggest other cuts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Yes, I was going to suggest other cuts."}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Also, I was going to suggest other cuts."}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? No, I was going to suggest other cuts."}}, "resps": [[["-161.0", "False"]], [["-170.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-170.0", "False"], ["-165.0", "False"]], "doc_hash": "130be050e9f20f0af0ac73cb9aa704a47ed3bc437057161014d94bd1d6e40f03", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81894794e-01 1.21175444e-04 1.79840305e-02]"]}
{"doc_id": 501, "doc": {"premise": "These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness.", "hypothesis": "All molecular devices are equally complex.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Yes, All molecular devices are equally complex."}, "gen_args_1": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Also, All molecular devices are equally complex."}, "gen_args_2": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? No, All molecular devices are equally complex."}}, "resps": [[["-191.0", "False"]], [["-190.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-190.0", "False"], ["-188.0", "False"]], "doc_hash": "2c51e28c2ed5a0499f67157340a63e44fec78adb5bdd5039a83eeae138223f35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 509, "doc": {"premise": "The law redeems not the individual but the community or the nation as a whole.", "hypothesis": "The law will save the community and the nation.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Yes, The law will save the community and the nation."}, "gen_args_1": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? Also, The law will save the community and the nation."}, "gen_args_2": {"arg_0": "", "arg_1": " The law redeems not the individual but the community or the nation as a whole., right? No, The law will save the community and the nation."}}, "resps": [[["-109.5", "False"]], [["-114.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-109.5", "False"], ["-114.0", "False"], ["-111.0", "False"]], "doc_hash": "4e42f904c26d9899e4b6b0ce8587d1d76476796062b0812b3697288e9e0906db", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81021575 0.00900068 0.18078357]"]}
{"doc_id": 517, "doc": {"premise": "Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light).", "hypothesis": "The chapters contained both common members and officers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Yes, The chapters contained both common members and officers."}, "gen_args_1": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Also, The chapters contained both common members and officers."}, "gen_args_2": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? No, The chapters contained both common members and officers."}}, "resps": [[["-254.0", "False"]], [["-255.0", "False"]], [["-253.0", "False"]]], "filtered_resps": [["-254.0", "False"], ["-255.0", "False"], ["-253.0", "False"]], "doc_hash": "fba526b66942bc05071048fb6580420494f4e24153f7e4272e6086bbb16f41d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 525, "doc": {"premise": "Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data.", "hypothesis": "A nonstationary world is undesirable to some if it must account for information from the distant past.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Yes, A nonstationary world is undesirable to some if it must account for information from the distant past."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Also, A nonstationary world is undesirable to some if it must account for information from the distant past."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? No, A nonstationary world is undesirable to some if it must account for information from the distant past."}}, "resps": [[["-193.0", "False"]], [["-195.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-195.0", "False"], ["-192.0", "False"]], "doc_hash": "ce441d7506c362e462b5b90364e47ae06af4fdf538d62e9db4d343aeb8e2058a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 533, "doc": {"premise": "And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens.", "hypothesis": "The state was entirely responsible for the behavior of the private persons.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Yes, The state was entirely responsible for the behavior of the private persons."}, "gen_args_1": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? Also, The state was entirely responsible for the behavior of the private persons."}, "gen_args_2": {"arg_0": "", "arg_1": " And, therefore, the state was not responsible for these private persons denying  social rights  to black citizens., right? No, The state was entirely responsible for the behavior of the private persons."}}, "resps": [[["-154.0", "False"]], [["-159.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-159.0", "False"], ["-151.0", "False"]], "doc_hash": "ed04977d17d0a6f03ae589d221d7d2eb90d67c3dd2b130a4a91780c7f8c0cad5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 541, "doc": {"premise": "Darwin starts with life already here.", "hypothesis": "Darwin started with life that already existed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Yes, Darwin started with life that already existed."}, "gen_args_1": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Also, Darwin started with life that already existed."}, "gen_args_2": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? No, Darwin started with life that already existed."}}, "resps": [[["-86.5", "False"]], [["-92.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-86.5", "False"], ["-92.0", "False"], ["-89.0", "False"]], "doc_hash": "212a391624a2f17f43f355dff9f476d77919581e912b6fec83f36a05465600bf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92066469 0.00376255 0.07557276]"]}
{"doc_id": 549, "doc": {"premise": "McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell.", "hypothesis": "Howard and Cauldwell were women.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Yes, Howard and Cauldwell were women."}, "gen_args_1": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Also, Howard and Cauldwell were women."}, "gen_args_2": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? No, Howard and Cauldwell were women."}}, "resps": [[["-149.0", "False"]], [["-149.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-149.0", "False"], ["-150.0", "False"]], "doc_hash": "17d22174f415d2f505561c0d87fbe212ebf019ac4b9cfd3fba4054faec0dfd98", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 557, "doc": {"premise": "Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves.", "hypothesis": "Young men in palomillas told jokes about horses.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Yes, Young men in palomillas told jokes about horses."}, "gen_args_1": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? Also, Young men in palomillas told jokes about horses."}, "gen_args_2": {"arg_0": "", "arg_1": " Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves., right? No, Young men in palomillas told jokes about horses."}}, "resps": [[["-219.0", "False"]], [["-225.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-225.0", "False"], ["-224.0", "False"]], "doc_hash": "7931522ef10191536284b1d9ec74ff70e37ae0cb9e768a3a60ab959938a902cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 565, "doc": {"premise": "Bato is a word centuries old that can be translated as  guy  or  dude.", "hypothesis": "Bato (or vato) is a Spanish word that means guy or dude.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Yes, Bato (or vato) is a Spanish word that means guy or dude."}, "gen_args_1": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Also, Bato (or vato) is a Spanish word that means guy or dude."}, "gen_args_2": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? No, Bato (or vato) is a Spanish word that means guy or dude."}}, "resps": [[["-144.0", "False"]], [["-149.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-149.0", "False"], ["-147.0", "False"]], "doc_hash": "e843dba3e0eefba2284fbcd1ffeca8de09b9063202902c64fe96a93dd33707a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 573, "doc": {"premise": "The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible.", "hypothesis": "The biosphere grew 1000 mile.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Yes, The biosphere grew 1000 mile."}, "gen_args_1": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Also, The biosphere grew 1000 mile."}, "gen_args_2": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? No, The biosphere grew 1000 mile."}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-174.0", "False"]], "doc_hash": "3a9d93a473bf0e4f644c356e1d8bb874fac1b9f9c0eb3f72d7a59a1483e392fc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 581, "doc": {"premise": "Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges.", "hypothesis": "People were trying to learn about trading on stock exchanges.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Yes, People were trying to learn about trading on stock exchanges."}, "gen_args_1": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? Also, People were trying to learn about trading on stock exchanges."}, "gen_args_2": {"arg_0": "", "arg_1": " Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges., right? No, People were trying to learn about trading on stock exchanges."}}, "resps": [[["-133.0", "False"]], [["-138.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-138.0", "False"], ["-135.0", "False"]], "doc_hash": "d0c1013c464fc82cfa92b36f10ade4497e4ccce4a141cbffcdc3ea718f381192", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 589, "doc": {"premise": "The end of plantation capitalism might have come as safely as the demise of communism in Europe.", "hypothesis": "Plantation capitalism is wrong.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Yes, Plantation capitalism is wrong."}, "gen_args_1": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Also, Plantation capitalism is wrong."}, "gen_args_2": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? No, Plantation capitalism is wrong."}}, "resps": [[["-128.0", "False"]], [["-132.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-132.0", "False"], ["-128.0", "False"]], "doc_hash": "f0bf91da17684595f1c18cdeda55bcb2d2fc44819929571bb4c96c8cf0473e6c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 597, "doc": {"premise": "Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew.", "hypothesis": "Diego did not really want to follow her instructions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Yes, Diego did not really want to follow her instructions."}, "gen_args_1": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Also, Diego did not really want to follow her instructions."}, "gen_args_2": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? No, Diego did not really want to follow her instructions."}}, "resps": [[["-160.0", "False"]], [["-161.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-161.0", "False"], ["-155.0", "False"]], "doc_hash": "e34d8d289314ce59451f87da5c3e9d4f810a7b6562247fa6b30cce30d5644d5a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 605, "doc": {"premise": "Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking.", "hypothesis": "There are at least two terms that mean cooking of meat in a pit.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Yes, There are at least two terms that mean cooking of meat in a pit."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? Also, There are at least two terms that mean cooking of meat in a pit."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking., right? No, There are at least two terms that mean cooking of meat in a pit."}}, "resps": [[["-133.0", "False"]], [["-136.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-136.0", "False"], ["-130.0", "False"]], "doc_hash": "b8d60f18ff143f13fa5f88417b90f56abfda708a5d51790932d689b2aec3f9bf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 613, "doc": {"premise": "The problem of exploitation in apparently voluntary sexual relations has long been with us.", "hypothesis": "There can be exploitation in sexual relations that are apparently voluntary.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Yes, There can be exploitation in sexual relations that are apparently voluntary."}, "gen_args_1": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Also, There can be exploitation in sexual relations that are apparently voluntary."}, "gen_args_2": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? No, There can be exploitation in sexual relations that are apparently voluntary."}}, "resps": [[["-118.5", "False"]], [["-122.5", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-118.5", "False"], ["-122.5", "False"], ["-120.5", "False"]], "doc_hash": "78a183bf8bf0dfa444986370ab619a93a59f46e35b02e657b6dbcb5e02a58ca9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 621, "doc": {"premise": "Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events.", "hypothesis": "Members of car clubs do competitions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Yes, Members of car clubs do competitions."}, "gen_args_1": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Also, Members of car clubs do competitions."}, "gen_args_2": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? No, Members of car clubs do competitions."}}, "resps": [[["-166.0", "False"]], [["-170.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-170.0", "False"], ["-169.0", "False"]], "doc_hash": "8eeccfeb2052edb16bf49cdc9604f5d9b9e0571d342c43a50b1863a7bf547ee0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 629, "doc": {"premise": "It would get really big, take us from our beds and never bring us back home  (November 1974).", "hypothesis": "They were removed from their beds.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Yes, They were removed from their beds."}, "gen_args_1": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? Also, They were removed from their beds."}, "gen_args_2": {"arg_0": "", "arg_1": " It would get really big, take us from our beds and never bring us back home  (November 1974)., right? No, They were removed from their beds."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-159.0", "False"]], "doc_hash": "5d8fe41282bf2c90dd5ed726a4a79dad69713a121886d5b1115658a97f57853d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 637, "doc": {"premise": "Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all.", "hypothesis": "The Greeks and Romans had laws that we use today.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Yes, The Greeks and Romans had laws that we use today."}, "gen_args_1": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Also, The Greeks and Romans had laws that we use today."}, "gen_args_2": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? No, The Greeks and Romans had laws that we use today."}}, "resps": [[["-156.0", "False"]], [["-153.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-153.0", "False"], ["-154.0", "False"]], "doc_hash": "e480b790f0856030855523e080c6975ee0e11b2d2137971f40b8bffe5743d5f6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.03511903 0.70538451 0.25949646]"]}
{"doc_id": 645, "doc": {"premise": "That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf.", "hypothesis": "Kids are playing with toy planes.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Yes, Kids are playing with toy planes."}, "gen_args_1": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Also, Kids are playing with toy planes."}, "gen_args_2": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? No, Kids are playing with toy planes."}}, "resps": [[["-160.0", "False"]], [["-159.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-159.0", "False"], ["-159.0", "False"]], "doc_hash": "c87051e1e5a73001b8cb2026f9f18fe5d774528b8510476ee5bc9fa711116a3f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 653, "doc": {"premise": "22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s.", "hypothesis": "Wage levels in the apparel industry are not stagnant.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Yes, Wage levels in the apparel industry are not stagnant."}, "gen_args_1": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? Also, Wage levels in the apparel industry are not stagnant."}, "gen_args_2": {"arg_0": "", "arg_1": " 22 Despite these strict legislated standards'with wage levels updated from time to time'widespread violations in apparel workplaces have become commonplace in the 1990s., right? No, Wage levels in the apparel industry are not stagnant."}}, "resps": [[["-214.0", "False"]], [["-214.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-214.0", "False"], ["-211.0", "False"]], "doc_hash": "9097ac6c056748cb3ed48f0a72701d8c80ebc3a0830105e8ae032dd1df39a2dc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 661, "doc": {"premise": "Of course, if we could not solve our chosen ways to make livings, we would be dead.", "hypothesis": "Humans can always survive any situation, even when they are not making a living.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Yes, Humans can always survive any situation, even when they are not making a living."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Also, Humans can always survive any situation, even when they are not making a living."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? No, Humans can always survive any situation, even when they are not making a living."}}, "resps": [[["-155.0", "False"]], [["-161.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-161.0", "False"], ["-152.0", "False"]], "doc_hash": "1c5852b07b5955a7498f3a0f9962d34a1ec23438d784322472917827fbd4cf53", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 669, "doc": {"premise": "The connection between the limited nation and unbounded equality has paradoxical overtones.", "hypothesis": "The limited nation used to be isolated.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Yes, The limited nation used to be isolated."}, "gen_args_1": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Also, The limited nation used to be isolated."}, "gen_args_2": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? No, The limited nation used to be isolated."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-146.0", "False"]], "doc_hash": "a085154123b217b9a7a4ed94e78f0541be22a3c39c463031f74f4037d702b881", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 677, "doc": {"premise": "We are literally making our world together, we critters.", "hypothesis": "People do not live in the world it is made up only of animals and plants.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Yes, People do not live in the world it is made up only of animals and plants."}, "gen_args_1": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? Also, People do not live in the world it is made up only of animals and plants."}, "gen_args_2": {"arg_0": "", "arg_1": " We are literally making our world together, we critters., right? No, People do not live in the world it is made up only of animals and plants."}}, "resps": [[["-146.0", "False"]], [["-149.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-149.0", "False"], ["-145.0", "False"]], "doc_hash": "03382e58ae8a4a41b1d08d7ac214ff84692968d0273c2e456f3b3400a3f5b19a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 685, "doc": {"premise": "As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable.", "hypothesis": "The universe is a very confusing place.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Yes, The universe is a very confusing place."}, "gen_args_1": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Also, The universe is a very confusing place."}, "gen_args_2": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? No, The universe is a very confusing place."}}, "resps": [[["-158.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "a4b715bd7ae7d591bad99aa108d390a0bea13d091a7b8392b0ca3aa55e9189c0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 693, "doc": {"premise": "On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys.", "hypothesis": "Children carried around big bags for collecting candy and toys on Christmas Day.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Yes, Children carried around big bags for collecting candy and toys on Christmas Day."}, "gen_args_1": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Also, Children carried around big bags for collecting candy and toys on Christmas Day."}, "gen_args_2": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? No, Children carried around big bags for collecting candy and toys on Christmas Day."}}, "resps": [[["-144.0", "False"]], [["-149.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-149.0", "False"], ["-146.0", "False"]], "doc_hash": "7f8c3a4b0883a8ea723def5c53ea927f055e86e7cc9a20decb10edb4beaa93d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 701, "doc": {"premise": "This is not to say that good architecture is merely utilitarian.", "hypothesis": "The single defining attribute of good architecture is utility.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Yes, The single defining attribute of good architecture is utility."}, "gen_args_1": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? Also, The single defining attribute of good architecture is utility."}, "gen_args_2": {"arg_0": "", "arg_1": " This is not to say that good architecture is merely utilitarian., right? No, The single defining attribute of good architecture is utility."}}, "resps": [[["-105.5", "False"]], [["-110.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-105.5", "False"], ["-110.0", "False"], ["-104.5", "False"]], "doc_hash": "3409b33dbcab8d125330ee6cebfd86edbddd3e7ea9166628f20c5e4fa0fc8da8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26814031 0.00297877 0.72888092]"]}
{"doc_id": 709, "doc": {"premise": "Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship.", "hypothesis": "Lipstadt wrote a book that got excellent reviews.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Yes, Lipstadt wrote a book that got excellent reviews."}, "gen_args_1": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Also, Lipstadt wrote a book that got excellent reviews."}, "gen_args_2": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? No, Lipstadt wrote a book that got excellent reviews."}}, "resps": [[["-205.0", "False"]], [["-205.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-205.0", "False"], ["-204.0", "False"]], "doc_hash": "24c6d6528e2718778dca0077b3e5312c8188b80396badc2a6a5f599ed3604370", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 717, "doc": {"premise": "Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons.", "hypothesis": "Established neurons branch out to form connections with other neurons, which enables them to perform various functions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Yes, Established neurons branch out to form connections with other neurons, which enables them to perform various functions."}, "gen_args_1": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Also, Established neurons branch out to form connections with other neurons, which enables them to perform various functions."}, "gen_args_2": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? No, Established neurons branch out to form connections with other neurons, which enables them to perform various functions."}}, "resps": [[["-173.0", "False"]], [["-179.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-179.0", "False"], ["-178.0", "False"]], "doc_hash": "532f6f3fefd1594bf2f5650254e4ccc5f3f0e70164fd695b17b839da56ae46ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 725, "doc": {"premise": "Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment.", "hypothesis": "Relajo told jokes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Yes, Relajo told jokes."}, "gen_args_1": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? Also, Relajo told jokes."}, "gen_args_2": {"arg_0": "", "arg_1": " Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment., right? No, Relajo told jokes."}}, "resps": [[["-193.0", "False"]], [["-194.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-194.0", "False"], ["-198.0", "False"]], "doc_hash": "0b2d6c751f7a2534b7e5fde93a5a5e762efd5f89c186219696d6246044cafb24", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.26762315 0.00490169]"]}
{"doc_id": 733, "doc": {"premise": "See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico.", "hypothesis": "There are no known existing photographs of ancient moradas in New Mexico.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Yes, There are no known existing photographs of ancient moradas in New Mexico."}, "gen_args_1": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Also, There are no known existing photographs of ancient moradas in New Mexico."}, "gen_args_2": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? No, There are no known existing photographs of ancient moradas in New Mexico."}}, "resps": [[["-181.0", "False"]], [["-186.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-186.0", "False"], ["-178.0", "False"]], "doc_hash": "b73336a8ac197c6dd883109a4567ba7095aed6dd4e8c60639d554b6955df2403", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 741, "doc": {"premise": "That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades.", "hypothesis": "Hollow walls let in a lot of noise from the park.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Yes, Hollow walls let in a lot of noise from the park."}, "gen_args_1": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Also, Hollow walls let in a lot of noise from the park."}, "gen_args_2": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? No, Hollow walls let in a lot of noise from the park."}}, "resps": [[["-145.0", "False"]], [["-149.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-149.0", "False"], ["-150.0", "False"]], "doc_hash": "7829390ced650a9b641c4b6306e11e395c5aeb8cb455c9b2f2ee86dff2e59970", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 749, "doc": {"premise": "He turned in appeal to Lord Julian.", "hypothesis": "Lord Julian was nowhere to be seen.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Yes, Lord Julian was nowhere to be seen."}, "gen_args_1": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? Also, Lord Julian was nowhere to be seen."}, "gen_args_2": {"arg_0": "", "arg_1": " He turned in appeal to Lord Julian., right? No, Lord Julian was nowhere to be seen."}}, "resps": [[["-100.5", "False"]], [["-102.0", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-100.5", "False"], ["-102.0", "False"], ["-98.5", "False"]], "doc_hash": "60bb46c5d0478a0eda7aee7c3daf8dcfc1838a7ad58e2d57abe47980d9b66fc6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11611453 0.02590865 0.85797681]"]}
{"doc_id": 757, "doc": {"premise": "The Colonel accepted it, and belatedly bowed, removing his broad hat.", "hypothesis": "The Colonel refused what he was being given and kept his hat on in a sign of defiance.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Yes, The Colonel refused what he was being given and kept his hat on in a sign of defiance."}, "gen_args_1": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Also, The Colonel refused what he was being given and kept his hat on in a sign of defiance."}, "gen_args_2": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? No, The Colonel refused what he was being given and kept his hat on in a sign of defiance."}}, "resps": [[["-155.0", "False"]], [["-158.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-158.0", "False"], ["-147.0", "False"]], "doc_hash": "d8f8fb6b3c7db91b5b55a4bc5b39e61f8cfce1afae0751bdcd2bb3603a81ebf0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35344532e-04 1.66958211e-05 9.99647960e-01]"]}
{"doc_id": 765, "doc": {"premise": "But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent.", "hypothesis": "The office screamed for minutes, enraged by the debauchery on his decks.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Yes, The office screamed for minutes, enraged by the debauchery on his decks."}, "gen_args_1": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Also, The office screamed for minutes, enraged by the debauchery on his decks."}, "gen_args_2": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? No, The office screamed for minutes, enraged by the debauchery on his decks."}}, "resps": [[["-226.0", "False"]], [["-227.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-226.0", "False"], ["-227.0", "False"], ["-224.0", "False"]], "doc_hash": "c0dcd281282aedf0e9d733f0b589e45362c68902fbfe1a14531b26d27634f6c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 773, "doc": {"premise": "Mary Traill would tell you of it.", "hypothesis": "Only I know about it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Yes, Only I know about it."}, "gen_args_1": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? Also, Only I know about it."}, "gen_args_2": {"arg_0": "", "arg_1": " Mary Traill would tell you of it., right? No, Only I know about it."}}, "resps": [[["-102.0", "False"]], [["-104.0", "False"]], [["-100.0", "False"]]], "filtered_resps": [["-102.0", "False"], ["-104.0", "False"], ["-100.0", "False"]], "doc_hash": "0136725dfaec3e5d99a2ac1f31694de8ab6fa71eb966825ae165435b453bdc4b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 781, "doc": {"premise": "Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden.", "hypothesis": "Blood put on his hat, and left the room without saying anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Yes, Blood put on his hat, and left the room without saying anything."}, "gen_args_1": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Also, Blood put on his hat, and left the room without saying anything."}, "gen_args_2": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? No, Blood put on his hat, and left the room without saying anything."}}, "resps": [[["-199.0", "False"]], [["-201.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-201.0", "False"], ["-198.0", "False"]], "doc_hash": "daf60d150239c75936bbc15385d7d4ede853a876b2c29cf6d554beca1eae64d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 789, "doc": {"premise": "I have sent for you, Captain Blood, because of certain news that has just reached me.", "hypothesis": "I have not heard any news, Captain Blood. Have you?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Yes, I have not heard any news, Captain Blood. Have you?"}, "gen_args_1": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Also, I have not heard any news, Captain Blood. Have you?"}, "gen_args_2": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? No, I have not heard any news, Captain Blood. Have you?"}}, "resps": [[["-126.0", "False"]], [["-131.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-126.0", "False"], ["-131.0", "False"], ["-122.5", "False"]], "doc_hash": "55c1cdfbf91ef258a6682a0d4e5df6bdda3d3e6248be11b02310c447ae168c92", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.93064426e-02 1.97465257e-04 9.70496092e-01]"]}
{"doc_id": 797, "doc": {"premise": "You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him.", "hypothesis": "Ogle was angry.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Yes, Ogle was angry."}, "gen_args_1": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? Also, Ogle was angry."}, "gen_args_2": {"arg_0": "", "arg_1": " You'll return to it at once, and take your crew with you, or else....   But Ogle, violent of mien and gesture, interrupted him., right? No, Ogle was angry."}}, "resps": [[["-188.0", "False"]], [["-193.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-193.0", "False"], ["-191.0", "False"]], "doc_hash": "4f518b0a756aee6e23dc16ac3add63a485b1f5bcecf447bdda35d9f601f8fd70", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 805, "doc": {"premise": "A murderer--I?  he said at last.", "hypothesis": "He hadn't murdered anyone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Yes, He hadn't murdered anyone."}, "gen_args_1": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Also, He hadn't murdered anyone."}, "gen_args_2": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? No, He hadn't murdered anyone."}}, "resps": [[["-116.0", "False"]], [["-117.5", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-117.5", "False"], ["-112.0", "False"]], "doc_hash": "25bb49b086ef3ab74973920aa8bfb96140eaf8b595c10989d5ae2a458a29f546", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01791432 0.00399722 0.97808846]"]}
{"doc_id": 813, "doc": {"premise": "What better way?  he demanded.", "hypothesis": "He did not ask any questions, since he knew he had picked the best way.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Yes, He did not ask any questions, since he knew he had picked the best way."}, "gen_args_1": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Also, He did not ask any questions, since he knew he had picked the best way."}, "gen_args_2": {"arg_0": "", "arg_1": " What better way?  he demanded., right? No, He did not ask any questions, since he knew he had picked the best way."}}, "resps": [[["-129.0", "False"]], [["-133.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-133.0", "False"], ["-130.0", "False"]], "doc_hash": "2e04c3643acd12344dbf93dd8e5b3074557609193431d2298417f25f6e8ec51b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 821, "doc": {"premise": "Life can be infernally complex,  he sighed.", "hypothesis": "Life is infernally complicated because of the many interactions one might have.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Yes, Life is infernally complicated because of the many interactions one might have."}, "gen_args_1": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? Also, Life is infernally complicated because of the many interactions one might have."}, "gen_args_2": {"arg_0": "", "arg_1": " Life can be infernally complex,  he sighed., right? No, Life is infernally complicated because of the many interactions one might have."}}, "resps": [[["-130.0", "False"]], [["-136.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-136.0", "False"], ["-133.0", "False"]], "doc_hash": "da43e474220c5830cb404d1dc7550733e52d691ac0c4d6ac8209e125a887be41", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 829, "doc": {"premise": "And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him.", "hypothesis": "He is alone and has no officers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Yes, He is alone and has no officers."}, "gen_args_1": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Also, He is alone and has no officers."}, "gen_args_2": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? No, He is alone and has no officers."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-149.0", "False"]], "doc_hash": "6ca4e4765e0e174eb4b4283c4b6e129f2ed19b553a62b6c1d4c7d7cefc368237", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 837, "doc": {"premise": "You're not very civil, sir, as I have already noticed.", "hypothesis": "The man is acting uncivilized.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Yes, The man is acting uncivilized."}, "gen_args_1": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Also, The man is acting uncivilized."}, "gen_args_2": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? No, The man is acting uncivilized."}}, "resps": [[["-115.5", "False"]], [["-116.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-115.5", "False"], ["-116.5", "False"], ["-115.5", "False"]], "doc_hash": "3f786fa4af2f90ef86d1278a11cf8f987acdbec53deec906936b0437db303025", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 845, "doc": {"premise": "He looked up in surprise, and then sat conning her with brooding glance.", "hypothesis": "She was braver than he expected.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Yes, She was braver than he expected."}, "gen_args_1": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? Also, She was braver than he expected."}, "gen_args_2": {"arg_0": "", "arg_1": " He looked up in surprise, and then sat conning her with brooding glance., right? No, She was braver than he expected."}}, "resps": [[["-134.0", "False"]], [["-137.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-137.0", "False"], ["-135.0", "False"]], "doc_hash": "ec0fa27e36273cbc5eff21f07ace5dc6ac3e90d3536299c6f0270e9f03095c2a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 853, "doc": {"premise": "If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke.", "hypothesis": "There was a fleet of ships.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Yes, There was a fleet of ships."}, "gen_args_1": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Also, There was a fleet of ships."}, "gen_args_2": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? No, There was a fleet of ships."}}, "resps": [[["-185.0", "False"]], [["-186.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-186.0", "False"], ["-184.0", "False"]], "doc_hash": "a2eab4526c83925e6b812356c10610be9651b87ee7116392306375da771a406f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 861, "doc": {"premise": "We went about, and it's been a race ever since.", "hypothesis": "It has always been a contest ever since we went about.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Yes, It has always been a contest ever since we went about."}, "gen_args_1": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Also, It has always been a contest ever since we went about."}, "gen_args_2": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? No, It has always been a contest ever since we went about."}}, "resps": [[["-108.5", "False"]], [["-115.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-108.5", "False"], ["-115.5", "False"], ["-110.0", "False"]], "doc_hash": "9211277c81145d6487531e96bcd7278216350313eaddae4fca101257b06f56a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.16965403e-01 7.44976017e-04 1.82289621e-01]"]}
{"doc_id": 869, "doc": {"premise": "Blood broke the seal, and read.", "hypothesis": "The seal was broken.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Yes, The seal was broken."}, "gen_args_1": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? Also, The seal was broken."}, "gen_args_2": {"arg_0": "", "arg_1": " Blood broke the seal, and read., right? No, The seal was broken."}}, "resps": [[["-91.5", "False"]], [["-96.0", "False"]], [["-92.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-96.0", "False"], ["-92.0", "False"]], "doc_hash": "ef72d66425843713ed2c7ed15628a1b597ae3c611e949dae6dc65a44f6af1e26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61818465 0.00686741 0.37494794]"]}
{"doc_id": 877, "doc": {"premise": "Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing.", "hypothesis": "The fact that she was here after the fight with Wolverstone was considered an embarrassment.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Yes, The fact that she was here after the fight with Wolverstone was considered an embarrassment."}, "gen_args_1": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Also, The fact that she was here after the fight with Wolverstone was considered an embarrassment."}, "gen_args_2": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? No, The fact that she was here after the fight with Wolverstone was considered an embarrassment."}}, "resps": [[["-166.0", "False"]], [["-174.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-174.0", "False"], ["-169.0", "False"]], "doc_hash": "3c25657de6b6aab0f8790079bfcc7c0442b68532a6298297cabc98b94e28e625", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 885, "doc": {"premise": "Steady, Old Wolf! Steady!  Captain Blood admonished him.", "hypothesis": "As he is experienced, Captain Blood helped boost morale amongst his crew members.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Yes, As he is experienced, Captain Blood helped boost morale amongst his crew members."}, "gen_args_1": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Also, As he is experienced, Captain Blood helped boost morale amongst his crew members."}, "gen_args_2": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? No, As he is experienced, Captain Blood helped boost morale amongst his crew members."}}, "resps": [[["-177.0", "False"]], [["-178.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-178.0", "False"], ["-179.0", "False"]], "doc_hash": "6457915213f6055fb487388b6d7e31b5ae35a81fd16ed0c141728f780de0de49", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 893, "doc": {"premise": "No.  Blood closed his telescope.", "hypothesis": "There was no sign of blood anywhere near the telescope.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Yes, There was no sign of blood anywhere near the telescope."}, "gen_args_1": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? Also, There was no sign of blood anywhere near the telescope."}, "gen_args_2": {"arg_0": "", "arg_1": " No.  Blood closed his telescope., right? No, There was no sign of blood anywhere near the telescope."}}, "resps": [[["-119.0", "False"]], [["-123.5", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-119.0", "False"], ["-123.5", "False"], ["-118.0", "False"]], "doc_hash": "c5b4d509bc1b5861e537be680892d76d57dd7719e47b9dc69d1595578314c9c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26814031 0.00297877 0.72888092]"]}
{"doc_id": 901, "doc": {"premise": "Since when have you commanded on the main deck, Ogle? I take my orders from the Captain.", "hypothesis": "The Captain of the ship was feeling rather ill.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Yes, The Captain of the ship was feeling rather ill."}, "gen_args_1": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Also, The Captain of the ship was feeling rather ill."}, "gen_args_2": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? No, The Captain of the ship was feeling rather ill."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-151.0", "False"]], "doc_hash": "183cde3d551ee2f14926cfc5e8c85e7e1caa990db9ee33a80e0ef0844ef7bf3a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 909, "doc": {"premise": "He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow.", "hypothesis": "He never desired to be anything like that dog in that one fable.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Yes, He never desired to be anything like that dog in that one fable."}, "gen_args_1": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Also, He never desired to be anything like that dog in that one fable."}, "gen_args_2": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? No, He never desired to be anything like that dog in that one fable."}}, "resps": [[["-191.0", "False"]], [["-193.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-193.0", "False"], ["-187.0", "False"]], "doc_hash": "a3a68da5feafc01fdd024630d0a5fba3c521cef2d75750bee82f0de8587f2d31", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 917, "doc": {"premise": "Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged.", "hypothesis": "It was clear that staying could have helped me, so no question was ever posed.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Yes, It was clear that staying could have helped me, so no question was ever posed."}, "gen_args_1": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? Also, It was clear that staying could have helped me, so no question was ever posed."}, "gen_args_2": {"arg_0": "", "arg_1": " Besides, how could their staying have helped me?  And as Pitt did not answer him:  Ye see?  he said, and shrugged., right? No, It was clear that staying could have helped me, so no question was ever posed."}}, "resps": [[["-229.0", "False"]], [["-231.0", "False"]], [["-229.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-231.0", "False"], ["-229.0", "False"]], "doc_hash": "697c94de80c70d14e8be46d2d84d64585451fc3177347ab0fcfa25f5fa70247b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 925, "doc": {"premise": "Your words have rankled with him.", "hypothesis": "He is going to punish you for those words.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Yes, He is going to punish you for those words."}, "gen_args_1": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Also, He is going to punish you for those words."}, "gen_args_2": {"arg_0": "", "arg_1": " Your words have rankled with him., right? No, He is going to punish you for those words."}}, "resps": [[["-95.0", "False"]], [["-99.0", "False"]], [["-96.0", "False"]]], "filtered_resps": [["-95.0", "False"], ["-99.0", "False"], ["-96.0", "False"]], "doc_hash": "dc9e7fbe6094414fa87c85a3ef17151d9b58dae8bdf0ececc66f0247a2768e50", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 933, "doc": {"premise": "I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels.", "hypothesis": "The lordship just took my advice and carried his acts accordingly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Yes, The lordship just took my advice and carried his acts accordingly."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Also, The lordship just took my advice and carried his acts accordingly."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? No, The lordship just took my advice and carried his acts accordingly."}}, "resps": [[["-202.0", "False"]], [["-208.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-208.0", "False"], ["-199.0", "False"]], "doc_hash": "f7e2bcf86ea4a14a20352bba314ec3fc6d1b0b53395bea711d249491eba219c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 941, "doc": {"premise": "Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle.", "hypothesis": "The ranks of men were dwindling, as everyone headed towards the forecastle for dinner.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Yes, The ranks of men were dwindling, as everyone headed towards the forecastle for dinner."}, "gen_args_1": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? Also, The ranks of men were dwindling, as everyone headed towards the forecastle for dinner."}, "gen_args_2": {"arg_0": "", "arg_1": " Some o' them dawcocks may believe that tale.  He jerked a contemptuous thumb towards the men in the waist, whose ranks were steadily being increased by the advent of others from the forecastle., right? No, The ranks of men were dwindling, as everyone headed towards the forecastle for dinner."}}, "resps": [[["-270.0", "False"]], [["-266.0", "False"]], [["-266.0", "False"]]], "filtered_resps": [["-270.0", "False"], ["-266.0", "False"], ["-266.0", "False"]], "doc_hash": "2fd743c2a704da540f7d6c6e4b30c908d05506e6eb84ba2200719c3ddb2aebd8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00907471 0.49546264 0.49546264]"]}
{"doc_id": 949, "doc": {"premise": "Good-day to you, sir,  Blood hailed him pleasantly.", "hypothesis": "Blood wished the man a good day.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Yes, Blood wished the man a good day."}, "gen_args_1": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Also, Blood wished the man a good day."}, "gen_args_2": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? No, Blood wished the man a good day."}}, "resps": [[["-122.5", "False"]], [["-123.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-123.5", "False"], ["-122.0", "False"]], "doc_hash": "4c445db577b44bd654899e678fc34fb9c8826552fad083cd44fb73a4906756d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.33149896 0.12195165 0.54654939]"]}
{"doc_id": 957, "doc": {"premise": "That girl, there.  He flung out a bare arm to point to her.", "hypothesis": "He didn't have any arms so he asked someone else to point to the girl.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Yes, He didn't have any arms so he asked someone else to point to the girl."}, "gen_args_1": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Also, He didn't have any arms so he asked someone else to point to the girl."}, "gen_args_2": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? No, He didn't have any arms so he asked someone else to point to the girl."}}, "resps": [[["-148.0", "False"]], [["-150.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-150.0", "False"], ["-148.0", "False"]], "doc_hash": "7e9f8cf4ceed98359f7de5660d8d09b5a5a9e22a270663bd9303add0d2a075ac", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 965, "doc": {"premise": "What I think of you can be a very little matter to you, sir.   This was a disarming stroke.", "hypothesis": "You should definitely care about what I think of you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Yes, You should definitely care about what I think of you."}, "gen_args_1": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? Also, You should definitely care about what I think of you."}, "gen_args_2": {"arg_0": "", "arg_1": " What I think of you can be a very little matter to you, sir.   This was a disarming stroke., right? No, You should definitely care about what I think of you."}}, "resps": [[["-160.0", "False"]], [["-160.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-160.0", "False"], ["-159.0", "False"]], "doc_hash": "5cfa2b047d22bec74613d8c51d36195cfa9a184b413ac54f8de43604e152c704", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 973, "doc": {"premise": "I cannot think why you should trouble to put yourself on your defence,   she discouraged him.", "hypothesis": "She had discouraged any form of defense that was applicable to you.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Yes, She had discouraged any form of defense that was applicable to you."}, "gen_args_1": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Also, She had discouraged any form of defense that was applicable to you."}, "gen_args_2": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? No, She had discouraged any form of defense that was applicable to you."}}, "resps": [[["-179.0", "False"]], [["-179.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-179.0", "False"], ["-177.0", "False"]], "doc_hash": "f7cefbdc77a48694f20f6a3bd718b82b49302315c69202d0b62df2999a203f9b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 981, "doc": {"premise": "He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it.", "hypothesis": "He found little safety through reading the passage on the page.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Yes, He found little safety through reading the passage on the page."}, "gen_args_1": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Also, He found little safety through reading the passage on the page."}, "gen_args_2": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? No, He found little safety through reading the passage on the page."}}, "resps": [[["-270.0", "False"]], [["-276.0", "False"]], [["-268.0", "False"]]], "filtered_resps": [["-270.0", "False"], ["-276.0", "False"], ["-268.0", "False"]], "doc_hash": "090b07fb3cddfeca97b191f3da59a239e78516a81ea4b2481dcddbe10d1fdc7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 989, "doc": {"premise": "See it manned for me.", "hypothesis": "The boat's cannons were currently unmanned.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See it manned for me., right? Yes, The boat's cannons were currently unmanned."}, "gen_args_1": {"arg_0": "", "arg_1": " See it manned for me., right? Also, The boat's cannons were currently unmanned."}, "gen_args_2": {"arg_0": "", "arg_1": " See it manned for me., right? No, The boat's cannons were currently unmanned."}}, "resps": [[["-112.5", "False"]], [["-112.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-112.5", "False"], ["-112.5", "False"]], "doc_hash": "261df6cabb92aafffb1db285d22acc9f1cd9cfa4cde020d1e404cae409b0f589", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 997, "doc": {"premise": "After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex.", "hypothesis": "You can see views of the coastline at the top of the hill.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Yes, You can see views of the coastline at the top of the hill."}, "gen_args_1": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Also, You can see views of the coastline at the top of the hill."}, "gen_args_2": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? No, You can see views of the coastline at the top of the hill."}}, "resps": [[["-180.0", "False"]], [["-185.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-185.0", "False"], ["-184.0", "False"]], "doc_hash": "aec2843270e1bce34a996ee690755dc98aab6fd44e1744d333f5f6a4a3e252b1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1005, "doc": {"premise": "Hopes were raised, and also fizzled, over Bahamian citrus and pineapple.", "hypothesis": "Althrough the pineapples tasted great the shipping costs were too high to bring them to market.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Yes, Althrough the pineapples tasted great the shipping costs were too high to bring them to market."}, "gen_args_1": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Also, Althrough the pineapples tasted great the shipping costs were too high to bring them to market."}, "gen_args_2": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? No, Althrough the pineapples tasted great the shipping costs were too high to bring them to market."}}, "resps": [[["-177.0", "False"]], [["-180.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-180.0", "False"], ["-179.0", "False"]], "doc_hash": "8237297dd184c5215edf64399ae0df4bb2846ecea913db2d85233f0fd060b21b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1013, "doc": {"premise": "The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption.", "hypothesis": "The 2 mile sound was probably caused by a volcanic eruption.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Yes, The 2 mile sound was probably caused by a volcanic eruption."}, "gen_args_1": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? Also, The 2 mile sound was probably caused by a volcanic eruption."}, "gen_args_2": {"arg_0": "", "arg_1": " The sound, some 3 km (2 miles) in diameter, is thought to be a huge caldera that formed after a powerful volcanic eruption., right? No, The 2 mile sound was probably caused by a volcanic eruption."}}, "resps": [[["-147.0", "False"]], [["-149.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-149.0", "False"], ["-150.0", "False"]], "doc_hash": "8c5c6500a4a8562a9d29ca8940406efb28145cd8a85a1396c578cd3869987bd3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1021, "doc": {"premise": "Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940.", "hypothesis": "Greece is one of the countries in the world that has had a dictator.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Yes, Greece is one of the countries in the world that has had a dictator."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Also, Greece is one of the countries in the world that has had a dictator."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? No, Greece is one of the countries in the world that has had a dictator."}}, "resps": [[["-190.0", "False"]], [["-194.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-194.0", "False"], ["-196.0", "False"]], "doc_hash": "057f5e6661ae4a103f253507d6a8fbe75d34a48755bdcfb0ed8cb7955e01d138", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.01794253 0.00242826]"]}
{"doc_id": 1029, "doc": {"premise": "An extensive program of refurbishment is due to be finished by late 2001.", "hypothesis": "The refurbishment program will end before the year 2001 begins.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Yes, The refurbishment program will end before the year 2001 begins."}, "gen_args_1": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Also, The refurbishment program will end before the year 2001 begins."}, "gen_args_2": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? No, The refurbishment program will end before the year 2001 begins."}}, "resps": [[["-120.5", "False"]], [["-128.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-120.5", "False"], ["-128.0", "False"], ["-119.0", "False"]], "doc_hash": "f1109eae03a7e061b47ea25c557d4dee14a6cda30f6e0594c58e622da1cf3e76", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.82407120e-01 1.00886527e-04 8.17491994e-01]"]}
{"doc_id": 1037, "doc": {"premise": "Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web.", "hypothesis": "Singel was an outer barrier.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Yes, Singel was an outer barrier."}, "gen_args_1": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? Also, Singel was an outer barrier."}, "gen_args_2": {"arg_0": "", "arg_1": " Singel was once the outer barrier for the medieval city, but as the city expanded, Herengracht (Gentleman's Canal), Keizersgracht (Emperor's Canal), and Prinsengracht (Princes' Canal) enlarged the web., right? No, Singel was an outer barrier."}}, "resps": [[["-159.0", "False"]], [["-165.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-165.0", "False"], ["-160.0", "False"]], "doc_hash": "b96a7704511053f1c2d01bc7202c8dc4dcf66b656ee13f4806f91a358b1b5aa7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 1045, "doc": {"premise": "Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands.", "hypothesis": "Culebra is located nowhere near Puerto Rico and St. Thomas in the US Virgin Islands.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Yes, Culebra is located nowhere near Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_1": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Also, Culebra is located nowhere near Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_2": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? No, Culebra is located nowhere near Puerto Rico and St. Thomas in the US Virgin Islands."}}, "resps": [[["-140.0", "False"]], [["-145.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-145.0", "False"], ["-136.0", "False"]], "doc_hash": "a450074658bd12c39af454120dbbdd4126c38387f743766e7446116d4c336c81", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 1053, "doc": {"premise": "The third member of the Hindu  trinity  is Brahma, whose only task was to create the world.", "hypothesis": "Brahma is a Christian apostle.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Yes, Brahma is a Christian apostle."}, "gen_args_1": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Also, Brahma is a Christian apostle."}, "gen_args_2": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? No, Brahma is a Christian apostle."}}, "resps": [[["-136.0", "False"]], [["-136.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-136.0", "False"], ["-131.0", "False"]], "doc_hash": "bb905410fc014ee585902a40df6f133a4155c7cbdddfcdd6c3de25093a4b1aef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1061, "doc": {"premise": "A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis.", "hypothesis": "The Spartans killed many of the Persian army at Thermopylae.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Yes, The Spartans killed many of the Persian army at Thermopylae."}, "gen_args_1": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? Also, The Spartans killed many of the Persian army at Thermopylae."}, "gen_args_2": {"arg_0": "", "arg_1": " A few hundred heroic troops under Leonidas of Sparta delayed the enormous Persian army at the pass of Thermopylae long enough for the Athenians to be evacuated to the island of Salamis., right? No, The Spartans killed many of the Persian army at Thermopylae."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-162.0", "False"]], "doc_hash": "b206e68de46d0fdb141d977d5be5705ebe75180f35c21ec13ccbbbd496469e31", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1069, "doc": {"premise": "Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith.", "hypothesis": "The Zenith is a big concert hall.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Yes, The Zenith is a big concert hall."}, "gen_args_1": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Also, The Zenith is a big concert hall."}, "gen_args_2": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? No, The Zenith is a big concert hall."}}, "resps": [[["-126.0", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "e8dda7b0c0f32a7e5b1ee1e38de8a46922dffaee1b10a6eafbce41c5df2fbba0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1077, "doc": {"premise": "Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi.", "hypothesis": "Kuala Perlis was 17 miles south.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Yes, Kuala Perlis was 17 miles south."}, "gen_args_1": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Also, Kuala Perlis was 17 miles south."}, "gen_args_2": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? No, Kuala Perlis was 17 miles south."}}, "resps": [[["-152.0", "False"]], [["-155.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-155.0", "False"], ["-150.0", "False"]], "doc_hash": "983bdd27892e6cbe40cf80d11d3a4b3918c7e48c912e1eeae80f84df04b562bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1085, "doc": {"premise": "702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory.", "hypothesis": "Vegas has no coffee houses.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Yes, Vegas has no coffee houses."}, "gen_args_1": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? Also, Vegas has no coffee houses."}, "gen_args_2": {"arg_0": "", "arg_1": " 702/369-1540) the oldest coffeehouse in Las Vegas and, according to some, still the best in all its Bohemian glory., right? No, Vegas has no coffee houses."}}, "resps": [[["-163.0", "False"]], [["-167.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-167.0", "False"], ["-161.0", "False"]], "doc_hash": "3d0523ba1094759ec6b409e580eec759b15fba97c15e258644e9c77d1008a0b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1093, "doc": {"premise": "Several small temples can be found here.", "hypothesis": "There are some little temples.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Yes, There are some little temples."}, "gen_args_1": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Also, There are some little temples."}, "gen_args_2": {"arg_0": "", "arg_1": " Several small temples can be found here., right? No, There are some little temples."}}, "resps": [[["-84.5", "False"]], [["-89.5", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-84.5", "False"], ["-89.5", "False"], ["-88.5", "False"]], "doc_hash": "fb52ce940f5266d9234e2c845b0980ac34b166b9aa1a9da8f2fec137c612fc32", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1101, "doc": {"premise": "The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors.", "hypothesis": "The acoustics are great for singing.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Yes, The acoustics are great for singing."}, "gen_args_1": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Also, The acoustics are great for singing."}, "gen_args_2": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? No, The acoustics are great for singing."}}, "resps": [[["-147.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "a6d2f74a08babe6e4af2eefb4d9022b0c63a5aa177f894953c67b7f83ce9a91d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1109, "doc": {"premise": "The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality.", "hypothesis": "The faaade was in the Temple of Ramses II.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Yes, The faaade was in the Temple of Ramses II."}, "gen_args_1": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? Also, The faaade was in the Temple of Ramses II."}, "gen_args_2": {"arg_0": "", "arg_1": " The faaade of the Temple of Ramses II is one of the most enduring images of Egypt and though you may have seen them in photographs, they are truly breathtaking in reality., right? No, The faaade was in the Temple of Ramses II."}}, "resps": [[["-170.0", "False"]], [["-172.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-172.0", "False"], ["-170.0", "False"]], "doc_hash": "b14671fd05970cd3b0fda8ec2c3aa4c623d905a5163136581a0fbd1ed5a39082", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1117, "doc": {"premise": "Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times.", "hypothesis": "The National Historical Museum has some old farm equipment.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Yes, The National Historical Museum has some old farm equipment."}, "gen_args_1": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Also, The National Historical Museum has some old farm equipment."}, "gen_args_2": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? No, The National Historical Museum has some old farm equipment."}}, "resps": [[["-169.0", "False"]], [["-171.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-171.0", "False"], ["-171.0", "False"]], "doc_hash": "04bcbacb53871b40d0b337e1f4265dd55e26bc99fded224256c337c6d3487b5f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1125, "doc": {"premise": "Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth.", "hypothesis": "A church, chapel, and hexagonal tower represent the city's post-war rebirth.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Yes, A church, chapel, and hexagonal tower represent the city's post-war rebirth."}, "gen_args_1": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Also, A church, chapel, and hexagonal tower represent the city's post-war rebirth."}, "gen_args_2": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? No, A church, chapel, and hexagonal tower represent the city's post-war rebirth."}}, "resps": [[["-167.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "816a41849cb39216f4194fe8d65a7b40abc060a58fa1e73152dc21fa57e413a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1133, "doc": {"premise": "The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops.", "hypothesis": "The shops nearby are duller than any others around.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Yes, The shops nearby are duller than any others around."}, "gen_args_1": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? Also, The shops nearby are duller than any others around."}, "gen_args_2": {"arg_0": "", "arg_1": " The nearby streets Mallorca, Valencia, and Provenaa are also overflowing with interesting shops., right? No, The shops nearby are duller than any others around."}}, "resps": [[["-169.0", "False"]], [["-171.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-171.0", "False"], ["-165.0", "False"]], "doc_hash": "9ebd371e7ffbaff0cf97eec56c981c33b95be0a800bc848ac9eaa84bdd3c4dfc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1141, "doc": {"premise": "You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum.", "hypothesis": "The museum is near the Egyptian museum.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Yes, The museum is near the Egyptian museum."}, "gen_args_1": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Also, The museum is near the Egyptian museum."}, "gen_args_2": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? No, The museum is near the Egyptian museum."}}, "resps": [[["-158.0", "False"]], [["-163.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-163.0", "False"], ["-161.0", "False"]], "doc_hash": "7d3f79df3d5002f0b1b684be43141be00c8f173f7f8a893c57d1fddb51eb9473", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1149, "doc": {"premise": "Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests.", "hypothesis": "National unity doesn't matter at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Yes, National unity doesn't matter at all."}, "gen_args_1": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Also, National unity doesn't matter at all."}, "gen_args_2": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? No, National unity doesn't matter at all."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "fd23a24f49aad1ab1fd215ba253ede36363474dab672e6085db324b8919ae0b7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1157, "doc": {"premise": "Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night.", "hypothesis": "Coupons are given out on the beach, hoping to attract customers at night.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Yes, Coupons are given out on the beach, hoping to attract customers at night."}, "gen_args_1": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? Also, Coupons are given out on the beach, hoping to attract customers at night."}, "gen_args_2": {"arg_0": "", "arg_1": " Special coupons are handed out aggressively on the beaches during the day, in hopes of luring the biggest crowd that night., right? No, Coupons are given out on the beach, hoping to attract customers at night."}}, "resps": [[["-164.0", "False"]], [["-168.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-168.0", "False"], ["-162.0", "False"]], "doc_hash": "17a9c5caa678f6bf2f4a4d5d58837b83fdd179f9518d0b95c54d644bec2b5b26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1165, "doc": {"premise": "The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village.", "hypothesis": "Alaior has a lot of white houses.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Yes, Alaior has a lot of white houses."}, "gen_args_1": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Also, Alaior has a lot of white houses."}, "gen_args_2": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? No, Alaior has a lot of white houses."}}, "resps": [[["-141.0", "False"]], [["-145.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-145.0", "False"], ["-146.0", "False"]], "doc_hash": "89edbe0388dde7f9f42d1890d27e92c6ba9598c5908dab9d36abfdc218b2fcdf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1173, "doc": {"premise": "Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy.", "hypothesis": "The snake eventually died from complications related to diabetes.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Yes, The snake eventually died from complications related to diabetes."}, "gen_args_1": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Also, The snake eventually died from complications related to diabetes."}, "gen_args_2": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? No, The snake eventually died from complications related to diabetes."}}, "resps": [[["-153.0", "False"]], [["-153.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-153.0", "False"], ["-154.0", "False"]], "doc_hash": "88f9c2653392b87235e0f407d928a298d5161cc36482e554627cba79130f344a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1181, "doc": {"premise": "Just so long as you don't object to being shown up by the resident ten-year-old experts.", "hypothesis": "The ten year olds know what they're talking about.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Yes, The ten year olds know what they're talking about."}, "gen_args_1": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? Also, The ten year olds know what they're talking about."}, "gen_args_2": {"arg_0": "", "arg_1": " Just so long as you don't object to being shown up by the resident ten-year-old experts., right? No, The ten year olds know what they're talking about."}}, "resps": [[["-121.0", "False"]], [["-124.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-124.0", "False"], ["-122.5", "False"]], "doc_hash": "d44c8ee34be5eb8b20c25d9e23121f1b1e3a2523de0a9490b0f3ef377a3eb53d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78559703 0.03911257 0.17529039]"]}
{"doc_id": 1189, "doc": {"premise": "Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies.", "hypothesis": "The Komische Oper is in Germany.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Yes, The Komische Oper is in Germany."}, "gen_args_1": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Also, The Komische Oper is in Germany."}, "gen_args_2": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? No, The Komische Oper is in Germany."}}, "resps": [[["-161.0", "False"]], [["-166.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-166.0", "False"], ["-160.0", "False"]], "doc_hash": "3967aa20f583f4d1ff32a213af3932d7dd2a46b6dfe2505ed437004afece7ad6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1197, "doc": {"premise": "The Great Depression hit California hard.", "hypothesis": "California was really hurt by the bad economy.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Yes, California was really hurt by the bad economy."}, "gen_args_1": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Also, California was really hurt by the bad economy."}, "gen_args_2": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? No, California was really hurt by the bad economy."}}, "resps": [[["-78.5", "False"]], [["-85.0", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-78.5", "False"], ["-85.0", "False"], ["-83.0", "False"]], "doc_hash": "3de73c85e00310daa6628453069ac9879320db76b8736c80639e91f610c525f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98754466 0.00148471 0.01097063]"]}
{"doc_id": 1205, "doc": {"premise": "Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door.", "hypothesis": "The town is so pleasant I never want to leave.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Yes, The town is so pleasant I never want to leave."}, "gen_args_1": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? Also, The town is so pleasant I never want to leave."}, "gen_args_2": {"arg_0": "", "arg_1": " Cynicism dissolves with your first taste of the town's gentle ambience, created by a clever combination of the comforts of sophisticated modernity with the simpler joys of the wilderness at its back door., right? No, The town is so pleasant I never want to leave."}}, "resps": [[["-212.0", "False"]], [["-214.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-214.0", "False"], ["-214.0", "False"]], "doc_hash": "192a50882079cae24045795f6414df04859adbb769bc2c09391459036e667c63", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1213, "doc": {"premise": "Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level.", "hypothesis": "Flag Hill is above the sea level.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Yes, Flag Hill is above the sea level."}, "gen_args_1": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Also, Flag Hill is above the sea level."}, "gen_args_2": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? No, Flag Hill is above the sea level."}}, "resps": [[["-119.5", "False"]], [["-126.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-126.0", "False"], ["-122.0", "False"]], "doc_hash": "1e67fef359d58f7f54fa107b55ff95818ce5322345d61f900b80ad96e4b5b4f6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.92285961 0.00138746 0.07575293]"]}
{"doc_id": 1221, "doc": {"premise": "Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site.", "hypothesis": "The square had nowhere to sit.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Yes, The square had nowhere to sit."}, "gen_args_1": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Also, The square had nowhere to sit."}, "gen_args_2": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? No, The square had nowhere to sit."}}, "resps": [[["-196.0", "False"]], [["-199.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-199.0", "False"], ["-196.0", "False"]], "doc_hash": "02ff7a3ca158184eb122c2a02123b07dcf2f4fd7916c3fedd363318de09dd33a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1229, "doc": {"premise": "Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible.", "hypothesis": "You can just book when you are there.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Yes, You can just book when you are there."}, "gen_args_1": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? Also, You can just book when you are there."}, "gen_args_2": {"arg_0": "", "arg_1": " Ask your travel agency or the Berlin tourist office for details of upcoming programs, and book in advance where possible., right? No, You can just book when you are there."}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-134.0", "False"]], "doc_hash": "1b020f30c5004eec4fdcdfd4182d508101c72c4e9be4369e2840fe917c1673da", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1237, "doc": {"premise": "Just east of the Star Ferry terminal, you'll come to City Hall.", "hypothesis": "City Hall is near the ferry terminal.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Yes, City Hall is near the ferry terminal."}, "gen_args_1": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Also, City Hall is near the ferry terminal."}, "gen_args_2": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? No, City Hall is near the ferry terminal."}}, "resps": [[["-103.0", "False"]], [["-112.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-103.0", "False"], ["-112.5", "False"], ["-106.0", "False"]], "doc_hash": "5074be7e3ae6168249a8fda8a9afce220d411f3459d3d0818bd342df3941eef6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52506211e-01 7.12968329e-05 4.74224919e-02]"]}
{"doc_id": 1245, "doc": {"premise": "Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base.", "hypothesis": "By consolidating human resources systems, room was created for new corporate structures.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Yes, By consolidating human resources systems, room was created for new corporate structures."}, "gen_args_1": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Also, By consolidating human resources systems, room was created for new corporate structures."}, "gen_args_2": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? No, By consolidating human resources systems, room was created for new corporate structures."}}, "resps": [[["-168.0", "False"]], [["-172.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-172.0", "False"], ["-170.0", "False"]], "doc_hash": "bed94dd11fdd595faf2c1892513fffde60989a7c4f4769b83a999f444d706274", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1253, "doc": {"premise": "The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c", "hypothesis": "This paper includes data on rural routes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Yes, This paper includes data on rural routes."}, "gen_args_1": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? Also, This paper includes data on rural routes."}, "gen_args_2": {"arg_0": "", "arg_1": " The statistics on rural routes presented in this paper are based on the 1989 National Mail Count data.c, right? No, This paper includes data on rural routes."}}, "resps": [[["-145.0", "False"]], [["-145.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-145.0", "False"], ["-148.0", "False"]], "doc_hash": "591c7a8084a2c0b26c7bdf1b668ca3212022fb3f044b41ed2c852bd4398c7a84", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 1261, "doc": {"premise": "189 and the user costs are estimated in the same way.", "hypothesis": "They guessed the user costs were $10000.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Yes, They guessed the user costs were $10000."}, "gen_args_1": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Also, They guessed the user costs were $10000."}, "gen_args_2": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? No, They guessed the user costs were $10000."}}, "resps": [[["-129.0", "False"]], [["-129.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-129.0", "False"], ["-128.0", "False"]], "doc_hash": "8d07d5019e5088933e1b5f893d7b73ecf793f09faf60135b35cd0f5ce7a707c6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1269, "doc": {"premise": "Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999.", "hypothesis": "Households all earned $10000 more last year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Yes, Households all earned $10000 more last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Also, Households all earned $10000 more last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? No, Households all earned $10000 more last year."}}, "resps": [[["-165.0", "False"]], [["-165.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-165.0", "False"], ["-164.0", "False"]], "doc_hash": "a9fa5184918f6cbfe5d369e561b00c793d5727cb5afb0e986a2ccc5592290013", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1277, "doc": {"premise": "It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities.", "hypothesis": "The CIO must communicate frequently with members to outline their responsibilities.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Yes, The CIO must communicate frequently with members to outline their responsibilities."}, "gen_args_1": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? Also, The CIO must communicate frequently with members to outline their responsibilities."}, "gen_args_2": {"arg_0": "", "arg_1": " It is the duty of a CIO to manage expectations and help ensure that all members of a CIO organization have a clear understanding of their responsibilities., right? No, The CIO must communicate frequently with members to outline their responsibilities."}}, "resps": [[["-146.0", "False"]], [["-150.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-150.0", "False"], ["-151.0", "False"]], "doc_hash": "11475ca2df7bf736640584b0f2e7919e167b1de35794b8237f7c01f6aa9ea761", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1285, "doc": {"premise": "It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere.", "hypothesis": "You can't know how much bias exists because it's hard to separate from other outside influences.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Yes, You can't know how much bias exists because it's hard to separate from other outside influences."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Also, You can't know how much bias exists because it's hard to separate from other outside influences."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? No, You can't know how much bias exists because it's hard to separate from other outside influences."}}, "resps": [[["-219.0", "False"]], [["-221.0", "False"]], [["-221.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-221.0", "False"], ["-221.0", "False"]], "doc_hash": "0081c20ef8ab4d008db84fafba50a0ab7e1afb3b3e813afda07fb1905f397aa4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1293, "doc": {"premise": ", the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3.", "hypothesis": "They estimated the benefits.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Yes, They estimated the benefits."}, "gen_args_1": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Also, They estimated the benefits."}, "gen_args_2": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? No, They estimated the benefits."}}, "resps": [[["-206.0", "False"]], [["-206.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-206.0", "False"], ["-205.0", "False"]], "doc_hash": "deb10b4b33a28b9926cd6c191865ded6a96ed61982c8c85081cf416f53c95b22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1301, "doc": {"premise": "In addition, program personnel conduct various workshops for and make educational materials available to new providers.", "hypothesis": "Program personnel host workshops.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Yes, Program personnel host workshops."}, "gen_args_1": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? Also, Program personnel host workshops."}, "gen_args_2": {"arg_0": "", "arg_1": " In addition, program personnel conduct various workshops for and make educational materials available to new providers., right? No, Program personnel host workshops."}}, "resps": [[["-135.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "01b4e01fa843e09e9924a10f608c13c4168a9891bd5fe4ce340cd40010f4f8ab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1309, "doc": {"premise": "LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States.", "hypothesis": "Some attorneys get paid by the LSC.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Yes, Some attorneys get paid by the LSC."}, "gen_args_1": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Also, Some attorneys get paid by the LSC."}, "gen_args_2": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? No, Some attorneys get paid by the LSC."}}, "resps": [[["-166.0", "False"]], [["-167.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-167.0", "False"], ["-167.0", "False"]], "doc_hash": "9763823f008c296b5d76d0042ac26c7577b1baab77436bf2482e87c5e328aec9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1317, "doc": {"premise": "But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one.", "hypothesis": "Her work as a judge helped poor minorities in New York.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Yes, Her work as a judge helped poor minorities in New York."}, "gen_args_1": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Also, Her work as a judge helped poor minorities in New York."}, "gen_args_2": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? No, Her work as a judge helped poor minorities in New York."}}, "resps": [[["-173.0", "False"]], [["-178.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-178.0", "False"], ["-174.0", "False"]], "doc_hash": "94652104cd11508b48d263599dd70cc6de72365a53091764097599924c2d6201", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1325, "doc": {"premise": "For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds.", "hypothesis": "The trust fund needed to borrow money.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Yes, The trust fund needed to borrow money."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? Also, The trust fund needed to borrow money."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in 1983 the Old-Age and Survivors Insurance trust fund borrowed from the Disability Insurance and Hospital Insurance trust funds., right? No, The trust fund needed to borrow money."}}, "resps": [[["-123.5", "False"]], [["-126.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-126.0", "False"], ["-124.0", "False"]], "doc_hash": "2bfc323dc697099f8ed52afd0eb1607b5b9e53d7a764d4b54999ad588b0c3d99", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 1333, "doc": {"premise": "Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process.", "hypothesis": "First you'll need to test the efficacy of an intervention.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Yes, First you'll need to test the efficacy of an intervention."}, "gen_args_1": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Also, First you'll need to test the efficacy of an intervention."}, "gen_args_2": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? No, First you'll need to test the efficacy of an intervention."}}, "resps": [[["-173.0", "False"]], [["-176.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-176.0", "False"], ["-172.0", "False"]], "doc_hash": "881398f85e57b22739e2ba92243c652c37b70927e776abc7c0af21b07d6be36e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1341, "doc": {"premise": "When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher.", "hypothesis": "When the travel voucher is used, the system can compare the info to make sure there is no fraud.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Yes, When the travel voucher is used, the system can compare the info to make sure there is no fraud."}, "gen_args_1": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Also, When the travel voucher is used, the system can compare the info to make sure there is no fraud."}, "gen_args_2": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? No, When the travel voucher is used, the system can compare the info to make sure there is no fraud."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-195.0", "False"]], "doc_hash": "d71fc6c56deac435f5dbe5b61ee14daf2a15435cd405082be315c224f856b59d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.11849965 0.00589975]"]}
{"doc_id": 1349, "doc": {"premise": "12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS).", "hypothesis": "12HEI was a sponsor for the project.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Yes, 12HEI was a sponsor for the project."}, "gen_args_1": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? Also, 12HEI was a sponsor for the project."}, "gen_args_2": {"arg_0": "", "arg_1": " 12HEI sponsored the multi-city the National Morbidity, Mortality, and Air Pollution Study (NMMAPS)., right? No, 12HEI was a sponsor for the project."}}, "resps": [[["-138.0", "False"]], [["-145.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-145.0", "False"], ["-142.0", "False"]], "doc_hash": "31e1f87ab1055c5dba59ce93d1416dccf2da5afeb36a3023ea1b4f6ad70954e3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1357, "doc": {"premise": "TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS", "hypothesis": "Mercury has allowances that are set.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Yes, Mercury has allowances that are set."}, "gen_args_1": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Also, Mercury has allowances that are set."}, "gen_args_2": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? No, Mercury has allowances that are set."}}, "resps": [[["-158.0", "False"]], [["-162.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-162.0", "False"], ["-158.0", "False"]], "doc_hash": "20e1575fdce867057d9b2c4ff643722e9b0768c041b497b850b3891677451307", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1365, "doc": {"premise": "C-R functions may also be estimated with or without explicit thresholds.", "hypothesis": "C-R functions can be estimated a couple different ways and then published for the reader to decide.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Yes, C-R functions can be estimated a couple different ways and then published for the reader to decide."}, "gen_args_1": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Also, C-R functions can be estimated a couple different ways and then published for the reader to decide."}, "gen_args_2": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? No, C-R functions can be estimated a couple different ways and then published for the reader to decide."}}, "resps": [[["-159.0", "False"]], [["-161.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-161.0", "False"], ["-160.0", "False"]], "doc_hash": "6c38f8b20d1f028a8c2bfed52d2ee39e957cc66ba8b6d8b180450229c2de0fde", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1373, "doc": {"premise": "We have already come a long way, and much is left to do.", "hypothesis": "We still have things to do even tho we have come so far.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Yes, We still have things to do even tho we have come so far."}, "gen_args_1": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? Also, We still have things to do even tho we have come so far."}, "gen_args_2": {"arg_0": "", "arg_1": " We have already come a long way, and much is left to do., right? No, We still have things to do even tho we have come so far."}}, "resps": [[["-100.5", "False"]], [["-106.0", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-100.5", "False"], ["-106.0", "False"], ["-102.0", "False"]], "doc_hash": "f729908e187cb0b418e2dda0f2b3bc70feecfa136c43fd99f8b02782c70c25d5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81485186 0.00333011 0.18181803]"]}
{"doc_id": 1381, "doc": {"premise": "Significant differences were noted, however, as", "hypothesis": "There was absolutely no detectable difference.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Yes, There was absolutely no detectable difference."}, "gen_args_1": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Also, There was absolutely no detectable difference."}, "gen_args_2": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? No, There was absolutely no detectable difference."}}, "resps": [[["-96.5", "False"]], [["-100.0", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-96.5", "False"], ["-100.0", "False"], ["-95.0", "False"]], "doc_hash": "450dc0b68d36c83d930b96e2d9ea6ec992c641b5c2ab99b42ca0602e5dc4f218", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.18142609 0.00547859 0.81309532]"]}
{"doc_id": 1389, "doc": {"premise": "Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees.", "hypothesis": "If this requirement were put in place the number of LSC grantees would fall by 80 percent.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Yes, If this requirement were put in place the number of LSC grantees would fall by 80 percent."}, "gen_args_1": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Also, If this requirement were put in place the number of LSC grantees would fall by 80 percent."}, "gen_args_2": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? No, If this requirement were put in place the number of LSC grantees would fall by 80 percent."}}, "resps": [[["-182.0", "False"]], [["-183.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-183.0", "False"], ["-182.0", "False"]], "doc_hash": "267c4b4eced26b3bfe4afad7a78fc04d47cec0b9da1c4066d6062cc5a198b45a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1397, "doc": {"premise": "This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared.", "hypothesis": "The demand curve won't change this month.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Yes, The demand curve won't change this month."}, "gen_args_1": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? Also, The demand curve won't change this month."}, "gen_args_2": {"arg_0": "", "arg_1": " This is a demand curve, conditional on the constraint that the discount remains the same, under which condition no mailers will shift to workshared., right? No, The demand curve won't change this month."}}, "resps": [[["-204.0", "False"]], [["-203.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-203.0", "False"], ["-203.0", "False"]], "doc_hash": "0283848aa183b826b889f108792d91b85f7535fdb3e6500fd2fcbdd556c47833", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1405, "doc": {"premise": "change are staff downsizing, changes in contract methods, and business", "hypothesis": "They're firing some people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Yes, They're firing some people."}, "gen_args_1": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Also, They're firing some people."}, "gen_args_2": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? No, They're firing some people."}}, "resps": [[["-126.0", "False"]], [["-126.5", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-126.5", "False"], ["-125.0", "False"]], "doc_hash": "0d66212bcfd6d15071ba2e62f76bb22c291bc20f79fa2d75116cbd88e37219ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.2312239  0.14024438 0.62853172]"]}
{"doc_id": 1413, "doc": {"premise": "and internal control in either of two 6", "hypothesis": "Internal controls don't exist.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Yes, Internal controls don't exist."}, "gen_args_1": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Also, Internal controls don't exist."}, "gen_args_2": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? No, Internal controls don't exist."}}, "resps": [[["-95.5", "False"]], [["-98.0", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-95.5", "False"], ["-98.0", "False"], ["-95.0", "False"]], "doc_hash": "e66a88db1ffbcef1689a4c5f0196d3bd9c7674a72fbd213c897cc0cdb6ec2d86", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.36619222 0.03005889 0.6037489 ]"]}
{"doc_id": 1421, "doc": {"premise": "The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed.", "hypothesis": "The two groups work together.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Yes, The two groups work together."}, "gen_args_1": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? Also, The two groups work together."}, "gen_args_2": {"arg_0": "", "arg_1": " The cooperation between the program and the integrity divisions is the vehicle by which emerging issues are addressed., right? No, The two groups work together."}}, "resps": [[["-133.0", "False"]], [["-139.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-139.0", "False"], ["-136.0", "False"]], "doc_hash": "7e369376e87796ef08e454fb8742811433c53615aed63956c3c709b306cd087d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1429, "doc": {"premise": "We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world.", "hypothesis": "We want to make GAO stronger because it has a lot of problems right now.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Yes, We want to make GAO stronger because it has a lot of problems right now."}, "gen_args_1": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Also, We want to make GAO stronger because it has a lot of problems right now."}, "gen_args_2": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? No, We want to make GAO stronger because it has a lot of problems right now."}}, "resps": [[["-173.0", "False"]], [["-176.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-176.0", "False"], ["-174.0", "False"]], "doc_hash": "aeea4ed2cc3210c8c7f666b9e360882085cf48d146c997bfd78607e8cfb0579c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1437, "doc": {"premise": "They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies.", "hypothesis": "Improvements in the operations of government agencies were included.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Yes, Improvements in the operations of government agencies were included."}, "gen_args_1": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Also, Improvements in the operations of government agencies were included."}, "gen_args_2": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? No, Improvements in the operations of government agencies were included."}}, "resps": [[["-154.0", "False"]], [["-158.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-158.0", "False"], ["-157.0", "False"]], "doc_hash": "0b7cc25332e8e3bd5294d6789ab889b5ff5305c5f78a5fa6a14f7ffb0ce5d1fc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1445, "doc": {"premise": "In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target.", "hypothesis": "It is wise to continue saving the same amount as always.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Yes, It is wise to continue saving the same amount as always."}, "gen_args_1": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? Also, It is wise to continue saving the same amount as always."}, "gen_args_2": {"arg_0": "", "arg_1": " In other words, when households' existing assets increase in value, people can save less from current income and still achieve their wealth-income target., right? No, It is wise to continue saving the same amount as always."}}, "resps": [[["-171.0", "False"]], [["-173.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-173.0", "False"], ["-170.0", "False"]], "doc_hash": "06503878deeb8ec60e7af7ac63c6e843b2eb214a4e208de250d9908617fc3d97", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1453, "doc": {"premise": "It made sense for the state to outsource tactical functions such as help desks and mainframe management.", "hypothesis": "The state outsourced things like help desks and mainframe management.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Yes, The state outsourced things like help desks and mainframe management."}, "gen_args_1": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Also, The state outsourced things like help desks and mainframe management."}, "gen_args_2": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? No, The state outsourced things like help desks and mainframe management."}}, "resps": [[["-125.0", "False"]], [["-129.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-129.0", "False"], ["-127.5", "False"]], "doc_hash": "5b84c81319d566ef6e27d5b33d55ebc44058aa5a617bdd3bcf49eeece75bc232", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.90875992 0.01664452 0.07459556]"]}
{"doc_id": 1461, "doc": {"premise": "Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect.", "hypothesis": "Air pollution has no effect on health regardless of the levels.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Yes, Air pollution has no effect on health regardless of the levels."}, "gen_args_1": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Also, Air pollution has no effect on health regardless of the levels."}, "gen_args_2": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? No, Air pollution has no effect on health regardless of the levels."}}, "resps": [[["-136.0", "False"]], [["-137.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-137.0", "False"], ["-135.0", "False"]], "doc_hash": "65ae4fa810b0b003694dd51af8d0e0e71e4e9021d0924c1d4a59043aaf4e2747", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1469, "doc": {"premise": "Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas.", "hypothesis": "Brendan Gill made money off the merger.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Yes, Brendan Gill made money off the merger."}, "gen_args_1": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? Also, Brendan Gill made money off the merger."}, "gen_args_2": {"arg_0": "", "arg_1": " Brendan Gill, the former executive director of the Bexar County group, said he has since come to see the merger as a positive move for South Texas., right? No, Brendan Gill made money off the merger."}}, "resps": [[["-150.0", "False"]], [["-153.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-153.0", "False"], ["-149.0", "False"]], "doc_hash": "c25c432feece9a42f11346b5f2901631bf69c210eab089656d9015990e2b3022", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1477, "doc": {"premise": "If households' existing assets lose value, people have to save more to attain their wealth-income target.", "hypothesis": "If households assets lose value people will have to save less.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Yes, If households assets lose value people will have to save less."}, "gen_args_1": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Also, If households assets lose value people will have to save less."}, "gen_args_2": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? No, If households assets lose value people will have to save less."}}, "resps": [[["-153.0", "False"]], [["-153.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-153.0", "False"], ["-147.0", "False"]], "doc_hash": "49442670f59577efb6cd96e7e963158651a29817d6bc8b182ba7b7088bdcfb94", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1485, "doc": {"premise": "An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options.", "hypothesis": "Aliens can have legal representation when they are in the US.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Yes, Aliens can have legal representation when they are in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Also, Aliens can have legal representation when they are in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? No, Aliens can have legal representation when they are in the US."}}, "resps": [[["-203.0", "False"]], [["-209.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-209.0", "False"], ["-207.0", "False"]], "doc_hash": "401eaee80beb9bfd6340a9b0d8a841c57c893bce8a8c76109ed87286719c8d03", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 1493, "doc": {"premise": "For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability.", "hypothesis": "It is possible for existing assets to accumulate gains.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Yes, It is possible for existing assets to accumulate gains."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? Also, It is possible for existing assets to accumulate gains."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, gains on existing assets reduce the amount of an employer's contribution necessary to fund its pension liability., right? No, It is possible for existing assets to accumulate gains."}}, "resps": [[["-142.0", "False"]], [["-146.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-146.0", "False"], ["-143.0", "False"]], "doc_hash": "0acc3cd550c3e105abe8043615c6f2b6f075774f879ff65c6f452b5488d82c44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1501, "doc": {"premise": "The system also chose passengers at random to receive additional security scrutiny.", "hypothesis": "Soem passengers get full-body scans.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Yes, Soem passengers get full-body scans."}, "gen_args_1": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Also, Soem passengers get full-body scans."}, "gen_args_2": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? No, Soem passengers get full-body scans."}}, "resps": [[["-136.0", "False"]], [["-133.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-133.0", "False"], ["-135.0", "False"]], "doc_hash": "bebcab982cb9a17e65369473efbf60aafa9d6450b9f557078b0624572babd8f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.84379473 0.1141952 ]"]}
{"doc_id": 1509, "doc": {"premise": "Intelligence report, interrogation of KSM, July 30, 2003.", "hypothesis": "An interrogation of KSM was performed in July of 2003.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Yes, An interrogation of KSM was performed in July of 2003."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Also, An interrogation of KSM was performed in July of 2003."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? No, An interrogation of KSM was performed in July of 2003."}}, "resps": [[["-121.0", "False"]], [["-124.0", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-124.0", "False"], ["-123.0", "False"]], "doc_hash": "3fb946f7c2d684afdd87e8fb80adf7b29bf495765a2c9d2df4772fa9bc7aa42d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1517, "doc": {"premise": "Delivering it repeatedly did not make it more effective.", "hypothesis": "It didn't make it any more effective when we delivered it to the White House.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Yes, It didn't make it any more effective when we delivered it to the White House."}, "gen_args_1": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? Also, It didn't make it any more effective when we delivered it to the White House."}, "gen_args_2": {"arg_0": "", "arg_1": " Delivering it repeatedly did not make it more effective., right? No, It didn't make it any more effective when we delivered it to the White House."}}, "resps": [[["-112.0", "False"]], [["-113.5", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-112.0", "False"], ["-113.5", "False"], ["-111.0", "False"]], "doc_hash": "f1f8f787bb5cf9685e65d5ed80fe19acfc50d56632912d5c0f335088e22c37c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25371618 0.05661173 0.68967209]"]}
{"doc_id": 1525, "doc": {"premise": "According to both KSM and Khallad, Abu Bara never applied for a U.S. visa.", "hypothesis": "Abu Bara never completed a Visa application", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Yes, Abu Bara never completed a Visa application"}, "gen_args_1": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Also, Abu Bara never completed a Visa application"}, "gen_args_2": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? No, Abu Bara never completed a Visa application"}}, "resps": [[["-127.5", "False"]], [["-129.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-129.0", "False"], ["-128.0", "False"]], "doc_hash": "179b07f34a2598090f4e3a2ae51ac18118a854828c3d5cb75ef2a2926a03c1a2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.54654939 0.12195165 0.33149896]"]}
{"doc_id": 1533, "doc": {"premise": "For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed.", "hypothesis": "The intercepts were handled perfectly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Yes, The intercepts were handled perfectly."}, "gen_args_1": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Also, The intercepts were handled perfectly."}, "gen_args_2": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? No, The intercepts were handled perfectly."}}, "resps": [[["-176.0", "False"]], [["-181.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-181.0", "False"], ["-175.0", "False"]], "doc_hash": "98c21ebd294ae704d447f735d2458ed4cc049706f229b56cfceb446552bb9e40", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1541, "doc": {"premise": "The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later.", "hypothesis": "The Southeast Air Defense Sector received word of the event just 28 seconds after it took place.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Yes, The Southeast Air Defense Sector received word of the event just 28 seconds after it took place."}, "gen_args_1": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? Also, The Southeast Air Defense Sector received word of the event just 28 seconds after it took place."}, "gen_args_2": {"arg_0": "", "arg_1": " The Southeast Air Defense Sector was notified of the event at 9:55, 28 minutes later., right? No, The Southeast Air Defense Sector received word of the event just 28 seconds after it took place."}}, "resps": [[["-144.0", "False"]], [["-148.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-148.0", "False"], ["-139.0", "False"]], "doc_hash": "b16aab267d83db5f16e9be108bf170f81f6ada780f177d6b84c50e05564204da", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 1549, "doc": {"premise": "According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation.", "hypothesis": "Bin Ladin didn't know the FBI had held Moussaoui.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Yes, Bin Ladin didn't know the FBI had held Moussaoui."}, "gen_args_1": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Also, Bin Ladin didn't know the FBI had held Moussaoui."}, "gen_args_2": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? No, Bin Ladin didn't know the FBI had held Moussaoui."}}, "resps": [[["-158.0", "False"]], [["-158.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-158.0", "False"], ["-156.0", "False"]], "doc_hash": "c174054a3daaf24cb70c493d69f3b0d2d1c43b5a1363db9288271941ed293de6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1557, "doc": {"premise": "It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious.", "hypothesis": "Khallad had financed Mihdhar's education in the Middle East.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Yes, Khallad had financed Mihdhar's education in the Middle East."}, "gen_args_1": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Also, Khallad had financed Mihdhar's education in the Middle East."}, "gen_args_2": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? No, Khallad had financed Mihdhar's education in the Middle East."}}, "resps": [[["-146.0", "False"]], [["-147.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-147.0", "False"], ["-150.0", "False"]], "doc_hash": "2dc36c95a47fbf3206bb57328776364133b748ec5a158130f9255e09e84ef255", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.26538793 0.01321289]"]}
{"doc_id": 1565, "doc": {"premise": "The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags.", "hypothesis": "The man's checked bags contained only clothing and nothing else.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Yes, The man's checked bags contained only clothing and nothing else."}, "gen_args_1": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? Also, The man's checked bags contained only clothing and nothing else."}, "gen_args_2": {"arg_0": "", "arg_1": " The terminal was evacuated, and police found miscellaneous gun parts, pistol ammunition, and military paraphernalia in the man's checked bags., right? No, The man's checked bags contained only clothing and nothing else."}}, "resps": [[["-153.0", "False"]], [["-157.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-157.0", "False"], ["-144.0", "False"]], "doc_hash": "1ac274ac304345ab3671394134e09d1c0153a84cf8790f142c904d64a656eb7c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.23394297e-04 2.26004539e-06 9.99874346e-01]"]}
{"doc_id": 1573, "doc": {"premise": "While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average.", "hypothesis": "The metal detector results were below the national average.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Yes, The metal detector results were below the national average."}, "gen_args_1": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Also, The metal detector results were below the national average."}, "gen_args_2": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? No, The metal detector results were below the national average."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-138.0", "False"]], "doc_hash": "abfa648f7511b05ea10eeb6419b9b2ecdb68b544238ae3bfc0209c0ef2c93056", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1581, "doc": {"premise": "As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process.", "hypothesis": "The Saudis and the US worked together.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Yes, The Saudis and the US worked together."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Also, The Saudis and the US worked together."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? No, The Saudis and the US worked together."}}, "resps": [[["-169.0", "False"]], [["-171.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-171.0", "False"], ["-167.0", "False"]], "doc_hash": "0cefff65741a19df1203604374871d9095e2b4ff7b71c590ad2c502b9cc36ccf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1589, "doc": {"premise": "It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role.", "hypothesis": "The FDNY was not the only agency in charge; others held just as much control.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Yes, The FDNY was not the only agency in charge; others held just as much control."}, "gen_args_1": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? Also, The FDNY was not the only agency in charge; others held just as much control."}, "gen_args_2": {"arg_0": "", "arg_1": " It was clear that the lead response agency was the FDNY, and that the other responding local, federal, bistate, and state agencies acted in a supporting role., right? No, The FDNY was not the only agency in charge; others held just as much control."}}, "resps": [[["-191.0", "False"]], [["-190.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-190.0", "False"], ["-184.0", "False"]], "doc_hash": "2fae43f3b2fe7c0d2c8d5e4d44b4a691eeaed79ef4f8b3b57e233eca95b8749d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.08800555e-04 2.47037604e-03 9.96620823e-01]"]}
{"doc_id": 1597, "doc": {"premise": "On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda.", "hypothesis": "President Bush wrote a letter to President Musharraf in August.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Yes, President Bush wrote a letter to President Musharraf in August."}, "gen_args_1": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Also, President Bush wrote a letter to President Musharraf in August."}, "gen_args_2": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? No, President Bush wrote a letter to President Musharraf in August."}}, "resps": [[["-142.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "93f5dac43d5a2723425e007cfef3c8acb7ff57af68018efb6db2f602aff919bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1605, "doc": {"premise": "He believed that there was sufficient probable cause for a criminal warrant at that time.", "hypothesis": "He suspected that the property was being used to conceal an illegal bomb making operation.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Yes, He suspected that the property was being used to conceal an illegal bomb making operation."}, "gen_args_1": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Also, He suspected that the property was being used to conceal an illegal bomb making operation."}, "gen_args_2": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? No, He suspected that the property was being used to conceal an illegal bomb making operation."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-139.0", "False"]], "doc_hash": "e469dbe12cc6f384eaa13d1874a2190bb0d843429eaaaf0a8ddcb05e78159ebf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1613, "doc": {"premise": "But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans.", "hypothesis": "The final defense policy document was over five hundred pages long.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Yes, The final defense policy document was over five hundred pages long."}, "gen_args_1": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? Also, The final defense policy document was over five hundred pages long."}, "gen_args_2": {"arg_0": "", "arg_1": " But his time was consumed with getting new officials in place and working on the foundation documents of a new defense policy, the quadrennial defense review, the defense planning guidance, and the existing contingency plans., right? No, The final defense policy document was over five hundred pages long."}}, "resps": [[["-207.0", "False"]], [["-208.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-208.0", "False"], ["-207.0", "False"]], "doc_hash": "8dc9a1aff10ed9c1a107c9a9b231eb2e4a662367a430d512cdc7847dbec171c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1621, "doc": {"premise": "Boston  A second one just hit the Trade Center.", "hypothesis": "The Trade Center was hit.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Yes, The Trade Center was hit."}, "gen_args_1": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Also, The Trade Center was hit."}, "gen_args_2": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? No, The Trade Center was hit."}}, "resps": [[["-106.0", "False"]], [["-111.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-111.5", "False"], ["-106.0", "False"]], "doc_hash": "a3c0d4625ba6d78021eca0315c29af810345b7024eaa51c23bcbbdfe0c27f68c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49898039 0.00203922 0.49898039]"]}
{"doc_id": 1629, "doc": {"premise": "Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy.", "hypothesis": "An emergency command post was set up at the Police Academy.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Yes, An emergency command post was set up at the Police Academy."}, "gen_args_1": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Also, An emergency command post was set up at the Police Academy."}, "gen_args_2": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? No, An emergency command post was set up at the Police Academy."}}, "resps": [[["-157.0", "False"]], [["-162.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-162.0", "False"], ["-159.0", "False"]], "doc_hash": "5569bc919a5f91164e0ee2e07598ca8c3f192b4f65eb5f9b82deb4f0c178cc07", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1637, "doc": {"premise": "Secure identification should begin in the United States.", "hypothesis": "There should be secure id in the US.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Yes, There should be secure id in the US."}, "gen_args_1": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? Also, There should be secure id in the US."}, "gen_args_2": {"arg_0": "", "arg_1": " Secure identification should begin in the United States., right? No, There should be secure id in the US."}}, "resps": [[["-100.5", "False"]], [["-107.0", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-100.5", "False"], ["-107.0", "False"], ["-103.5", "False"]], "doc_hash": "f596ba9d02e6302c67b233fb0f0465b9a48c586b4dcb356c93cb047f1dcce2b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95121186 0.00143009 0.04735805]"]}
{"doc_id": 1645, "doc": {"premise": "At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed.", "hypothesis": "The South Tower collapsed before 10:15.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Yes, The South Tower collapsed before 10:15."}, "gen_args_1": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Also, The South Tower collapsed before 10:15."}, "gen_args_2": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? No, The South Tower collapsed before 10:15."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-156.0", "False"]], "doc_hash": "74a4310d3482247e159fc743e3e3279f1dad228f1ce262748805a453f7646be9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1653, "doc": {"premise": "Intelligence report, interrogation of detainee, Dec. 2, 2001.", "hypothesis": "A detainee was interrogated.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Yes, A detainee was interrogated."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Also, A detainee was interrogated."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? No, A detainee was interrogated."}}, "resps": [[["-110.0", "False"]], [["-115.5", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-110.0", "False"], ["-115.5", "False"], ["-111.0", "False"]], "doc_hash": "1d1fe8c1db9c9f15723183902154e9bf0e86ede7e818dc2979fd431ea22c3395", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72888092 0.00297877 0.26814031]"]}
{"doc_id": 1661, "doc": {"premise": "Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11.", "hypothesis": "The Sentencing Order was never issued.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Yes, The Sentencing Order was never issued."}, "gen_args_1": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? Also, The Sentencing Order was never issued."}, "gen_args_2": {"arg_0": "", "arg_1": " Summary of Judgment and Sentencing Order by Hanseatic Regional High Court, Motassadeq trial, Feb. 19,2003, pp.10-11., right? No, The Sentencing Order was never issued."}}, "resps": [[["-192.0", "False"]], [["-195.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-192.0", "False"], ["-195.0", "False"], ["-188.0", "False"]], "doc_hash": "38b7f7a0df5076243c6451546c0c561df85ab2bc9d7d44aebf7f7d067beb9ea9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1669, "doc": {"premise": "The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq.", "hypothesis": "The United States fully supports any tyrant controlling Bosnia.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Yes, The United States fully supports any tyrant controlling Bosnia."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Also, The United States fully supports any tyrant controlling Bosnia."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? No, The United States fully supports any tyrant controlling Bosnia."}}, "resps": [[["-152.0", "False"]], [["-157.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-157.0", "False"], ["-151.0", "False"]], "doc_hash": "c762255dacdfff5722e2983f65da20304454896542f9e6c8000efa2d176d32c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1677, "doc": {"premise": "In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation.", "hypothesis": "Khalid al Mihdhar never traveled.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Yes, Khalid al Mihdhar never traveled."}, "gen_args_1": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Also, Khalid al Mihdhar never traveled."}, "gen_args_2": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? No, Khalid al Mihdhar never traveled."}}, "resps": [[["-184.0", "False"]], [["-182.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-182.0", "False"], ["-180.0", "False"]], "doc_hash": "438d2ad18f4ee4c30d3343213b91486d2012b91ee176a4ad3770ada2ec71a588", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 1685, "doc": {"premise": "We will recap it briefly here.", "hypothesis": "We will recap the events from Monday to Wednesday only.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Yes, We will recap the events from Monday to Wednesday only."}, "gen_args_1": {"arg_0": "", "arg_1": " We will recap it briefly here., right? Also, We will recap the events from Monday to Wednesday only."}, "gen_args_2": {"arg_0": "", "arg_1": " We will recap it briefly here., right? No, We will recap the events from Monday to Wednesday only."}}, "resps": [[["-98.0", "False"]], [["-102.5", "False"]], [["-99.5", "False"]]], "filtered_resps": [["-98.0", "False"], ["-102.5", "False"], ["-99.5", "False"]], "doc_hash": "261bf7f92f3a3c2513a158b66d1b015d0ed1a2dbf83ae0e0240554b59088a82c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.81021575 0.00900068 0.18078357]"]}
{"doc_id": 1693, "doc": {"premise": "After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism.", "hypothesis": "Sudan was designated a state sponsor of terrorism in 1993.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Yes, Sudan was designated a state sponsor of terrorism in 1993."}, "gen_args_1": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Also, Sudan was designated a state sponsor of terrorism in 1993."}, "gen_args_2": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? No, Sudan was designated a state sponsor of terrorism in 1993."}}, "resps": [[["-111.0", "False"]], [["-118.5", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-111.0", "False"], ["-118.5", "False"], ["-111.5", "False"]], "doc_hash": "e3df1c382e1814299f3d9e50b8b4e1bf37f57c997fdcfce5e9e80bd571775976", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[6.22245109e-01 3.44154044e-04 3.77410737e-01]"]}
{"doc_id": 1701, "doc": {"premise": "When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office.", "hypothesis": "The Florida field office took over because it was al Quaeda related.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Yes, The Florida field office took over because it was al Quaeda related."}, "gen_args_1": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Also, The Florida field office took over because it was al Quaeda related."}, "gen_args_2": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? No, The Florida field office took over because it was al Quaeda related."}}, "resps": [[["-146.0", "False"]], [["-152.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-152.0", "False"], ["-146.0", "False"]], "doc_hash": "bf028bf1e7ea0ff11b78d18523d21875d6cbf356ed71fcd6f457bdda642b1e60", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1709, "doc": {"premise": "For units staged at the Brooklyn-Battery tunnel, see ibid.", "hypothesis": "These units were composed of fire fighters and local police.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Yes, These units were composed of fire fighters and local police."}, "gen_args_1": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? Also, These units were composed of fire fighters and local police."}, "gen_args_2": {"arg_0": "", "arg_1": " For units staged at the Brooklyn-Battery tunnel, see ibid., right? No, These units were composed of fire fighters and local police."}}, "resps": [[["-149.0", "False"]], [["-149.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-149.0", "False"], ["-150.0", "False"]], "doc_hash": "55c324841851e41da44369c19eabb2e51b08c19ac08ee5207dc65f146ed4e605", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1717, "doc": {"premise": "A jet fuel fireball erupted upon impact and shot down at least one bank of elevators.", "hypothesis": "The fireball traveled down at least one elevator shaft.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Yes, The fireball traveled down at least one elevator shaft."}, "gen_args_1": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Also, The fireball traveled down at least one elevator shaft."}, "gen_args_2": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? No, The fireball traveled down at least one elevator shaft."}}, "resps": [[["-130.0", "False"]], [["-134.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-134.0", "False"], ["-135.0", "False"]], "doc_hash": "f618b2ac249f60a543948907b450d7fd55a7ec49519490bcdde486c8765ac687", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 1725, "doc": {"premise": "This effort was going on before 9/11 and it continues on a vastly enlarged scale.", "hypothesis": "After 9/11 the effort increased dramatically.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Yes, After 9/11 the effort increased dramatically."}, "gen_args_1": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Also, After 9/11 the effort increased dramatically."}, "gen_args_2": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? No, After 9/11 the effort increased dramatically."}}, "resps": [[["-116.0", "False"]], [["-120.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-116.0", "False"], ["-120.5", "False"], ["-115.5", "False"]], "doc_hash": "dc45efd873661b8496ea4738379af74de782ab34624a3b065c154bf6f516763f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 1733, "doc": {"premise": "The U.S. government readily provides copious information about spending on its military forces, including military intelligence.", "hypothesis": "The US government won't tell anyone how much they spend on anything.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Yes, The US government won't tell anyone how much they spend on anything."}, "gen_args_1": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? Also, The US government won't tell anyone how much they spend on anything."}, "gen_args_2": {"arg_0": "", "arg_1": " The U.S. government readily provides copious information about spending on its military forces, including military intelligence., right? No, The US government won't tell anyone how much they spend on anything."}}, "resps": [[["-145.0", "False"]], [["-145.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-145.0", "False"], ["-139.0", "False"]], "doc_hash": "e84d77ff994449eb6288633a2433ba16a9351d5b229e8b22a987b0ef9ef3a71f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1741, "doc": {"premise": "For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr.", "hypothesis": "The FBI was interested in the instructor's reaction to a video of two kittens playing with a ball.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Yes, The FBI was interested in the instructor's reaction to a video of two kittens playing with a ball."}, "gen_args_1": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Also, The FBI was interested in the instructor's reaction to a video of two kittens playing with a ball."}, "gen_args_2": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? No, The FBI was interested in the instructor's reaction to a video of two kittens playing with a ball."}}, "resps": [[["-201.0", "False"]], [["-203.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-203.0", "False"], ["-200.0", "False"]], "doc_hash": "b971054681d651921e79af5e4bcdaafa6a648f97db57b69da5888c3f71189070", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1749, "doc": {"premise": "Most important is the fact that attending a performance at the IRT is not just a field trip.", "hypothesis": "Attending a performance at the IRT isn't just a fun walk in the park.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Yes, Attending a performance at the IRT isn't just a fun walk in the park."}, "gen_args_1": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Also, Attending a performance at the IRT isn't just a fun walk in the park."}, "gen_args_2": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? No, Attending a performance at the IRT isn't just a fun walk in the park."}}, "resps": [[["-138.0", "False"]], [["-138.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-138.0", "False"], ["-137.0", "False"]], "doc_hash": "c98af376f7994746e0f0dd26c6a5ab44e2583dd7a64a31c25bc91bbb4b96aaf6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1757, "doc": {"premise": "Thank you for supporting the Indianapolis Museum of Art in 1999.", "hypothesis": "We are very glad you helped support the museum.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Yes, We are very glad you helped support the museum."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? Also, We are very glad you helped support the museum."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank you for supporting the Indianapolis Museum of Art in 1999., right? No, We are very glad you helped support the museum."}}, "resps": [[["-99.0", "False"]], [["-106.5", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-99.0", "False"], ["-106.5", "False"], ["-104.0", "False"]], "doc_hash": "bee222e2685f883cb43c05b110da3ff4f01f6ec8c24872934fcc4598cf9ce7b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92761743e-01 5.49081003e-04 6.68917601e-03]"]}
{"doc_id": 1765, "doc": {"premise": "P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country.", "hypothesis": "We're celebrating the grand opening of Indianapolis's newest theater.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Yes, We're celebrating the grand opening of Indianapolis's newest theater."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Also, We're celebrating the grand opening of Indianapolis's newest theater."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? No, We're celebrating the grand opening of Indianapolis's newest theater."}}, "resps": [[["-172.0", "False"]], [["-171.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-171.0", "False"], ["-171.0", "False"]], "doc_hash": "fb7ce9641d829648b0006f82c62b6061bd2232bcf6a298e33412d013022b0309", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1773, "doc": {"premise": "Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live.", "hypothesis": "Biomes simulate animals natural living environments.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Yes, Biomes simulate animals natural living environments."}, "gen_args_1": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Also, Biomes simulate animals natural living environments."}, "gen_args_2": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? No, Biomes simulate animals natural living environments."}}, "resps": [[["-129.0", "False"]], [["-135.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-135.0", "False"], ["-136.0", "False"]], "doc_hash": "6c2d9a0112aad4067ac5cbe03ecf407a0928a2886e1bce6a017acba9d676cb55", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.96620823e-01 2.47037604e-03 9.08800555e-04]"]}
{"doc_id": 1781, "doc": {"premise": "From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage.", "hypothesis": "There will be no other medical school in Indiana for the next five years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Yes, There will be no other medical school in Indiana for the next five years."}, "gen_args_1": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? Also, There will be no other medical school in Indiana for the next five years."}, "gen_args_2": {"arg_0": "", "arg_1": " From a modest beginning to its rank today as one of the best academic medical centers in the nation, Indiana's only medical school boasts a proud heritage., right? No, There will be no other medical school in Indiana for the next five years."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-158.0", "False"]], "doc_hash": "e80224b05f467991eb36ada33e934e922e79adb58a2e18b2452b608b975d6295", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1789, "doc": {"premise": "We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th.", "hypothesis": "We will contact by mail in the next 45 days those who have not donated this fiscal year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Yes, We will contact by mail in the next 45 days those who have not donated this fiscal year."}, "gen_args_1": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Also, We will contact by mail in the next 45 days those who have not donated this fiscal year."}, "gen_args_2": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? No, We will contact by mail in the next 45 days those who have not donated this fiscal year."}}, "resps": [[["-173.0", "False"]], [["-174.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-174.0", "False"], ["-175.0", "False"]], "doc_hash": "2ad2a17d29abe7cf87868713bf1ea211af9b9bf0f1fe3a3addc3148ac3cb662d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1797, "doc": {"premise": "It means everything to Becky, Stephanie, Marcus and Emily, and students like them.", "hypothesis": "Becky doesn't care about it at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Yes, Becky doesn't care about it at all."}, "gen_args_1": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Also, Becky doesn't care about it at all."}, "gen_args_2": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? No, Becky doesn't care about it at all."}}, "resps": [[["-132.0", "False"]], [["-133.0", "False"]], [["-127.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-133.0", "False"], ["-127.0", "False"]], "doc_hash": "b7f81ea25178693ac115e1438f6534a2164f931eece28211dc38893e9f4bdb00", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1805, "doc": {"premise": "I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year.", "hypothesis": "Your gift last year was $33.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Yes, Your gift last year was $33."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? Also, Your gift last year was $33."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope you will remain a contributor and even consider honoring our 25 years of storytelling by increasing your gift $25 this year., right? No, Your gift last year was $33."}}, "resps": [[["-157.0", "False"]], [["-160.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-160.0", "False"], ["-157.0", "False"]], "doc_hash": "a8f00a86274346757d79a76913e05002b96a50c55ed6697ddb929927b3023df2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1813, "doc": {"premise": "Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan.", "hypothesis": "The Society cares for animals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Yes, The Society cares for animals."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Also, The Society cares for animals."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? No, The Society cares for animals."}}, "resps": [[["-152.0", "False"]], [["-158.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-158.0", "False"], ["-155.0", "False"]], "doc_hash": "3179a4bffac1214a5280b1ad23ca9d8f14659ee72bce6669387d7dfdbfa88c93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1821, "doc": {"premise": "Provide a professional atmosphere for many talented community actors to hone and perfect their skills.", "hypothesis": "Community theaters never help actors improve.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Yes, Community theaters never help actors improve."}, "gen_args_1": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Also, Community theaters never help actors improve."}, "gen_args_2": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? No, Community theaters never help actors improve."}}, "resps": [[["-143.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "3a9be50e650fc46274086fc0d735409d72bb66480826451e067b837ce072b7cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1829, "doc": {"premise": "What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now", "hypothesis": "Some actors toured in Indiana in 1973.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Yes, Some actors toured in Indiana in 1973."}, "gen_args_1": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? Also, Some actors toured in Indiana in 1973."}, "gen_args_2": {"arg_0": "", "arg_1": " What began as a touring group of actors in 1973 that played to students in cities like Gary , Elkhart and Terre Haute, the IRT education program today now, right? No, Some actors toured in Indiana in 1973."}}, "resps": [[["-207.0", "False"]], [["-213.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-213.0", "False"], ["-209.0", "False"]], "doc_hash": "7cc781862964d83291c7c603495dba4ad6d965307ab89f36111d722255e62ee0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1837, "doc": {"premise": "Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves.", "hypothesis": "Laurel wreaths, olive branches, and acanthus leaves are on the rug's border.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Yes, Laurel wreaths, olive branches, and acanthus leaves are on the rug's border."}, "gen_args_1": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Also, Laurel wreaths, olive branches, and acanthus leaves are on the rug's border."}, "gen_args_2": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? No, Laurel wreaths, olive branches, and acanthus leaves are on the rug's border."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "fb43433b0fd18ef34be11d410f34dcd9cd7523dca53d1065b8c14f0272e4e1ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1845, "doc": {"premise": "You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate.", "hypothesis": "It costs $30 only if you join in the next two days.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Yes, It costs $30 only if you join in the next two days."}, "gen_args_1": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Also, It costs $30 only if you join in the next two days."}, "gen_args_2": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? No, It costs $30 only if you join in the next two days."}}, "resps": [[["-148.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "a15b8a5a39ebb3ba7ac1779e777e4b46a3a53b455f8ef002b75430bc0429efc8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1853, "doc": {"premise": "Others continue to notice our success.", "hypothesis": "We are succeeding.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Yes, We are succeeding."}, "gen_args_1": {"arg_0": "", "arg_1": " Others continue to notice our success., right? Also, We are succeeding."}, "gen_args_2": {"arg_0": "", "arg_1": " Others continue to notice our success., right? No, We are succeeding."}}, "resps": [[["-81.5", "False"]], [["-89.5", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-81.5", "False"], ["-89.5", "False"], ["-85.0", "False"]], "doc_hash": "d3b895aa1e11300845008c24c1d32d2928a0bbc0377b85fa37bb014949356006", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.70371788e-01 3.25523470e-04 2.93026889e-02]"]}
{"doc_id": 1861, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!", "hypothesis": "The connections made were made in vain no thanks to you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Yes, The connections made were made in vain no thanks to you."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Also, The connections made were made in vain no thanks to you."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? No, The connections made were made in vain no thanks to you."}}, "resps": [[["-174.0", "False"]], [["-175.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-175.0", "False"], ["-169.0", "False"]], "doc_hash": "dc2ff6ea5ed95ea59542392af2d288f1fe518b21e00aa5e4baccbc08b4b68572", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1869, "doc": {"premise": "Last year, you generously donated $-.", "hypothesis": "You didn't donate any money last year.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Yes, You didn't donate any money last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Also, You didn't donate any money last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? No, You didn't donate any money last year."}}, "resps": [[["-90.5", "False"]], [["-95.0", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-90.5", "False"], ["-95.0", "False"], ["-88.5", "False"]], "doc_hash": "a0930cdf35464eb9e278d1e9176249aaf77afab0305c33aa14eca998d232437f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11904528 0.00132247 0.87963225]"]}
{"doc_id": 1877, "doc": {"premise": "The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars.", "hypothesis": "The rug is six feet in diameter.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Yes, The rug is six feet in diameter."}, "gen_args_1": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? Also, The rug is six feet in diameter."}, "gen_args_2": {"arg_0": "", "arg_1": " The deep blue rug is emblazoned with a full-color Presidential Seal encircled by fifty white stars., right? No, The rug is six feet in diameter."}}, "resps": [[["-132.0", "False"]], [["-134.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-134.0", "False"], ["-134.0", "False"]], "doc_hash": "80c14ffb0ddf2124f6d2260def9e0f612430a5d282d96f3a024506afbdda29c6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1885, "doc": {"premise": "It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!", "hypothesis": "You should visit the school and see the musical production we've been working on.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Yes, You should visit the school and see the musical production we've been working on."}, "gen_args_1": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Also, You should visit the school and see the musical production we've been working on."}, "gen_args_2": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? No, You should visit the school and see the musical production we've been working on."}}, "resps": [[["-171.0", "False"]], [["-173.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-173.0", "False"], ["-172.0", "False"]], "doc_hash": "92c305b9bcc18bc23180b7a4a25ab90bbed629239657300da6edfb42199616d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1893, "doc": {"premise": "Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you.", "hypothesis": "No one gives us anything, but we have enough money so it's ok.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Yes, No one gives us anything, but we have enough money so it's ok."}, "gen_args_1": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Also, No one gives us anything, but we have enough money so it's ok."}, "gen_args_2": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? No, No one gives us anything, but we have enough money so it's ok."}}, "resps": [[["-208.0", "False"]], [["-213.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-208.0", "False"], ["-213.0", "False"], ["-207.0", "False"]], "doc_hash": "d1578c39c05efc7ba78b860bfece73787be991632a74b485c1ff8cac161b8b78", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 1901, "doc": {"premise": "00 invested in a job-training program for a person on welfare saves $3.", "hypothesis": "There are some monetary savings for investments in a job-training program.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Yes, There are some monetary savings for investments in a job-training program."}, "gen_args_1": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? Also, There are some monetary savings for investments in a job-training program."}, "gen_args_2": {"arg_0": "", "arg_1": " 00 invested in a job-training program for a person on welfare saves $3., right? No, There are some monetary savings for investments in a job-training program."}}, "resps": [[["-141.0", "False"]], [["-146.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-146.0", "False"], ["-143.0", "False"]], "doc_hash": "e0653a97d1043aa820fe47afa5c55bbd1972d46a7a8f42dd78805e384bd99d55", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1909, "doc": {"premise": "If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed.", "hypothesis": "The Salvation Army donates money to people who need it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Yes, The Salvation Army donates money to people who need it."}, "gen_args_1": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Also, The Salvation Army donates money to people who need it."}, "gen_args_2": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? No, The Salvation Army donates money to people who need it."}}, "resps": [[["-137.0", "False"]], [["-139.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-139.0", "False"], ["-135.0", "False"]], "doc_hash": "2bb2f5886f0b616f3f99388a23c4c85f1d92515d99ad2473b1e2e670d6122e47", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1917, "doc": {"premise": "Very soon, a friend of the IRT will be calling you to take your pledge over the phone.", "hypothesis": "We don't do phone drives because of security concerns.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Yes, We don't do phone drives because of security concerns."}, "gen_args_1": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Also, We don't do phone drives because of security concerns."}, "gen_args_2": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? No, We don't do phone drives because of security concerns."}}, "resps": [[["-137.0", "False"]], [["-141.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-141.0", "False"], ["-133.0", "False"]], "doc_hash": "bab1885595c47e27810313c4293590885d0d9d5d8c30fc8e3eb6f1d6c22e4af8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 1925, "doc": {"premise": "McCoy invites the support of The __ Company Foundation in the amount of $10,000.", "hypothesis": "McCoy needs more money, but right now $10,000 is being requested.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Yes, McCoy needs more money, but right now $10,000 is being requested."}, "gen_args_1": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? Also, McCoy needs more money, but right now $10,000 is being requested."}, "gen_args_2": {"arg_0": "", "arg_1": " McCoy invites the support of The __ Company Foundation in the amount of $10,000., right? No, McCoy needs more money, but right now $10,000 is being requested."}}, "resps": [[["-157.0", "False"]], [["-159.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-159.0", "False"], ["-155.0", "False"]], "doc_hash": "8d987e5a183eacf04ee07c961155b1d54c343cd60cb63aad872129ae65b4396f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1933, "doc": {"premise": "The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school.", "hypothesis": "Indiana refuses to commit to help the dental school.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Yes, Indiana refuses to commit to help the dental school."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Also, Indiana refuses to commit to help the dental school."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? No, Indiana refuses to commit to help the dental school."}}, "resps": [[["-171.0", "False"]], [["-175.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-175.0", "False"], ["-167.0", "False"]], "doc_hash": "96b3421d7b9651102980c0ee8d8496b4ba391958e4105730a76f983296e07049", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79802867e-02 3.29320439e-04 9.81690393e-01]"]}
{"doc_id": 1941, "doc": {"premise": "Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters.", "hypothesis": "Members don't get a discount, because we'd lose too much money.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Yes, Members don't get a discount, because we'd lose too much money."}, "gen_args_1": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Also, Members don't get a discount, because we'd lose too much money."}, "gen_args_2": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? No, Members don't get a discount, because we'd lose too much money."}}, "resps": [[["-187.0", "False"]], [["-192.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-192.0", "False"], ["-180.0", "False"]], "doc_hash": "73b524d0a16b405b93c8683ce4211e8580feaaba06ca3143435d73bddbeec558", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11045602e-04 6.13857698e-06 9.99082816e-01]"]}
{"doc_id": 1949, "doc": {"premise": "As with all gifts to the Institute, 100% of your contribution will be used directly for research.", "hypothesis": "We spend half your money on administrative fees.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Yes, We spend half your money on administrative fees."}, "gen_args_1": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? Also, We spend half your money on administrative fees."}, "gen_args_2": {"arg_0": "", "arg_1": " As with all gifts to the Institute, 100% of your contribution will be used directly for research., right? No, We spend half your money on administrative fees."}}, "resps": [[["-123.5", "False"]], [["-123.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-123.0", "False"], ["-119.0", "False"]], "doc_hash": "ba1ea46ed638be25525f150f7f8c1b92506207d08f19ab11f07302bcdc7b6246", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01079146 0.01779211 0.97141643]"]}
{"doc_id": 1957, "doc": {"premise": "If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today.", "hypothesis": "Bob Lovell is no longer associated with this.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Yes, Bob Lovell is no longer associated with this."}, "gen_args_1": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Also, Bob Lovell is no longer associated with this."}, "gen_args_2": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? No, Bob Lovell is no longer associated with this."}}, "resps": [[["-158.0", "False"]], [["-162.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-162.0", "False"], ["-156.0", "False"]], "doc_hash": "34d2458aecea66d92b1a2e034c691950d6f25229537ad95a860bbcebf39b0d26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1965, "doc": {"premise": "Your name or other inscription of your choice will be engraved on a plaque and.", "hypothesis": "The plaque doesn't give any specific names or details.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Yes, The plaque doesn't give any specific names or details."}, "gen_args_1": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Also, The plaque doesn't give any specific names or details."}, "gen_args_2": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? No, The plaque doesn't give any specific names or details."}}, "resps": [[["-127.0", "False"]], [["-129.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-129.0", "False"], ["-125.0", "False"]], "doc_hash": "dba65a02498cb9b5c185a493b7eb7e02f5a90a1e6e84e92079705df3dd2d126c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1973, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations.", "hypothesis": "The Society helps people find people who are also interested in the arts.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Yes, The Society helps people find people who are also interested in the arts."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? Also, The Society helps people find people who are also interested in the arts."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations., right? No, The Society helps people find people who are also interested in the arts."}}, "resps": [[["-146.0", "False"]], [["-151.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-151.0", "False"], ["-148.0", "False"]], "doc_hash": "2aca1979444eb6bd9fd9dfa8cf4f23ff52987c5d4f53f2ef1509f2575ed2984d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1981, "doc": {"premise": "Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education.", "hypothesis": "The IU School of Law teaches future lawyers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Yes, The IU School of Law teaches future lawyers."}, "gen_args_1": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Also, The IU School of Law teaches future lawyers."}, "gen_args_2": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? No, The IU School of Law teaches future lawyers."}}, "resps": [[["-162.0", "False"]], [["-168.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-168.0", "False"], ["-165.0", "False"]], "doc_hash": "663db085d43cd08a024da59b5c0e15c1d0bcd07156a1f6fa620a874ff7fa593d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1989, "doc": {"premise": "Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment.", "hypothesis": "Everyone is being discouraged from emulating your terrible judgment.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Yes, Everyone is being discouraged from emulating your terrible judgment."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Also, Everyone is being discouraged from emulating your terrible judgment."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? No, Everyone is being discouraged from emulating your terrible judgment."}}, "resps": [[["-140.0", "False"]], [["-139.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-139.0", "False"], ["-136.0", "False"]], "doc_hash": "f8da095bc77c871bb1a0c8de7d3d743aac337ac8d444f268a9a0e9255337938d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 1997, "doc": {"premise": "The newsweeklies' cover packages pander to anxious parents.", "hypothesis": "Parents are more likely to spend money on new car purchases, making them a lucrative advertising segment for magazines.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Yes, Parents are more likely to spend money on new car purchases, making them a lucrative advertising segment for magazines."}, "gen_args_1": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? Also, Parents are more likely to spend money on new car purchases, making them a lucrative advertising segment for magazines."}, "gen_args_2": {"arg_0": "", "arg_1": " The newsweeklies' cover packages pander to anxious parents., right? No, Parents are more likely to spend money on new car purchases, making them a lucrative advertising segment for magazines."}}, "resps": [[["-162.0", "False"]], [["-161.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-161.0", "False"], ["-163.0", "False"]], "doc_hash": "9d262d6f4a45f6cb0423fc998ad910ac9b0b44ecee49e2c361a2f861eaff2f5a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 2005, "doc": {"premise": "Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age.", "hypothesis": "Time magazine has a picture of Bill Gates on the cover.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Yes, Time magazine has a picture of Bill Gates on the cover."}, "gen_args_1": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Also, Time magazine has a picture of Bill Gates on the cover."}, "gen_args_2": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? No, Time magazine has a picture of Bill Gates on the cover."}}, "resps": [[["-118.0", "False"]], [["-119.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-118.0", "False"], ["-119.0", "False"], ["-121.0", "False"]], "doc_hash": "bbe4953f78ca469a58f4184aaaf5ab5e9611f6c1f48c945ddfde23ce12578075", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.25949646 0.03511903]"]}
{"doc_id": 2013, "doc": {"premise": "With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux.", "hypothesis": "I have never dealt with Linux.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Yes, I have never dealt with Linux."}, "gen_args_1": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Also, I have never dealt with Linux."}, "gen_args_2": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? No, I have never dealt with Linux."}}, "resps": [[["-177.0", "False"]], [["-176.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-176.0", "False"], ["-176.0", "False"]], "doc_hash": "a9cdc38bc9c1c12985a62b2b825e845fad20b1bb0c9835952a234c2f130e89a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 2021, "doc": {"premise": "The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position.", "hypothesis": "The Nerds have a future.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Yes, The Nerds have a future."}, "gen_args_1": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? Also, The Nerds have a future."}, "gen_args_2": {"arg_0": "", "arg_1": " The Nerds, who hole up in the economics and computer classrooms, have an even more hopeless position., right? No, The Nerds have a future."}}, "resps": [[["-146.0", "False"]], [["-150.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-150.0", "False"], ["-144.0", "False"]], "doc_hash": "1aedfe4486876c11441c9fb875d4d7b79f6fd66d757ad9b1db01e0a9e1a88278", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 2029, "doc": {"premise": "Which is more than the News Quiz can promise about Fox.", "hypothesis": "It's more than News Quiz can assure about Fox.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Yes, It's more than News Quiz can assure about Fox."}, "gen_args_1": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Also, It's more than News Quiz can assure about Fox."}, "gen_args_2": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? No, It's more than News Quiz can assure about Fox."}}, "resps": [[["-121.0", "False"]], [["-123.5", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-123.5", "False"], ["-122.0", "False"]], "doc_hash": "3c3bfeab956feb763e376c0030b6d80d3c5218facfb5f01367b47f615f6e4833", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 2037, "doc": {"premise": "Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee.", "hypothesis": "Bradley was from Arkansas.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Yes, Bradley was from Arkansas."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Also, Bradley was from Arkansas."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? No, Bradley was from Arkansas."}}, "resps": [[["-155.0", "False"]], [["-157.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-157.0", "False"], ["-155.0", "False"]], "doc_hash": "4ae73a9b99b36ec114c3200512e710ef8122620f6c8013cd448f47ac364062ec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2045, "doc": {"premise": "The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history.", "hypothesis": "The stars and the acting, more than the plot line of First Wives Club, helped to set record box office sales.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Yes, The stars and the acting, more than the plot line of First Wives Club, helped to set record box office sales."}, "gen_args_1": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? Also, The stars and the acting, more than the plot line of First Wives Club, helped to set record box office sales."}, "gen_args_2": {"arg_0": "", "arg_1": " The First Wives Club, a revenge-comedy about three abandoned wives, grossed more on its first weekend than any other women's film in history., right? No, The stars and the acting, more than the plot line of First Wives Club, helped to set record box office sales."}}, "resps": [[["-197.0", "False"]], [["-198.0", "False"]], [["-196.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-198.0", "False"], ["-196.0", "False"]], "doc_hash": "12898a0069ed2da877b036851a59ea0f14ea33004eab94ab17716e8d2808d7dc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2053, "doc": {"premise": "Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed.", "hypothesis": "Jon Benet Ramsey's half-sister has a strong alibi for the fact that she was out of town when the crime was committed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Yes, Jon Benet Ramsey's half-sister has a strong alibi for the fact that she was out of town when the crime was committed."}, "gen_args_1": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Also, Jon Benet Ramsey's half-sister has a strong alibi for the fact that she was out of town when the crime was committed."}, "gen_args_2": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? No, Jon Benet Ramsey's half-sister has a strong alibi for the fact that she was out of town when the crime was committed."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-163.0", "False"]], "doc_hash": "53a0d5e55b7f96b725ae1a2f120f37a8c1f55165cb488e9351bb2b0749d981f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2061, "doc": {"premise": "One day, the technology that today creates a market for visionaries will be as mundane as light bulbs.", "hypothesis": "Technology gets boring after a while.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Yes, Technology gets boring after a while."}, "gen_args_1": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Also, Technology gets boring after a while."}, "gen_args_2": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? No, Technology gets boring after a while."}}, "resps": [[["-132.0", "False"]], [["-135.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-135.0", "False"], ["-135.0", "False"]], "doc_hash": "7d49e9458df449991543629615b36eeb048a7a09f2dab114c47a5d3eaea241d9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 2069, "doc": {"premise": "Pundits often say history is written by the winners.", "hypothesis": "Pundits say the winners tell history.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Yes, Pundits say the winners tell history."}, "gen_args_1": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? Also, Pundits say the winners tell history."}, "gen_args_2": {"arg_0": "", "arg_1": " Pundits often say history is written by the winners., right? No, Pundits say the winners tell history."}}, "resps": [[["-92.0", "False"]], [["-90.0", "False"]], [["-87.5", "False"]]], "filtered_resps": [["-92.0", "False"], ["-90.0", "False"], ["-87.5", "False"]], "doc_hash": "adde21d69998d9a19269ba1645f8741c1d773bd6c8f1c7c47d7c18b8be9d56a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.01016196 0.07508731 0.91475073]"]}
{"doc_id": 2077, "doc": {"premise": "Thank You, Sir, Could I Have Another Answer", "hypothesis": "Thank you, Sir; that is the only answer I needed.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Yes, Thank you, Sir; that is the only answer I needed."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Also, Thank you, Sir; that is the only answer I needed."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? No, Thank you, Sir; that is the only answer I needed."}}, "resps": [[["-100.0", "False"]], [["-103.5", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-103.5", "False"], ["-97.5", "False"]], "doc_hash": "e95d7a0ff7e940434a858793815a8a069afc97a08fe2ba07277b4e3bbc7b5549", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07568481 0.00228548 0.92202971]"]}
{"doc_id": 2085, "doc": {"premise": "Why is the consistent solution the right solution?", "hypothesis": "It's obvious the consistent solution is always wrong.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Yes, It's obvious the consistent solution is always wrong."}, "gen_args_1": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Also, It's obvious the consistent solution is always wrong."}, "gen_args_2": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? No, It's obvious the consistent solution is always wrong."}}, "resps": [[["-100.5", "False"]], [["-103.5", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-100.5", "False"], ["-103.5", "False"], ["-98.0", "False"]], "doc_hash": "3e51579e881ad3391974ae7063297ccefad1f1a0c359c20601c80982af6ee481", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 2093, "doc": {"premise": "TV dinners carry a terrible stigma.", "hypothesis": "TV dinners always show a family eating some meat dish.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Yes, TV dinners always show a family eating some meat dish."}, "gen_args_1": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? Also, TV dinners always show a family eating some meat dish."}, "gen_args_2": {"arg_0": "", "arg_1": " TV dinners carry a terrible stigma., right? No, TV dinners always show a family eating some meat dish."}}, "resps": [[["-115.5", "False"]], [["-112.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-115.5", "False"], ["-112.5", "False"], ["-117.0", "False"]], "doc_hash": "cf5345f73a7fdb3432ff4610dc98598e08478ac46498760239a7d6edb7923059", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04692926 0.94259941 0.01047133]"]}
{"doc_id": 2101, "doc": {"premise": "Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason.", "hypothesis": "It is difficult to reconcile faith and reason.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Yes, It is difficult to reconcile faith and reason."}, "gen_args_1": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Also, It is difficult to reconcile faith and reason."}, "gen_args_2": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? No, It is difficult to reconcile faith and reason."}}, "resps": [[["-130.0", "False"]], [["-135.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-135.0", "False"], ["-134.0", "False"]], "doc_hash": "5f5f2f180ca9d0a41897b46b29c1e72a2048ca2b1d490fad082f5aac5d30a56c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 2109, "doc": {"premise": "Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft.", "hypothesis": "Dickenson wrote novels.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Yes, Dickenson wrote novels."}, "gen_args_1": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Also, Dickenson wrote novels."}, "gen_args_2": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? No, Dickenson wrote novels."}}, "resps": [[["-145.0", "False"]], [["-145.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-145.0", "False"], ["-145.0", "False"]], "doc_hash": "fcd22217deebcddcda1d58def30e66c79d09397684be0a14529ce6c86068373a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2117, "doc": {"premise": "The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers.", "hypothesis": "The trip was a complete waste of time, the misunderstanding is even greater now.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Yes, The trip was a complete waste of time, the misunderstanding is even greater now."}, "gen_args_1": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? Also, The trip was a complete waste of time, the misunderstanding is even greater now."}, "gen_args_2": {"arg_0": "", "arg_1": " The trip was worth it, at least in terms of understanding what motivates Republic of Texas believers., right? No, The trip was a complete waste of time, the misunderstanding is even greater now."}}, "resps": [[["-159.0", "False"]], [["-162.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-162.0", "False"], ["-154.0", "False"]], "doc_hash": "6cd6cda151eb4a5dfcda7f3d01f3bd35260039d4c3f107f8661f8e8a7d599d82", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 2125, "doc": {"premise": "On the other hand, he's got Mark Twain between him and daylight.", "hypothesis": "Mark Twain cannot stop him.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Yes, Mark Twain cannot stop him."}, "gen_args_1": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Also, Mark Twain cannot stop him."}, "gen_args_2": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? No, Mark Twain cannot stop him."}}, "resps": [[["-108.5", "False"]], [["-111.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-108.5", "False"], ["-111.5", "False"], ["-106.0", "False"]], "doc_hash": "bafecad766ddbc73ab82ba298888813885ecf43eef75824ff06b3a2c5a378d1c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 2133, "doc": {"premise": "Why would human beings have Laibson-style preferences in the first place?", "hypothesis": "Everyone should have Laibson-style preferences.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Yes, Everyone should have Laibson-style preferences."}, "gen_args_1": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Also, Everyone should have Laibson-style preferences."}, "gen_args_2": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? No, Everyone should have Laibson-style preferences."}}, "resps": [[["-113.5", "False"]], [["-118.0", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-118.0", "False"], ["-113.5", "False"]], "doc_hash": "8f05999bc8c55565cd6f33957d9061e1affd96279d65c624b3d062c7216f8cdc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 2141, "doc": {"premise": "The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people.", "hypothesis": "The presence of these rappers in our history doesn't guarantee we are tough.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Yes, The presence of these rappers in our history doesn't guarantee we are tough."}, "gen_args_1": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? Also, The presence of these rappers in our history doesn't guarantee we are tough."}, "gen_args_2": {"arg_0": "", "arg_1": " The presence of Bugsy Siegel and Kid Twist in our recent history does not mean we are a tough people., right? No, The presence of these rappers in our history doesn't guarantee we are tough."}}, "resps": [[["-169.0", "False"]], [["-169.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-169.0", "False"], ["-166.0", "False"]], "doc_hash": "67884d5d1d74eacac72dfea055419fdc3580e39e4315757481a290fa60e2178a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 2149, "doc": {"premise": "Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?", "hypothesis": "Clarke has worries about our foreign policy.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Yes, Clarke has worries about our foreign policy."}, "gen_args_1": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Also, Clarke has worries about our foreign policy."}, "gen_args_2": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? No, Clarke has worries about our foreign policy."}}, "resps": [[["-172.0", "False"]], [["-175.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-175.0", "False"], ["-172.0", "False"]], "doc_hash": "f17fab1ecbf06ccc051e8a45ecc368b6fef4ae9a97ecf203c846c538bf578a8e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2157, "doc": {"premise": "This man was born in Germany, is wealthy, educated, well-traveled...", "hypothesis": "The man moved from Germany after he was born.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Yes, The man moved from Germany after he was born."}, "gen_args_1": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Also, The man moved from Germany after he was born."}, "gen_args_2": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? No, The man moved from Germany after he was born."}}, "resps": [[["-120.0", "False"]], [["-119.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-119.5", "False"], ["-117.0", "False"]], "doc_hash": "53b4f799c6ee34dfb7d2d17d9d11f4da71d3d78831ee1ef74050040afc27088f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04398648 0.07252145 0.88349207]"]}
{"doc_id": 2165, "doc": {"premise": "Time runs two anti-emotion articles.", "hypothesis": "Time magazine runs two controversial anit-emotion pieces.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Yes, Time magazine runs two controversial anit-emotion pieces."}, "gen_args_1": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? Also, Time magazine runs two controversial anit-emotion pieces."}, "gen_args_2": {"arg_0": "", "arg_1": " Time runs two anti-emotion articles., right? No, Time magazine runs two controversial anit-emotion pieces."}}, "resps": [[["-116.0", "False"]], [["-121.0", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-121.0", "False"], ["-118.0", "False"]], "doc_hash": "c8ad2ca713425be38f131ab21891c43c4aed36b6c111c1115583354db3aaa557", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2173, "doc": {"premise": "Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals.", "hypothesis": "Catholics and Christians never partake in the same activities.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Yes, Catholics and Christians never partake in the same activities."}, "gen_args_1": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Also, Catholics and Christians never partake in the same activities."}, "gen_args_2": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? No, Catholics and Christians never partake in the same activities."}}, "resps": [[["-208.0", "False"]], [["-209.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-208.0", "False"], ["-209.0", "False"], ["-204.0", "False"]], "doc_hash": "6ef80398fa9189e74a6de1a50c8ada5764fa2419537190fb5b544facfcc5760b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 2181, "doc": {"premise": "The Boston Globe has published a hard-hitting four part series on Harvard University.", "hypothesis": "Harvard University gave The Boston Globe permission to write about them.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Yes, Harvard University gave The Boston Globe permission to write about them."}, "gen_args_1": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Also, Harvard University gave The Boston Globe permission to write about them."}, "gen_args_2": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? No, Harvard University gave The Boston Globe permission to write about them."}}, "resps": [[["-114.0", "False"]], [["-117.0", "False"]], [["-110.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-117.0", "False"], ["-110.5", "False"]], "doc_hash": "6097836722bee55eeb32ef045340f4e5385dfdedd2a06bbd981bb3aa68b01f07", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.02926952 0.00145724 0.96927324]"]}
{"doc_id": 2189, "doc": {"premise": "So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb.", "hypothesis": "It's always above 80 in Cuba.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Yes, It's always above 80 in Cuba."}, "gen_args_1": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? Also, It's always above 80 in Cuba."}, "gen_args_2": {"arg_0": "", "arg_1": " So in the Cuban tropics, too, there has just now been a day as beautiful as glory, cold as the tomb., right? No, It's always above 80 in Cuba."}}, "resps": [[["-171.0", "False"]], [["-174.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-174.0", "False"], ["-171.0", "False"]], "doc_hash": "609f220e19b20b0d1848785a1a0878b95239aaf5b7bf0902ec1f3a4b57f1a303", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2197, "doc": {"premise": "This is no secret to music retailers.", "hypothesis": "Music retailers are well aware of this fact.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Yes, Music retailers are well aware of this fact."}, "gen_args_1": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Also, Music retailers are well aware of this fact."}, "gen_args_2": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? No, Music retailers are well aware of this fact."}}, "resps": [[["-87.0", "False"]], [["-95.0", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-87.0", "False"], ["-95.0", "False"], ["-89.0", "False"]], "doc_hash": "148c64a7b8c58bbfa184a45bafc018d10300f074facc3f13e0994f0992a892ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 2205, "doc": {"premise": "There is no need to apologize for our leadership role.", "hypothesis": "Our only option is to follow whatever directions we are given from our superiors and the higher-ups.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Yes, Our only option is to follow whatever directions we are given from our superiors and the higher-ups."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Also, Our only option is to follow whatever directions we are given from our superiors and the higher-ups."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? No, Our only option is to follow whatever directions we are given from our superiors and the higher-ups."}}, "resps": [[["-122.5", "False"]], [["-124.5", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-124.5", "False"], ["-123.5", "False"]], "doc_hash": "4e9d8b553a055e073e250484b29ddb0f84a29673b92225872013d6bd2977ba21", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2213, "doc": {"premise": "The MCI Web site spells out the intended method of measuring these home runs.", "hypothesis": "There is no mention of home runs on the MCI Web site at this time.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Yes, There is no mention of home runs on the MCI Web site at this time."}, "gen_args_1": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? Also, There is no mention of home runs on the MCI Web site at this time."}, "gen_args_2": {"arg_0": "", "arg_1": " The MCI Web site spells out the intended method of measuring these home runs., right? No, There is no mention of home runs on the MCI Web site at this time."}}, "resps": [[["-146.0", "False"]], [["-153.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-153.0", "False"], ["-146.0", "False"]], "doc_hash": "0c06f55da0856de4a235d45ab81842c848dfe8e8e5222af1d25728672c0bced2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 2221, "doc": {"premise": "What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence.", "hypothesis": "The only things Herstein and Murray use to determine IQ is age and gender.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Yes, The only things Herstein and Murray use to determine IQ is age and gender."}, "gen_args_1": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Also, The only things Herstein and Murray use to determine IQ is age and gender."}, "gen_args_2": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? No, The only things Herstein and Murray use to determine IQ is age and gender."}}, "resps": [[["-156.0", "False"]], [["-155.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-155.0", "False"], ["-151.0", "False"]], "doc_hash": "cf52c526a9c1abe46d301906bd200f75062b3066fe74ed69ae06cd66941f3b74", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00657326 0.01786798 0.97555875]"]}
{"doc_id": 2229, "doc": {"premise": "The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway.", "hypothesis": "The ABM Treaty has nothing to do with weaponry.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Yes, The ABM Treaty has nothing to do with weaponry."}, "gen_args_1": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Also, The ABM Treaty has nothing to do with weaponry."}, "gen_args_2": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? No, The ABM Treaty has nothing to do with weaponry."}}, "resps": [[["-165.0", "False"]], [["-164.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-164.0", "False"], ["-161.0", "False"]], "doc_hash": "9248f6b9afd71f6df202b97b9bc73e3ef5ed53b239ac0ed79c4669c66bf0a104", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 2237, "doc": {"premise": "The Feminization of Culture Answer", "hypothesis": "There is only one answer tot he feminization of culture.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Yes, There is only one answer tot he feminization of culture."}, "gen_args_1": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? Also, There is only one answer tot he feminization of culture."}, "gen_args_2": {"arg_0": "", "arg_1": " The Feminization of Culture Answer, right? No, There is only one answer tot he feminization of culture."}}, "resps": [[["-106.0", "False"]], [["-112.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-112.0", "False"], ["-106.0", "False"]], "doc_hash": "2dd3e19f31772593c28428ac35127624c5e79857c13afd5849a493eafcc2da9f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 2245, "doc": {"premise": "By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less", "hypothesis": "As Skeat got older he gave off the feeling that he took these matters less.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Yes, As Skeat got older he gave off the feeling that he took these matters less."}, "gen_args_1": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Also, As Skeat got older he gave off the feeling that he took these matters less."}, "gen_args_2": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? No, As Skeat got older he gave off the feeling that he took these matters less."}}, "resps": [[["-167.0", "False"]], [["-174.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-174.0", "False"], ["-172.0", "False"]], "doc_hash": "13187be53cbe84ec8e9ca19fa9aefa0d6046912b7243786afc769c2d69e97312", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 9.04959183e-04 6.68679417e-03]"]}
{"doc_id": 2253, "doc": {"premise": "..,  but the second time the encounter is  he is caught in the middle between two friends.", "hypothesis": "He does not know which side to pick, between his two friends.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Yes, He does not know which side to pick, between his two friends."}, "gen_args_1": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Also, He does not know which side to pick, between his two friends."}, "gen_args_2": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? No, He does not know which side to pick, between his two friends."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-163.0", "False"]], "doc_hash": "c7e5900eb3c5789a8758ad5282d7616114900bd39fb7c1e4674edf10ec27ec0e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2261, "doc": {"premise": "Given time and improved technology, all non-radio phones may be branded as wire phones .", "hypothesis": "Wire phones are more basic than non-radio phones.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Yes, Wire phones are more basic than non-radio phones."}, "gen_args_1": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? Also, Wire phones are more basic than non-radio phones."}, "gen_args_2": {"arg_0": "", "arg_1": " Given time and improved technology, all non-radio phones may be branded as wire phones ., right? No, Wire phones are more basic than non-radio phones."}}, "resps": [[["-156.0", "False"]], [["-157.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-157.0", "False"], ["-151.0", "False"]], "doc_hash": "d1b204f551ae31c27f995e17e034f4bd133014f71bf64d1fd39060d0958b6bfe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 2269, "doc": {"premise": "Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096.", "hypothesis": "The first Lingua France was spoken in France after the first crusade had ended.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Yes, The first Lingua France was spoken in France after the first crusade had ended."}, "gen_args_1": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Also, The first Lingua France was spoken in France after the first crusade had ended."}, "gen_args_2": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? No, The first Lingua France was spoken in France after the first crusade had ended."}}, "resps": [[["-189.0", "False"]], [["-191.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-189.0", "False"], ["-191.0", "False"], ["-187.0", "False"]], "doc_hash": "1e3f80df04210d595daae3c6e026a06a2fb98b77bdf70595cb4b2809228511a6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2277, "doc": {"premise": "We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk.", "hypothesis": "Everyone passionately ate their meals and commented that it reminded them of their favorite holiday dishes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Yes, Everyone passionately ate their meals and commented that it reminded them of their favorite holiday dishes."}, "gen_args_1": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Also, Everyone passionately ate their meals and commented that it reminded them of their favorite holiday dishes."}, "gen_args_2": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? No, Everyone passionately ate their meals and commented that it reminded them of their favorite holiday dishes."}}, "resps": [[["-230.0", "False"]], [["-230.0", "False"]], [["-229.0", "False"]]], "filtered_resps": [["-230.0", "False"], ["-230.0", "False"], ["-229.0", "False"]], "doc_hash": "9d80f0af8a72de996f7f73a89d0f3aff3ae0e116491df7da0ce097892d711ff1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2285, "doc": {"premise": "Today these Germanisms do not even stay put in the United States.", "hypothesis": "These Germanisms are used all over the Americas these days.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Yes, These Germanisms are used all over the Americas these days."}, "gen_args_1": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? Also, These Germanisms are used all over the Americas these days."}, "gen_args_2": {"arg_0": "", "arg_1": " Today these Germanisms do not even stay put in the United States., right? No, These Germanisms are used all over the Americas these days."}}, "resps": [[["-130.0", "False"]], [["-133.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-133.0", "False"], ["-129.0", "False"]], "doc_hash": "7131c448500736a771e184aad33fe2cb8e7c8f7e2a62e34df221163f732da011", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2293, "doc": {"premise": "For example, some have derivations distinctly removed from the equipment used or the court on which the game is played.", "hypothesis": "Some games are not named after either equipment or court.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Yes, Some games are not named after either equipment or court."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Also, Some games are not named after either equipment or court."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? No, Some games are not named after either equipment or court."}}, "resps": [[["-164.0", "False"]], [["-162.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-162.0", "False"], ["-166.0", "False"]], "doc_hash": "5b9da72c3b62070a4737890f5fc2dd0d3db985fe5d33fa77e5ea709d3b2c4a9c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.86681333 0.01587624]"]}
{"doc_id": 2301, "doc": {"premise": "But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before.", "hypothesis": "The book was dedicated to the author's mother.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Yes, The book was dedicated to the author's mother."}, "gen_args_1": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Also, The book was dedicated to the author's mother."}, "gen_args_2": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? No, The book was dedicated to the author's mother."}}, "resps": [[["-141.0", "False"]], [["-141.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-141.0", "False"], ["-140.0", "False"]], "doc_hash": "594920a7ff452b3c78bd21278637dbbcbd010f088f1491fc8d2fe4dae0408d3a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2309, "doc": {"premise": "I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?", "hypothesis": "Rebecca explained that I did not understand the words because I was an ignorant buffoon.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Yes, Rebecca explained that I did not understand the words because I was an ignorant buffoon."}, "gen_args_1": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? Also, Rebecca explained that I did not understand the words because I was an ignorant buffoon."}, "gen_args_2": {"arg_0": "", "arg_1": " I was puzzled by Rebecca Christian's mention in  Blessed Be the Words That Bind' [XVI,3] of  Vikki Carr's song, `Is That All There Is?, right? No, Rebecca explained that I did not understand the words because I was an ignorant buffoon."}}, "resps": [[["-272.0", "False"]], [["-272.0", "False"]], [["-272.0", "False"]]], "filtered_resps": [["-272.0", "False"], ["-272.0", "False"], ["-272.0", "False"]], "doc_hash": "26b46c3e0e3926e702541c59e157e558197aadd2190ae1660e08e2aceee76b6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2317, "doc": {"premise": "But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular.", "hypothesis": "The acknowledgements are not dedications.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Yes, The acknowledgements are not dedications."}, "gen_args_1": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Also, The acknowledgements are not dedications."}, "gen_args_2": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? No, The acknowledgements are not dedications."}}, "resps": [[["-147.0", "False"]], [["-152.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-152.0", "False"], ["-146.0", "False"]], "doc_hash": "7fc6ae136c405180c6aba84d4593888e9c61879d66955dcfdd8aab62d1d7d5af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 2325, "doc": {"premise": "said my wife, raising an eyebrow.", "hypothesis": "My wife raised her eyebrow as she made the inquiry.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Yes, My wife raised her eyebrow as she made the inquiry."}, "gen_args_1": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Also, My wife raised her eyebrow as she made the inquiry."}, "gen_args_2": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? No, My wife raised her eyebrow as she made the inquiry."}}, "resps": [[["-98.5", "False"]], [["-103.5", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-103.5", "False"], ["-101.5", "False"]], "doc_hash": "5799dfb43a21ef0242d8160dccd23d4f925b9329f3a96cbdee7ade142b9b858a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 2333, "doc": {"premise": "Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins.", "hypothesis": "This work has won several prestigious writing awards over the years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Yes, This work has won several prestigious writing awards over the years."}, "gen_args_1": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? Also, This work has won several prestigious writing awards over the years."}, "gen_args_2": {"arg_0": "", "arg_1": " Still others will simply marvel at the use of language and wonder just where our analytical side ends and our emotional side begins., right? No, This work has won several prestigious writing awards over the years."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-165.0", "False"]], "doc_hash": "0d202a3ec607d559c90c35826c738d5d2df77901c5618d3be9bc7c2bceb9cc45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.11849965 0.00589975]"]}
{"doc_id": 2341, "doc": {"premise": "The equally whimsical nature of the  definitions' defies description.", "hypothesis": "The definitions are also very whimsical seeming.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Yes, The definitions are also very whimsical seeming."}, "gen_args_1": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Also, The definitions are also very whimsical seeming."}, "gen_args_2": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? No, The definitions are also very whimsical seeming."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-150.0", "False"]], "doc_hash": "9a1cf7f9a88e4051dd0035c8d9a39fc8c1d3ca345fcac9b9ccb6ff37fa00ccb6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.11849965 0.00589975]"]}
{"doc_id": 2349, "doc": {"premise": "Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line.", "hypothesis": "The birds and bees are mentioned in this Latin poem, but no people are described.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Yes, The birds and bees are mentioned in this Latin poem, but no people are described."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Also, The birds and bees are mentioned in this Latin poem, but no people are described."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? No, The birds and bees are mentioned in this Latin poem, but no people are described."}}, "resps": [[["-184.0", "False"]], [["-185.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-185.0", "False"], ["-184.0", "False"]], "doc_hash": "c9c0459fa2eb917244a11573e4a9a9bff815c338930f5bfb8528554361e182e9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2357, "doc": {"premise": "What are you doing becomes  Watch a dune.", "hypothesis": "they change the words up.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Yes, they change the words up."}, "gen_args_1": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? Also, they change the words up."}, "gen_args_2": {"arg_0": "", "arg_1": " What are you doing becomes  Watch a dune., right? No, they change the words up."}}, "resps": [[["-125.0", "False"]], [["-126.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-126.5", "False"], ["-122.5", "False"]], "doc_hash": "813f845210a3a94ded810761b3c58448b7cdf70065f4e0ddcce12bb7fc725601", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.07459556 0.01664452 0.90875992]"]}
{"doc_id": 2365, "doc": {"premise": "Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth.", "hypothesis": "People who can't speak the language will have a hard time answering.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Yes, People who can't speak the language will have a hard time answering."}, "gen_args_1": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Also, People who can't speak the language will have a hard time answering."}, "gen_args_2": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? No, People who can't speak the language will have a hard time answering."}}, "resps": [[["-177.0", "False"]], [["-180.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-180.0", "False"], ["-180.0", "False"]], "doc_hash": "d10aa0bc5bd15f4d7e07923e1081b10ca208ce85b56c1f616e228741a6082a77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 2373, "doc": {"premise": "It sweeps words in its passage, as well.", "hypothesis": "It also sweeps words when passing by.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Yes, It also sweeps words when passing by."}, "gen_args_1": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Also, It also sweeps words when passing by."}, "gen_args_2": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? No, It also sweeps words when passing by."}}, "resps": [[["-106.5", "False"]], [["-111.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-111.5", "False"], ["-109.5", "False"]], "doc_hash": "7e6ef5b7ee64dca670b8ec36c43dd9a70ca5868d9dc5b393422c945a32a1861d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 2381, "doc": {"premise": "Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included.", "hypothesis": "I'm pretty sure that Hendrickson didn't have much to base his ideas on.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Yes, I'm pretty sure that Hendrickson didn't have much to base his ideas on."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? Also, I'm pretty sure that Hendrickson didn't have much to base his ideas on."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, I cannot accept Hendrickson's origin for horse latitudes , though, to give him his due, he only copied the etymology from other sources, the OED included., right? No, I'm pretty sure that Hendrickson didn't have much to base his ideas on."}}, "resps": [[["-210.0", "False"]], [["-209.0", "False"]], [["-210.0", "False"]]], "filtered_resps": [["-210.0", "False"], ["-209.0", "False"], ["-210.0", "False"]], "doc_hash": "40da5e73d802e1f8c0e053a2bb3990246b8728ae787737973556eaae9e7d4906", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 2389, "doc": {"premise": "And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?", "hypothesis": "The Kermit telecommunications protocol refers to a way of talking between Facebook Messenger and WhatsApp.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Yes, The Kermit telecommunications protocol refers to a way of talking between Facebook Messenger and WhatsApp."}, "gen_args_1": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Also, The Kermit telecommunications protocol refers to a way of talking between Facebook Messenger and WhatsApp."}, "gen_args_2": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? No, The Kermit telecommunications protocol refers to a way of talking between Facebook Messenger and WhatsApp."}}, "resps": [[["-202.0", "False"]], [["-205.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-202.0", "False"], ["-205.0", "False"], ["-198.0", "False"]], "doc_hash": "030f689757204bbe2aad9ee08a817f66f1f1e549b30b04341b0b10fe3e5d6ddc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 2397, "doc": {"premise": "The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort.", "hypothesis": "Children's words allay crashes, bombs and aborts on computers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Yes, Children's words allay crashes, bombs and aborts on computers."}, "gen_args_1": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Also, Children's words allay crashes, bombs and aborts on computers."}, "gen_args_2": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? No, Children's words allay crashes, bombs and aborts on computers."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-194.0", "False"]], "doc_hash": "498161fa0e523d424e1941d1e7c281f02b99dabdbf46526b9db85c959e7a7e29", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 2405, "doc": {"premise": "One can also find some definitions here and there that are not entirely wrong yet with which one might disagree.", "hypothesis": "You may disagree with some definitions even though they are not entirely wrong.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Yes, You may disagree with some definitions even though they are not entirely wrong."}, "gen_args_1": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? Also, You may disagree with some definitions even though they are not entirely wrong."}, "gen_args_2": {"arg_0": "", "arg_1": " One can also find some definitions here and there that are not entirely wrong yet with which one might disagree., right? No, You may disagree with some definitions even though they are not entirely wrong."}}, "resps": [[["-134.0", "False"]], [["-142.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-142.0", "False"], ["-138.0", "False"]], "doc_hash": "38ad8227a1b521aea5b7f05994018321573d1bd46cb5fd24993d0be7c8b248b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 2413, "doc": {"premise": "The teacher explained, in terms that she hoped were appropriate to her audience.", "hypothesis": "The teacher deliberately tried to give her lecture using obscure words.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Yes, The teacher deliberately tried to give her lecture using obscure words."}, "gen_args_1": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Also, The teacher deliberately tried to give her lecture using obscure words."}, "gen_args_2": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? No, The teacher deliberately tried to give her lecture using obscure words."}}, "resps": [[["-139.0", "False"]], [["-139.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-139.0", "False"], ["-135.0", "False"]], "doc_hash": "10326c587918a7c70654d6bf3313a7740a2cc5f7a5bf32c9020ff1935226e909", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 2421, "doc": {"premise": "In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk.", "hypothesis": "A reporter for The Economist was in Tokyo and noticed a particular T-shirt.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Yes, A reporter for The Economist was in Tokyo and noticed a particular T-shirt."}, "gen_args_1": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Also, A reporter for The Economist was in Tokyo and noticed a particular T-shirt."}, "gen_args_2": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? No, A reporter for The Economist was in Tokyo and noticed a particular T-shirt."}}, "resps": [[["-206.0", "False"]], [["-211.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-211.0", "False"], ["-207.0", "False"]], "doc_hash": "7737b6d166c872497c79711f95b2272a620e4bb461f6f5b1afa643f5e770ec9e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 2429, "doc": {"premise": "Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops.", "hypothesis": "The term Hogwash is formed because of the stench that comes from washing pigs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Yes, The term Hogwash is formed because of the stench that comes from washing pigs."}, "gen_args_1": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? Also, The term Hogwash is formed because of the stench that comes from washing pigs."}, "gen_args_2": {"arg_0": "", "arg_1": " Hogwash, of course, is a designation for language as `worthless, disgusting, and unfit for human consumption, as pig slops., right? No, The term Hogwash is formed because of the stench that comes from washing pigs."}}, "resps": [[["-191.0", "False"]], [["-192.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-192.0", "False"], ["-189.0", "False"]], "doc_hash": "9703637e6031b317f77ccee64810fa1e86308c475671f6394ef7e6c9bd350403", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 2437, "doc": {"premise": "'  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist.", "hypothesis": "A dictionary required more than specialist skills.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Yes, A dictionary required more than specialist skills."}, "gen_args_1": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Also, A dictionary required more than specialist skills."}, "gen_args_2": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? No, A dictionary required more than specialist skills."}}, "resps": [[["-185.0", "False"]], [["-191.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-191.0", "False"], ["-186.0", "False"]], "doc_hash": "dee668e6d4fb44eeb294dcaf1530bbc3e33cc28e342cc6c49ba0e719c7569b61", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 2445, "doc": {"premise": "Words that do not fit cannot be returned.", "hypothesis": "All words fit.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Yes, All words fit."}, "gen_args_1": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Also, All words fit."}, "gen_args_2": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? No, All words fit."}}, "resps": [[["-85.0", "False"]], [["-88.0", "False"]], [["-82.5", "False"]]], "filtered_resps": [["-85.0", "False"], ["-88.0", "False"], ["-82.5", "False"]], "doc_hash": "adc43fae6de0316c4215f5b4f5c066afda0bc1f10249985e0e7d5322c9145253", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 2453, "doc": {"premise": "A virgin forest is a forest in which the hand of man has never set foot .", "hypothesis": "The newest condo development in the center of the forest won't impact its virgin forest status.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Yes, The newest condo development in the center of the forest won't impact its virgin forest status."}, "gen_args_1": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? Also, The newest condo development in the center of the forest won't impact its virgin forest status."}, "gen_args_2": {"arg_0": "", "arg_1": " A virgin forest is a forest in which the hand of man has never set foot ., right? No, The newest condo development in the center of the forest won't impact its virgin forest status."}}, "resps": [[["-150.0", "False"]], [["-148.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-150.0", "False"], ["-148.0", "False"], ["-148.0", "False"]], "doc_hash": "1863a23aefbc230016a6108ae5686fd23b513f47a1428df034eb112ef7ffac05", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 2461, "doc": {"premise": "I have yet Room for six scotches more.", "hypothesis": "I only have room for one more glass of scotch.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Yes, I only have room for one more glass of scotch."}, "gen_args_1": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Also, I only have room for one more glass of scotch."}, "gen_args_2": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? No, I only have room for one more glass of scotch."}}, "resps": [[["-113.0", "False"]], [["-113.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-113.0", "False"], ["-113.5", "False"], ["-110.0", "False"]], "doc_hash": "ccc9225e026aa98a219df090fb077d1d08acc40ab913fa63d569897b3c9d70b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0460998  0.02796094 0.92593926]"]}
{"doc_id": 2469, "doc": {"premise": "Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World.", "hypothesis": "Schools use Webster's COllege because it is the best.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Yes, Schools use Webster's COllege because it is the best."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Also, Schools use Webster's COllege because it is the best."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? No, Schools use Webster's COllege because it is the best."}}, "resps": [[["-197.0", "False"]], [["-196.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-197.0", "False"], ["-196.0", "False"], ["-194.0", "False"]], "doc_hash": "60ec8d57f673ba11fbc031e4a3cb7f85638e01991ebb08a11a3b9e9f4a08baec", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 2477, "doc": {"premise": "The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out.", "hypothesis": "There are many English words that should be removed from the language.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Yes, There are many English words that should be removed from the language."}, "gen_args_1": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? Also, There are many English words that should be removed from the language."}, "gen_args_2": {"arg_0": "", "arg_1": " The English speech is already overburdened with outlandish words that ought never to have been taken in, and ought even now to be turned out., right? No, There are many English words that should be removed from the language."}}, "resps": [[["-160.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "afbab2337df3b8bdd516d1cc96560c5617955914811f989d36f9f11d718567d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2485, "doc": {"premise": "Feisty, like fizzle, began as Middle English fysten, fisten `to fart.", "hypothesis": "Fiesty has been around for 100 years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Yes, Fiesty has been around for 100 years."}, "gen_args_1": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Also, Fiesty has been around for 100 years."}, "gen_args_2": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? No, Fiesty has been around for 100 years."}}, "resps": [[["-166.0", "False"]], [["-165.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-165.0", "False"], ["-165.0", "False"]], "doc_hash": "f6ec7fa9b36038c48cebb47858ecf11360a7a377d32b64ec146f2851cf907287", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 6, "doc": {"premise": "He didn't get to go.", "hypothesis": "He was the first to be invited and enjoyed the experience.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't get to go., right? Yes, He was the first to be invited and enjoyed the experience."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't get to go., right? Also, He was the first to be invited and enjoyed the experience."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't get to go., right? No, He was the first to be invited and enjoyed the experience."}}, "resps": [[["-94.0", "False"]], [["-96.5", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-94.0", "False"], ["-96.5", "False"], ["-95.5", "False"]], "doc_hash": "792887571414831e690151715fe530c218d4a26ed50b5ce41d9da0c066147da8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.76615721 0.06289001 0.17095278]"]}
{"doc_id": 14, "doc": {"premise": "I was just there just trying to figure it out.", "hypothesis": "I was trying to understand.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Yes, I was trying to understand."}, "gen_args_1": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? Also, I was trying to understand."}, "gen_args_2": {"arg_0": "", "arg_1": " I was just there just trying to figure it out., right? No, I was trying to understand."}}, "resps": [[["-78.5", "False"]], [["-83.0", "False"]], [["-78.0", "False"]]], "filtered_resps": [["-78.5", "False"], ["-83.0", "False"], ["-78.0", "False"]], "doc_hash": "ed0939a3da4cd0a4691865d0dc117acd66a50ffc58c5f2f0651d334da085435b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 22, "doc": {"premise": "Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well.", "hypothesis": "Santo specialized in fire safety because it was an issue that was dear to him.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Yes, Santo specialized in fire safety because it was an issue that was dear to him."}, "gen_args_1": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Also, Santo specialized in fire safety because it was an issue that was dear to him."}, "gen_args_2": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? No, Santo specialized in fire safety because it was an issue that was dear to him."}}, "resps": [[["-320.0", "False"]], [["-322.0", "False"]], [["-324.0", "False"]]], "filtered_resps": [["-320.0", "False"], ["-322.0", "False"], ["-324.0", "False"]], "doc_hash": "d2e810c20943db101c06e3043df11a8855e3c6bba8c1936ffdb4c37f00d91494", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 30, "doc": {"premise": "Now that's how, uh, I stay buckled in.", "hypothesis": "I made sure the buckle was on tight so I would be safe.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Yes, I made sure the buckle was on tight so I would be safe."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Also, I made sure the buckle was on tight so I would be safe."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? No, I made sure the buckle was on tight so I would be safe."}}, "resps": [[["-119.0", "False"]], [["-119.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-119.0", "False"], ["-119.5", "False"], ["-120.0", "False"]], "doc_hash": "6a9188753413840c0c81f1b8d61e757c118474d958f419bc910ccca8c9af0749", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.50648039 0.30719589 0.18632372]"]}
{"doc_id": 38, "doc": {"premise": "When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight.", "hypothesis": "There were instruments in the aircraft that melted.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Yes, There were instruments in the aircraft that melted."}, "gen_args_1": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? Also, There were instruments in the aircraft that melted."}, "gen_args_2": {"arg_0": "", "arg_1": " When I pull, when he pulls the canopy for me to start getting him out, he points to two instruments on the left side of the aircraft that had actually melted during the flight., right? No, There were instruments in the aircraft that melted."}}, "resps": [[["-200.0", "False"]], [["-202.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-202.0", "False"], ["-203.0", "False"]], "doc_hash": "4cf9ee9776fa83da9e4f23fc295f33b15cd728ae1bc2ff661bbef8921c35ebc3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 46, "doc": {"premise": "Only lost two, three aircraft while we was there, and, uh, test phase.", "hypothesis": "A couple of aircraft were lost.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Yes, A couple of aircraft were lost."}, "gen_args_1": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Also, A couple of aircraft were lost."}, "gen_args_2": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? No, A couple of aircraft were lost."}}, "resps": [[["-141.0", "False"]], [["-146.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-146.0", "False"], ["-141.0", "False"]], "doc_hash": "b5fad185453eb46041377bf475fd385a5e06521aa06f6f40c4c9bfce65878be4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 54, "doc": {"premise": "It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's.", "hypothesis": "Rudolph Anderson was nowhere to be found, so we only had one U2's.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Yes, Rudolph Anderson was nowhere to be found, so we only had one U2's."}, "gen_args_1": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Also, Rudolph Anderson was nowhere to be found, so we only had one U2's."}, "gen_args_2": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? No, Rudolph Anderson was nowhere to be found, so we only had one U2's."}}, "resps": [[["-188.0", "False"]], [["-189.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-189.0", "False"], ["-185.0", "False"]], "doc_hash": "fce36fc59ae306c0ca2defb3545ad800e4cb314f93c9b842baf24336d25626f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 62, "doc": {"premise": "Also, oh, let me go through this.", "hypothesis": "I'll look through these reports.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Yes, I'll look through these reports."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? Also, I'll look through these reports."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, oh, let me go through this., right? No, I'll look through these reports."}}, "resps": [[["-91.5", "False"]], [["-92.0", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-91.5", "False"], ["-92.0", "False"], ["-95.0", "False"]], "doc_hash": "0673edac0fcb86384e9c0badfe2e3da1432013479cb196a6c9a174cb4bd797e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.61097505 0.3705751  0.01844985]"]}
{"doc_id": 70, "doc": {"premise": "Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord.", "hypothesis": "Ramona has never been to Concord.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Yes, Ramona has never been to Concord."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Also, Ramona has never been to Concord."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? No, Ramona has never been to Concord."}}, "resps": [[["-212.0", "False"]], [["-212.0", "False"]], [["-209.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-212.0", "False"], ["-209.0", "False"]], "doc_hash": "11c19e32a6dd7841da75c6a39cc69e03e3075c924961ce779b61b2c11d71aba5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 78, "doc": {"premise": "And it makes you feel just awful.", "hypothesis": "It makes you feel great.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Yes, It makes you feel great."}, "gen_args_1": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Also, It makes you feel great."}, "gen_args_2": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? No, It makes you feel great."}}, "resps": [[["-72.5", "False"]], [["-76.5", "False"]], [["-67.5", "False"]]], "filtered_resps": [["-72.5", "False"], ["-76.5", "False"], ["-67.5", "False"]], "doc_hash": "ae04e578411ffb413d6662abffa487454e23bc19b9da22630e81619a84d12e73", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69203059e-03 1.22568816e-04 9.93185401e-01]"]}
{"doc_id": 86, "doc": {"premise": "That was, that was a pretty scary day.", "hypothesis": "That day really scared me.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Yes, That day really scared me."}, "gen_args_1": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? Also, That day really scared me."}, "gen_args_2": {"arg_0": "", "arg_1": " That was, that was a pretty scary day., right? No, That day really scared me."}}, "resps": [[["-80.0", "False"]], [["-85.0", "False"]], [["-82.5", "False"]]], "filtered_resps": [["-80.0", "False"], ["-85.0", "False"], ["-82.5", "False"]], "doc_hash": "1142262d9132c52495806dc44257892a4c9089f17221fa1764f6fc21600f8cfc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.91842297 0.00618829 0.07538875]"]}
{"doc_id": 94, "doc": {"premise": "Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?", "hypothesis": "I would like a glass of chocolate milk.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Yes, I would like a glass of chocolate milk."}, "gen_args_1": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Also, I would like a glass of chocolate milk."}, "gen_args_2": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? No, I would like a glass of chocolate milk."}}, "resps": [[["-106.0", "False"]], [["-113.5", "False"]], [["-113.0", "False"]]], "filtered_resps": [["-106.0", "False"], ["-113.5", "False"], ["-113.0", "False"]], "doc_hash": "bab9c62d021546b5e06ef1d22761666834f3aa92f2edc70bb5fc6a13b4082b1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.98537177e-01 5.52275305e-04 9.10548043e-04]"]}
{"doc_id": 102, "doc": {"premise": "They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do.", "hypothesis": "Everyone in the house was moping because they missed Joe so much.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Yes, Everyone in the house was moping because they missed Joe so much."}, "gen_args_1": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Also, Everyone in the house was moping because they missed Joe so much."}, "gen_args_2": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? No, Everyone in the house was moping because they missed Joe so much."}}, "resps": [[["-182.0", "False"]], [["-183.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-183.0", "False"], ["-184.0", "False"]], "doc_hash": "a81f7dd06ac00fac8e42e074c835ed4a5b197eba8647d17fda6bab7ba367d077", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 110, "doc": {"premise": "I don't want to go into the Third SS that's Third Strategic Support Squadron.", "hypothesis": "The Third SS is the worst possible squadron.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Yes, The Third SS is the worst possible squadron."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? Also, The Third SS is the worst possible squadron."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't want to go into the Third SS that's Third Strategic Support Squadron., right? No, The Third SS is the worst possible squadron."}}, "resps": [[["-137.0", "False"]], [["-141.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-141.0", "False"], ["-137.0", "False"]], "doc_hash": "51efacd3da33a407f7c4c5ba612567886a4bf215d0b23e7027e8cb8b19d5f6a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 118, "doc": {"premise": "He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married.", "hypothesis": "He is a Greek man.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Yes, He is a Greek man."}, "gen_args_1": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Also, He is a Greek man."}, "gen_args_2": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? No, He is a Greek man."}}, "resps": [[["-175.0", "False"]], [["-180.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-180.0", "False"], ["-178.0", "False"]], "doc_hash": "485e11a3b20bf3f06057e4a6577114409eb911b53efe1e46b41e7c7a7dde1b1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 126, "doc": {"premise": "Well, there's nobody there to help me.", "hypothesis": "I'm not able to do it on my own.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Yes, I'm not able to do it on my own."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Also, I'm not able to do it on my own."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? No, I'm not able to do it on my own."}}, "resps": [[["-78.0", "False"]], [["-79.5", "False"]], [["-76.0", "False"]]], "filtered_resps": [["-78.0", "False"], ["-79.5", "False"], ["-76.0", "False"]], "doc_hash": "2eed31f94646b7581b8fe864772b25412b2dc48b3b2654c83fbf96a4554aa864", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11611453 0.02590865 0.85797681]"]}
{"doc_id": 134, "doc": {"premise": "I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed.", "hypothesis": "I told him I needed more information.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Yes, I told him I needed more information."}, "gen_args_1": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? Also, I told him I needed more information."}, "gen_args_2": {"arg_0": "", "arg_1": " I already told him, I tried to explain to him that I was frustrated I didn't have all the information I needed., right? No, I told him I needed more information."}}, "resps": [[["-109.0", "False"]], [["-111.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-111.5", "False"], ["-110.0", "False"]], "doc_hash": "45b87b9ab48cdd164a68a0ed800b54097fe17285f23191b309bb55fef6fa2c9c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 142, "doc": {"premise": "So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there.", "hypothesis": "Granny walked 100 feet from the house.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Yes, Granny walked 100 feet from the house."}, "gen_args_1": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Also, Granny walked 100 feet from the house."}, "gen_args_2": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? No, Granny walked 100 feet from the house."}}, "resps": [[["-159.0", "False"]], [["-162.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-162.0", "False"], ["-157.0", "False"]], "doc_hash": "8d1fd4b484ca3c066ffe6238d2fc9d11a0e4e41d30aea175cf8427c6aa0cd3c3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 150, "doc": {"premise": "And then I heard him leave, so I'm still finishing what I had to do.", "hypothesis": "I am doing what I'm required to do today.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Yes, I am doing what I'm required to do today."}, "gen_args_1": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Also, I am doing what I'm required to do today."}, "gen_args_2": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? No, I am doing what I'm required to do today."}}, "resps": [[["-119.5", "False"]], [["-123.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-119.5", "False"], ["-123.5", "False"], ["-120.0", "False"]], "doc_hash": "0e3a79b37ea36065025180ce4f50c64d63f4e69f3e5dc3a6c1477bb684962b3a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61544283 0.01127223 0.37328494]"]}
{"doc_id": 158, "doc": {"premise": "It would not explode without the trigger.", "hypothesis": "There's no trigger to pull.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Yes, There's no trigger to pull."}, "gen_args_1": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? Also, There's no trigger to pull."}, "gen_args_2": {"arg_0": "", "arg_1": " It would not explode without the trigger., right? No, There's no trigger to pull."}}, "resps": [[["-84.5", "False"]], [["-85.0", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-84.5", "False"], ["-85.0", "False"], ["-84.5", "False"]], "doc_hash": "cd79b6354c27ad67dc22b35ee3bfa7f589c20e7d46efb93ea0798fe1618fc5bf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.38365173 0.23269654 0.38365173]"]}
{"doc_id": 166, "doc": {"premise": "I don't care if you don't know anything about it.", "hypothesis": "I think you should change your mind and be very interested in this!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Yes, I think you should change your mind and be very interested in this!"}, "gen_args_1": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Also, I think you should change your mind and be very interested in this!"}, "gen_args_2": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? No, I think you should change your mind and be very interested in this!"}}, "resps": [[["-96.5", "False"]], [["-97.0", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-96.5", "False"], ["-97.0", "False"], ["-95.5", "False"]], "doc_hash": "a1a743d914918227c0fb61bd6fc72ac4019f424ff7f7842e1e97626f56d8c59a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.2312239  0.14024438 0.62853172]"]}
{"doc_id": 174, "doc": {"premise": "They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington.", "hypothesis": "They told me I should stay home.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Yes, They told me I should stay home."}, "gen_args_1": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Also, They told me I should stay home."}, "gen_args_2": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? No, They told me I should stay home."}}, "resps": [[["-170.0", "False"]], [["-173.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-173.0", "False"], ["-168.0", "False"]], "doc_hash": "843fbdf340211ec8df0780798a6a023e1df781755b3fee5844c081c24f1d0777", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 182, "doc": {"premise": "If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression.", "hypothesis": "your hand would grow a ton if you were on the moon and you stuck it out of the suit.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Yes, your hand would grow a ton if you were on the moon and you stuck it out of the suit."}, "gen_args_1": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? Also, your hand would grow a ton if you were on the moon and you stuck it out of the suit."}, "gen_args_2": {"arg_0": "", "arg_1": " If, if your hand was exposed outside of the pressure suit, your hands would go to about five times the size, if you had a decompression., right? No, your hand would grow a ton if you were on the moon and you stuck it out of the suit."}}, "resps": [[["-201.0", "False"]], [["-204.0", "False"]], [["-202.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-204.0", "False"], ["-202.0", "False"]], "doc_hash": "eba3a99fc24de5f918afc3ab78ff73642096b856366988ff837066cbdb6cb7ab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 190, "doc": {"premise": "No, it was just that one time in the morning, and she said that she was going to come back to the office.", "hypothesis": "She said she was going to return later.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Yes, She said she was going to return later."}, "gen_args_1": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Also, She said she was going to return later."}, "gen_args_2": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? No, She said she was going to return later."}}, "resps": [[["-120.5", "False"]], [["-125.5", "False"]], [["-121.5", "False"]]], "filtered_resps": [["-120.5", "False"], ["-125.5", "False"], ["-121.5", "False"]], "doc_hash": "c8301779858111d3697da21eb410246264ea5e432cbff67a321ef81df8dd64f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 198, "doc": {"premise": "So he stayed in Augusta after that?", "hypothesis": "Did he remain in Augusta?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Yes, Did he remain in Augusta?"}, "gen_args_1": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Also, Did he remain in Augusta?"}, "gen_args_2": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? No, Did he remain in Augusta?"}}, "resps": [[["-87.0", "False"]], [["-91.0", "False"]], [["-90.0", "False"]]], "filtered_resps": [["-87.0", "False"], ["-91.0", "False"], ["-90.0", "False"]], "doc_hash": "0f96a349abb3a09ab97ec701f1bb155ff50cff83d26c28b49d52155ddca12d24", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 206, "doc": {"premise": "Anyhow, so I finished came home at 6:30 today and that was my day.", "hypothesis": "I spent most of the day dealing with a complicated customer billing issue.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Yes, I spent most of the day dealing with a complicated customer billing issue."}, "gen_args_1": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? Also, I spent most of the day dealing with a complicated customer billing issue."}, "gen_args_2": {"arg_0": "", "arg_1": " Anyhow, so I finished came home at 6:30 today and that was my day., right? No, I spent most of the day dealing with a complicated customer billing issue."}}, "resps": [[["-139.0", "False"]], [["-141.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-141.0", "False"], ["-136.0", "False"]], "doc_hash": "c33f779eab400074d948c3238a9696cf564fe75dd29c9401a81ebd3e7694245a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 214, "doc": {"premise": "I don't have enough information.", "hypothesis": "I need more information to decide what kind of car to purchase.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't have enough information., right? Yes, I need more information to decide what kind of car to purchase."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't have enough information., right? Also, I need more information to decide what kind of car to purchase."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't have enough information., right? No, I need more information to decide what kind of car to purchase."}}, "resps": [[["-79.5", "False"]], [["-82.0", "False"]], [["-79.5", "False"]]], "filtered_resps": [["-79.5", "False"], ["-82.0", "False"], ["-79.5", "False"]], "doc_hash": "c6346f136a53ee65cec9355021ba9e93246bbb55460f1c2a308aa4bd79de0c15", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48028779 0.03942442 0.48028779]"]}
{"doc_id": 222, "doc": {"premise": "I had to start training in course.", "hypothesis": "I didn't need any preparation.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I had to start training in course., right? Yes, I didn't need any preparation."}, "gen_args_1": {"arg_0": "", "arg_1": " I had to start training in course., right? Also, I didn't need any preparation."}, "gen_args_2": {"arg_0": "", "arg_1": " I had to start training in course., right? No, I didn't need any preparation."}}, "resps": [[["-89.5", "False"]], [["-91.5", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-89.5", "False"], ["-91.5", "False"], ["-86.0", "False"]], "doc_hash": "3827896c1f7d27954e143a5fe0037f958670c98ac15b4bb071fd69632790f12e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02919641 0.0039513  0.96685229]"]}
{"doc_id": 230, "doc": {"premise": "Now that's how classified it was.", "hypothesis": "It was very classified.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Yes, It was very classified."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how classified it was., right? Also, It was very classified."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how classified it was., right? No, It was very classified."}}, "resps": [[["-80.0", "False"]], [["-91.5", "False"]], [["-85.0", "False"]]], "filtered_resps": [["-80.0", "False"], ["-91.5", "False"], ["-85.0", "False"]], "doc_hash": "a77550f2d39f1d4ad2e3d304cfe06fff04f4e458a41c8cbad4a4aacbfe42ccb9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.93297154e-01 1.00621931e-05 6.69278358e-03]"]}
{"doc_id": 238, "doc": {"premise": "Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down.", "hypothesis": "Pilots have to be tested in altitude chambers about 20 times a month.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Yes, Pilots have to be tested in altitude chambers about 20 times a month."}, "gen_args_1": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Also, Pilots have to be tested in altitude chambers about 20 times a month."}, "gen_args_2": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? No, Pilots have to be tested in altitude chambers about 20 times a month."}}, "resps": [[["-223.0", "False"]], [["-227.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-227.0", "False"], ["-228.0", "False"]], "doc_hash": "02f2168d95072393114f75a1f73da2b23ac70477a697ef9b97ef82ae038f63a5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 246, "doc": {"premise": "She's like, But you need to look here, look here, she's gives me like three different places to look in the computer.", "hypothesis": "She had no idea where to look.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Yes, She had no idea where to look."}, "gen_args_1": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Also, She had no idea where to look."}, "gen_args_2": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? No, She had no idea where to look."}}, "resps": [[["-145.0", "False"]], [["-150.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-150.0", "False"], ["-145.0", "False"]], "doc_hash": "001e291ada91a010d7162a4c434efc24ac648c88bfd7967c9ca715ac588ce4c3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 254, "doc": {"premise": "yeah i have a credit union", "hypothesis": "What's a credit union?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Yes, What's a credit union?"}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i have a credit union, right? Also, What's a credit union?"}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i have a credit union, right? No, What's a credit union?"}}, "resps": [[["-73.5", "False"]], [["-73.5", "False"]], [["-71.5", "False"]]], "filtered_resps": [["-73.5", "False"], ["-73.5", "False"], ["-71.5", "False"]], "doc_hash": "f1797ef6c84a71cc29123dcf6d0cae7ac349da571d7158d0d8be066f25a1e64d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 262, "doc": {"premise": "and they can be very nice too after after they've been trained", "hypothesis": "They change rapidly while undergoing training.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Yes, They change rapidly while undergoing training."}, "gen_args_1": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Also, They change rapidly while undergoing training."}, "gen_args_2": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? No, They change rapidly while undergoing training."}}, "resps": [[["-120.0", "False"]], [["-120.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-120.5", "False"], ["-120.0", "False"]], "doc_hash": "57f876551e7b100e406344581fa9450ccef928bdcac4a3ce130186e12b57c4e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.38365173 0.23269654 0.38365173]"]}
{"doc_id": 270, "doc": {"premise": "are you saying the teachers or the parents", "hypothesis": "Are you saying the students or the teacher's aide did it?", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Yes, Are you saying the students or the teacher's aide did it?"}, "gen_args_1": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Also, Are you saying the students or the teacher's aide did it?"}, "gen_args_2": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? No, Are you saying the students or the teacher's aide did it?"}}, "resps": [[["-99.0", "False"]], [["-95.5", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-99.0", "False"], ["-95.5", "False"], ["-98.5", "False"]], "doc_hash": "2ba2a2c34b9fc9adae66a50c90d8aa6676787177753d3b0978fc33afbc0500d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02796094 0.92593926 0.0460998 ]"]}
{"doc_id": 278, "doc": {"premise": "well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs", "hypothesis": "I think so but I have not gone through my emotions with regards to drug testing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Yes, I think so but I have not gone through my emotions with regards to drug testing."}, "gen_args_1": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? Also, I think so but I have not gone through my emotions with regards to drug testing."}, "gen_args_2": {"arg_0": "", "arg_1": " well i guess it would i guess so well i don't know i i i really haven't sorted out all my feelings on the drug testing uh i'm totally straight would never consider using drugs, right? No, I think so but I have not gone through my emotions with regards to drug testing."}}, "resps": [[["-215.0", "False"]], [["-224.0", "False"]], [["-219.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-224.0", "False"], ["-219.0", "False"]], "doc_hash": "4159d6f4aa5f44b06749f119e0592a6d167da4f4b0fbc44e699750f88d5a8643", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81894794e-01 1.21175444e-04 1.79840305e-02]"]}
{"doc_id": 286, "doc": {"premise": "yeah there there's something about having a place to live i don't know", "hypothesis": "I don't really care if i have a place to live.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Yes, I don't really care if i have a place to live."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Also, I don't really care if i have a place to live."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? No, I don't really care if i have a place to live."}}, "resps": [[["-102.5", "False"]], [["-107.5", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-107.5", "False"], ["-102.0", "False"]], "doc_hash": "99a98b45978261bb7633cf638e8169dcc059bc235c83938d5b62bac4cc58adf8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.3765827  0.00253739 0.62087991]"]}
{"doc_id": 294, "doc": {"premise": "and uh i kind of kind of like the black eyed pea but i don't think it's a chain", "hypothesis": "I can not stand the Black Eyed Pea.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Yes, I can not stand the Black Eyed Pea."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Also, I can not stand the Black Eyed Pea."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? No, I can not stand the Black Eyed Pea."}}, "resps": [[["-123.0", "False"]], [["-127.5", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-123.0", "False"], ["-127.5", "False"], ["-122.5", "False"]], "doc_hash": "38d244aff5167261132e81fe6026c110eb49b6099d3ab691c7fe307471db3282", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 302, "doc": {"premise": "one of the benefits we get of course is travel", "hypothesis": "We don't get any benefits.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Yes, We don't get any benefits."}, "gen_args_1": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? Also, We don't get any benefits."}, "gen_args_2": {"arg_0": "", "arg_1": " one of the benefits we get of course is travel, right? No, We don't get any benefits."}}, "resps": [[["-87.5", "False"]], [["-91.0", "False"]], [["-82.5", "False"]]], "filtered_resps": [["-87.5", "False"], ["-91.0", "False"], ["-82.5", "False"]], "doc_hash": "67f3545a6fc15898bf85d4ed8861c9545c488f6c379f47e0ef4467984dcecd94", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69149853e-03 2.02065747e-04 9.93106436e-01]"]}
{"doc_id": 310, "doc": {"premise": "so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it", "hypothesis": "We go to the cottage in Minnesota.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Yes, We go to the cottage in Minnesota."}, "gen_args_1": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Also, We go to the cottage in Minnesota."}, "gen_args_2": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? No, We go to the cottage in Minnesota."}}, "resps": [[["-160.0", "False"]], [["-166.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-166.0", "False"], ["-164.0", "False"]], "doc_hash": "5bac77c394b9b4b85fb7e04144c84b7a5d19b4aa5d4c60cba9d3260f8b134b9f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 318, "doc": {"premise": "yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was", "hypothesis": "She loved the surprise party.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Yes, She loved the surprise party."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Also, She loved the surprise party."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? No, She loved the surprise party."}}, "resps": [[["-131.0", "False"]], [["-137.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-137.0", "False"], ["-131.0", "False"]], "doc_hash": "e609d130ef9749587a29234f54fb8fedba3a72f95fc14a3a17b5a9ed36321aa7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 326, "doc": {"premise": "uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody", "hypothesis": "She refuses to sit next to anybody who she does not already know.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Yes, She refuses to sit next to anybody who she does not already know."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? Also, She refuses to sit next to anybody who she does not already know."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh oh she's great she's you know she's a character she'll sit with anybody she'll play with anybody, right? No, She refuses to sit next to anybody who she does not already know."}}, "resps": [[["-145.0", "False"]], [["-150.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-150.0", "False"], ["-139.0", "False"]], "doc_hash": "0703b1b83478043922a8f5e283f25d9687f31ccde9ff1bacf315af375f28a347", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47258196e-03 1.66601262e-05 9.97510758e-01]"]}
{"doc_id": 334, "doc": {"premise": "but uh so you like different foods huh", "hypothesis": "I hear you say you don't like trying new foods.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Yes, I hear you say you don't like trying new foods."}, "gen_args_1": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Also, I hear you say you don't like trying new foods."}, "gen_args_2": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? No, I hear you say you don't like trying new foods."}}, "resps": [[["-105.5", "False"]], [["-100.5", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-105.5", "False"], ["-100.5", "False"], ["-101.5", "False"]], "doc_hash": "f961c860b7c08e4a6928924061877e231fffdc172e28c33001d7a81af0d0ee7f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00490169 0.72747516 0.26762315]"]}
{"doc_id": 342, "doc": {"premise": "well why don't you start because you've had more time to think about it if you don't mind", "hypothesis": "Why don't you explain your book to us all.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Yes, Why don't you explain your book to us all."}, "gen_args_1": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Also, Why don't you explain your book to us all."}, "gen_args_2": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? No, Why don't you explain your book to us all."}}, "resps": [[["-114.5", "False"]], [["-119.0", "False"]], [["-117.5", "False"]]], "filtered_resps": [["-114.5", "False"], ["-119.0", "False"], ["-117.5", "False"]], "doc_hash": "aff4dd7dc42959f2511beffa251da884d36a8bbb808d813a8871c8e7cb16d42c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 350, "doc": {"premise": "yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes", "hypothesis": "It passed by a 99% margin.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Yes, It passed by a 99% margin."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? Also, It passed by a 99% margin."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah i don't yeah well what get's me you know this thing it went down to defeat last December by how many votes by just a few hundred votes, right? No, It passed by a 99% margin."}}, "resps": [[["-190.0", "False"]], [["-192.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-192.0", "False"], ["-189.0", "False"]], "doc_hash": "9c72035fa640782706fdfed4363797dc6fa2d3af49938e66e24ec296013e68f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 358, "doc": {"premise": "right they will go through the slot", "hypothesis": "They go in the opening.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " right they will go through the slot, right? Yes, They go in the opening."}, "gen_args_1": {"arg_0": "", "arg_1": " right they will go through the slot, right? Also, They go in the opening."}, "gen_args_2": {"arg_0": "", "arg_1": " right they will go through the slot, right? No, They go in the opening."}}, "resps": [[["-80.5", "False"]], [["-87.0", "False"]], [["-78.5", "False"]]], "filtered_resps": [["-80.5", "False"], ["-87.0", "False"], ["-78.5", "False"]], "doc_hash": "cd4208c6582706793478783b9937a018025d4974ff84e7db7e038b29062ce775", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19181563e-01 1.79182233e-04 8.80639255e-01]"]}
{"doc_id": 366, "doc": {"premise": "uh-huh it's funny and um i i guess i just like funny shows mostly", "hypothesis": "I don't like funny shows.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Yes, I don't like funny shows."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Also, I don't like funny shows."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? No, I don't like funny shows."}}, "resps": [[["-108.0", "False"]], [["-113.5", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-113.5", "False"], ["-101.0", "False"]], "doc_hash": "e038586c07ba6f7dae5308336458c63d5abc9c8f3a5511c71dfd262aeabf5126", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.11047802e-04 3.72324414e-06 9.99085229e-01]"]}
{"doc_id": 374, "doc": {"premise": "came back from uh uh Grand Rapids where we saw one of our sons graduate", "hypothesis": "We went to Grand Rapids to see our son graduate.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Yes, We went to Grand Rapids to see our son graduate."}, "gen_args_1": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? Also, We went to Grand Rapids to see our son graduate."}, "gen_args_2": {"arg_0": "", "arg_1": " came back from uh uh Grand Rapids where we saw one of our sons graduate, right? No, We went to Grand Rapids to see our son graduate."}}, "resps": [[["-110.5", "False"]], [["-118.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-110.5", "False"], ["-118.0", "False"], ["-112.0", "False"]], "doc_hash": "93dee296c226c4802a6fba6d8c633e79d54a90fd591bb05e872823c4d51fff2a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.17204946e-01 4.51983283e-04 1.82343071e-01]"]}
{"doc_id": 382, "doc": {"premise": "and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i", "hypothesis": "I do not wish to lose it but that is what could happen when you own a yard.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Yes, I do not wish to lose it but that is what could happen when you own a yard."}, "gen_args_1": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Also, I do not wish to lose it but that is what could happen when you own a yard."}, "gen_args_2": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? No, I do not wish to lose it but that is what could happen when you own a yard."}}, "resps": [[["-172.0", "False"]], [["-180.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-180.0", "False"], ["-175.0", "False"]], "doc_hash": "825f2d536de8df2391a848cb9670c5b8969d290b0eba91b8cb88dac6b825b3f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 390, "doc": {"premise": "and uh that was twenty five hundred people when i joined and uh", "hypothesis": "At the time that I became a member there was at least twenty five hundred individuals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Yes, At the time that I became a member there was at least twenty five hundred individuals."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Also, At the time that I became a member there was at least twenty five hundred individuals."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? No, At the time that I became a member there was at least twenty five hundred individuals."}}, "resps": [[["-135.0", "False"]], [["-142.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-142.0", "False"], ["-138.0", "False"]], "doc_hash": "05bc1e19c7eec66b06f1c8d9f18bf98fb1dca762c0543ecb42925ef396e18f09", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 398, "doc": {"premise": "yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in", "hypothesis": "We don't want it because we like local news and it doesn't get local stations.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Yes, We don't want it because we like local news and it doesn't get local stations."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? Also, We don't want it because we like local news and it doesn't get local stations."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah but i don't think we're gonna to do it because it's uh you can't get local stations and that's the news that we're mostly interested in, right? No, We don't want it because we like local news and it doesn't get local stations."}}, "resps": [[["-175.0", "False"]], [["-183.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-183.0", "False"], ["-176.0", "False"]], "doc_hash": "70232f6fbf39f93638f42ee774d99de6e71d3e11f4933bd810d0b21668b83d0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 406, "doc": {"premise": "a few years ago i was a student there and spent um a semester studying abroad in London", "hypothesis": "I have never studied abroad before.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Yes, I have never studied abroad before."}, "gen_args_1": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Also, I have never studied abroad before."}, "gen_args_2": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? No, I have never studied abroad before."}}, "resps": [[["-112.5", "False"]], [["-114.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-112.5", "False"], ["-114.0", "False"], ["-109.0", "False"]], "doc_hash": "6308acde5cac42c098eb927e09e1e6c6d2f7b599470084435b5202c82770934e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02912176 0.00649794 0.9643803 ]"]}
{"doc_id": 414, "doc": {"premise": "well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture", "hypothesis": "I have a VCR that keeps breaking.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Yes, I have a VCR that keeps breaking."}, "gen_args_1": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Also, I have a VCR that keeps breaking."}, "gen_args_2": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? No, I have a VCR that keeps breaking."}}, "resps": [[["-164.0", "False"]], [["-171.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-171.0", "False"], ["-167.0", "False"]], "doc_hash": "cdaddaed6a260f73caa4068b6ee954b3840803e075a3b59a3f2d08fc7112bf9c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 422, "doc": {"premise": "yeah because it's uh it had definitely been through the mill but uh", "hypothesis": "Yes is have surely gone through a lot.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Yes, Yes is have surely gone through a lot."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? Also, Yes is have surely gone through a lot."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah because it's uh it had definitely been through the mill but uh, right? No, Yes is have surely gone through a lot."}}, "resps": [[["-134.0", "False"]], [["-141.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-141.0", "False"], ["-138.0", "False"]], "doc_hash": "240265493e7553752425e7e0442cba4ade220a07c363336ded08f5511854f89d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 430, "doc": {"premise": "do we know what we're going to say", "hypothesis": "I know we don't have a clue what we'll say.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Yes, I know we don't have a clue what we'll say."}, "gen_args_1": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Also, I know we don't have a clue what we'll say."}, "gen_args_2": {"arg_0": "", "arg_1": " do we know what we're going to say, right? No, I know we don't have a clue what we'll say."}}, "resps": [[["-67.5", "False"]], [["-74.5", "False"]], [["-69.5", "False"]]], "filtered_resps": [["-67.5", "False"], ["-74.5", "False"], ["-69.5", "False"]], "doc_hash": "15c154ef25d7fadcb479649151b09a81b9af8730ab896f8d152dba6c084b210d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 438, "doc": {"premise": "okay and do they have good lasagna", "hypothesis": "The lasagna is the worst thing I've tried!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Yes, The lasagna is the worst thing I've tried!"}, "gen_args_1": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Also, The lasagna is the worst thing I've tried!"}, "gen_args_2": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? No, The lasagna is the worst thing I've tried!"}}, "resps": [[["-97.0", "False"]], [["-102.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-102.5", "False"], ["-95.0", "False"]], "doc_hash": "9e9ea2efdbfb317c84e939c10af0b1ee47c1811423bae54bf260e9ab0a7ce85f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19144880e-01 4.86917893e-04 8.80368202e-01]"]}
{"doc_id": 446, "doc": {"premise": "yeah some special interest group", "hypothesis": "The group is interested in the matter.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah some special interest group, right? Yes, The group is interested in the matter."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah some special interest group, right? Also, The group is interested in the matter."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah some special interest group, right? No, The group is interested in the matter."}}, "resps": [[["-85.5", "False"]], [["-87.5", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-85.5", "False"], ["-87.5", "False"], ["-84.5", "False"]], "doc_hash": "105332813286caf4dfcb01fe84e17f5e9e96495a8dc87e6cf5974a79a3e97a01", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 454, "doc": {"premise": "expensive you can get a lot of money in that kind of stuff especially the good stuff", "hypothesis": "You can get paid a lot for that.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Yes, You can get paid a lot for that."}, "gen_args_1": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Also, You can get paid a lot for that."}, "gen_args_2": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? No, You can get paid a lot for that."}}, "resps": [[["-106.0", "False"]], [["-109.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-106.0", "False"], ["-109.5", "False"], ["-109.5", "False"]], "doc_hash": "47e2dc5a910382ab1ddecbef1057ba16eaccfba9b62a8c15ed9cbe053e4c1cc7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94304502 0.02847749 0.02847749]"]}
{"doc_id": 462, "doc": {"premise": "yeah we have between the spouse and myself we have six", "hypothesis": "I'm single, never married.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Yes, I'm single, never married."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Also, I'm single, never married."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? No, I'm single, never married."}}, "resps": [[["-95.0", "False"]], [["-98.5", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-95.0", "False"], ["-98.5", "False"], ["-95.5", "False"]], "doc_hash": "acbe71a7ef20f762758fb0cf9f7ad37ead5789ca06267f2902ffab62c72c2a4c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.61097505 0.01844985 0.3705751 ]"]}
{"doc_id": 470, "doc": {"premise": "um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and", "hypothesis": "I have two computers in my house.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Yes, I have two computers in my house."}, "gen_args_1": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? Also, I have two computers in my house."}, "gen_args_2": {"arg_0": "", "arg_1": " um well i sort of own a computer we have two PCs at home but neither one do we really own um both are no both of them are sort of work related and, right? No, I have two computers in my house."}}, "resps": [[["-187.0", "False"]], [["-195.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-195.0", "False"], ["-189.0", "False"]], "doc_hash": "0629072d64a3bf8fb1f45e94ea74fff2696f274080be55a5341e0ed2d43ed93d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 478, "doc": {"premise": "wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it", "hypothesis": "We can go eat Chinese food after we watch that Oscar-nominated movie.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Yes, We can go eat Chinese food after we watch that Oscar-nominated movie."}, "gen_args_1": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Also, We can go eat Chinese food after we watch that Oscar-nominated movie."}, "gen_args_2": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? No, We can go eat Chinese food after we watch that Oscar-nominated movie."}}, "resps": [[["-148.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "6c1bbd80176a970dea4589ce2ffeb38555dda9a7e44d3556ecca209eced27e21", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 486, "doc": {"premise": "it's kind of like a soap a nighttime soap opera type thing", "hypothesis": "It's a very serious new show.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Yes, It's a very serious new show."}, "gen_args_1": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Also, It's a very serious new show."}, "gen_args_2": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? No, It's a very serious new show."}}, "resps": [[["-105.0", "False"]], [["-109.0", "False"]], [["-102.5", "False"]]], "filtered_resps": [["-105.0", "False"], ["-109.0", "False"], ["-102.5", "False"]], "doc_hash": "5a69c3015a4e92749ad18917324b9e8efcf62250a43c932af185af91e567375b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07575293 0.00138746 0.92285961]"]}
{"doc_id": 494, "doc": {"premise": "um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there", "hypothesis": "There is just nothing else they can cut!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Yes, There is just nothing else they can cut!"}, "gen_args_1": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? Also, There is just nothing else they can cut!"}, "gen_args_2": {"arg_0": "", "arg_1": " um-hum well and i was gonna say there are some other areas they could cut you know i don't they wouldn't necessarily have to cut it out of there, right? No, There is just nothing else they can cut!"}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-176.0", "False"]], "doc_hash": "e51d253cf5bf42753be8b267278ceceffcb8dd891b91f6fa20781c55f76c3131", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 502, "doc": {"premise": "These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness.", "hypothesis": "More complex molecular devices can arise under some conditions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Yes, More complex molecular devices can arise under some conditions."}, "gen_args_1": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Also, More complex molecular devices can arise under some conditions."}, "gen_args_2": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? No, More complex molecular devices can arise under some conditions."}}, "resps": [[["-193.0", "False"]], [["-196.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-196.0", "False"], ["-198.0", "False"]], "doc_hash": "123d614c3e118391b4d1d5731ff8c6658522a804fdaea956192645a78c78b65c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.04712342 0.00637746]"]}
{"doc_id": 510, "doc": {"premise": "The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory.", "hypothesis": "In 1787 a law was passed that stopped people from reclaiming any slaves that had made it to free lands.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Yes, In 1787 a law was passed that stopped people from reclaiming any slaves that had made it to free lands."}, "gen_args_1": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Also, In 1787 a law was passed that stopped people from reclaiming any slaves that had made it to free lands."}, "gen_args_2": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? No, In 1787 a law was passed that stopped people from reclaiming any slaves that had made it to free lands."}}, "resps": [[["-175.0", "False"]], [["-176.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-176.0", "False"], ["-174.0", "False"]], "doc_hash": "e03c0426ec7a917f3b01091551d4ffb5258430b25ba574023b950d0838258219", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 518, "doc": {"premise": "Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light).", "hypothesis": "These units were responsible for converting native populations in Central America.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Yes, These units were responsible for converting native populations in Central America."}, "gen_args_1": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? Also, These units were responsible for converting native populations in Central America."}, "gen_args_2": {"arg_0": "", "arg_1": " Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two  common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light)., right? No, These units were responsible for converting native populations in Central America."}}, "resps": [[["-274.0", "False"]], [["-272.0", "False"]], [["-274.0", "False"]]], "filtered_resps": [["-274.0", "False"], ["-272.0", "False"], ["-274.0", "False"]], "doc_hash": "30a4e97f467f568ac6baa61151008d0a9011023598f61c434f43049d14dafe34", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.10650698 0.78698604 0.10650698]"]}
{"doc_id": 526, "doc": {"premise": "Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data.", "hypothesis": "All data from every time frame is valid for any world.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Yes, All data from every time frame is valid for any world."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Also, All data from every time frame is valid for any world."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? No, All data from every time frame is valid for any world."}}, "resps": [[["-173.0", "False"]], [["-176.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-176.0", "False"], ["-167.0", "False"]], "doc_hash": "f9b1c50657aea313ae1993f44e74b794c16fc8e3b47add4be01afa5c1641d78f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47231880e-03 1.23089505e-04 9.97404592e-01]"]}
{"doc_id": 534, "doc": {"premise": "No difference exists between younger and older classmates in achievement test scores.", "hypothesis": "While test results for young and older classmates are the same, younger classmates finish test faster", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Yes, While test results for young and older classmates are the same, younger classmates finish test faster"}, "gen_args_1": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Also, While test results for young and older classmates are the same, younger classmates finish test faster"}, "gen_args_2": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? No, While test results for young and older classmates are the same, younger classmates finish test faster"}}, "resps": [[["-144.0", "False"]], [["-143.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-143.0", "False"], ["-143.0", "False"]], "doc_hash": "89a839c0c119aa7ea90689aecf3c2b4880fdf2cc6540dea73ade220f939fd658", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 542, "doc": {"premise": "Darwin starts with life already here.", "hypothesis": "Darwin was only focused on studying dead things.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Yes, Darwin was only focused on studying dead things."}, "gen_args_1": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? Also, Darwin was only focused on studying dead things."}, "gen_args_2": {"arg_0": "", "arg_1": " Darwin starts with life already here., right? No, Darwin was only focused on studying dead things."}}, "resps": [[["-107.5", "False"]], [["-109.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-107.5", "False"], ["-109.5", "False"], ["-106.0", "False"]], "doc_hash": "88d837322bb1255fb9a21a17f83dbe63421a75596f7c1880e02bd7c43c4ce1f6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17803021 0.02409377 0.79787603]"]}
{"doc_id": 550, "doc": {"premise": "McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell.", "hypothesis": "McKim was ecstatic because he finished first.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Yes, McKim was ecstatic because he finished first."}, "gen_args_1": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Also, McKim was ecstatic because he finished first."}, "gen_args_2": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? No, McKim was ecstatic because he finished first."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-156.0", "False"]], "doc_hash": "8501d4c265689f95165cf35f3c2df1549a50f42d6cea1898b4c71d673f6ec6bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 558, "doc": {"premise": "But consider bread and butter.", "hypothesis": "Think about Wonder Bread and Challenge Butter.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But consider bread and butter., right? Yes, Think about Wonder Bread and Challenge Butter."}, "gen_args_1": {"arg_0": "", "arg_1": " But consider bread and butter., right? Also, Think about Wonder Bread and Challenge Butter."}, "gen_args_2": {"arg_0": "", "arg_1": " But consider bread and butter., right? No, Think about Wonder Bread and Challenge Butter."}}, "resps": [[["-95.5", "False"]], [["-98.0", "False"]], [["-94.5", "False"]]], "filtered_resps": [["-95.5", "False"], ["-98.0", "False"], ["-94.5", "False"]], "doc_hash": "0d5a154ad55498f6d7d405ece0c05cecda164473223bce19a8f35ea3cb664fc3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26313249 0.02159923 0.71526828]"]}
{"doc_id": 566, "doc": {"premise": "Bato is a word centuries old that can be translated as  guy  or  dude.", "hypothesis": "Batos are lesbians.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Yes, Batos are lesbians."}, "gen_args_1": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? Also, Batos are lesbians."}, "gen_args_2": {"arg_0": "", "arg_1": " Bato is a word centuries old that can be translated as  guy  or  dude., right? No, Batos are lesbians."}}, "resps": [[["-141.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "43ed27806fa5bec070a4ab4722fa13162581558feb2b027814ec1dcbd450ab74", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 574, "doc": {"premise": "The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible.", "hypothesis": "The biosphere grew.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Yes, The biosphere grew."}, "gen_args_1": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Also, The biosphere grew."}, "gen_args_2": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? No, The biosphere grew."}}, "resps": [[["-152.0", "False"]], [["-155.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-155.0", "False"], ["-153.0", "False"]], "doc_hash": "761af3574669c872dd101ca01efe3d219dc5dedc09a88ba6d977a7e6fd220eaf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 582, "doc": {"premise": "The relationship between rights and freedom is thus turned on its head.", "hypothesis": "You can't have rights without freedom.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Yes, You can't have rights without freedom."}, "gen_args_1": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Also, You can't have rights without freedom."}, "gen_args_2": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? No, You can't have rights without freedom."}}, "resps": [[["-95.0", "False"]], [["-97.5", "False"]], [["-95.5", "False"]]], "filtered_resps": [["-95.0", "False"], ["-97.5", "False"], ["-95.5", "False"]], "doc_hash": "3a222abcda0d0f3d289b1caef8308ff54cb8dac264864234558fe433c7a0e4f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 590, "doc": {"premise": "The end of plantation capitalism might have come as safely as the demise of communism in Europe.", "hypothesis": "There was no end to communism in Europe.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Yes, There was no end to communism in Europe."}, "gen_args_1": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? Also, There was no end to communism in Europe."}, "gen_args_2": {"arg_0": "", "arg_1": " The end of plantation capitalism might have come as safely as the demise of communism in Europe., right? No, There was no end to communism in Europe."}}, "resps": [[["-135.0", "False"]], [["-138.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-138.0", "False"], ["-133.0", "False"]], "doc_hash": "c1d9d5af3700033a3de3e2793d723204ac3fc20a3358faea12b4c58b627019fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 598, "doc": {"premise": "Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew.", "hypothesis": "Diego refused to do what she said.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Yes, Diego refused to do what she said."}, "gen_args_1": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Also, Diego refused to do what she said."}, "gen_args_2": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? No, Diego refused to do what she said."}}, "resps": [[["-158.0", "False"]], [["-160.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-160.0", "False"], ["-151.0", "False"]], "doc_hash": "7355b64c49aa8540c0e30035389fc283c6b188529c9037601342d481b38fbfa7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10938878e-04 1.23282171e-04 9.98965779e-01]"]}
{"doc_id": 606, "doc": {"premise": "And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation.", "hypothesis": "The assumption that officials have racial and ethnic maps is untrue.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Yes, The assumption that officials have racial and ethnic maps is untrue."}, "gen_args_1": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Also, The assumption that officials have racial and ethnic maps is untrue."}, "gen_args_2": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? No, The assumption that officials have racial and ethnic maps is untrue."}}, "resps": [[["-173.0", "False"]], [["-177.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-177.0", "False"], ["-172.0", "False"]], "doc_hash": "6537ceca5972347e2cfc1b69729c4f04a48b75b8c61fdd56d93e437645dc1797", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 614, "doc": {"premise": "The problem of exploitation in apparently voluntary sexual relations has long been with us.", "hypothesis": "There is no exploitation in sexual relations that are voluntary.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Yes, There is no exploitation in sexual relations that are voluntary."}, "gen_args_1": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? Also, There is no exploitation in sexual relations that are voluntary."}, "gen_args_2": {"arg_0": "", "arg_1": " The problem of exploitation in apparently voluntary sexual relations has long been with us., right? No, There is no exploitation in sexual relations that are voluntary."}}, "resps": [[["-120.0", "False"]], [["-122.0", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-120.0", "False"], ["-122.0", "False"], ["-115.5", "False"]], "doc_hash": "748cd0d54376e0e94b39a8670254a929d31647910de38a9be6a20de2d5e4342a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01097063 0.00148471 0.98754466]"]}
{"doc_id": 622, "doc": {"premise": "Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events.", "hypothesis": "Members of car clubs do not ride.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Yes, Members of car clubs do not ride."}, "gen_args_1": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Also, Members of car clubs do not ride."}, "gen_args_2": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? No, Members of car clubs do not ride."}}, "resps": [[["-171.0", "False"]], [["-172.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-172.0", "False"], ["-164.0", "False"]], "doc_hash": "ea89b69c00281ff0842be7e5585ee447420650b793930b4e99d11a97a6c5c810", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10745952e-04 3.35044712e-04 9.98754209e-01]"]}
{"doc_id": 630, "doc": {"premise": "The same is true of the sense of nationhood.", "hypothesis": "The same applies to the sense of national identity.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Yes, The same applies to the sense of national identity."}, "gen_args_1": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Also, The same applies to the sense of national identity."}, "gen_args_2": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? No, The same applies to the sense of national identity."}}, "resps": [[["-86.0", "False"]], [["-90.5", "False"]], [["-88.5", "False"]]], "filtered_resps": [["-86.0", "False"], ["-90.5", "False"], ["-88.5", "False"]], "doc_hash": "313a4aefa0f69f662d8469462780192c927fd7eeed614d6133813b3ec9cf59fb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.91475073 0.01016196 0.07508731]"]}
{"doc_id": 638, "doc": {"premise": "Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all.", "hypothesis": "The law has been around for a while.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Yes, The law has been around for a while."}, "gen_args_1": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? Also, The law has been around for a while."}, "gen_args_2": {"arg_0": "", "arg_1": " Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all., right? No, The law has been around for a while."}}, "resps": [[["-146.0", "False"]], [["-144.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-144.0", "False"], ["-145.0", "False"]], "doc_hash": "47bc924d0e6fc353e38b06bcb9b77d028d5f72c10348595fbf3b0760fc1e37dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 646, "doc": {"premise": "That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf.", "hypothesis": "Someone is ignoring Vance.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Yes, Someone is ignoring Vance."}, "gen_args_1": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Also, Someone is ignoring Vance."}, "gen_args_2": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? No, Someone is ignoring Vance."}}, "resps": [[["-157.0", "False"]], [["-157.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-157.0", "False"], ["-157.0", "False"]], "doc_hash": "e93c5e11a755e3747bea943a2fc898b0a805a66d99788d0727e17183d1b2f386", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 654, "doc": {"premise": "If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear.", "hypothesis": "It is possible for the particle-horizon problem to disappear.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Yes, It is possible for the particle-horizon problem to disappear."}, "gen_args_1": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Also, It is possible for the particle-horizon problem to disappear."}, "gen_args_2": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? No, It is possible for the particle-horizon problem to disappear."}}, "resps": [[["-203.0", "False"]], [["-207.0", "False"]], [["-208.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-207.0", "False"], ["-208.0", "False"]], "doc_hash": "6c1ef270ad1768cd9c61df501e840800b86344858d7421f0ac4838a56746baa3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 662, "doc": {"premise": "Of course, if we could not solve our chosen ways to make livings, we would be dead.", "hypothesis": "We have to figure out how to make livings, in order to survive.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Yes, We have to figure out how to make livings, in order to survive."}, "gen_args_1": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? Also, We have to figure out how to make livings, in order to survive."}, "gen_args_2": {"arg_0": "", "arg_1": " Of course, if we could not solve our chosen ways to make livings, we would be dead., right? No, We have to figure out how to make livings, in order to survive."}}, "resps": [[["-137.0", "False"]], [["-143.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-143.0", "False"], ["-139.0", "False"]], "doc_hash": "ecc04ea1b81cb138773c9059ec1d7ca32327447faeedd2056814d580d9f6e2d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 670, "doc": {"premise": "The connection between the limited nation and unbounded equality has paradoxical overtones.", "hypothesis": "The nation is not connected to unbounded equality.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Yes, The nation is not connected to unbounded equality."}, "gen_args_1": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Also, The nation is not connected to unbounded equality."}, "gen_args_2": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? No, The nation is not connected to unbounded equality."}}, "resps": [[["-140.0", "False"]], [["-141.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-141.0", "False"], ["-134.0", "False"]], "doc_hash": "3258445427c18b61372683e954d1a6cb2a29815fe4eb8b4d80407d5b9f8a9d93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 678, "doc": {"premise": "Limpiar means to clean and a limpia is similar to a barrida.", "hypothesis": "Although barrida and limpia are similar, there are many things that distinguish them from each other.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Yes, Although barrida and limpia are similar, there are many things that distinguish them from each other."}, "gen_args_1": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Also, Although barrida and limpia are similar, there are many things that distinguish them from each other."}, "gen_args_2": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? No, Although barrida and limpia are similar, there are many things that distinguish them from each other."}}, "resps": [[["-139.0", "False"]], [["-142.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-142.0", "False"], ["-141.0", "False"]], "doc_hash": "5d90041a7d69a4ba2173117bff6100742f67a5b347ae205dbd8fc21eae351b69", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 686, "doc": {"premise": "As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable.", "hypothesis": "There is nothing happening in the universe at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Yes, There is nothing happening in the universe at all."}, "gen_args_1": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? Also, There is nothing happening in the universe at all."}, "gen_args_2": {"arg_0": "", "arg_1": " As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable., right? No, There is nothing happening in the universe at all."}}, "resps": [[["-162.0", "False"]], [["-163.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-163.0", "False"], ["-156.0", "False"]], "doc_hash": "cd4ef16c838d31a0b60dbafca6ac74e905d016457920c16c0b732320d57e858b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 694, "doc": {"premise": "On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys.", "hypothesis": "Children did not stay indoors on Christmas Day.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Yes, Children did not stay indoors on Christmas Day."}, "gen_args_1": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Also, Children did not stay indoors on Christmas Day."}, "gen_args_2": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? No, Children did not stay indoors on Christmas Day."}}, "resps": [[["-130.0", "False"]], [["-133.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-133.0", "False"], ["-126.0", "False"]], "doc_hash": "bca179ae35d9185276f47683de2c8490b6bab992462bb3aa9ccb3094b56284e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 702, "doc": {"premise": "Could statistical averaging be the source of order in organisms?", "hypothesis": "It is clear that there is order in organisms.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Yes, It is clear that there is order in organisms."}, "gen_args_1": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Also, It is clear that there is order in organisms."}, "gen_args_2": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? No, It is clear that there is order in organisms."}}, "resps": [[["-113.5", "False"]], [["-117.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-117.5", "False"], ["-115.5", "False"]], "doc_hash": "9a0b45a253dc18797a15f8fe883ad7fd4dabe6ece8bd3a7298650f60a398e3a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 710, "doc": {"premise": "Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship.", "hypothesis": "Lipstadt wrote a book.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Yes, Lipstadt wrote a book."}, "gen_args_1": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? Also, Lipstadt wrote a book."}, "gen_args_2": {"arg_0": "", "arg_1": " Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship., right? No, Lipstadt wrote a book."}}, "resps": [[["-187.0", "False"]], [["-189.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-189.0", "False"], ["-185.0", "False"]], "doc_hash": "283b6c4c2b8e51cab2fe376098609e36d387f2613226257a4f825230589a86ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 718, "doc": {"premise": "Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons.", "hypothesis": "Neurons must be fully established before they can perform certain functions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Yes, Neurons must be fully established before they can perform certain functions."}, "gen_args_1": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Also, Neurons must be fully established before they can perform certain functions."}, "gen_args_2": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? No, Neurons must be fully established before they can perform certain functions."}}, "resps": [[["-166.0", "False"]], [["-168.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-168.0", "False"], ["-166.0", "False"]], "doc_hash": "bb5e20ee54a039fbbe817c9f15b5e7e88a564fd68265fd588af63c0fe8df9891", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 726, "doc": {"premise": "7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3).", "hypothesis": "The low demand and high demand groups combine to a total of twenty.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Yes, The low demand and high demand groups combine to a total of twenty."}, "gen_args_1": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Also, The low demand and high demand groups combine to a total of twenty."}, "gen_args_2": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? No, The low demand and high demand groups combine to a total of twenty."}}, "resps": [[["-205.0", "False"]], [["-205.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-205.0", "False"], ["-205.0", "False"], ["-204.0", "False"]], "doc_hash": "4d6e5fad0dd3bd45973882808e2fde4a59fcba88ce4f3b736b9a95ea494b9ae5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 734, "doc": {"premise": "See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico.", "hypothesis": "Wallis and Varjabedian provide professional, colorful photographs of the old New Mexico moradas.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Yes, Wallis and Varjabedian provide professional, colorful photographs of the old New Mexico moradas."}, "gen_args_1": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? Also, Wallis and Varjabedian provide professional, colorful photographs of the old New Mexico moradas."}, "gen_args_2": {"arg_0": "", "arg_1": " See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico., right? No, Wallis and Varjabedian provide professional, colorful photographs of the old New Mexico moradas."}}, "resps": [[["-196.0", "False"]], [["-201.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-196.0", "False"], ["-201.0", "False"], ["-199.0", "False"]], "doc_hash": "832c13cf19e5a0f2fc3ac083a62f6021da5376a1c9c66062b63501f6e91bcca5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 742, "doc": {"premise": "That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades.", "hypothesis": "We appreciate the hollow walls and flimsy doors.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Yes, We appreciate the hollow walls and flimsy doors."}, "gen_args_1": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Also, We appreciate the hollow walls and flimsy doors."}, "gen_args_2": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? No, We appreciate the hollow walls and flimsy doors."}}, "resps": [[["-138.0", "False"]], [["-141.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-141.0", "False"], ["-135.0", "False"]], "doc_hash": "d88770256ce9f15826cd51493f2146d9af13e7804e92d6cebf8d9b5fe1ddf51c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 750, "doc": {"premise": "Jeremy Pitt answered the laugh with an oath.", "hypothesis": "Jeremy Pitt answered the laugh by giggling and throwing an uppercut into the laugher's face.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Yes, Jeremy Pitt answered the laugh by giggling and throwing an uppercut into the laugher's face."}, "gen_args_1": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Also, Jeremy Pitt answered the laugh by giggling and throwing an uppercut into the laugher's face."}, "gen_args_2": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? No, Jeremy Pitt answered the laugh by giggling and throwing an uppercut into the laugher's face."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-148.0", "False"]], "doc_hash": "9c8635139c2e8bc1f5546a7a929b67c9ffe4af5b8c51341c4a3c7e84750138f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35237708e-04 3.35237708e-04 9.99329525e-01]"]}
{"doc_id": 758, "doc": {"premise": "The Colonel accepted it, and belatedly bowed, removing his broad hat.", "hypothesis": "The Colonel was wearing a hat.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Yes, The Colonel was wearing a hat."}, "gen_args_1": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? Also, The Colonel was wearing a hat."}, "gen_args_2": {"arg_0": "", "arg_1": " The Colonel accepted it, and belatedly bowed, removing his broad hat., right? No, The Colonel was wearing a hat."}}, "resps": [[["-121.0", "False"]], [["-121.5", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-121.0", "False"], ["-121.5", "False"], ["-119.5", "False"]], "doc_hash": "b7927c27f48f726830576f37bf3d6effb278ed678f6fde0f68a867b25076acf0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.16425163 0.09962365 0.73612472]"]}
{"doc_id": 766, "doc": {"premise": "But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent.", "hypothesis": "The officer was confused by what was happening aboard the ship.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Yes, The officer was confused by what was happening aboard the ship."}, "gen_args_1": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Also, The officer was confused by what was happening aboard the ship."}, "gen_args_2": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? No, The officer was confused by what was happening aboard the ship."}}, "resps": [[["-180.0", "False"]], [["-182.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-182.0", "False"], ["-180.0", "False"]], "doc_hash": "62e2f7d1ff181d3a8a91a3f46834a7f4d32d01332e2c3eef5fb054a56fe6ce3b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 774, "doc": {"premise": "There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him.", "hypothesis": "Blood is an international criminal organization based in Port Royal that Lord Julian contracts with for illicit purposes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Yes, Blood is an international criminal organization based in Port Royal that Lord Julian contracts with for illicit purposes."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Also, Blood is an international criminal organization based in Port Royal that Lord Julian contracts with for illicit purposes."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? No, Blood is an international criminal organization based in Port Royal that Lord Julian contracts with for illicit purposes."}}, "resps": [[["-240.0", "False"]], [["-242.0", "False"]], [["-240.0", "False"]]], "filtered_resps": [["-240.0", "False"], ["-242.0", "False"], ["-240.0", "False"]], "doc_hash": "4e17cd9ddbaa11fedb204d53873146ff814616f2ca241d6ee708829f45b77d2c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 782, "doc": {"premise": "Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden.", "hypothesis": "Blood's hat was black, with three eagle feathers on it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Yes, Blood's hat was black, with three eagle feathers on it."}, "gen_args_1": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? Also, Blood's hat was black, with three eagle feathers on it."}, "gen_args_2": {"arg_0": "", "arg_1": " Will you cease your blather of mutiny and treason and courts-martial?   Blood put on his hat, and sat down unbidden., right? No, Blood's hat was black, with three eagle feathers on it."}}, "resps": [[["-214.0", "False"]], [["-215.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-215.0", "False"], ["-214.0", "False"]], "doc_hash": "0257a87009ede96c7513b89857cea7a893767a3f27e6f58cf8b5644b5b4ef348", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 790, "doc": {"premise": "I have sent for you, Captain Blood, because of certain news that has just reached me.", "hypothesis": "I received some news before sending for you, Captain Blood.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Yes, I received some news before sending for you, Captain Blood."}, "gen_args_1": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Also, I received some news before sending for you, Captain Blood."}, "gen_args_2": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? No, I received some news before sending for you, Captain Blood."}}, "resps": [[["-126.0", "False"]], [["-132.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-126.0", "False"], ["-132.0", "False"], ["-124.0", "False"]], "doc_hash": "36e1663712ab2cb9af2b89a5ec9cbf81d4025a4c5d2b093ff6bf961bc774dedd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 798, "doc": {"premise": "Well, well, maybe he'll not find me quite so easy to grasp as he imagines.", "hypothesis": "He has never imagined grasping me.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Yes, He has never imagined grasping me."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Also, He has never imagined grasping me."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? No, He has never imagined grasping me."}}, "resps": [[["-127.5", "False"]], [["-129.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-127.5", "False"], ["-129.0", "False"], ["-125.5", "False"]], "doc_hash": "e2f16a12de22ce30b218c41a30ccbca7667a8891ee04a57817500ee181e633a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11611453 0.02590865 0.85797681]"]}
{"doc_id": 806, "doc": {"premise": "A murderer--I?  he said at last.", "hypothesis": "Immediately he said, A murderer, I.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Yes, Immediately he said, A murderer, I."}, "gen_args_1": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? Also, Immediately he said, A murderer, I."}, "gen_args_2": {"arg_0": "", "arg_1": " A murderer--I?  he said at last., right? No, Immediately he said, A murderer, I."}}, "resps": [[["-125.0", "False"]], [["-131.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-131.0", "False"], ["-126.0", "False"]], "doc_hash": "8368687cd587ea103db4e5afc9b87bfdd3887c423b10fda553415646cc41984d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 814, "doc": {"premise": "What better way?  he demanded.", "hypothesis": "He wanted to know if there was a better way.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Yes, He wanted to know if there was a better way."}, "gen_args_1": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Also, He wanted to know if there was a better way."}, "gen_args_2": {"arg_0": "", "arg_1": " What better way?  he demanded., right? No, He wanted to know if there was a better way."}}, "resps": [[["-97.5", "False"]], [["-103.0", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-103.0", "False"], ["-97.5", "False"]], "doc_hash": "6cd51fc0f46b867598b323a94873c16130129fb3db45a33468893408950e2cae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49898039 0.00203922 0.49898039]"]}
{"doc_id": 822, "doc": {"premise": "Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis.", "hypothesis": "Colonel Bishop has done something to make Wolverstone his enemy.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Yes, Colonel Bishop has done something to make Wolverstone his enemy."}, "gen_args_1": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Also, Colonel Bishop has done something to make Wolverstone his enemy."}, "gen_args_2": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? No, Colonel Bishop has done something to make Wolverstone his enemy."}}, "resps": [[["-264.0", "False"]], [["-264.0", "False"]], [["-266.0", "False"]]], "filtered_resps": [["-264.0", "False"], ["-264.0", "False"], ["-266.0", "False"]], "doc_hash": "95b8015f907f955fa0dda77eff3c3522caa96fa0569f965d0e0ace29c172f211", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 830, "doc": {"premise": "And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him.", "hypothesis": "His officers respect him.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Yes, His officers respect him."}, "gen_args_1": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? Also, His officers respect him."}, "gen_args_2": {"arg_0": "", "arg_1": " And though he should dare attempt it, be sure that his own officers will not dare to do other than oppose him., right? No, His officers respect him."}}, "resps": [[["-144.0", "False"]], [["-150.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-150.0", "False"], ["-144.0", "False"]], "doc_hash": "a86a63aa9d0461041eecf65acf4a1938ee0a3c0b4c57ef5406475270fe1f0572", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 838, "doc": {"premise": "You're not very civil, sir, as I have already noticed.", "hypothesis": "The man is calm and reasonable.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Yes, The man is calm and reasonable."}, "gen_args_1": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Also, The man is calm and reasonable."}, "gen_args_2": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? No, The man is calm and reasonable."}}, "resps": [[["-110.5", "False"]], [["-111.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-110.5", "False"], ["-111.5", "False"], ["-108.5", "False"]], "doc_hash": "b98b30b0057f5167f8d59642760781f3b06ed00aa4ba333cc6280a031d63920c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 846, "doc": {"premise": "But Pitt, although he shared it, was prompt to obey.", "hypothesis": "Pitt completely ignored what was asked of him.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Yes, Pitt completely ignored what was asked of him."}, "gen_args_1": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Also, Pitt completely ignored what was asked of him."}, "gen_args_2": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? No, Pitt completely ignored what was asked of him."}}, "resps": [[["-127.5", "False"]], [["-130.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-127.5", "False"], ["-130.0", "False"], ["-124.0", "False"]], "doc_hash": "a42482dfcd9523adb574344b9b41cf017323f55edee4de01a575cb10b4fa1c25", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 854, "doc": {"premise": "If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke.", "hypothesis": "There were no ships in sight.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Yes, There were no ships in sight."}, "gen_args_1": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? Also, There were no ships in sight."}, "gen_args_2": {"arg_0": "", "arg_1": " If you will go below, and get your gear and your woman, you shall presently be sent aboard one of the ships of the fleet.  He pointed to the boat as he spoke., right? No, There were no ships in sight."}}, "resps": [[["-186.0", "False"]], [["-186.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-186.0", "False"], ["-182.0", "False"]], "doc_hash": "93fd9c048ee25bf1547c7d81216c1da2bc2daa06eddbf2ec957af812318485a1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 862, "doc": {"premise": "We went about, and it's been a race ever since.", "hypothesis": "The race had begun ever since we were four.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Yes, The race had begun ever since we were four."}, "gen_args_1": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Also, The race had begun ever since we were four."}, "gen_args_2": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? No, The race had begun ever since we were four."}}, "resps": [[["-115.5", "False"]], [["-123.5", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-115.5", "False"], ["-123.5", "False"], ["-118.0", "False"]], "doc_hash": "89727ee664e7d3e277525d20c00410836999b554c5818560702db7704fa20656", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.23855411e-01 3.09918964e-04 7.58346701e-02]"]}
{"doc_id": 870, "doc": {"premise": "In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone.", "hypothesis": "Miss Bishop was alone in the garden.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Yes, Miss Bishop was alone in the garden."}, "gen_args_1": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Also, Miss Bishop was alone in the garden."}, "gen_args_2": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? No, Miss Bishop was alone in the garden."}}, "resps": [[["-159.0", "False"]], [["-167.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-167.0", "False"], ["-164.0", "False"]], "doc_hash": "815837b3944a375769b268d7c5ab16468eebbd2f3010d168d15756c070b82216", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92976272e-01 3.33106430e-04 6.69062149e-03]"]}
{"doc_id": 878, "doc": {"premise": "Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing.", "hypothesis": "Wolverstone never got into a dispute with her.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Yes, Wolverstone never got into a dispute with her."}, "gen_args_1": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? Also, Wolverstone never got into a dispute with her."}, "gen_args_2": {"arg_0": "", "arg_1": " Her presence at this moment, and considering the nature of his altercation with Wolverstone, was embarrassing., right? No, Wolverstone never got into a dispute with her."}}, "resps": [[["-160.0", "False"]], [["-158.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-158.0", "False"], ["-156.0", "False"]], "doc_hash": "909884e1072b8f02938436d60119d851f3fadc62629ba16f96fa9f47520667af", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01587624 0.11731043 0.86681333]"]}
{"doc_id": 886, "doc": {"premise": "Steady, Old Wolf! Steady!  Captain Blood admonished him.", "hypothesis": "Captain Blood yelled to Old Wolf.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Yes, Captain Blood yelled to Old Wolf."}, "gen_args_1": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Also, Captain Blood yelled to Old Wolf."}, "gen_args_2": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? No, Captain Blood yelled to Old Wolf."}}, "resps": [[["-132.0", "False"]], [["-136.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-136.0", "False"], ["-135.0", "False"]], "doc_hash": "0b141be9b42ebfaecc8e9f693bfddd813a2a8d0ac596394a16f8284b28749874", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 894, "doc": {"premise": "And that was practically the end of the matter.", "hypothesis": "The matter had been resolved.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Yes, The matter had been resolved."}, "gen_args_1": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Also, The matter had been resolved."}, "gen_args_2": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? No, The matter had been resolved."}}, "resps": [[["-79.5", "False"]], [["-86.0", "False"]], [["-84.5", "False"]]], "filtered_resps": [["-79.5", "False"], ["-86.0", "False"], ["-84.5", "False"]], "doc_hash": "d9fafb7051373c8d1f7edc8f6a90fc5942477dd56e668c058cd6a077b75cd68b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.99182598 0.00149115 0.00668287]"]}
{"doc_id": 902, "doc": {"premise": "Since when have you commanded on the main deck, Ogle? I take my orders from the Captain.", "hypothesis": "There was no one on the ship to give orders.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Yes, There was no one on the ship to give orders."}, "gen_args_1": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? Also, There was no one on the ship to give orders."}, "gen_args_2": {"arg_0": "", "arg_1": " Since when have you commanded on the main deck, Ogle? I take my orders from the Captain., right? No, There was no one on the ship to give orders."}}, "resps": [[["-149.0", "False"]], [["-148.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-148.0", "False"], ["-147.0", "False"]], "doc_hash": "878492f0b1730dc66fc1b480465d64aed4c9a03e60f3aae45439b7415bd66e00", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 910, "doc": {"premise": "He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow.", "hypothesis": "The fable is as old as time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Yes, The fable is as old as time."}, "gen_args_1": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Also, The fable is as old as time."}, "gen_args_2": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? No, The fable is as old as time."}}, "resps": [[["-167.0", "False"]], [["-169.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-169.0", "False"], ["-168.0", "False"]], "doc_hash": "9a3126a9caf580a84abfb3abf3f3a61904715bd416e3707c1a142b11b566dc44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 918, "doc": {"premise": "But it'll be about the Old Wolf that he wants to see you.", "hypothesis": "He wants to see you about the Old Bear and not about the Old Wolf.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Yes, He wants to see you about the Old Bear and not about the Old Wolf."}, "gen_args_1": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Also, He wants to see you about the Old Bear and not about the Old Wolf."}, "gen_args_2": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? No, He wants to see you about the Old Bear and not about the Old Wolf."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "6cc4be209fd38d5e2d97e47a9aab0e32348469e536addf4c32367d723a1f647e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 926, "doc": {"premise": "Your words have rankled with him.", "hypothesis": "He really enjoyed what you said.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Yes, He really enjoyed what you said."}, "gen_args_1": {"arg_0": "", "arg_1": " Your words have rankled with him., right? Also, He really enjoyed what you said."}, "gen_args_2": {"arg_0": "", "arg_1": " Your words have rankled with him., right? No, He really enjoyed what you said."}}, "resps": [[["-93.0", "False"]], [["-97.5", "False"]], [["-91.0", "False"]]], "filtered_resps": [["-93.0", "False"], ["-97.5", "False"], ["-91.0", "False"]], "doc_hash": "e6458db5ab6df2a8de75115f1f1328abaaecbdb939df52d1d02dd7d1b53cc058", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11904528 0.00132247 0.87963225]"]}
{"doc_id": 934, "doc": {"premise": "I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels.", "hypothesis": "While the lordship was very smart, his grave mistake of not listening to my counsel will spell the end of the kingdom.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Yes, While the lordship was very smart, his grave mistake of not listening to my counsel will spell the end of the kingdom."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Also, While the lordship was very smart, his grave mistake of not listening to my counsel will spell the end of the kingdom."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? No, While the lordship was very smart, his grave mistake of not listening to my counsel will spell the end of the kingdom."}}, "resps": [[["-229.0", "False"]], [["-233.0", "False"]], [["-232.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-233.0", "False"], ["-232.0", "False"]], "doc_hash": "7802e4596c2ad570dfb06341a26e8a12552163eb28d97c5d80fe9a317d69d939", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 942, "doc": {"premise": "If anything it increased his excitement.", "hypothesis": "It decreased his excitement.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Yes, It decreased his excitement."}, "gen_args_1": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Also, It decreased his excitement."}, "gen_args_2": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? No, It decreased his excitement."}}, "resps": [[["-85.5", "False"]], [["-92.0", "False"]], [["-80.5", "False"]]], "filtered_resps": [["-85.5", "False"], ["-92.0", "False"], ["-80.5", "False"]], "doc_hash": "e861a5ae20b2e248e8b5f35f5d126c38cd28fcbdc150571f3394b790e377b173", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69278358e-03 1.00621931e-05 9.93297154e-01]"]}
{"doc_id": 950, "doc": {"premise": "Good-day to you, sir,  Blood hailed him pleasantly.", "hypothesis": "The man was old.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Yes, The man was old."}, "gen_args_1": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? Also, The man was old."}, "gen_args_2": {"arg_0": "", "arg_1": " Good-day to you, sir,  Blood hailed him pleasantly., right? No, The man was old."}}, "resps": [[["-125.0", "False"]], [["-128.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-128.0", "False"], ["-124.0", "False"]], "doc_hash": "97e251cf46cd6f83a014c64dac6179e8395ae8dedbbfdc6a0e3ff18c8b0f77cb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 958, "doc": {"premise": "That girl, there.  He flung out a bare arm to point to her.", "hypothesis": "He pointed at the girl.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Yes, He pointed at the girl."}, "gen_args_1": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Also, He pointed at the girl."}, "gen_args_2": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? No, He pointed at the girl."}}, "resps": [[["-119.0", "False"]], [["-122.5", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-119.0", "False"], ["-122.5", "False"], ["-119.5", "False"]], "doc_hash": "36edbfa97b6aa4585c56f671bc37a43c50416563e6ab6f55ac2aa26cddf45508", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61097505 0.01844985 0.3705751 ]"]}
{"doc_id": 966, "doc": {"premise": "I'll not be bubbled by what Wolverstone has said.", "hypothesis": "As many said before, Wolverstone was a simple man with few words.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Yes, As many said before, Wolverstone was a simple man with few words."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Also, As many said before, Wolverstone was a simple man with few words."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? No, As many said before, Wolverstone was a simple man with few words."}}, "resps": [[["-155.0", "False"]], [["-157.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-157.0", "False"], ["-156.0", "False"]], "doc_hash": "2dd6ed52b98ec80acb56f54ece8bf0f973b0f7f1ae357e53c340ff288462de01", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 974, "doc": {"premise": "I cannot think why you should trouble to put yourself on your defence,   she discouraged him.", "hypothesis": "The defense that was put forth by her was insufficient.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Yes, The defense that was put forth by her was insufficient."}, "gen_args_1": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? Also, The defense that was put forth by her was insufficient."}, "gen_args_2": {"arg_0": "", "arg_1": " I cannot think why you should trouble to put yourself on your defence,   she discouraged him., right? No, The defense that was put forth by her was insufficient."}}, "resps": [[["-164.0", "False"]], [["-163.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-163.0", "False"], ["-164.0", "False"]], "doc_hash": "6925beb59ecb549b7c7d3ac29bf4f2526f82a956a6038ed6ea176c40ccf05afc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 982, "doc": {"premise": "He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it.", "hypothesis": "The language described in the pages are of a language native to the land.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Yes, The language described in the pages are of a language native to the land."}, "gen_args_1": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Also, The language described in the pages are of a language native to the land."}, "gen_args_2": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? No, The language described in the pages are of a language native to the land."}}, "resps": [[["-280.0", "False"]], [["-282.0", "False"]], [["-280.0", "False"]]], "filtered_resps": [["-280.0", "False"], ["-282.0", "False"], ["-280.0", "False"]], "doc_hash": "98432f6e9934cdb5cc07e59cf617a11d5a13aeab19e166595e9388982a6b62f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 990, "doc": {"premise": "He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic.", "hypothesis": "Captain Blood was nowhere to be found.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Yes, Captain Blood was nowhere to be found."}, "gen_args_1": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Also, Captain Blood was nowhere to be found."}, "gen_args_2": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? No, Captain Blood was nowhere to be found."}}, "resps": [[["-193.0", "False"]], [["-192.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-192.0", "False"], ["-190.0", "False"]], "doc_hash": "8b4a13344e413bd78929f46e00855e283890b2048cb40cac143df8b49f19c4ba", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 998, "doc": {"premise": "After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex.", "hypothesis": "You cannot see the coast from the top of the hill.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Yes, You cannot see the coast from the top of the hill."}, "gen_args_1": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? Also, You cannot see the coast from the top of the hill."}, "gen_args_2": {"arg_0": "", "arg_1": " After looking around these collections, climb the hill to the Commissioner's House, where you will find fine views of the surrounding coastline and the rest of the dockyard complex., right? No, You cannot see the coast from the top of the hill."}}, "resps": [[["-180.0", "False"]], [["-182.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-182.0", "False"], ["-177.0", "False"]], "doc_hash": "b248adddeffdbef71bc217050fd9dc8965869f9dacc0f5484d59a3956d93fe47", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1006, "doc": {"premise": "Hopes were raised, and also fizzled, over Bahamian citrus and pineapple.", "hypothesis": "The Bahamian citrus was just a huge success, just as everyone had predicted.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Yes, The Bahamian citrus was just a huge success, just as everyone had predicted."}, "gen_args_1": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Also, The Bahamian citrus was just a huge success, just as everyone had predicted."}, "gen_args_2": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? No, The Bahamian citrus was just a huge success, just as everyone had predicted."}}, "resps": [[["-162.0", "False"]], [["-166.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-166.0", "False"], ["-164.0", "False"]], "doc_hash": "3a4612276a8fe6548e724a87d5cee76be1a10bfc5b072d126a6df8e96f2fbf7c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1014, "doc": {"premise": "There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society.", "hypothesis": "It is a good idea to have a translator with you.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Yes, It is a good idea to have a translator with you."}, "gen_args_1": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Also, It is a good idea to have a translator with you."}, "gen_args_2": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? No, It is a good idea to have a translator with you."}}, "resps": [[["-174.0", "False"]], [["-174.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-174.0", "False"], ["-177.0", "False"]], "doc_hash": "17cb2ca356fa5fcf29ec7d1d5f06f46500bd579f5b51fe698e73cf3c99c01be8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 1022, "doc": {"premise": "Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940.", "hypothesis": "Greece's economy did not do so well under the military dictatorship of Metaxas.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Yes, Greece's economy did not do so well under the military dictatorship of Metaxas."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? Also, Greece's economy did not do so well under the military dictatorship of Metaxas."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 1936 and 1940 Greece was under the military dictatorship of Ioannis Metaxas, remembered for the resounding echi ( no ) he gave in reply to Mussolini's ultimatum to surrender in 1940., right? No, Greece's economy did not do so well under the military dictatorship of Metaxas."}}, "resps": [[["-193.0", "False"]], [["-191.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-191.0", "False"], ["-192.0", "False"]], "doc_hash": "60961e9843ad4669c2397b76afbb173f207e64d261895cdcaf13f3755d13fa6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 1030, "doc": {"premise": "An extensive program of refurbishment is due to be finished by late 2001.", "hypothesis": "The refurbishment program will not be done till well after the year 2000 ends.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Yes, The refurbishment program will not be done till well after the year 2000 ends."}, "gen_args_1": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Also, The refurbishment program will not be done till well after the year 2000 ends."}, "gen_args_2": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? No, The refurbishment program will not be done till well after the year 2000 ends."}}, "resps": [[["-137.0", "False"]], [["-140.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-140.0", "False"], ["-136.0", "False"]], "doc_hash": "69871b0a2daeb8fec7984ea7676c6dff2866f72aefed282b01072c3609929768", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1038, "doc": {"premise": "The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast.", "hypothesis": "The mountains constantly have landslides for the harbors aren't easily built there.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Yes, The mountains constantly have landslides for the harbors aren't easily built there."}, "gen_args_1": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Also, The mountains constantly have landslides for the harbors aren't easily built there."}, "gen_args_2": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? No, The mountains constantly have landslides for the harbors aren't easily built there."}}, "resps": [[["-227.0", "False"]], [["-228.0", "False"]], [["-225.0", "False"]]], "filtered_resps": [["-227.0", "False"], ["-228.0", "False"], ["-225.0", "False"]], "doc_hash": "53ed2bb144061f175621191526c6a778ebb3164c4cfc93414ebe28b2b4fb9ece", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1046, "doc": {"premise": "Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands.", "hypothesis": "Culebra is somewhere between Puerto Rico and St. Thomas in the US Virgin Islands.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Yes, Culebra is somewhere between Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_1": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? Also, Culebra is somewhere between Puerto Rico and St. Thomas in the US Virgin Islands."}, "gen_args_2": {"arg_0": "", "arg_1": " Culebra was known as the Spanish Virgin Island until the American takeover it lies halfway between Puerto Rico and St. Thomas in the US Virgin Islands., right? No, Culebra is somewhere between Puerto Rico and St. Thomas in the US Virgin Islands."}}, "resps": [[["-130.0", "False"]], [["-139.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-139.0", "False"], ["-133.0", "False"]], "doc_hash": "991c168c1825968b4764e60069cb20d137d57d7e80ffd21684042fc96b226839", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.52462158e-01 1.17543168e-04 4.74202986e-02]"]}
{"doc_id": 1054, "doc": {"premise": "The third member of the Hindu  trinity  is Brahma, whose only task was to create the world.", "hypothesis": "Brahma is part of the Hindu trinity.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Yes, Brahma is part of the Hindu trinity."}, "gen_args_1": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Also, Brahma is part of the Hindu trinity."}, "gen_args_2": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? No, Brahma is part of the Hindu trinity."}}, "resps": [[["-120.0", "False"]], [["-121.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-121.5", "False"], ["-117.0", "False"]], "doc_hash": "bceab64e9abfaf4ce9195d7a2f4542cb9ebb68f13fc841f19f5f0699829ef8e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04692926 0.01047133 0.94259941]"]}
{"doc_id": 1062, "doc": {"premise": "The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor.", "hypothesis": "Some of the antiques are shown.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Yes, Some of the antiques are shown."}, "gen_args_1": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Also, Some of the antiques are shown."}, "gen_args_2": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? No, Some of the antiques are shown."}}, "resps": [[["-188.0", "False"]], [["-192.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-192.0", "False"], ["-192.0", "False"]], "doc_hash": "b752fe6ade227a41480b73c7eda8e7471d10c6f9df2293242608e3a0579d36b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1070, "doc": {"premise": "Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith.", "hypothesis": "The Zenith is a train station.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Yes, The Zenith is a train station."}, "gen_args_1": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? Also, The Zenith is a train station."}, "gen_args_2": {"arg_0": "", "arg_1": " Opposite, in the Cite de la Musique are the Musee de la Musique and a giant concert hall, the Zenith., right? No, The Zenith is a train station."}}, "resps": [[["-132.0", "False"]], [["-133.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-133.0", "False"], ["-130.0", "False"]], "doc_hash": "52aa386c0f16746a8e37589d765076d8c0ec9cb9cb75ff12a9c3dfd3080f97d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1078, "doc": {"premise": "Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi.", "hypothesis": "Kuala Perlis was straight north of Kangar.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Yes, Kuala Perlis was straight north of Kangar."}, "gen_args_1": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Also, Kuala Perlis was straight north of Kangar."}, "gen_args_2": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? No, Kuala Perlis was straight north of Kangar."}}, "resps": [[["-151.0", "False"]], [["-153.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-153.0", "False"], ["-148.0", "False"]], "doc_hash": "89d6afb809a15a1b0b7e2b32a516fa898f00cc62c88d5128cb6b0be2080981f2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1086, "doc": {"premise": "May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them.", "hypothesis": "Bad things will happen to those people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Yes, Bad things will happen to those people."}, "gen_args_1": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Also, Bad things will happen to those people."}, "gen_args_2": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? No, Bad things will happen to those people."}}, "resps": [[["-170.0", "False"]], [["-174.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-174.0", "False"], ["-172.0", "False"]], "doc_hash": "0eb245e6ffcf07d75e96abc6a34c7408101bc6dd202a1990e3b55b5ebc982b77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1094, "doc": {"premise": "Several small temples can be found here.", "hypothesis": "There are some tiny temples only one person can fit in.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Yes, There are some tiny temples only one person can fit in."}, "gen_args_1": {"arg_0": "", "arg_1": " Several small temples can be found here., right? Also, There are some tiny temples only one person can fit in."}, "gen_args_2": {"arg_0": "", "arg_1": " Several small temples can be found here., right? No, There are some tiny temples only one person can fit in."}}, "resps": [[["-102.5", "False"]], [["-106.5", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.5", "False"], ["-103.5", "False"]], "doc_hash": "03244ccd1a645aec7a991ecb683ffb1e5811be3f068606f55d59290732f73ca5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1102, "doc": {"premise": "The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors.", "hypothesis": "The acoustics are just a mess in that place.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Yes, The acoustics are just a mess in that place."}, "gen_args_1": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Also, The acoustics are just a mess in that place."}, "gen_args_2": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? No, The acoustics are just a mess in that place."}}, "resps": [[["-158.0", "False"]], [["-159.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-159.0", "False"], ["-153.0", "False"]], "doc_hash": "bd0d3e3ee25be2aa36af8930e394962a529f3e97841aa85ed9be21eddc46a4c0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1110, "doc": {"premise": "Don't fire unless fired upon!", "hypothesis": "Fire if you think that you need to at any time.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Yes, Fire if you think that you need to at any time."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Also, Fire if you think that you need to at any time."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? No, Fire if you think that you need to at any time."}}, "resps": [[["-89.0", "False"]], [["-94.0", "False"]], [["-86.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-94.0", "False"], ["-86.0", "False"]], "doc_hash": "a02e13bc8fda331179f7f2fa3b0db4b630fcacdaee93059d5d8b25bfde01885d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 1118, "doc": {"premise": "Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times.", "hypothesis": "The National Historical Museum only has recent things.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Yes, The National Historical Museum only has recent things."}, "gen_args_1": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? Also, The National Historical Museum only has recent things."}, "gen_args_2": {"arg_0": "", "arg_1": " Nearer to Syntagma, in Koloktroni Square, is the National Historical Museum with a collection of artifacts dating from post-Classical times., right? No, The National Historical Museum only has recent things."}}, "resps": [[["-168.0", "False"]], [["-172.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-172.0", "False"], ["-167.0", "False"]], "doc_hash": "c53e2e3b4ecabaaf1bcea9bdb6c1d0e4b24ebf4ed03f3cc6050197c4a3547537", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1126, "doc": {"premise": "Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth.", "hypothesis": "The marketplace represents the city's post-war rebirth.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Yes, The marketplace represents the city's post-war rebirth."}, "gen_args_1": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Also, The marketplace represents the city's post-war rebirth."}, "gen_args_2": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? No, The marketplace represents the city's post-war rebirth."}}, "resps": [[["-168.0", "False"]], [["-173.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-173.0", "False"], ["-163.0", "False"]], "doc_hash": "a2d5ec5204312fb756d0d49e3607db8c65aebf121052d16ff56d2ba861f0461c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69254912e-03 4.50940412e-05 9.93262357e-01]"]}
{"doc_id": 1134, "doc": {"premise": "Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge.", "hypothesis": "The collection is growing, but not as fast as it did last year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Yes, The collection is growing, but not as fast as it did last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Also, The collection is growing, but not as fast as it did last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? No, The collection is growing, but not as fast as it did last year."}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-176.0", "False"]], "doc_hash": "1f01fa7819c8e333365957914ef4686191de9490e4e96eed5aa6ce01792f6ea7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1142, "doc": {"premise": "You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum.", "hypothesis": "The museum is very far from the museum about Egypt.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Yes, The museum is very far from the museum about Egypt."}, "gen_args_1": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? Also, The museum is very far from the museum about Egypt."}, "gen_args_2": {"arg_0": "", "arg_1": " You will find the Brehan Museum (dedicated to Art Deco and Art Nouveau) in a former infantry barracks opposite the Egyptian museum., right? No, The museum is very far from the museum about Egypt."}}, "resps": [[["-177.0", "False"]], [["-181.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-181.0", "False"], ["-176.0", "False"]], "doc_hash": "d39e50da3eac14f6a232587e7b012538120c7f4a5af1236d630857b6d552493e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1150, "doc": {"premise": "Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests.", "hypothesis": "National unity is more important than everything else combined.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Yes, National unity is more important than everything else combined."}, "gen_args_1": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Also, National unity is more important than everything else combined."}, "gen_args_2": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? No, National unity is more important than everything else combined."}}, "resps": [[["-138.0", "False"]], [["-140.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-140.0", "False"], ["-134.0", "False"]], "doc_hash": "d4788059e1a15b6df3f55e842ac93286423e4d2dd2f9682b7ef62f2470dcf2d9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1158, "doc": {"premise": "Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market.", "hypothesis": "The market is called Mercat de la Cantaloupe.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Yes, The market is called Mercat de la Cantaloupe."}, "gen_args_1": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Also, The market is called Mercat de la Cantaloupe."}, "gen_args_2": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? No, The market is called Mercat de la Cantaloupe."}}, "resps": [[["-237.0", "False"]], [["-238.0", "False"]], [["-237.0", "False"]]], "filtered_resps": [["-237.0", "False"], ["-238.0", "False"], ["-237.0", "False"]], "doc_hash": "ea8c83845148603abe2af15a33101623b96ab5bbf865c45674c0998ae6cf0536", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1166, "doc": {"premise": "The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village.", "hypothesis": "Alaior is all little black houses.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Yes, Alaior is all little black houses."}, "gen_args_1": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? Also, Alaior is all little black houses."}, "gen_args_2": {"arg_0": "", "arg_1": " The town of Alaior, a mass of white houses clustered on a low hill, looks at a distance like an Arab or Andalusian village., right? No, Alaior is all little black houses."}}, "resps": [[["-159.0", "False"]], [["-162.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-162.0", "False"], ["-154.0", "False"]], "doc_hash": "a2f42b7868deeed28adbf922f79b51253bbc33e967f08ec4fc52a6818662ced3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.69062149e-03 3.33106430e-04 9.92976272e-01]"]}
{"doc_id": 1174, "doc": {"premise": "Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy.", "hypothesis": "The snake lived near the entrance to the temple and ate honey cakes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Yes, The snake lived near the entrance to the temple and ate honey cakes."}, "gen_args_1": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Also, The snake lived near the entrance to the temple and ate honey cakes."}, "gen_args_2": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? No, The snake lived near the entrance to the temple and ate honey cakes."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-155.0", "False"]], "doc_hash": "07057d4c9d472161eb3e638d33e9f91ca605fa510aa78c3b3c698e8ac765c80a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1182, "doc": {"premise": "Today the site is called the Temple of Heaven Park (Tiantan Gongyuan).", "hypothesis": "Temple of Heaven Park is kind of new.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Yes, Temple of Heaven Park is kind of new."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Also, Temple of Heaven Park is kind of new."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? No, Temple of Heaven Park is kind of new."}}, "resps": [[["-101.0", "False"]], [["-103.0", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-101.0", "False"], ["-103.0", "False"], ["-98.5", "False"]], "doc_hash": "39d9ff6e619df2ff1a95095df5b90d057ad208158840b96a382dae5e7bd6fef2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.07508731 0.01016196 0.91475073]"]}
{"doc_id": 1190, "doc": {"premise": "Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies.", "hypothesis": "The Komische Oper is the most famous one in Germany.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Yes, The Komische Oper is the most famous one in Germany."}, "gen_args_1": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? Also, The Komische Oper is the most famous one in Germany."}, "gen_args_2": {"arg_0": "", "arg_1": " Continuing east, you pass the unprepossessing modern faaade of the Komische Oper, one of Berlin's most important opera companies., right? No, The Komische Oper is the most famous one in Germany."}}, "resps": [[["-164.0", "False"]], [["-171.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-171.0", "False"], ["-166.0", "False"]], "doc_hash": "471f60d3dd12408fd9331f7099492031ddb2b834004575562211a3fa00092b8b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 1198, "doc": {"premise": "The Great Depression hit California hard.", "hypothesis": "California's economy has always thrived.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Yes, California's economy has always thrived."}, "gen_args_1": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Also, California's economy has always thrived."}, "gen_args_2": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? No, California's economy has always thrived."}}, "resps": [[["-79.5", "False"]], [["-82.0", "False"]], [["-77.0", "False"]]], "filtered_resps": [["-79.5", "False"], ["-82.0", "False"], ["-77.0", "False"]], "doc_hash": "96e0118011684c1d3ea6fcfdcd6a8dcd94328581e6cbab3ae0784b3623c069a9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07538875 0.00618829 0.91842297]"]}
{"doc_id": 1206, "doc": {"premise": "Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates.", "hypothesis": "People like to eat meals in the garden.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Yes, People like to eat meals in the garden."}, "gen_args_1": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Also, People like to eat meals in the garden."}, "gen_args_2": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? No, People like to eat meals in the garden."}}, "resps": [[["-162.0", "False"]], [["-164.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-164.0", "False"], ["-165.0", "False"]], "doc_hash": "30ad4d8e62a86a4f2bb3e0c643664c1bff78fe1612b4ad07c81f776972bc1aef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.1141952  0.04201007]"]}
{"doc_id": 1214, "doc": {"premise": "Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level.", "hypothesis": "Flag Hill is below sea level.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Yes, Flag Hill is below sea level."}, "gen_args_1": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? Also, Flag Hill is below sea level."}, "gen_args_2": {"arg_0": "", "arg_1": " Beside the cruise port is Flag Hill, rising 700 ft (214 m) above sea level., right? No, Flag Hill is below sea level."}}, "resps": [[["-121.0", "False"]], [["-126.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-126.0", "False"], ["-119.0", "False"]], "doc_hash": "97496a683fff8c492777343d2676c8603c7dd7091f4e54453f49c979fc0a4a79", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19107257e-01 8.02538386e-04 8.80090205e-01]"]}
{"doc_id": 1222, "doc": {"premise": "Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site.", "hypothesis": "There's a square near the church.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Yes, There's a square near the church."}, "gen_args_1": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Also, There's a square near the church."}, "gen_args_2": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? No, There's a square near the church."}}, "resps": [[["-186.0", "False"]], [["-192.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-192.0", "False"], ["-188.0", "False"]], "doc_hash": "b6b38f414d0d87675167e43d636c6bf101b3a80f1c0ddcb226453d8734cd24d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1230, "doc": {"premise": "Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar.", "hypothesis": "Chinatown is on the water in San Diego.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Yes, Chinatown is on the water in San Diego."}, "gen_args_1": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Also, Chinatown is on the water in San Diego."}, "gen_args_2": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? No, Chinatown is on the water in San Diego."}}, "resps": [[["-136.0", "False"]], [["-143.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-143.0", "False"], ["-136.0", "False"]], "doc_hash": "781f69222d015d28ad3d87f5a62bec6a0d566deebfe1f1205f6526941132d59f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 1238, "doc": {"premise": "Just east of the Star Ferry terminal, you'll come to City Hall.", "hypothesis": "City Hall is very far from the terminal.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Yes, City Hall is very far from the terminal."}, "gen_args_1": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? Also, City Hall is very far from the terminal."}, "gen_args_2": {"arg_0": "", "arg_1": " Just east of the Star Ferry terminal, you'll come to City Hall., right? No, City Hall is very far from the terminal."}}, "resps": [[["-112.5", "False"]], [["-120.5", "False"]], [["-110.0", "False"]]], "filtered_resps": [["-112.5", "False"], ["-120.5", "False"], ["-110.0", "False"]], "doc_hash": "d6b1c06318ef36d7be691014049bb2c879149a3cd760f65b82b43473fc3fd22a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58562497e-02 2.54469369e-05 9.24118303e-01]"]}
{"doc_id": 1246, "doc": {"premise": "Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base.", "hypothesis": "Corporate structures were created.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Yes, Corporate structures were created."}, "gen_args_1": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Also, Corporate structures were created."}, "gen_args_2": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? No, Corporate structures were created."}}, "resps": [[["-148.0", "False"]], [["-153.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-153.0", "False"], ["-150.0", "False"]], "doc_hash": "e15e53ea6b7934163be0eeacf52980237af73a498cde34400e70e4f538e53a28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1254, "doc": {"premise": "Executives could also receive a rating of provisional or fail for each element.", "hypothesis": "Each element the executive is tested on could result in different ratings.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Yes, Each element the executive is tested on could result in different ratings."}, "gen_args_1": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Also, Each element the executive is tested on could result in different ratings."}, "gen_args_2": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? No, Each element the executive is tested on could result in different ratings."}}, "resps": [[["-151.0", "False"]], [["-159.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-159.0", "False"], ["-159.0", "False"]], "doc_hash": "51f2516b46b925ffe1745c34af75dcfb0f7a7bbe79ca07c2acd1ccd62b6bb349", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.99329525e-01 3.35237708e-04 3.35237708e-04]"]}
{"doc_id": 1262, "doc": {"premise": "189 and the user costs are estimated in the same way.", "hypothesis": "They knew the exact user costs.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Yes, They knew the exact user costs."}, "gen_args_1": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? Also, They knew the exact user costs."}, "gen_args_2": {"arg_0": "", "arg_1": " 189 and the user costs are estimated in the same way., right? No, They knew the exact user costs."}}, "resps": [[["-120.5", "False"]], [["-122.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-120.5", "False"], ["-122.5", "False"], ["-119.0", "False"]], "doc_hash": "7d14324390725584d4335f76abb3d99c51ed6fdda18d3316de8091e564333666", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17803021 0.02409377 0.79787603]"]}
{"doc_id": 1270, "doc": {"premise": "Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999.", "hypothesis": "Households have been losing a lot of wealth.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Yes, Households have been losing a lot of wealth."}, "gen_args_1": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Also, Households have been losing a lot of wealth."}, "gen_args_2": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? No, Households have been losing a lot of wealth."}}, "resps": [[["-147.0", "False"]], [["-147.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-147.0", "False"], ["-145.0", "False"]], "doc_hash": "1ea80907586b9ffec2f8492f6f2ef2004320a12580f48db8d638639c51d43187", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1278, "doc": {"premise": "19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler.", "hypothesis": "It only took two months to retrofit it.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Yes, It only took two months to retrofit it."}, "gen_args_1": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Also, It only took two months to retrofit it."}, "gen_args_2": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? No, It only took two months to retrofit it."}}, "resps": [[["-181.0", "False"]], [["-184.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-184.0", "False"], ["-177.0", "False"]], "doc_hash": "6b79d266fec2b5c6219dda50ab0009babfe653aaaf2b01453f05190b38e1094b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1286, "doc": {"premise": "It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere.", "hypothesis": "You cant know how much bias there is.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Yes, You cant know how much bias there is."}, "gen_args_1": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? Also, You cant know how much bias there is."}, "gen_args_2": {"arg_0": "", "arg_1": " It is not possible to know the extent or direction of the bias in the total incidence change based on the general application of a single C-R function everywhere., right? No, You cant know how much bias there is."}}, "resps": [[["-191.0", "False"]], [["-194.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-194.0", "False"], ["-191.0", "False"]], "doc_hash": "fc2ef122cbb051714ca1f529b0e23b82c3858db0ad1b6ea68790b70aadb1ca06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1294, "doc": {"premise": ", the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3.", "hypothesis": "They had  rough estimate of the benefits but it was likely wrong.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Yes, They had  rough estimate of the benefits but it was likely wrong."}, "gen_args_1": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Also, They had  rough estimate of the benefits but it was likely wrong."}, "gen_args_2": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? No, They had  rough estimate of the benefits but it was likely wrong."}}, "resps": [[["-243.0", "False"]], [["-243.0", "False"]], [["-242.0", "False"]]], "filtered_resps": [["-243.0", "False"], ["-243.0", "False"], ["-242.0", "False"]], "doc_hash": "ec5ad22d9801a46ea5396b9e3652be7e09cffc50fa5d1bbf0da24e65e4c41fb7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1302, "doc": {"premise": "49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage.", "hypothesis": "Skimmers are usually doing something illegal but they get away with it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Yes, Skimmers are usually doing something illegal but they get away with it."}, "gen_args_1": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Also, Skimmers are usually doing something illegal but they get away with it."}, "gen_args_2": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? No, Skimmers are usually doing something illegal but they get away with it."}}, "resps": [[["-186.0", "False"]], [["-186.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-186.0", "False"], ["-186.0", "False"]], "doc_hash": "8f92257aa3e5612d89fb1f3768002ca694fb284487dc63beb82553e48fae5546", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1310, "doc": {"premise": "LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States.", "hypothesis": "The LSC only funds medical students.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Yes, The LSC only funds medical students."}, "gen_args_1": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? Also, The LSC only funds medical students."}, "gen_args_2": {"arg_0": "", "arg_1": " LSC-funded attorneys would be required to monitor the movements of their clients, and to withdraw from cases whenever their alien clients leave the United States., right? No, The LSC only funds medical students."}}, "resps": [[["-175.0", "False"]], [["-174.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-174.0", "False"], ["-173.0", "False"]], "doc_hash": "a711e36e8ebd9f563668cc03edaa2b6ed306fe8547c799ed65d7e7379bd9afa6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 1318, "doc": {"premise": "But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one.", "hypothesis": "Her work as a judge helped poor people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Yes, Her work as a judge helped poor people."}, "gen_args_1": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Also, Her work as a judge helped poor people."}, "gen_args_2": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? No, Her work as a judge helped poor people."}}, "resps": [[["-161.0", "False"]], [["-166.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-166.0", "False"], ["-163.0", "False"]], "doc_hash": "aff104487f9a549cad497433a8f1e86c3566f45463f4d10d69b0cb77554b7fee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1326, "doc": {"premise": "1) Increasing penetration of alternative modes of communication", "hypothesis": "Alternate communication makes up 60% of communication now.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Yes, Alternate communication makes up 60% of communication now."}, "gen_args_1": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Also, Alternate communication makes up 60% of communication now."}, "gen_args_2": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? No, Alternate communication makes up 60% of communication now."}}, "resps": [[["-115.0", "False"]], [["-119.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-115.0", "False"], ["-119.0", "False"], ["-117.0", "False"]], "doc_hash": "653b733980190726436dc547925c0e8c5905d74663b20f22f57af5978000ea24", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1334, "doc": {"premise": "Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process.", "hypothesis": "The efficacy test is the last step.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Yes, The efficacy test is the last step."}, "gen_args_1": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? Also, The efficacy test is the last step."}, "gen_args_2": {"arg_0": "", "arg_1": " Efficacy trials are the first step, but implementation of proven alcohol screening and brief intervention systems in hospital- and community-based settings has been the most difficult part of the process., right? No, The efficacy test is the last step."}}, "resps": [[["-166.0", "False"]], [["-168.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-168.0", "False"], ["-160.0", "False"]], "doc_hash": "ed6b203529b132172691b4ce92db7051c1fcd02c1ecfee33fc9bddf89b1f7575", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 1342, "doc": {"premise": "When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher.", "hypothesis": "When the travel voucher is used, the system can compare the info.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Yes, When the travel voucher is used, the system can compare the info."}, "gen_args_1": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Also, When the travel voucher is used, the system can compare the info."}, "gen_args_2": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? No, When the travel voucher is used, the system can compare the info."}}, "resps": [[["-178.0", "False"]], [["-182.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-182.0", "False"], ["-182.0", "False"]], "doc_hash": "1b5d8ab31a921715987e2ff800c6120f99f021b32e743d8e0df7df864893cc95", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1350, "doc": {"premise": "I would be pleased to respond to any questions that the Members of the Subcommittee may have.", "hypothesis": "I don't take questions.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Yes, I don't take questions."}, "gen_args_1": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Also, I don't take questions."}, "gen_args_2": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? No, I don't take questions."}}, "resps": [[["-93.5", "False"]], [["-93.5", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-93.5", "False"], ["-93.5", "False"], ["-89.0", "False"]], "doc_hash": "a71f3e258b602498b7480e05c42b3496204e7d821ee55382db7715263dddcdd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01086754 0.01086754 0.97826492]"]}
{"doc_id": 1358, "doc": {"premise": "TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS", "hypothesis": "There are no rules about mercury.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Yes, There are no rules about mercury."}, "gen_args_1": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? Also, There are no rules about mercury."}, "gen_args_2": {"arg_0": "", "arg_1": " TABLE A.- TOTAL MERCURY ALLOWANCES ALLOCATED OR AUCTIONED FOR EGUS, right? No, There are no rules about mercury."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-155.0", "False"]], "doc_hash": "1efad3d7114472c3dbbeda1db3b2b823914916f8ae511c415b8b9ce0f19855e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1366, "doc": {"premise": "C-R functions may also be estimated with or without explicit thresholds.", "hypothesis": "C-R functions can be estimated a couple different ways.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Yes, C-R functions can be estimated a couple different ways."}, "gen_args_1": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Also, C-R functions can be estimated a couple different ways."}, "gen_args_2": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? No, C-R functions can be estimated a couple different ways."}}, "resps": [[["-122.5", "False"]], [["-126.5", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-126.5", "False"], ["-124.5", "False"]], "doc_hash": "6e138be3d520ef1313c7b4c25e70b077a3f38c1ae7cff59f59aa4521554609c0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1374, "doc": {"premise": "Dr. Gentilello recommends the development of an ED alcohol research center.", "hypothesis": "An ED alcohol research center is recommended by some.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Yes, An ED alcohol research center is recommended by some."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Also, An ED alcohol research center is recommended by some."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? No, An ED alcohol research center is recommended by some."}}, "resps": [[["-135.0", "False"]], [["-141.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-141.0", "False"], ["-135.0", "False"]], "doc_hash": "0265efb4fb3bdc61a26157eb29325a99bfc938e6f88cab1021d08ed3211ef802", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1382, "doc": {"premise": "Significant differences were noted, however, as", "hypothesis": "There were apparent, notable differences.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Yes, There were apparent, notable differences."}, "gen_args_1": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? Also, There were apparent, notable differences."}, "gen_args_2": {"arg_0": "", "arg_1": " Significant differences were noted, however, as, right? No, There were apparent, notable differences."}}, "resps": [[["-102.5", "False"]], [["-106.0", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.0", "False"], ["-103.5", "False"]], "doc_hash": "a863c8f5bf541acb2cac830922292ec1ac169ee662b44d9ed73c3e84f3cc525e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 1390, "doc": {"premise": "Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees.", "hypothesis": "It would be a trivial matter for attorney to monitor eligible aliens at all times.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Yes, It would be a trivial matter for attorney to monitor eligible aliens at all times."}, "gen_args_1": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Also, It would be a trivial matter for attorney to monitor eligible aliens at all times."}, "gen_args_2": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? No, It would be a trivial matter for attorney to monitor eligible aliens at all times."}}, "resps": [[["-173.0", "False"]], [["-178.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-178.0", "False"], ["-169.0", "False"]], "doc_hash": "b9a24886ef03f41d25a06fbf21961dbf0c0a6ad663e309c39181b0aa782efd35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79840305e-02 1.21175444e-04 9.81894794e-01]"]}
{"doc_id": 1398, "doc": {"premise": "Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed.", "hypothesis": "The control device needs to be completed first.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Yes, The control device needs to be completed first."}, "gen_args_1": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Also, The control device needs to be completed first."}, "gen_args_2": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? No, The control device needs to be completed first."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-149.0", "False"]], "doc_hash": "7fba21bbeef333fc024ccba64ebeee64f07a0c76f6e945924d123947afc7ec99", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1406, "doc": {"premise": "change are staff downsizing, changes in contract methods, and business", "hypothesis": "They're hiring like crazy!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Yes, They're hiring like crazy!"}, "gen_args_1": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? Also, They're hiring like crazy!"}, "gen_args_2": {"arg_0": "", "arg_1": " change are staff downsizing, changes in contract methods, and business, right? No, They're hiring like crazy!"}}, "resps": [[["-126.5", "False"]], [["-127.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-127.0", "False"], ["-124.0", "False"]], "doc_hash": "005ca58d2d8b6a4c2fac9fc297d5a86b988f0356a68d80c4c2ece990372f0ddb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07252145 0.04398648 0.88349207]"]}
{"doc_id": 1414, "doc": {"premise": "and internal control in either of two 6", "hypothesis": "Some cars have internal controls.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Yes, Some cars have internal controls."}, "gen_args_1": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Also, Some cars have internal controls."}, "gen_args_2": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? No, Some cars have internal controls."}}, "resps": [[["-102.5", "False"]], [["-104.5", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-104.5", "False"], ["-103.5", "False"]], "doc_hash": "6f4b076b70e0733cf17d4e60b4e03fc1d04a1bbbd4d36454e99d147142a835f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1422, "doc": {"premise": "Managing Change in the Postal and Delivery Industries, Ed.", "hypothesis": "Change in the Postal and Delivery Industries needs to be managed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Yes, Change in the Postal and Delivery Industries needs to be managed."}, "gen_args_1": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Also, Change in the Postal and Delivery Industries needs to be managed."}, "gen_args_2": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? No, Change in the Postal and Delivery Industries needs to be managed."}}, "resps": [[["-99.0", "False"]], [["-107.0", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-99.0", "False"], ["-107.0", "False"], ["-102.0", "False"]], "doc_hash": "86458cc36f0bf3b98b2b382cfae942146e74ce0f362a61122cb2acf02dea4b39", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 1430, "doc": {"premise": "We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world.", "hypothesis": "We want to make GAO stronger.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Yes, We want to make GAO stronger."}, "gen_args_1": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? Also, We want to make GAO stronger."}, "gen_args_2": {"arg_0": "", "arg_1": " We need these additional resources to continue our efforts to further strengthen GAO and be a model organization for the rest of the federal government and accountability organizations around the world., right? No, We want to make GAO stronger."}}, "resps": [[["-154.0", "False"]], [["-160.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-160.0", "False"], ["-159.0", "False"]], "doc_hash": "c333efd4ed070915d59889b2bbed60d4765c5ea65586f2f6336d7ad299631ad1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99086747 0.00245611 0.00667641]"]}
{"doc_id": 1438, "doc": {"premise": "They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies.", "hypothesis": "There should have been been more things included.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Yes, There should have been been more things included."}, "gen_args_1": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Also, There should have been been more things included."}, "gen_args_2": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? No, There should have been been more things included."}}, "resps": [[["-170.0", "False"]], [["-172.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-172.0", "False"], ["-169.0", "False"]], "doc_hash": "3f94d742a30e8055aeaabb965426a87dde3085f8e30edee4e81026cd702178ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1446, "doc": {"premise": "The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses.", "hypothesis": "A contingency plan to minimize losses should be included in the the plan.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Yes, A contingency plan to minimize losses should be included in the the plan."}, "gen_args_1": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Also, A contingency plan to minimize losses should be included in the the plan."}, "gen_args_2": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? No, A contingency plan to minimize losses should be included in the the plan."}}, "resps": [[["-161.0", "False"]], [["-170.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-170.0", "False"], ["-167.0", "False"]], "doc_hash": "3af648825e8ca34a1d6f497f0f38ce167032a44dda3c85a5fba628e8adac16f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.97404592e-01 1.23089505e-04 2.47231880e-03]"]}
{"doc_id": 1454, "doc": {"premise": "It made sense for the state to outsource tactical functions such as help desks and mainframe management.", "hypothesis": "There were many other functions that the state could have outsourced as well.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Yes, There were many other functions that the state could have outsourced as well."}, "gen_args_1": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? Also, There were many other functions that the state could have outsourced as well."}, "gen_args_2": {"arg_0": "", "arg_1": " It made sense for the state to outsource tactical functions such as help desks and mainframe management., right? No, There were many other functions that the state could have outsourced as well."}}, "resps": [[["-133.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "50c34d4847e374344e7fd8ea1577df89d168d5d6c3ae7844f6947adc213814ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1462, "doc": {"premise": "Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect.", "hypothesis": "Air pollution levels can cause hazardous health effects depending on the threshold.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Yes, Air pollution levels can cause hazardous health effects depending on the threshold."}, "gen_args_1": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Also, Air pollution levels can cause hazardous health effects depending on the threshold."}, "gen_args_2": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? No, Air pollution levels can cause hazardous health effects depending on the threshold."}}, "resps": [[["-146.0", "False"]], [["-146.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-146.0", "False"], ["-143.0", "False"]], "doc_hash": "2e3565782780a6120c131d6947604173c34a589695767a7aea0c9f424264c43c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1470, "doc": {"premise": "In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup.", "hypothesis": "9a is not the rate difference.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Yes, 9a is not the rate difference."}, "gen_args_1": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Also, 9a is not the rate difference."}, "gen_args_2": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? No, 9a is not the rate difference."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-131.0", "False"]], "doc_hash": "a76b6fe8690d6600d9ce27d431a032af47adee10b085f4645cfe065d91a18027", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.53971105e-05 1.67006637e-05 9.99937902e-01]"]}
{"doc_id": 1478, "doc": {"premise": "If households' existing assets lose value, people have to save more to attain their wealth-income target.", "hypothesis": "If people's assets lose value they end up having to save more.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Yes, If people's assets lose value they end up having to save more."}, "gen_args_1": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? Also, If people's assets lose value they end up having to save more."}, "gen_args_2": {"arg_0": "", "arg_1": " If households' existing assets lose value, people have to save more to attain their wealth-income target., right? No, If people's assets lose value they end up having to save more."}}, "resps": [[["-151.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "1af7753f281816f70fe4ce2149741e1370e28ff3a26e642b867c901b7ec8b25e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1486, "doc": {"premise": "An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options.", "hypothesis": "Most aliens do not seek legal services when they need it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Yes, Most aliens do not seek legal services when they need it."}, "gen_args_1": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Also, Most aliens do not seek legal services when they need it."}, "gen_args_2": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? No, Most aliens do not seek legal services when they need it."}}, "resps": [[["-219.0", "False"]], [["-216.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-216.0", "False"], ["-217.0", "False"]], "doc_hash": "ddab79d2131b6dff897d00b9b199e5fbac09c8c1fbf783543ed72ad88026ffa7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.03511903 0.70538451 0.25949646]"]}
{"doc_id": 1494, "doc": {"premise": "The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization.", "hypothesis": "Marxist-Leninist concepts were incorporated into the Islamist movement.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Yes, Marxist-Leninist concepts were incorporated into the Islamist movement."}, "gen_args_1": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Also, Marxist-Leninist concepts were incorporated into the Islamist movement."}, "gen_args_2": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? No, Marxist-Leninist concepts were incorporated into the Islamist movement."}}, "resps": [[["-143.0", "False"]], [["-151.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-151.0", "False"], ["-146.0", "False"]], "doc_hash": "fb343bef02aa53dd4a87ba37b8447600c74c2caf4a08436fa651779416b396d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 1502, "doc": {"premise": "The system also chose passengers at random to receive additional security scrutiny.", "hypothesis": "Some passengers get checked more thoroughly by security.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Yes, Some passengers get checked more thoroughly by security."}, "gen_args_1": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? Also, Some passengers get checked more thoroughly by security."}, "gen_args_2": {"arg_0": "", "arg_1": " The system also chose passengers at random to receive additional security scrutiny., right? No, Some passengers get checked more thoroughly by security."}}, "resps": [[["-125.5", "False"]], [["-129.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-125.5", "False"], ["-129.0", "False"], ["-127.5", "False"]], "doc_hash": "6d03b9cc2d153ed79973fdb8f162a5c5ae1c889d85c94a35ea3b6bcf1582d388", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.85797681 0.02590865 0.11611453]"]}
{"doc_id": 1510, "doc": {"premise": "Intelligence report, interrogation of KSM, July 30, 2003.", "hypothesis": "KSM was not captured until late 2008, when he was finally interrogated in detail.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Yes, KSM was not captured until late 2008, when he was finally interrogated in detail."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Also, KSM was not captured until late 2008, when he was finally interrogated in detail."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? No, KSM was not captured until late 2008, when he was finally interrogated in detail."}}, "resps": [[["-138.0", "False"]], [["-138.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-138.0", "False"], ["-132.0", "False"]], "doc_hash": "295f404c87f04d7035efa16f5b07a7598050c09b16c93e2d73463b7b3836b6f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1518, "doc": {"premise": "The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done.", "hypothesis": "The director didn't want to get involved because he was almost retired.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Yes, The director didn't want to get involved because he was almost retired."}, "gen_args_1": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Also, The director didn't want to get involved because he was almost retired."}, "gen_args_2": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? No, The director didn't want to get involved because he was almost retired."}}, "resps": [[["-200.0", "False"]], [["-201.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-201.0", "False"], ["-200.0", "False"]], "doc_hash": "c84fc3599093914924b96f5a7dc2dcbeb42cc9f5085f41d1948a48284fa6184f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1526, "doc": {"premise": "According to both KSM and Khallad, Abu Bara never applied for a U.S. visa.", "hypothesis": "Abu Bara was granted a visa in 2011.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Yes, Abu Bara was granted a visa in 2011."}, "gen_args_1": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? Also, Abu Bara was granted a visa in 2011."}, "gen_args_2": {"arg_0": "", "arg_1": " According to both KSM and Khallad, Abu Bara never applied for a U.S. visa., right? No, Abu Bara was granted a visa in 2011."}}, "resps": [[["-128.0", "False"]], [["-128.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-128.0", "False"], ["-128.0", "False"], ["-126.5", "False"]], "doc_hash": "5b4b5eb8abcd7928080ef1877b80cd610b84904846c187c6e047de8b91afc0fd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.15428077 0.15428077 0.69143845]"]}
{"doc_id": 1534, "doc": {"premise": "For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed.", "hypothesis": "The intercepts were sent to the wrong person for analysis.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Yes, The intercepts were sent to the wrong person for analysis."}, "gen_args_1": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Also, The intercepts were sent to the wrong person for analysis."}, "gen_args_2": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? No, The intercepts were sent to the wrong person for analysis."}}, "resps": [[["-183.0", "False"]], [["-188.0", "False"]], [["-184.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-188.0", "False"], ["-184.0", "False"]], "doc_hash": "7805532753ae28990ae37c74527af1c2e7f81cc2cbf14e33389d2812bb7913db", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1542, "doc": {"premise": "We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate.", "hypothesis": "There's no point in debating this topic.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Yes, There's no point in debating this topic."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Also, There's no point in debating this topic."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? No, There's no point in debating this topic."}}, "resps": [[["-130.0", "False"]], [["-132.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-132.0", "False"], ["-128.0", "False"]], "doc_hash": "b93b3381eba0dfad2a0fc5d3cbb051a5606834aa3bb30f9d4fd52ea46d10e48b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1550, "doc": {"premise": "According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation.", "hypothesis": "Bin Ladin wasn't worried about Moussaoui being held for questioning.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Yes, Bin Ladin wasn't worried about Moussaoui being held for questioning."}, "gen_args_1": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? Also, Bin Ladin wasn't worried about Moussaoui being held for questioning."}, "gen_args_2": {"arg_0": "", "arg_1": " According to Binalshibh, had Bin Ladin and KSM learned prior to 9/11 that Moussaoui had been detained, they might have canceled the operation., right? No, Bin Ladin wasn't worried about Moussaoui being held for questioning."}}, "resps": [[["-158.0", "False"]], [["-154.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-154.0", "False"], ["-153.0", "False"]], "doc_hash": "238c2c3c4489b7b10640ff93dc64ac0613a26b6f1f6e2c2bfbbc3d43b4c8f712", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00490169 0.26762315 0.72747516]"]}
{"doc_id": 1558, "doc": {"premise": "It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious.", "hypothesis": "Khallad was associated with Mihdhar.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Yes, Khallad was associated with Mihdhar."}, "gen_args_1": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Also, Khallad was associated with Mihdhar."}, "gen_args_2": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? No, Khallad was associated with Mihdhar."}}, "resps": [[["-129.0", "False"]], [["-132.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-132.0", "False"], ["-132.0", "False"]], "doc_hash": "161da4ac92664c594c0521ee4c738b9c0d758a0105bbd46a8b998603bc152628", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1566, "doc": {"premise": "Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles.", "hypothesis": "Atta and Omari sat in window seats while the others sat on the isles.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Yes, Atta and Omari sat in window seats while the others sat on the isles."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Also, Atta and Omari sat in window seats while the others sat on the isles."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? No, Atta and Omari sat in window seats while the others sat on the isles."}}, "resps": [[["-187.0", "False"]], [["-187.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-187.0", "False"], ["-186.0", "False"]], "doc_hash": "f3caa36229ba29b479a54160ff49c70ef35b61dee1e873dda746c01457acd0da", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1574, "doc": {"premise": "While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average.", "hypothesis": "The test results for X-rays were well above the national average.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Yes, The test results for X-rays were well above the national average."}, "gen_args_1": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? Also, The test results for X-rays were well above the national average."}, "gen_args_2": {"arg_0": "", "arg_1": " While the test results for physical search exceeded the national average, both the metal detector and X-ray results were below average., right? No, The test results for X-rays were well above the national average."}}, "resps": [[["-148.0", "False"]], [["-149.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-149.0", "False"], ["-143.0", "False"]], "doc_hash": "3434d9f96aafe1c7d61d9f1bb54020d8782d49a4205de8acaa53edf360ca6060", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1582, "doc": {"premise": "As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process.", "hypothesis": "The Saudis invited the US envoy to come work on the middle east peace project.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Yes, The Saudis invited the US envoy to come work on the middle east peace project."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Also, The Saudis invited the US envoy to come work on the middle east peace project."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? No, The Saudis invited the US envoy to come work on the middle east peace project."}}, "resps": [[["-203.0", "False"]], [["-204.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-204.0", "False"], ["-200.0", "False"]], "doc_hash": "486663a0944377d6f6d5a37c1f3c54a866a4ea0daa4b5e5680405800de4207a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 1590, "doc": {"premise": "There is no indication that Atta or Shehhi received any additional flight training in June.", "hypothesis": "Atta and Shehhi received their flight certifications in May.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Yes, Atta and Shehhi received their flight certifications in May."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Also, Atta and Shehhi received their flight certifications in May."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? No, Atta and Shehhi received their flight certifications in May."}}, "resps": [[["-121.0", "False"]], [["-124.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-124.0", "False"], ["-121.0", "False"]], "doc_hash": "be4d5ecc8ee930b3b27f7be19f691f6c1f30fdf5ddcbc3d696bf17bdc52acc33", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1598, "doc": {"premise": "On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda.", "hypothesis": "President Musharraf replied to President Bush right away.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Yes, President Musharraf replied to President Bush right away."}, "gen_args_1": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? Also, President Musharraf replied to President Bush right away."}, "gen_args_2": {"arg_0": "", "arg_1": " On August 4, President Bush wrote President Musharraf to request his support in dealing with terrorism and to urge Pakistan to engage actively against al Qaeda., right? No, President Musharraf replied to President Bush right away."}}, "resps": [[["-148.0", "False"]], [["-151.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-151.0", "False"], ["-152.0", "False"]], "doc_hash": "dc90ae88c04992db6e983779c528101308fbef2dc4ffa104bf3c4624e6ebb126", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 1606, "doc": {"premise": "He believed that there was sufficient probable cause for a criminal warrant at that time.", "hypothesis": "He was convinced that there was nothing suspicious going on.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Yes, He was convinced that there was nothing suspicious going on."}, "gen_args_1": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Also, He was convinced that there was nothing suspicious going on."}, "gen_args_2": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? No, He was convinced that there was nothing suspicious going on."}}, "resps": [[["-115.5", "False"]], [["-117.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-115.5", "False"], ["-117.5", "False"], ["-113.5", "False"]], "doc_hash": "5b443b1dba3f1730905b7d20a6023f20f02ce5702c5f98e0d4553a5a355454d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1614, "doc": {"premise": "The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups.", "hypothesis": "Britain also gave money to al Qaeda.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Yes, Britain also gave money to al Qaeda."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Also, Britain also gave money to al Qaeda."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? No, Britain also gave money to al Qaeda."}}, "resps": [[["-138.0", "False"]], [["-139.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-139.0", "False"], ["-137.0", "False"]], "doc_hash": "3c66c475c315f6ca398a8f1868f935aff9732551698cc5785327e94e6636b383", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1622, "doc": {"premise": "Boston  A second one just hit the Trade Center.", "hypothesis": "The Trade Center was not hit.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Yes, The Trade Center was not hit."}, "gen_args_1": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? Also, The Trade Center was not hit."}, "gen_args_2": {"arg_0": "", "arg_1": " Boston  A second one just hit the Trade Center., right? No, The Trade Center was not hit."}}, "resps": [[["-112.5", "False"]], [["-114.0", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-112.5", "False"], ["-114.0", "False"], ["-106.5", "False"]], "doc_hash": "b65a97e2f58c1aa33471c42199c8d39a7e91d4b28f43db566f025187b2b55bc4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47125972e-03 5.51412577e-04 9.96977328e-01]"]}
{"doc_id": 1630, "doc": {"premise": "Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy.", "hypothesis": "More than two dozen people were eventually involved in manning the command post.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Yes, More than two dozen people were eventually involved in manning the command post."}, "gen_args_1": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Also, More than two dozen people were eventually involved in manning the command post."}, "gen_args_2": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? No, More than two dozen people were eventually involved in manning the command post."}}, "resps": [[["-179.0", "False"]], [["-184.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-184.0", "False"], ["-180.0", "False"]], "doc_hash": "b706f46f999b7a158029c2c27ab2cc7c86b17e9c96c6b184daeffacf62f8e96f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1638, "doc": {"premise": "Hard Put to Find Proof Bin Laden Directed Attacks.", "hypothesis": "Bin Laden was not involved in directing the attacks.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Yes, Bin Laden was not involved in directing the attacks."}, "gen_args_1": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Also, Bin Laden was not involved in directing the attacks."}, "gen_args_2": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? No, Bin Laden was not involved in directing the attacks."}}, "resps": [[["-107.0", "False"]], [["-108.5", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-107.0", "False"], ["-108.5", "False"], ["-104.0", "False"]], "doc_hash": "e2135858bfcee1dfb00b432e15e0276bf5923fa76e21f272adfd11342bf90989", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04692926 0.01047133 0.94259941]"]}
{"doc_id": 1646, "doc": {"premise": "At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed.", "hypothesis": "The South Tower did not collapse.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Yes, The South Tower did not collapse."}, "gen_args_1": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? Also, The South Tower did not collapse."}, "gen_args_2": {"arg_0": "", "arg_1": " At about 10:15, the FDNY Chief of Department and the Chief of Safety, who had returned to West Street from the parking garage, confirmed that the South Tower had collapsed., right? No, The South Tower did not collapse."}}, "resps": [[["-158.0", "False"]], [["-157.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-157.0", "False"], ["-151.0", "False"]], "doc_hash": "34e74b8ef24adb07569f4863fc1082c4bcd675f94ec3f453d590fff39a455d45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.08800555e-04 2.47037604e-03 9.96620823e-01]"]}
{"doc_id": 1654, "doc": {"premise": "Intelligence report, interrogation of detainee, Dec. 2, 2001.", "hypothesis": "No detainees were interrogated.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Yes, No detainees were interrogated."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Also, No detainees were interrogated."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? No, No detainees were interrogated."}}, "resps": [[["-117.0", "False"]], [["-119.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-119.0", "False"], ["-112.0", "False"]], "doc_hash": "4bba3243e37f30b018b83cf277ea2ed92255589071094a58bc6f273cf4b456b9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 1662, "doc": {"premise": "The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing.", "hypothesis": "A foreign government had a photo of someone involved in the Cole bombing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Yes, A foreign government had a photo of someone involved in the Cole bombing."}, "gen_args_1": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Also, A foreign government had a photo of someone involved in the Cole bombing."}, "gen_args_2": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? No, A foreign government had a photo of someone involved in the Cole bombing."}}, "resps": [[["-131.0", "False"]], [["-137.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-137.0", "False"], ["-134.0", "False"]], "doc_hash": "9cd29d0a6b24bbfbcc0f38c79b99c5299fb0722748f6b1d8976165ca66d43aad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 1670, "doc": {"premise": "The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq.", "hypothesis": "These tyrants are usually fond of wearing green hats.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Yes, These tyrants are usually fond of wearing green hats."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? Also, These tyrants are usually fond of wearing green hats."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States defended, and still defends, Muslims against tyrants and criminals in Somalia, Bosnia, Kosovo, Afghanistan, and Iraq., right? No, These tyrants are usually fond of wearing green hats."}}, "resps": [[["-157.0", "False"]], [["-157.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-157.0", "False"], ["-158.0", "False"]], "doc_hash": "87c72cfc7911aeda787725bcc0be3be69e41edd0c7deff8ee66d3857b27405ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1678, "doc": {"premise": "In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation.", "hypothesis": "Nawaf al Hazmi traveled in January 2000.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Yes, Nawaf al Hazmi traveled in January 2000."}, "gen_args_1": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Also, Nawaf al Hazmi traveled in January 2000."}, "gen_args_2": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? No, Nawaf al Hazmi traveled in January 2000."}}, "resps": [[["-176.0", "False"]], [["-178.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-178.0", "False"], ["-175.0", "False"]], "doc_hash": "7698a01494e3d2523f565d007b714d19da972b8ff3f878e3ffde462320f468b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 1686, "doc": {"premise": "For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed.", "hypothesis": "Anthony L. Fusco, the Chief of Department, wrote a report on the rescue efforts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Yes, Anthony L. Fusco, the Chief of Department, wrote a report on the rescue efforts."}, "gen_args_1": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Also, Anthony L. Fusco, the Chief of Department, wrote a report on the rescue efforts."}, "gen_args_2": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? No, Anthony L. Fusco, the Chief of Department, wrote a report on the rescue efforts."}}, "resps": [[["-167.0", "False"]], [["-173.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-173.0", "False"], ["-173.0", "False"]], "doc_hash": "4a20549b16b67bacf64b550aaa563491b78feb066c03849d785cbb7736a52b16", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99506695 0.00246652 0.00246652]"]}
{"doc_id": 1694, "doc": {"premise": "After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism.", "hypothesis": "Sudan was known as a leader in the fight against terrorist throughout the nineties.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Yes, Sudan was known as a leader in the fight against terrorist throughout the nineties."}, "gen_args_1": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? Also, Sudan was known as a leader in the fight against terrorist throughout the nineties."}, "gen_args_2": {"arg_0": "", "arg_1": " After repeatedly demanding that Sudan stop supporting terrorist groups, in 1993 the U.S. government designated the country a state sponsor of terrorism., right? No, Sudan was known as a leader in the fight against terrorist throughout the nineties."}}, "resps": [[["-153.0", "False"]], [["-155.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-155.0", "False"], ["-151.0", "False"]], "doc_hash": "89b71b24ef150a7cbc5fc097a739a0ea723bdb06880c6099795aa643ea7e05df", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1702, "doc": {"premise": "When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office.", "hypothesis": "The New York Field Office handled it when they decided al Qaeda was involved.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Yes, The New York Field Office handled it when they decided al Qaeda was involved."}, "gen_args_1": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Also, The New York Field Office handled it when they decided al Qaeda was involved."}, "gen_args_2": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? No, The New York Field Office handled it when they decided al Qaeda was involved."}}, "resps": [[["-138.0", "False"]], [["-142.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-142.0", "False"], ["-139.0", "False"]], "doc_hash": "91331d029cd54b3f7e60e83e03be204bc7eb099f7231862517b806a8a506ccbd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1710, "doc": {"premise": "This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque.", "hypothesis": "The mosque contained extremist factions.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Yes, The mosque contained extremist factions."}, "gen_args_1": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Also, The mosque contained extremist factions."}, "gen_args_2": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? No, The mosque contained extremist factions."}}, "resps": [[["-140.0", "False"]], [["-146.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-146.0", "False"], ["-142.0", "False"]], "doc_hash": "23649e321fedf7f89ce96089a5ce01068186fe8b1fa77bdc174cc2a289605a49", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1718, "doc": {"premise": "A jet fuel fireball erupted upon impact and shot down at least one bank of elevators.", "hypothesis": "The jet fuel pooled on the ground but did not ignite.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Yes, The jet fuel pooled on the ground but did not ignite."}, "gen_args_1": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? Also, The jet fuel pooled on the ground but did not ignite."}, "gen_args_2": {"arg_0": "", "arg_1": " A jet fuel fireball erupted upon impact and shot down at least one bank of elevators., right? No, The jet fuel pooled on the ground but did not ignite."}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-134.0", "False"]], "doc_hash": "b9936695206280fbe19396ca1639e4713b13d88bf62f7160575a9ff2f70448a7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1726, "doc": {"premise": "This effort was going on before 9/11 and it continues on a vastly enlarged scale.", "hypothesis": "After 9/11 the effort was abandoned entirely in favor of different tactics.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Yes, After 9/11 the effort was abandoned entirely in favor of different tactics."}, "gen_args_1": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Also, After 9/11 the effort was abandoned entirely in favor of different tactics."}, "gen_args_2": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? No, After 9/11 the effort was abandoned entirely in favor of different tactics."}}, "resps": [[["-145.0", "False"]], [["-143.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-143.0", "False"], ["-138.0", "False"]], "doc_hash": "60ea663ac197a28ac2f5d98ed2846cac79bb7b2b57c7d773656fcaba9b32a0d7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.04959183e-04 6.68679417e-03 9.92408247e-01]"]}
{"doc_id": 1734, "doc": {"premise": "The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed.", "hypothesis": "Bin Ladin's security threat should have been evident to the government after the embassy bombings.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Yes, Bin Ladin's security threat should have been evident to the government after the embassy bombings."}, "gen_args_1": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Also, Bin Ladin's security threat should have been evident to the government after the embassy bombings."}, "gen_args_2": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? No, Bin Ladin's security threat should have been evident to the government after the embassy bombings."}}, "resps": [[["-169.0", "False"]], [["-173.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-173.0", "False"], ["-170.0", "False"]], "doc_hash": "1290fbd3aadf2256a89ae534757ccf16b0f50bf82ae0627d182b9ad53808d625", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1742, "doc": {"premise": "For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr.", "hypothesis": "The instructor of the Academy was James Milton.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Yes, The instructor of the Academy was James Milton."}, "gen_args_1": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? Also, The instructor of the Academy was James Milton."}, "gen_args_2": {"arg_0": "", "arg_1": " For the Academy's instructor's reaction, see FBI report of investigation, interview of James Milton, Apr., right? No, The instructor of the Academy was James Milton."}}, "resps": [[["-166.0", "False"]], [["-169.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-169.0", "False"], ["-167.0", "False"]], "doc_hash": "f866ce91a2539a08a777785547377192c93967e4fd55e54f1c6156d204cecca6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1750, "doc": {"premise": "Most important is the fact that attending a performance at the IRT is not just a field trip.", "hypothesis": "Attending a performance at the IRT will be a nice, easy break from hard work and thought.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Yes, Attending a performance at the IRT will be a nice, easy break from hard work and thought."}, "gen_args_1": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Also, Attending a performance at the IRT will be a nice, easy break from hard work and thought."}, "gen_args_2": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? No, Attending a performance at the IRT will be a nice, easy break from hard work and thought."}}, "resps": [[["-164.0", "False"]], [["-163.0", "False"]], [["-164.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-163.0", "False"], ["-164.0", "False"]], "doc_hash": "86851cc5d4207e65bc4a2e7d4c82c29acc24b0892540d0a0edb96f53388d6179", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 1758, "doc": {"premise": "My hope is you were greatly blessed and encouraged by this issue.", "hypothesis": "I hope this issue gave you newfound enthusiasm.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Yes, I hope this issue gave you newfound enthusiasm."}, "gen_args_1": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Also, I hope this issue gave you newfound enthusiasm."}, "gen_args_2": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? No, I hope this issue gave you newfound enthusiasm."}}, "resps": [[["-109.5", "False"]], [["-109.5", "False"]], [["-113.5", "False"]]], "filtered_resps": [["-109.5", "False"], ["-109.5", "False"], ["-113.5", "False"]], "doc_hash": "6c3c0a0fc959a0f7c3695a6dc11db5dfa4a0a2934083effe365a4cef5bbfbd50", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.49546264 0.00907471]"]}
{"doc_id": 1766, "doc": {"premise": "P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country.", "hypothesis": "We're very happy that the Indianapolis Civic Theater has been operating for 85 years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Yes, We're very happy that the Indianapolis Civic Theater has been operating for 85 years."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? Also, We're very happy that the Indianapolis Civic Theater has been operating for 85 years."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. Your gift is important to our celebration of 85 years making the Indianapolis Civic Theatre the oldest continuously operating community theatre in the country., right? No, We're very happy that the Indianapolis Civic Theater has been operating for 85 years."}}, "resps": [[["-166.0", "False"]], [["-170.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-170.0", "False"], ["-169.0", "False"]], "doc_hash": "0c6b4d019648ed97839da2307cd8f9269cdb2a2b9a26b0f5e9e4f24aaa9c5960", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1774, "doc": {"premise": "Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live.", "hypothesis": "In our zoo, we believe that artificial habitats are better than natural ones.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Yes, In our zoo, we believe that artificial habitats are better than natural ones."}, "gen_args_1": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Also, In our zoo, we believe that artificial habitats are better than natural ones."}, "gen_args_2": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? No, In our zoo, we believe that artificial habitats are better than natural ones."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "acbf2f68562cd68bc3e0d0683518d805a64c2e114f10518c7513c3c0916815a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1782, "doc": {"premise": "However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget.", "hypothesis": "Maintaining our present collections only costs a third of our annual budget.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Yes, Maintaining our present collections only costs a third of our annual budget."}, "gen_args_1": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Also, Maintaining our present collections only costs a third of our annual budget."}, "gen_args_2": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? No, Maintaining our present collections only costs a third of our annual budget."}}, "resps": [[["-162.0", "False"]], [["-169.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-169.0", "False"], ["-160.0", "False"]], "doc_hash": "7d3d886be86b859d4abc4896470976e756584fc7fe0cf9c63602afd5b97cc899", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19189966e-01 1.08687181e-04 8.80701347e-01]"]}
{"doc_id": 1790, "doc": {"premise": "We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th.", "hypothesis": "We will try to contact those who have not donated this fiscal year in the next 45 days.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Yes, We will try to contact those who have not donated this fiscal year in the next 45 days."}, "gen_args_1": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? Also, We will try to contact those who have not donated this fiscal year in the next 45 days."}, "gen_args_2": {"arg_0": "", "arg_1": " We will try to contact each of you who have not participated this fiscal year in the next 45 days so that our goal can be reached by the deadline of June 30th., right? No, We will try to contact those who have not donated this fiscal year in the next 45 days."}}, "resps": [[["-160.0", "False"]], [["-163.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-163.0", "False"], ["-163.0", "False"]], "doc_hash": "813536fe43185467f44002a56ddd4fc8286c5e182a3d735514561d74edf3fe82", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 1798, "doc": {"premise": "It means everything to Becky, Stephanie, Marcus and Emily, and students like them.", "hypothesis": "Becky is a 8th grade student.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Yes, Becky is a 8th grade student."}, "gen_args_1": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Also, Becky is a 8th grade student."}, "gen_args_2": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? No, Becky is a 8th grade student."}}, "resps": [[["-131.0", "False"]], [["-135.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-135.0", "False"], ["-133.0", "False"]], "doc_hash": "b4f1e35d2e2de9ba4c3b34a72372f0b9a4932be3b237f949a3a006a4bf36d5f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1806, "doc": {"premise": "And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year.", "hypothesis": "The Civic Theater is fully funded and will turn away any more money.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Yes, The Civic Theater is fully funded and will turn away any more money."}, "gen_args_1": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Also, The Civic Theater is fully funded and will turn away any more money."}, "gen_args_2": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? No, The Civic Theater is fully funded and will turn away any more money."}}, "resps": [[["-160.0", "False"]], [["-162.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-162.0", "False"], ["-156.0", "False"]], "doc_hash": "40663facbfef0346d6e52f29ea27687e882eb40723d90366cb86d7d08efe1fb6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1814, "doc": {"premise": "Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan.", "hypothesis": "The Society cares for little kids.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Yes, The Society cares for little kids."}, "gen_args_1": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? Also, The Society cares for little kids."}, "gen_args_2": {"arg_0": "", "arg_1": " Your support helps the Society maintain quality care of animal and plant collections and to conduct important research on rare species including those in the Species Survival Plan., right? No, The Society cares for little kids."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-167.0", "False"]], "doc_hash": "0561e3d8c0e677f8c35bccd9bf187bb02ad57bb11ab62326ecda2eae1684353b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 1822, "doc": {"premise": "Provide a professional atmosphere for many talented community actors to hone and perfect their skills.", "hypothesis": "Most professional actors started in the community theaters.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Yes, Most professional actors started in the community theaters."}, "gen_args_1": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Also, Most professional actors started in the community theaters."}, "gen_args_2": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? No, Most professional actors started in the community theaters."}}, "resps": [[["-136.0", "False"]], [["-137.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-137.0", "False"], ["-138.0", "False"]], "doc_hash": "7782801a88aec471db38bd861cd5ded901bcbeb5641f05924d7801ba2b21020e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 1830, "doc": {"premise": "We need resources to recruit and develop outstanding teachers.", "hypothesis": "We don't need to recruit teachers, they just come to us.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Yes, We don't need to recruit teachers, they just come to us."}, "gen_args_1": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Also, We don't need to recruit teachers, they just come to us."}, "gen_args_2": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? No, We don't need to recruit teachers, they just come to us."}}, "resps": [[["-102.0", "False"]], [["-104.5", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-102.0", "False"], ["-104.5", "False"], ["-100.5", "False"]], "doc_hash": "3970383579506a894963ee043fc94074e8da8a64d5100591319e459e21056fb9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17973411 0.01475347 0.80551241]"]}
{"doc_id": 1838, "doc": {"premise": "Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves.", "hypothesis": "The rug is beige.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Yes, The rug is beige."}, "gen_args_1": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? Also, The rug is beige."}, "gen_args_2": {"arg_0": "", "arg_1": " Laurel wreaths, symbolizing victory, and olive branches symbolizing peace, also adorn the rug's border along with acanthus leaves., right? No, The rug is beige."}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-137.0", "False"]], "doc_hash": "7a0a9d40ff3d8d9d8d07e081c95069d953e1c2593bdde71e8ff5507108b8a2a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 1846, "doc": {"premise": "You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate.", "hypothesis": "It costs $30 to be a member for the next two years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Yes, It costs $30 to be a member for the next two years."}, "gen_args_1": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Also, It costs $30 to be a member for the next two years."}, "gen_args_2": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? No, It costs $30 to be a member for the next two years."}}, "resps": [[["-136.0", "False"]], [["-142.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-142.0", "False"], ["-140.0", "False"]], "doc_hash": "49cf1f23418544ec5b4b59cd42f122be5de18a0711e88112807265e821bd7269", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 1854, "doc": {"premise": "Will you add your dreams to ours?", "hypothesis": "We discourage you from dreaming with us.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Yes, We discourage you from dreaming with us."}, "gen_args_1": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Also, We discourage you from dreaming with us."}, "gen_args_2": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? No, We discourage you from dreaming with us."}}, "resps": [[["-98.5", "False"]], [["-101.5", "False"]], [["-96.5", "False"]]], "filtered_resps": [["-98.5", "False"], ["-101.5", "False"], ["-96.5", "False"]], "doc_hash": "29d089f32eb694a571e6e90e8aaf5a9efbc5cf78280d29e1267181611d16e517", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1862, "doc": {"premise": "The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!", "hypothesis": "Without your organization these awesome connections would have never been formed.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Yes, Without your organization these awesome connections would have never been formed."}, "gen_args_1": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? Also, Without your organization these awesome connections would have never been formed."}, "gen_args_2": {"arg_0": "", "arg_1": " The wonderful connections formed each day are made possible through the support of Society operations by organizations like yours!, right? No, Without your organization these awesome connections would have never been formed."}}, "resps": [[["-165.0", "False"]], [["-168.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-168.0", "False"], ["-166.0", "False"]], "doc_hash": "b948f02b6e6044dfe3bc731efedc99f996bca472d29e585bb2ef8b5a3ecfa33e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1870, "doc": {"premise": "Last year, you generously donated $-.", "hypothesis": "You donated $10,000 last year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Yes, You donated $10,000 last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Also, You donated $10,000 last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? No, You donated $10,000 last year."}}, "resps": [[["-91.0", "False"]], [["-95.5", "False"]], [["-91.0", "False"]]], "filtered_resps": [["-91.0", "False"], ["-95.5", "False"], ["-91.0", "False"]], "doc_hash": "de51057742748685af8aad5c2d4ffcb652748e43c4a62dd6d4462418fcfd1681", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49723809 0.00552382 0.49723809]"]}
{"doc_id": 1878, "doc": {"premise": "I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support.", "hypothesis": "I am asking you to donate $10.00 to the ASPCA.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Yes, I am asking you to donate $10.00 to the ASPCA."}, "gen_args_1": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Also, I am asking you to donate $10.00 to the ASPCA."}, "gen_args_2": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? No, I am asking you to donate $10.00 to the ASPCA."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-137.0", "False"]], "doc_hash": "ef58f6cccaf1766d6fb0363ffe62fff084850a4504bbd1bb3a6c103c626949bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1886, "doc": {"premise": "It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!", "hypothesis": "You should visit your school and see what we've been up to.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Yes, You should visit your school and see what we've been up to."}, "gen_args_1": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? Also, You should visit your school and see what we've been up to."}, "gen_args_2": {"arg_0": "", "arg_1": " It would be wonderful if you could take the time to visit your School, and see for yourself the progress we have made over the years and share in the pride of our heritage!, right? No, You should visit your school and see what we've been up to."}}, "resps": [[["-151.0", "False"]], [["-158.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-158.0", "False"], ["-155.0", "False"]], "doc_hash": "e999f84e0c24774de672bebee22df23f0cd15ba634c7139cfa6aadd8b94e8372", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81135202e-01 8.94679497e-04 1.79701181e-02]"]}
{"doc_id": 1894, "doc": {"premise": "Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you.", "hypothesis": "People give us money to help us fill the $1million budget gap.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Yes, People give us money to help us fill the $1million budget gap."}, "gen_args_1": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Also, People give us money to help us fill the $1million budget gap."}, "gen_args_2": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? No, People give us money to help us fill the $1million budget gap."}}, "resps": [[["-207.0", "False"]], [["-210.0", "False"]], [["-208.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-210.0", "False"], ["-208.0", "False"]], "doc_hash": "c8ae05b9206ab2580ce2359d032205348799a901d24b6ee5b35e78a814627288", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1902, "doc": {"premise": "We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself.", "hypothesis": "The majority of that money is from ticket sales.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Yes, The majority of that money is from ticket sales."}, "gen_args_1": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Also, The majority of that money is from ticket sales."}, "gen_args_2": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? No, The majority of that money is from ticket sales."}}, "resps": [[["-157.0", "False"]], [["-161.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-161.0", "False"], ["-156.0", "False"]], "doc_hash": "374e5f818577bbef70cd0c3f4f1672cbf261f7d2405b813f10abffe10c5ba103", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1910, "doc": {"premise": "If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed.", "hypothesis": "The Salvation Army helps anyone who needs it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Yes, The Salvation Army helps anyone who needs it."}, "gen_args_1": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? Also, The Salvation Army helps anyone who needs it."}, "gen_args_2": {"arg_0": "", "arg_1": " If The Salvation Army's Red Shield could talk, it might tell you how we recently helped a man with diabetes get the insulin he needed., right? No, The Salvation Army helps anyone who needs it."}}, "resps": [[["-128.0", "False"]], [["-132.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-128.0", "False"], ["-132.0", "False"], ["-129.0", "False"]], "doc_hash": "9085ab0c3cacbed9989a878ee664d3f261e23184bc9c35c1582acbae0b52af8c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1918, "doc": {"premise": "Very soon, a friend of the IRT will be calling you to take your pledge over the phone.", "hypothesis": "You can give money over the phone.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Yes, You can give money over the phone."}, "gen_args_1": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Also, You can give money over the phone."}, "gen_args_2": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? No, You can give money over the phone."}}, "resps": [[["-119.5", "False"]], [["-124.0", "False"]], [["-123.5", "False"]]], "filtered_resps": [["-119.5", "False"], ["-124.0", "False"], ["-123.5", "False"]], "doc_hash": "8d098b06bc47bcebca038819ab6814c066acdd35c798762f1946fc340e551042", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97141643 0.01079146 0.01779211]"]}
{"doc_id": 1926, "doc": {"premise": "The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research.", "hypothesis": "Loren Field is the chief scientist at the school", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Yes, Loren Field is the chief scientist at the school"}, "gen_args_1": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Also, Loren Field is the chief scientist at the school"}, "gen_args_2": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? No, Loren Field is the chief scientist at the school"}}, "resps": [[["-191.0", "False"]], [["-195.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-195.0", "False"], ["-194.0", "False"]], "doc_hash": "5bcfb9c578ea59adc1c6038874fc32d8cb36d4f33f21d0482c5e67f12e0f5b1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1934, "doc": {"premise": "The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school.", "hypothesis": "Indiana's state dental association has pledged $1million to the dental school.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Yes, Indiana's state dental association has pledged $1million to the dental school."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? Also, Indiana's state dental association has pledged $1million to the dental school."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indiana Dental Association Distinguished Chair will represent the first state dental association in the country to complete such a commitment to its dental school., right? No, Indiana's state dental association has pledged $1million to the dental school."}}, "resps": [[["-168.0", "False"]], [["-171.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-171.0", "False"], ["-169.0", "False"]], "doc_hash": "414d2bcad29aa5780b38bcd5a351f4d0b31bb41e3468fcef89bacc250ebff2bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1942, "doc": {"premise": "Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters.", "hypothesis": "Members get a discount when they buy things at the gift shop.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Yes, Members get a discount when they buy things at the gift shop."}, "gen_args_1": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Also, Members get a discount when they buy things at the gift shop."}, "gen_args_2": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? No, Members get a discount when they buy things at the gift shop."}}, "resps": [[["-173.0", "False"]], [["-180.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-180.0", "False"], ["-178.0", "False"]], "doc_hash": "d09b91f6c923b9fdb5ecf3d0418f49af58942fc677f2ef09ff71f758211b482c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92408247e-01 9.04959183e-04 6.68679417e-03]"]}
{"doc_id": 1950, "doc": {"premise": "Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre.", "hypothesis": "IRT artists don't do anything with kids and instead focus on adults in the community.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Yes, IRT artists don't do anything with kids and instead focus on adults in the community."}, "gen_args_1": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Also, IRT artists don't do anything with kids and instead focus on adults in the community."}, "gen_args_2": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? No, IRT artists don't do anything with kids and instead focus on adults in the community."}}, "resps": [[["-173.0", "False"]], [["-172.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-172.0", "False"], ["-165.0", "False"]], "doc_hash": "5bf6189ca6ff3561c99b688595ae2367b8a40aeebc7aa96c4e5257e280c8c349", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35044712e-04 9.10745952e-04 9.98754209e-01]"]}
{"doc_id": 1958, "doc": {"premise": "If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today.", "hypothesis": "Bob Lovell is working on the campaign for the next year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Yes, Bob Lovell is working on the campaign for the next year."}, "gen_args_1": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? Also, Bob Lovell is working on the campaign for the next year."}, "gen_args_2": {"arg_0": "", "arg_1": " If you have questions or suggestions, please call either myself (924-5471) or Bob Lovell (274-0622) today., right? No, Bob Lovell is working on the campaign for the next year."}}, "resps": [[["-167.0", "False"]], [["-171.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-171.0", "False"], ["-168.0", "False"]], "doc_hash": "0ba39810b74476b244e837fbd2b2524b6f73142d484f7a87c61d4c003e1560e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1966, "doc": {"premise": "Your name or other inscription of your choice will be engraved on a plaque and.", "hypothesis": "Your message is engraved on the plaque if you donate more than $100.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Yes, Your message is engraved on the plaque if you donate more than $100."}, "gen_args_1": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Also, Your message is engraved on the plaque if you donate more than $100."}, "gen_args_2": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? No, Your message is engraved on the plaque if you donate more than $100."}}, "resps": [[["-122.5", "False"]], [["-129.0", "False"]], [["-124.5", "False"]]], "filtered_resps": [["-122.5", "False"], ["-129.0", "False"], ["-124.5", "False"]], "doc_hash": "b46e88afa0b3cc4e35236c942de2fac7d25ec51a951a191ec25d7b1f6305f6e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.87963225 0.00132247 0.11904528]"]}
{"doc_id": 1974, "doc": {"premise": "P. S. A tribute donation to the IMA makes a wonderful holiday gift.", "hypothesis": "A donation in honor of someone is not appropriate for this particular type of fund.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Yes, A donation in honor of someone is not appropriate for this particular type of fund."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Also, A donation in honor of someone is not appropriate for this particular type of fund."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? No, A donation in honor of someone is not appropriate for this particular type of fund."}}, "resps": [[["-144.0", "False"]], [["-146.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-146.0", "False"], ["-140.0", "False"]], "doc_hash": "6f2a4e4a59756fe3950974be4f8f639ec1b149ac4f23024c6aa84a8eca96cc15", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1982, "doc": {"premise": "Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education.", "hypothesis": "The IU School of law was shut down long ago.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Yes, The IU School of law was shut down long ago."}, "gen_args_1": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? Also, The IU School of law was shut down long ago."}, "gen_args_2": {"arg_0": "", "arg_1": " Graduates of the I. U .School of Law-Indianapolis leave with fundamental lawyering skills and a sound legal education., right? No, The IU School of law was shut down long ago."}}, "resps": [[["-173.0", "False"]], [["-176.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-176.0", "False"], ["-170.0", "False"]], "doc_hash": "24b580befdea892f61eaf55c61b813d842fabe4d15b3c7dd7ab9bb599647f8b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1990, "doc": {"premise": "Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment.", "hypothesis": "You colleagues are happy to emulate your good judgment.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Yes, You colleagues are happy to emulate your good judgment."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Also, You colleagues are happy to emulate your good judgment."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? No, You colleagues are happy to emulate your good judgment."}}, "resps": [[["-134.0", "False"]], [["-134.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-134.0", "False"], ["-137.0", "False"]], "doc_hash": "08ddbd5479e8c52df449fbad32c6a1d117f7b40028cf08573f86bba64a532a77", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 1998, "doc": {"premise": "There is one detail of Southern japes that has inverted its class associations.", "hypothesis": "Southern japes has a population of five thousand in the summer and two thousand in the winter.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Yes, Southern japes has a population of five thousand in the summer and two thousand in the winter."}, "gen_args_1": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Also, Southern japes has a population of five thousand in the summer and two thousand in the winter."}, "gen_args_2": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? No, Southern japes has a population of five thousand in the summer and two thousand in the winter."}}, "resps": [[["-165.0", "False"]], [["-161.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-161.0", "False"], ["-163.0", "False"]], "doc_hash": "444bd6bdf738354b6c9cb6dc1649d9ec06ff11321f6b953855d1eabe2d4b48d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.01587624 0.86681333 0.11731043]"]}
{"doc_id": 2006, "doc": {"premise": "Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age.", "hypothesis": "Time magazine is running a story about Bill Gates and success in the digital age.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Yes, Time magazine is running a story about Bill Gates and success in the digital age."}, "gen_args_1": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? Also, Time magazine is running a story about Bill Gates and success in the digital age."}, "gen_args_2": {"arg_0": "", "arg_1": " Time 's cover story is Bill Gates' 12-step program for succeeding in the digital age., right? No, Time magazine is running a story about Bill Gates and success in the digital age."}}, "resps": [[["-127.0", "False"]], [["-131.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-127.0", "False"], ["-131.0", "False"], ["-132.0", "False"]], "doc_hash": "14051bd034e37a2eb3cb13397d669c945c7d4958a5050477b6b861149c769438", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 2014, "doc": {"premise": "With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux.", "hypothesis": "I was having trouble getting Linux to connect to my modem.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Yes, I was having trouble getting Linux to connect to my modem."}, "gen_args_1": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Also, I was having trouble getting Linux to connect to my modem."}, "gen_args_2": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? No, I was having trouble getting Linux to connect to my modem."}}, "resps": [[["-182.0", "False"]], [["-179.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-179.0", "False"], ["-180.0", "False"]], "doc_hash": "41f613136ef2781357101e3e020a57409fdf9d731b1e6be4cef00c6833f27872", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.03511903 0.70538451 0.25949646]"]}
{"doc_id": 2022, "doc": {"premise": "Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre.", "hypothesis": "Most people have heard the Tripp recordings.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Yes, Most people have heard the Tripp recordings."}, "gen_args_1": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Also, Most people have heard the Tripp recordings."}, "gen_args_2": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? No, Most people have heard the Tripp recordings."}}, "resps": [[["-157.0", "False"]], [["-158.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-158.0", "False"], ["-158.0", "False"]], "doc_hash": "9cf25c6e169eceaa66e7d2689ae26b0f10557cfb7cf49af29c95ce566b56f15d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2030, "doc": {"premise": "Which is more than the News Quiz can promise about Fox.", "hypothesis": "It's probably more than News Quiz can say about Fox/", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Yes, It's probably more than News Quiz can say about Fox/"}, "gen_args_1": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? Also, It's probably more than News Quiz can say about Fox/"}, "gen_args_2": {"arg_0": "", "arg_1": " Which is more than the News Quiz can promise about Fox., right? No, It's probably more than News Quiz can say about Fox/"}}, "resps": [[["-131.0", "False"]], [["-132.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-132.0", "False"], ["-131.0", "False"]], "doc_hash": "42862e3aee91f073eb060f1a69c3f2b8d8dfe6f755514a05b38aa721e722386e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2038, "doc": {"premise": "Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee.", "hypothesis": "Bradley was from Missouri.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Yes, Bradley was from Missouri."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Also, Bradley was from Missouri."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? No, Bradley was from Missouri."}}, "resps": [[["-154.0", "False"]], [["-157.0", "False"]], [["-154.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-157.0", "False"], ["-154.0", "False"]], "doc_hash": "e3f9b98217cc12faabe2cdbc41855f4d661454140fb07f301659067b26fa9b1d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2046, "doc": {"premise": "Why doesn't this apply on the Web?", "hypothesis": "This applies on the web.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Yes, This applies on the web."}, "gen_args_1": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Also, This applies on the web."}, "gen_args_2": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? No, This applies on the web."}}, "resps": [[["-79.0", "False"]], [["-87.5", "False"]], [["-80.5", "False"]]], "filtered_resps": [["-79.0", "False"], ["-87.5", "False"], ["-80.5", "False"]], "doc_hash": "a5392d2bb1c62ec7d994093bb698cd9dc1a81ef6a8ba75d0699946b86d4c02aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[8.17438495e-01 1.66322877e-04 1.82395182e-01]"]}
{"doc_id": 2054, "doc": {"premise": "Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed.", "hypothesis": "There is enough evidence to arrest Jon Benet Ramsey's half brother as the murderer.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Yes, There is enough evidence to arrest Jon Benet Ramsey's half brother as the murderer."}, "gen_args_1": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? Also, There is enough evidence to arrest Jon Benet Ramsey's half brother as the murderer."}, "gen_args_2": {"arg_0": "", "arg_1": " Police announced that they have ruled out JonBenet Ramsey's half-brother and half-sister as suspects in her murder, evidently because both were out of town when the crime was committed., right? No, There is enough evidence to arrest Jon Benet Ramsey's half brother as the murderer."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-162.0", "False"]], "doc_hash": "44cb0cc489bd8757a9a7b769884d6dc3e4c485065b57d5e285a12dbf43d0fe22", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2062, "doc": {"premise": "One day, the technology that today creates a market for visionaries will be as mundane as light bulbs.", "hypothesis": "Technology is always fun!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Yes, Technology is always fun!"}, "gen_args_1": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Also, Technology is always fun!"}, "gen_args_2": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? No, Technology is always fun!"}}, "resps": [[["-136.0", "False"]], [["-138.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-138.0", "False"], ["-133.0", "False"]], "doc_hash": "104244257753c677cb900ab44cd27718aa50419348b9ed61c0deda68d40709a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 2070, "doc": {"premise": "The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat.", "hypothesis": "Some students might have cheated at Edinburgh University.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Yes, Some students might have cheated at Edinburgh University."}, "gen_args_1": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Also, Some students might have cheated at Edinburgh University."}, "gen_args_2": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? No, Some students might have cheated at Edinburgh University."}}, "resps": [[["-157.0", "False"]], [["-157.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-157.0", "False"], ["-157.0", "False"]], "doc_hash": "ca0d28dbe67ce9c9d50dd782f9946702934f1d9d55226d976a45abc07fce9bc0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2078, "doc": {"premise": "Thank You, Sir, Could I Have Another Answer", "hypothesis": "You will need to give me five answers in total, Sir.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Yes, You will need to give me five answers in total, Sir."}, "gen_args_1": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? Also, You will need to give me five answers in total, Sir."}, "gen_args_2": {"arg_0": "", "arg_1": " Thank You, Sir, Could I Have Another Answer, right? No, You will need to give me five answers in total, Sir."}}, "resps": [[["-114.0", "False"]], [["-118.5", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-118.5", "False"], ["-109.5", "False"]], "doc_hash": "101e236e03bbcf4834a1fb3d8c1f75e200efee5f5419ff21251d87e60ba64e06", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[1.09856018e-02 1.22039012e-04 9.88892359e-01]"]}
{"doc_id": 2086, "doc": {"premise": "Why is the consistent solution the right solution?", "hypothesis": "When it comes to waste removal why is the consistent solution correct?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Yes, When it comes to waste removal why is the consistent solution correct?"}, "gen_args_1": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Also, When it comes to waste removal why is the consistent solution correct?"}, "gen_args_2": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? No, When it comes to waste removal why is the consistent solution correct?"}}, "resps": [[["-109.0", "False"]], [["-116.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-116.0", "False"], ["-111.0", "False"]], "doc_hash": "85093fb991fdb2b76275c150bd23153970fdc777e926c3ed937fdba45f09466f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 2094, "doc": {"premise": "She was a big-haired brunette with a fleshy face, full lips, and large teeth.", "hypothesis": "She had brunette hair and some teeth in her mouth.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Yes, She had brunette hair and some teeth in her mouth."}, "gen_args_1": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Also, She had brunette hair and some teeth in her mouth."}, "gen_args_2": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? No, She had brunette hair and some teeth in her mouth."}}, "resps": [[["-129.0", "False"]], [["-132.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-132.0", "False"], ["-128.0", "False"]], "doc_hash": "2e861798147ef28db5e3eedc093a1e564b1e9fc5291127c19c2844484b22fa07", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2102, "doc": {"premise": "Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason.", "hypothesis": "There is no way to reconcile faith and reason.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Yes, There is no way to reconcile faith and reason."}, "gen_args_1": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? Also, There is no way to reconcile faith and reason."}, "gen_args_2": {"arg_0": "", "arg_1": " Though this approach will seem quite reasonable to rationalists, it is one of the more controversial approaches to reconciling faith and reason., right? No, There is no way to reconcile faith and reason."}}, "resps": [[["-134.0", "False"]], [["-136.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-136.0", "False"], ["-133.0", "False"]], "doc_hash": "e86db6e63d7975e6f08d826101a8bdb9aa961a70fc4301cad9c5551ba8c153bb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 2110, "doc": {"premise": "Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft.", "hypothesis": "Dickenson wrote poems about love.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Yes, Dickenson wrote poems about love."}, "gen_args_1": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Also, Dickenson wrote poems about love."}, "gen_args_2": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? No, Dickenson wrote poems about love."}}, "resps": [[["-145.0", "False"]], [["-146.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-146.0", "False"], ["-145.0", "False"]], "doc_hash": "120770d019e04939168c0092161a726041819f8244452a788252264a328c4817", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2118, "doc": {"premise": "Like Ross, Mehta struggles to express William Shawn's ineffable virtues.", "hypothesis": "Both Mehta and Ross have a tough time expressing Willliam Shawn's virtues.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Yes, Both Mehta and Ross have a tough time expressing Willliam Shawn's virtues."}, "gen_args_1": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Also, Both Mehta and Ross have a tough time expressing Willliam Shawn's virtues."}, "gen_args_2": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? No, Both Mehta and Ross have a tough time expressing Willliam Shawn's virtues."}}, "resps": [[["-157.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "2a2b6b691d31ce4e33ad6aa17194915931346533df8225f80679f6da838c0095", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 2126, "doc": {"premise": "On the other hand, he's got Mark Twain between him and daylight.", "hypothesis": "Mark Twain stands between the daylight and him.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Yes, Mark Twain stands between the daylight and him."}, "gen_args_1": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? Also, Mark Twain stands between the daylight and him."}, "gen_args_2": {"arg_0": "", "arg_1": " On the other hand, he's got Mark Twain between him and daylight., right? No, Mark Twain stands between the daylight and him."}}, "resps": [[["-114.5", "False"]], [["-119.5", "False"]], [["-114.0", "False"]]], "filtered_resps": [["-114.5", "False"], ["-119.5", "False"], ["-114.0", "False"]], "doc_hash": "7cb210f94b894519d9f565943ada190a13a232c4d3fcc502893dff97b5bfef83", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.3765827  0.00253739 0.62087991]"]}
{"doc_id": 2134, "doc": {"premise": "Why would human beings have Laibson-style preferences in the first place?", "hypothesis": "I don't know why humans would have Laibson style preferences.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Yes, I don't know why humans would have Laibson style preferences."}, "gen_args_1": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Also, I don't know why humans would have Laibson style preferences."}, "gen_args_2": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? No, I don't know why humans would have Laibson style preferences."}}, "resps": [[["-114.0", "False"]], [["-117.0", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-117.0", "False"], ["-111.5", "False"]], "doc_hash": "3fcf0b167414b49ea3733cec4ae8b3dd4b7bc0cca7525e452560509acb6cf3ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 2142, "doc": {"premise": "John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting.", "hypothesis": "It is obvious John Horgan never read the book, Climbing Mount Impossible (The Mystery of Life).", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Yes, It is obvious John Horgan never read the book, Climbing Mount Impossible (The Mystery of Life)."}, "gen_args_1": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Also, It is obvious John Horgan never read the book, Climbing Mount Impossible (The Mystery of Life)."}, "gen_args_2": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? No, It is obvious John Horgan never read the book, Climbing Mount Impossible (The Mystery of Life)."}}, "resps": [[["-157.0", "False"]], [["-157.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-157.0", "False"], ["-157.0", "False"]], "doc_hash": "acfefb201bdb85021e451ccd2e1f7b1239958f796d6186634eb9c965e95c6900", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2150, "doc": {"premise": "Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?", "hypothesis": "Clarke knows everything will be fine.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Yes, Clarke knows everything will be fine."}, "gen_args_1": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? Also, Clarke knows everything will be fine."}, "gen_args_2": {"arg_0": "", "arg_1": " Which aspect of our foreign policy does Richard Clarke most fear will be abandoned--standing around while civilians are slaughtered in Rwanda or standing around while civilians are slaughtered in Kosovo?, right? No, Clarke knows everything will be fine."}}, "resps": [[["-178.0", "False"]], [["-178.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-178.0", "False"], ["-173.0", "False"]], "doc_hash": "ddfe8f14c9eafbb9f4c4b41cd209e1273ee248566d5976aef91f87355a88c8d9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 2158, "doc": {"premise": "This man was born in Germany, is wealthy, educated, well-traveled...", "hypothesis": "The rich, schooled, traveled man was born in Germany.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Yes, The rich, schooled, traveled man was born in Germany."}, "gen_args_1": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Also, The rich, schooled, traveled man was born in Germany."}, "gen_args_2": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? No, The rich, schooled, traveled man was born in Germany."}}, "resps": [[["-120.0", "False"]], [["-125.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-120.0", "False"], ["-125.0", "False"], ["-122.0", "False"]], "doc_hash": "c837268c81f781a48f090d9fa172603447d7afb16560cbff603a929b048c5df8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2166, "doc": {"premise": "This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious.", "hypothesis": "Forbes only has supporters.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Yes, Forbes only has supporters."}, "gen_args_1": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Also, Forbes only has supporters."}, "gen_args_2": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? No, Forbes only has supporters."}}, "resps": [[["-137.0", "False"]], [["-138.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-138.0", "False"], ["-136.0", "False"]], "doc_hash": "957f72e8e2d795bbbe7ac3d46b521479a6e98f6cf87992e020c63bea0661f5a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2174, "doc": {"premise": "Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals.", "hypothesis": "There are some exclusively Catholic traditions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Yes, There are some exclusively Catholic traditions."}, "gen_args_1": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? Also, There are some exclusively Catholic traditions."}, "gen_args_2": {"arg_0": "", "arg_1": " Thanks to Vatican II (and one of its little-noted consequences, an ebbing of American anti-Catholicism), Catholics unself-consciously socialize with other Christians and attend their christenings, weddings, and funerals., right? No, There are some exclusively Catholic traditions."}}, "resps": [[["-206.0", "False"]], [["-208.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-206.0", "False"], ["-208.0", "False"], ["-204.0", "False"]], "doc_hash": "16d8416090bf82a6f571583ad6fdfc7018d1d093ad3c2bf91e71c9ee8282fc28", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2182, "doc": {"premise": "The Boston Globe has published a hard-hitting four part series on Harvard University.", "hypothesis": "The Boston Globe has never written about a university.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Yes, The Boston Globe has never written about a university."}, "gen_args_1": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Also, The Boston Globe has never written about a university."}, "gen_args_2": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? No, The Boston Globe has never written about a university."}}, "resps": [[["-113.5", "False"]], [["-115.5", "False"]], [["-108.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-115.5", "False"], ["-108.5", "False"]], "doc_hash": "abfbb296286e957e847fc132ac5e10e49bccb7cbcb0f830b5f4823813bcda406", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 2190, "doc": {"premise": "Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;", "hypothesis": "Intentional irony is more common than unintentional irony.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Yes, Intentional irony is more common than unintentional irony."}, "gen_args_1": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Also, Intentional irony is more common than unintentional irony."}, "gen_args_2": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? No, Intentional irony is more common than unintentional irony."}}, "resps": [[["-169.0", "False"]], [["-167.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-167.0", "False"], ["-170.0", "False"]], "doc_hash": "a54fe0bd17db3adf92d3c118f3925ff42f2a81ae2077ddd0771010d382b5778f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.84379473 0.04201007]"]}
{"doc_id": 2198, "doc": {"premise": "This is no secret to music retailers.", "hypothesis": "Music retailers knew about this issue before the news broke to the public a month ago.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Yes, Music retailers knew about this issue before the news broke to the public a month ago."}, "gen_args_1": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? Also, Music retailers knew about this issue before the news broke to the public a month ago."}, "gen_args_2": {"arg_0": "", "arg_1": " This is no secret to music retailers., right? No, Music retailers knew about this issue before the news broke to the public a month ago."}}, "resps": [[["-116.5", "False"]], [["-121.5", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-121.5", "False"], ["-118.0", "False"]], "doc_hash": "8ad6ce99c0b3e097221c16c198eaea5c3eb008676941aa1f6cec2a3582f50f48", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.81309532 0.00547859 0.18142609]"]}
{"doc_id": 2206, "doc": {"premise": "There is no need to apologize for our leadership role.", "hypothesis": "We have earned the respect and the right to be proud leaders on this subject.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Yes, We have earned the respect and the right to be proud leaders on this subject."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Also, We have earned the respect and the right to be proud leaders on this subject."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? No, We have earned the respect and the right to be proud leaders on this subject."}}, "resps": [[["-114.0", "False"]], [["-120.0", "False"]], [["-114.5", "False"]]], "filtered_resps": [["-114.0", "False"], ["-120.0", "False"], ["-114.5", "False"]], "doc_hash": "d76117c48982da7bd34c655fec2ed9f4ab7e3dff004172fbd01ff0eb006cc96e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.6215004  0.00154055 0.37695905]"]}
{"doc_id": 2214, "doc": {"premise": "The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future.", "hypothesis": "Despite this, the New Yorker has refused to publish any special issues.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Yes, Despite this, the New Yorker has refused to publish any special issues."}, "gen_args_1": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Also, Despite this, the New Yorker has refused to publish any special issues."}, "gen_args_2": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? No, Despite this, the New Yorker has refused to publish any special issues."}}, "resps": [[["-171.0", "False"]], [["-174.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-174.0", "False"], ["-167.0", "False"]], "doc_hash": "32baebff293f89ca12a4a0b214a119217703de85ef5640bfc43b2ae33f18e8fe", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 2222, "doc": {"premise": "What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence.", "hypothesis": "To determine the IQ of the children, Hernstein and Murray used educated and intelligence.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Yes, To determine the IQ of the children, Hernstein and Murray used educated and intelligence."}, "gen_args_1": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? Also, To determine the IQ of the children, Hernstein and Murray used educated and intelligence."}, "gen_args_2": {"arg_0": "", "arg_1": " What Herrnstein and Murray used to measure IQ is actually a measure of education as well as intelligence., right? No, To determine the IQ of the children, Hernstein and Murray used educated and intelligence."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-163.0", "False"]], "doc_hash": "aa5c74657ae0ec9e0877852c7b54745b7baeaab7d2ad3945f269d81c7595b867", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2230, "doc": {"premise": "The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway.", "hypothesis": "The ABM Treaty has saved billions of dollars.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Yes, The ABM Treaty has saved billions of dollars."}, "gen_args_1": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Also, The ABM Treaty has saved billions of dollars."}, "gen_args_2": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? No, The ABM Treaty has saved billions of dollars."}}, "resps": [[["-169.0", "False"]], [["-166.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-166.0", "False"], ["-166.0", "False"]], "doc_hash": "72ebb854e7388d0b41f3fbfa9b92c1259bc5a30e0311cfe252a6fdb06d3c220a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.0242889  0.48785555 0.48785555]"]}
{"doc_id": 2238, "doc": {"premise": "The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them.", "hypothesis": "Decter is so young!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Yes, Decter is so young!"}, "gen_args_1": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Also, Decter is so young!"}, "gen_args_2": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? No, Decter is so young!"}}, "resps": [[["-158.0", "False"]], [["-157.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-157.0", "False"], ["-158.0", "False"]], "doc_hash": "722046e18138d88e5122b0be7ddfa72cdeb3f08779f41323e90bb7d940850fc1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.21194156 0.57611688 0.21194156]"]}
{"doc_id": 2246, "doc": {"premise": "By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less", "hypothesis": "Skeat started to care about different things as he got older.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Yes, Skeat started to care about different things as he got older."}, "gen_args_1": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? Also, Skeat started to care about different things as he got older."}, "gen_args_2": {"arg_0": "", "arg_1": " By the time he entered his sixties, in 1895, Skeat gave the impression that he was beginning to take these matters a little less, right? No, Skeat started to care about different things as he got older."}}, "resps": [[["-153.0", "False"]], [["-157.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-157.0", "False"], ["-158.0", "False"]], "doc_hash": "e83316e11f43c94f9fd6858ff46fbaead1d7af5d31e53471b4f30c4ab2aa1819", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 2254, "doc": {"premise": "..,  but the second time the encounter is  he is caught in the middle between two friends.", "hypothesis": "He only has one encounter, which involves a friend of his.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Yes, He only has one encounter, which involves a friend of his."}, "gen_args_1": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Also, He only has one encounter, which involves a friend of his."}, "gen_args_2": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? No, He only has one encounter, which involves a friend of his."}}, "resps": [[["-167.0", "False"]], [["-166.0", "False"]], [["-166.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-166.0", "False"], ["-166.0", "False"]], "doc_hash": "79c0d08f94c95776eb4d6ad65cf870c9a82759dca1ca9ae955447f8a954e2dd8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 2262, "doc": {"premise": "The last sentence   We assume, of course, that you have not submitted this essay elsewhere.", "hypothesis": "We take it that you have presented this essay to no one else.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Yes, We take it that you have presented this essay to no one else."}, "gen_args_1": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Also, We take it that you have presented this essay to no one else."}, "gen_args_2": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? No, We take it that you have presented this essay to no one else."}}, "resps": [[["-136.0", "False"]], [["-135.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-135.0", "False"], ["-134.0", "False"]], "doc_hash": "d25905d2e73e9e816d1d84167448a034e895a5d05e49380f6a43beae327a9e0d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 2270, "doc": {"premise": "Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096.", "hypothesis": "The first Lingua France was spoken in the Mediterranean.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Yes, The first Lingua France was spoken in the Mediterranean."}, "gen_args_1": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? Also, The first Lingua France was spoken in the Mediterranean."}, "gen_args_2": {"arg_0": "", "arg_1": " Linguists have demonstrated that the first lingua france (called Mediterranean Lingua Franca by many linguists) was actually spoken before the first Crusade began in A.D. 1096., right? No, The first Lingua France was spoken in the Mediterranean."}}, "resps": [[["-174.0", "False"]], [["-178.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-178.0", "False"], ["-179.0", "False"]], "doc_hash": "db7f930d72c4a24c653a7522f2d309a9b0409143bc1ac29292da833018e3e764", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 2278, "doc": {"premise": "We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk.", "hypothesis": "We felt obligated to eat what was put before us because we didn't want to offend our hosts.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Yes, We felt obligated to eat what was put before us because we didn't want to offend our hosts."}, "gen_args_1": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Also, We felt obligated to eat what was put before us because we didn't want to offend our hosts."}, "gen_args_2": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? No, We felt obligated to eat what was put before us because we didn't want to offend our hosts."}}, "resps": [[["-199.0", "False"]], [["-199.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-199.0", "False"], ["-200.0", "False"]], "doc_hash": "7f97557180cd0a3bbe48594ae8558ad1116adf886d696f38f502f0b1c025167e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 2286, "doc": {"premise": "According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations.", "hypothesis": "By my calculations, the ODNW has more information has more information than the blurbs suggest.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Yes, By my calculations, the ODNW has more information has more information than the blurbs suggest."}, "gen_args_1": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Also, By my calculations, the ODNW has more information has more information than the blurbs suggest."}, "gen_args_2": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? No, By my calculations, the ODNW has more information has more information than the blurbs suggest."}}, "resps": [[["-212.0", "False"]], [["-216.0", "False"]], [["-213.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-216.0", "False"], ["-213.0", "False"]], "doc_hash": "db367dc046ea81434cc44e8e555a8dabac4d9eaa0746ed0e3c2c26e5b1b3d4f4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2294, "doc": {"premise": "For example, some have derivations distinctly removed from the equipment used or the court on which the game is played.", "hypothesis": "This often happens when a sport is created using existing equipment from other sports.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Yes, This often happens when a sport is created using existing equipment from other sports."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? Also, This often happens when a sport is created using existing equipment from other sports."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, some have derivations distinctly removed from the equipment used or the court on which the game is played., right? No, This often happens when a sport is created using existing equipment from other sports."}}, "resps": [[["-169.0", "False"]], [["-172.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-172.0", "False"], ["-173.0", "False"]], "doc_hash": "e3ac01713302b03a0dac0dacae3fe3cf0bff15d3d57453ac49aa2a3609feba2f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2302, "doc": {"premise": "But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before.", "hypothesis": "The review covered all information that a reader might need to know.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Yes, The review covered all information that a reader might need to know."}, "gen_args_1": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Also, The review covered all information that a reader might need to know."}, "gen_args_2": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? No, The review covered all information that a reader might need to know."}}, "resps": [[["-156.0", "False"]], [["-160.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-160.0", "False"], ["-155.0", "False"]], "doc_hash": "5c4f818e3f490a50ccf60a924c0931cef97d92ddb421de0761247f7add152d75", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 2310, "doc": {"premise": "But they have one private, hidden name which remains a family secret.", "hypothesis": "A member of the family published a book and revealed all of the family secrets.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Yes, A member of the family published a book and revealed all of the family secrets."}, "gen_args_1": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Also, A member of the family published a book and revealed all of the family secrets."}, "gen_args_2": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? No, A member of the family published a book and revealed all of the family secrets."}}, "resps": [[["-140.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-140.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "a0343621a9fadcc846a30dca722f85a8a49d1f32a387c9d345528ec7c1f4718c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 2318, "doc": {"premise": "But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular.", "hypothesis": "The acknowledgements are not useful.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Yes, The acknowledgements are not useful."}, "gen_args_1": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? Also, The acknowledgements are not useful."}, "gen_args_2": {"arg_0": "", "arg_1": " But such acknowledgments do not qualify as dedications in the sense generally understood and in the book at hand in particular., right? No, The acknowledgements are not useful."}}, "resps": [[["-158.0", "False"]], [["-159.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-159.0", "False"], ["-158.0", "False"]], "doc_hash": "b137dcbb5623c2ca6b288805b2ea2eac88cdd6c6b924a02dbb68909541492010", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2326, "doc": {"premise": "said my wife, raising an eyebrow.", "hypothesis": "My wife raised her eyebrows as she spoke.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Yes, My wife raised her eyebrows as she spoke."}, "gen_args_1": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Also, My wife raised her eyebrows as she spoke."}, "gen_args_2": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? No, My wife raised her eyebrows as she spoke."}}, "resps": [[["-91.0", "False"]], [["-95.0", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-91.0", "False"], ["-95.0", "False"], ["-93.5", "False"]], "doc_hash": "b3bfbc18deff0017486f12a9057a275d883cc68eaa00e5c248458d4ab8141c9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.90875992 0.01664452 0.07459556]"]}
{"doc_id": 2334, "doc": {"premise": "'  It is remarkable that this anomaly still persists, even in many modern sources.", "hypothesis": "The anomaly was eliminated several centuries ago.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Yes, The anomaly was eliminated several centuries ago."}, "gen_args_1": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Also, The anomaly was eliminated several centuries ago."}, "gen_args_2": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? No, The anomaly was eliminated several centuries ago."}}, "resps": [[["-135.0", "False"]], [["-141.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-141.0", "False"], ["-132.0", "False"]], "doc_hash": "939d34cf948f27fc0584c58705fbabad1413d381f76f8202131e95194aa1be76", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 2342, "doc": {"premise": "The equally whimsical nature of the  definitions' defies description.", "hypothesis": "There are seventeen different definitions given.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Yes, There are seventeen different definitions given."}, "gen_args_1": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? Also, There are seventeen different definitions given."}, "gen_args_2": {"arg_0": "", "arg_1": " The equally whimsical nature of the  definitions' defies description., right? No, There are seventeen different definitions given."}}, "resps": [[["-142.0", "False"]], [["-143.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-143.0", "False"], ["-142.0", "False"]], "doc_hash": "3c7db1c2e7a72aa77527aee72f86014dcb71e657a02dc085e4c63bd5a4983db6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2350, "doc": {"premise": "Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line.", "hypothesis": "The love story depicted in the Latin poem explains the reason for the distance between the man and the women in the middle of the first sentence.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Yes, The love story depicted in the Latin poem explains the reason for the distance between the man and the women in the middle of the first sentence."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Also, The love story depicted in the Latin poem explains the reason for the distance between the man and the women in the middle of the first sentence."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? No, The love story depicted in the Latin poem explains the reason for the distance between the man and the women in the middle of the first sentence."}}, "resps": [[["-209.0", "False"]], [["-212.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-209.0", "False"], ["-212.0", "False"], ["-207.0", "False"]], "doc_hash": "7d2845c454fd107cb4fa7bee0dacd2fdf395ef10ff02b0e1d48b403bc85eb272", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2358, "doc": {"premise": "Let it be remembered that they make no declarations.", "hypothesis": "Their written declaration was printed in the newspaper this morning.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Yes, Their written declaration was printed in the newspaper this morning."}, "gen_args_1": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Also, Their written declaration was printed in the newspaper this morning."}, "gen_args_2": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? No, Their written declaration was printed in the newspaper this morning."}}, "resps": [[["-116.5", "False"]], [["-119.5", "False"]], [["-116.5", "False"]]], "filtered_resps": [["-116.5", "False"], ["-119.5", "False"], ["-116.5", "False"]], "doc_hash": "ccd7dad2c5c3c09545dc0b8c4e286e82f6caee97cac8d89d4493f9fa717ee5bc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2366, "doc": {"premise": "Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth.", "hypothesis": "They would be better off if they had someone to interpret.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Yes, They would be better off if they had someone to interpret."}, "gen_args_1": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? Also, They would be better off if they had someone to interpret."}, "gen_args_2": {"arg_0": "", "arg_1": " Persons not conversant with the languages involved will probably have no answers to these rhetorical questions, but I feel sure they will prefer to be spared the obnoxious truth., right? No, They would be better off if they had someone to interpret."}}, "resps": [[["-184.0", "False"]], [["-186.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-186.0", "False"], ["-185.0", "False"]], "doc_hash": "52ce80a75356e139df265363a382a0bb9dc30d4f875fcdd8fa595004c6d2f872", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2374, "doc": {"premise": "It sweeps words in its passage, as well.", "hypothesis": "It sweeps words quickly.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Yes, It sweeps words quickly."}, "gen_args_1": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Also, It sweeps words quickly."}, "gen_args_2": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? No, It sweeps words quickly."}}, "resps": [[["-102.5", "False"]], [["-106.0", "False"]], [["-103.5", "False"]]], "filtered_resps": [["-102.5", "False"], ["-106.0", "False"], ["-103.5", "False"]], "doc_hash": "7c5c83fbbe4038a38b50f1eaa240213ddfe895d517709059ed87b9a2da92921c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 2382, "doc": {"premise": "Many languages have this ambiguity.", "hypothesis": "No other language has this kind of ambiguity.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Yes, No other language has this kind of ambiguity."}, "gen_args_1": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Also, No other language has this kind of ambiguity."}, "gen_args_2": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? No, No other language has this kind of ambiguity."}}, "resps": [[["-84.5", "False"]], [["-85.0", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-84.5", "False"], ["-85.0", "False"], ["-83.0", "False"]], "doc_hash": "31331ccb35a90a31a75c7be7682f10de2f90381f02a5470bba757561913403d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.16425163 0.09962365 0.73612472]"]}
{"doc_id": 2390, "doc": {"premise": "And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?", "hypothesis": "The Kermit telecommunications protocol was named after a frog.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Yes, The Kermit telecommunications protocol was named after a frog."}, "gen_args_1": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? Also, The Kermit telecommunications protocol was named after a frog."}, "gen_args_2": {"arg_0": "", "arg_1": " And how did such a cold and unhuman thing like a telecommunications protocol for transferring files between a mainframe and a microcomputer get dubbed Kermit?, right? No, The Kermit telecommunications protocol was named after a frog."}}, "resps": [[["-169.0", "False"]], [["-174.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-174.0", "False"], ["-168.0", "False"]], "doc_hash": "bd334bba996b5b056e046515723fd26d79da693b452b2b5b84a9b1b72fd3ee14", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 2398, "doc": {"premise": "The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort.", "hypothesis": "Children's words are soft and warm which allays our fears about computers that crash and bomb and abort.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Yes, Children's words are soft and warm which allays our fears about computers that crash and bomb and abort."}, "gen_args_1": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Also, Children's words are soft and warm which allays our fears about computers that crash and bomb and abort."}, "gen_args_2": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? No, Children's words are soft and warm which allays our fears about computers that crash and bomb and abort."}}, "resps": [[["-181.0", "False"]], [["-184.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-184.0", "False"], ["-186.0", "False"]], "doc_hash": "0b8a45450545222cf1ed00f3891dbd43be55387fb8093fda10d665fa84f89542", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.04712342 0.00637746]"]}
{"doc_id": 2406, "doc": {"premise": "RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of.", "hypothesis": "According to RH-II, this expression means to be on the verge of.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Yes, According to RH-II, this expression means to be on the verge of."}, "gen_args_1": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Also, According to RH-II, this expression means to be on the verge of."}, "gen_args_2": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? No, According to RH-II, this expression means to be on the verge of."}}, "resps": [[["-200.0", "False"]], [["-201.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-201.0", "False"], ["-201.0", "False"]], "doc_hash": "a17e920e4a7a5b6c2869e2c63f0b06d53925d2bc8aa219c6413752a67258c810", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2414, "doc": {"premise": "The teacher explained, in terms that she hoped were appropriate to her audience.", "hypothesis": "The teacher tried to explain in audience-appropriate terms.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Yes, The teacher tried to explain in audience-appropriate terms."}, "gen_args_1": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? Also, The teacher tried to explain in audience-appropriate terms."}, "gen_args_2": {"arg_0": "", "arg_1": " The teacher explained, in terms that she hoped were appropriate to her audience., right? No, The teacher tried to explain in audience-appropriate terms."}}, "resps": [[["-116.0", "False"]], [["-119.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-116.0", "False"], ["-119.0", "False"], ["-115.0", "False"]], "doc_hash": "57bce2d53a1c6845c7f5b7d63424de3fe1b00c1ed9e4f82804054176f15abaed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2422, "doc": {"premise": "In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk.", "hypothesis": "The T-shirt that said  O D on Bourgeoisie Milk Boy Milk seemed out of place and confusing in Tokyo.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Yes, The T-shirt that said  O D on Bourgeoisie Milk Boy Milk seemed out of place and confusing in Tokyo."}, "gen_args_1": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Also, The T-shirt that said  O D on Bourgeoisie Milk Boy Milk seemed out of place and confusing in Tokyo."}, "gen_args_2": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? No, The T-shirt that said  O D on Bourgeoisie Milk Boy Milk seemed out of place and confusing in Tokyo."}}, "resps": [[["-229.0", "False"]], [["-232.0", "False"]], [["-233.0", "False"]]], "filtered_resps": [["-229.0", "False"], ["-232.0", "False"], ["-233.0", "False"]], "doc_hash": "65573d0e35cbe9e8144c28e699d8aaa8263d2a38c7e093debf581a262f78cc08", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.04661262 0.01714783]"]}
{"doc_id": 2430, "doc": {"premise": "The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament.", "hypothesis": "The King James Bible contains both the Old and the New Testament.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Yes, The King James Bible contains both the Old and the New Testament."}, "gen_args_1": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Also, The King James Bible contains both the Old and the New Testament."}, "gen_args_2": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? No, The King James Bible contains both the Old and the New Testament."}}, "resps": [[["-121.0", "False"]], [["-127.5", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-127.5", "False"], ["-119.0", "False"]], "doc_hash": "fc470c91139af30a13f29fdbc9cbd8d493de219a01b81232cd6eccd35d0564c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[1.19181563e-01 1.79182233e-04 8.80639255e-01]"]}
{"doc_id": 2438, "doc": {"premise": "'  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist.", "hypothesis": "A dictionary requires only a specialist's skills.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Yes, A dictionary requires only a specialist's skills."}, "gen_args_1": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? Also, A dictionary requires only a specialist's skills."}, "gen_args_2": {"arg_0": "", "arg_1": " '  My further point is that to be totally successful, a dictionary of this kind requires far more than the academic skills of a place-name specialist., right? No, A dictionary requires only a specialist's skills."}}, "resps": [[["-187.0", "False"]], [["-194.0", "False"]], [["-187.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-194.0", "False"], ["-187.0", "False"]], "doc_hash": "846343051d66abddf77232847bbbfa4e39aa4e863712c7bcece543db3c6ccbf0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 2446, "doc": {"premise": "Words that do not fit cannot be returned.", "hypothesis": "Some words do not fit in the puzzle.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Yes, Some words do not fit in the puzzle."}, "gen_args_1": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Also, Some words do not fit in the puzzle."}, "gen_args_2": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? No, Some words do not fit in the puzzle."}}, "resps": [[["-94.0", "False"]], [["-97.0", "False"]], [["-94.5", "False"]]], "filtered_resps": [["-94.0", "False"], ["-97.0", "False"], ["-94.5", "False"]], "doc_hash": "547a6886f4d10951572d9b97a2eff738887e16a96093226e7aa5cdbe0048d7f5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.6037489  0.03005889 0.36619222]"]}
{"doc_id": 2454, "doc": {"premise": "These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source.", "hypothesis": "Cables are a much more prestigious word than wires whenever in a trade.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Yes, Cables are a much more prestigious word than wires whenever in a trade."}, "gen_args_1": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Also, Cables are a much more prestigious word than wires whenever in a trade."}, "gen_args_2": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? No, Cables are a much more prestigious word than wires whenever in a trade."}}, "resps": [[["-204.0", "False"]], [["-207.0", "False"]], [["-205.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-207.0", "False"], ["-205.0", "False"]], "doc_hash": "d6515ec9c5910d52c220426070e6ec0b5b2926fa18b8bd6e06fe40d1cfdedfc9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 2462, "doc": {"premise": "I have yet Room for six scotches more.", "hypothesis": "Six more scotches on the rocks will do just fine.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Yes, Six more scotches on the rocks will do just fine."}, "gen_args_1": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? Also, Six more scotches on the rocks will do just fine."}, "gen_args_2": {"arg_0": "", "arg_1": " I have yet Room for six scotches more., right? No, Six more scotches on the rocks will do just fine."}}, "resps": [[["-120.5", "False"]], [["-128.0", "False"]], [["-122.5", "False"]]], "filtered_resps": [["-120.5", "False"], ["-128.0", "False"], ["-122.5", "False"]], "doc_hash": "eacbc35f6dc9f6f564c59df100293f072def0497fb4e4ac8fd4d9f2b6259dbef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80368202e-01 4.86917893e-04 1.19144880e-01]"]}
{"doc_id": 2470, "doc": {"premise": "Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World.", "hypothesis": "There is more information in the Webster's College than New World.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Yes, There is more information in the Webster's College than New World."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Also, There is more information in the Webster's College than New World."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? No, There is more information in the Webster's College than New World."}}, "resps": [[["-179.0", "False"]], [["-179.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-179.0", "False"], ["-182.0", "False"]], "doc_hash": "1049e489110708b843b37c57f36d7a04e5c8936fed9a09af23a10c320ec4e893", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.48785555 0.0242889 ]"]}
{"doc_id": 2478, "doc": {"premise": "John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip.", "hypothesis": "John Burke dislikes Boswell.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Yes, John Burke dislikes Boswell."}, "gen_args_1": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Also, John Burke dislikes Boswell."}, "gen_args_2": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? No, John Burke dislikes Boswell."}}, "resps": [[["-222.0", "False"]], [["-223.0", "False"]], [["-220.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-223.0", "False"], ["-220.0", "False"]], "doc_hash": "450e7879581512d42dc0626c8b43cfa5feee70ec804c3f6fdb4c3236067c8d5c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 2486, "doc": {"premise": "Feisty, like fizzle, began as Middle English fysten, fisten `to fart.", "hypothesis": "Fiesty is unrelated to fisten.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Yes, Fiesty is unrelated to fisten."}, "gen_args_1": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? Also, Fiesty is unrelated to fisten."}, "gen_args_2": {"arg_0": "", "arg_1": " Feisty, like fizzle, began as Middle English fysten, fisten `to fart., right? No, Fiesty is unrelated to fisten."}}, "resps": [[["-171.0", "False"]], [["-171.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-171.0", "False"], ["-165.0", "False"]], "doc_hash": "2cca04873119d5147b5acd963555f1aba8f1ff5ca89fccff3aa71dcbc5f1f62f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 7, "doc": {"premise": "He didn't get to go.", "hypothesis": "He wasn't allowed to attend.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He didn't get to go., right? Yes, He wasn't allowed to attend."}, "gen_args_1": {"arg_0": "", "arg_1": " He didn't get to go., right? Also, He wasn't allowed to attend."}, "gen_args_2": {"arg_0": "", "arg_1": " He didn't get to go., right? No, He wasn't allowed to attend."}}, "resps": [[["-70.5", "False"]], [["-75.5", "False"]], [["-70.5", "False"]]], "filtered_resps": [["-70.5", "False"], ["-75.5", "False"], ["-70.5", "False"]], "doc_hash": "5b0ac88cbcb41ea1aea882feff905b46f1237022842a89c24f2242371be5bda2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 15, "doc": {"premise": "And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white.", "hypothesis": "They continued to visit every day.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Yes, They continued to visit every day."}, "gen_args_1": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? Also, They continued to visit every day."}, "gen_args_2": {"arg_0": "", "arg_1": " And, uh, they kind of actually stopped visiting the family because they were just, just determined that they were going to be white., right? No, They continued to visit every day."}}, "resps": [[["-160.0", "False"]], [["-166.0", "False"]], [["-156.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-166.0", "False"], ["-156.0", "False"]], "doc_hash": "9f90841e969a1b2bdbcd9c768bdc3f8ae9d1bd454bb1e83a1d38a0a4abb9318e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79854081e-02 4.45813695e-05 9.81970011e-01]"]}
{"doc_id": 23, "doc": {"premise": "Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well.", "hypothesis": "Santo worked for Disney and operated the tea cups.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Yes, Santo worked for Disney and operated the tea cups."}, "gen_args_1": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? Also, Santo worked for Disney and operated the tea cups."}, "gen_args_2": {"arg_0": "", "arg_1": " Michael Santo of, of Firewell and Company, of Buffalo, NY, they was the one that uh, manufactured, uh, invented the high O2 regulator before that they built fire control on the stove well., right? No, Santo worked for Disney and operated the tea cups."}}, "resps": [[["-316.0", "False"]], [["-314.0", "False"]], [["-314.0", "False"]]], "filtered_resps": [["-316.0", "False"], ["-314.0", "False"], ["-314.0", "False"]], "doc_hash": "ad666150edbaef2229726c838f39be6e9c23b22d3b45447e7d4b8e4109a09cf6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 31, "doc": {"premise": "Now that's how, uh, I stay buckled in.", "hypothesis": "That is exactly how I was unhooked.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Yes, That is exactly how I was unhooked."}, "gen_args_1": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? Also, That is exactly how I was unhooked."}, "gen_args_2": {"arg_0": "", "arg_1": " Now that's how, uh, I stay buckled in., right? No, That is exactly how I was unhooked."}}, "resps": [[["-116.5", "False"]], [["-122.0", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-122.0", "False"], ["-117.0", "False"]], "doc_hash": "9d1a40355ce3050b26bbee1b93cf2086dee363e0ca3dcf99a85f1c53442f94bd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.62087991 0.00253739 0.3765827 ]"]}
{"doc_id": 39, "doc": {"premise": "And, she didn't really understand.", "hypothesis": "Alas, she was not able to understand clearly due to a language barrier.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Yes, Alas, she was not able to understand clearly due to a language barrier."}, "gen_args_1": {"arg_0": "", "arg_1": " And, she didn't really understand., right? Also, Alas, she was not able to understand clearly due to a language barrier."}, "gen_args_2": {"arg_0": "", "arg_1": " And, she didn't really understand., right? No, Alas, she was not able to understand clearly due to a language barrier."}}, "resps": [[["-103.5", "False"]], [["-109.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-103.5", "False"], ["-109.5", "False"], ["-105.0", "False"]], "doc_hash": "668476425f859742fb9840bc64890adc3621e5cfd17bc63c0f8b6ca271e0ecbd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.81592096 0.00202247 0.18205657]"]}
{"doc_id": 47, "doc": {"premise": "Only lost two, three aircraft while we was there, and, uh, test phase.", "hypothesis": "We've never lost an aircraft.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Yes, We've never lost an aircraft."}, "gen_args_1": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? Also, We've never lost an aircraft."}, "gen_args_2": {"arg_0": "", "arg_1": " Only lost two, three aircraft while we was there, and, uh, test phase., right? No, We've never lost an aircraft."}}, "resps": [[["-142.0", "False"]], [["-145.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-145.0", "False"], ["-140.0", "False"]], "doc_hash": "dc2a16944b7e6201ce4aee248ad84c69b68c30c64e860d0397d3c298387f063a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 55, "doc": {"premise": "It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's.", "hypothesis": "Rudolph Anderson was part of three U2's.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Yes, Rudolph Anderson was part of three U2's."}, "gen_args_1": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? Also, Rudolph Anderson was part of three U2's."}, "gen_args_2": {"arg_0": "", "arg_1": " It was, uh, which we, uh, had Rudolph Anderson in a, a formulation of three U2's., right? No, Rudolph Anderson was part of three U2's."}}, "resps": [[["-162.0", "False"]], [["-167.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-167.0", "False"], ["-163.0", "False"]], "doc_hash": "73d06078fb2a93f467a79c2207e0fb0f948b1e404d4484e7d15672b3a3f93342", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 63, "doc": {"premise": "But all of a sudden, we was called out to look at what was flying.", "hypothesis": "We were supposed to look at the flying plane.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Yes, We were supposed to look at the flying plane."}, "gen_args_1": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? Also, We were supposed to look at the flying plane."}, "gen_args_2": {"arg_0": "", "arg_1": " But all of a sudden, we was called out to look at what was flying., right? No, We were supposed to look at the flying plane."}}, "resps": [[["-119.0", "False"]], [["-126.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-119.0", "False"], ["-126.0", "False"], ["-119.0", "False"]], "doc_hash": "be6018e267b36aab7f44b730e307b9480334eeaf39366b79139e7e1df244af7b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 71, "doc": {"premise": "Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord.", "hypothesis": "Ramona is located in Concord.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Yes, Ramona is located in Concord."}, "gen_args_1": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? Also, Ramona is located in Concord."}, "gen_args_2": {"arg_0": "", "arg_1": " Um, You need to call Ramona at Concord, mind you she's at an office, actually she's in a client, all the way across town, we're in Monroe, she's in Concord., right? No, Ramona is located in Concord."}}, "resps": [[["-203.0", "False"]], [["-210.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-210.0", "False"], ["-206.0", "False"]], "doc_hash": "dd3f47e36a9a94be8700e0511e004c3ce533420fc4836047e3bef9bc9342c9e9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 79, "doc": {"premise": "And it makes you feel just awful.", "hypothesis": "It makes you feel horrible.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Yes, It makes you feel horrible."}, "gen_args_1": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? Also, It makes you feel horrible."}, "gen_args_2": {"arg_0": "", "arg_1": " And it makes you feel just awful., right? No, It makes you feel horrible."}}, "resps": [[["-68.5", "False"]], [["-76.0", "False"]], [["-69.5", "False"]]], "filtered_resps": [["-68.5", "False"], ["-76.0", "False"], ["-69.5", "False"]], "doc_hash": "6548714a48deaa632661b834378d394ccebaeb1e813ca4d5081baac2177c0fc5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30763104e-01 4.04173651e-04 2.68832722e-01]"]}
{"doc_id": 87, "doc": {"premise": "Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas.", "hypothesis": "It kept getting faster.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Yes, It kept getting faster."}, "gen_args_1": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? Also, It kept getting faster."}, "gen_args_2": {"arg_0": "", "arg_1": " Uh, well it's, uh, the speeds got faster, faster, and faster until we deployed overseas., right? No, It kept getting faster."}}, "resps": [[["-138.0", "False"]], [["-144.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-144.0", "False"], ["-139.0", "False"]], "doc_hash": "1632b25205223ba0a85f2a2c162996d717d4bef54eed654b2b4593bb10faa5ea", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 95, "doc": {"premise": "Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?", "hypothesis": "I'd love to drink some chocolate milk and relax a bit since I know i messed up.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Yes, I'd love to drink some chocolate milk and relax a bit since I know i messed up."}, "gen_args_1": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? Also, I'd love to drink some chocolate milk and relax a bit since I know i messed up."}, "gen_args_2": {"arg_0": "", "arg_1": " Before you give me a spanking, why don't you just let me have one big glass of chocolate milk first?, right? No, I'd love to drink some chocolate milk and relax a bit since I know i messed up."}}, "resps": [[["-148.0", "False"]], [["-155.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-155.0", "False"], ["-158.0", "False"]], "doc_hash": "2eca7075f1fc6459f640ef015eed49c05f5cc2aeb58dce0c4d400d61af099ac6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.99043634e-01 9.11009872e-04 4.53565108e-05]"]}
{"doc_id": 103, "doc": {"premise": "They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do.", "hypothesis": "Everyone was so happy!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Yes, Everyone was so happy!"}, "gen_args_1": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? Also, Everyone was so happy!"}, "gen_args_2": {"arg_0": "", "arg_1": " They took Joe with them, and my Granny said, she said it was such a sad time in the house because, you know, everybody was missing Joe and they didn't know what to do., right? No, Everyone was so happy!"}}, "resps": [[["-173.0", "False"]], [["-174.0", "False"]], [["-172.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-174.0", "False"], ["-172.0", "False"]], "doc_hash": "b8572ee7d17b4a64cb97e5d8884740b83ae209c8087aac1d0a9425fcfe1189a0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 111, "doc": {"premise": "It wasn't nothing but a desert; there was sagebrush out on the runway.", "hypothesis": "It was a tropical rainforest.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Yes, It was a tropical rainforest."}, "gen_args_1": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? Also, It was a tropical rainforest."}, "gen_args_2": {"arg_0": "", "arg_1": " It wasn't nothing but a desert; there was sagebrush out on the runway., right? No, It was a tropical rainforest."}}, "resps": [[["-128.0", "False"]], [["-128.0", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-128.0", "False"], ["-128.0", "False"], ["-120.5", "False"]], "doc_hash": "c1e0e7b1f17d01a18f9298b7c7a07ee6ad83275f10f890f0f57549e6fb5a904e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[5.52473242e-04 5.52473242e-04 9.98895054e-01]"]}
{"doc_id": 119, "doc": {"premise": "He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married.", "hypothesis": "He's from Ireland.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Yes, He's from Ireland."}, "gen_args_1": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? Also, He's from Ireland."}, "gen_args_2": {"arg_0": "", "arg_1": " He is from Greece and he is from a small village in Greece called Tokalleka and he came to America and I believe it was 1969 or 1970 and he shortly got married., right? No, He's from Ireland."}}, "resps": [[["-183.0", "False"]], [["-185.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-185.0", "False"], ["-180.0", "False"]], "doc_hash": "5101628ab821aaa63949336c1ef489bc19a1250ee793311455a637ac2eb6c579", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 127, "doc": {"premise": "Well, there's nobody there to help me.", "hypothesis": "There are plenty of people to help me there.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Yes, There are plenty of people to help me there."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? Also, There are plenty of people to help me there."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, there's nobody there to help me., right? No, There are plenty of people to help me there."}}, "resps": [[["-83.5", "False"]], [["-88.0", "False"]], [["-83.0", "False"]]], "filtered_resps": [["-83.5", "False"], ["-88.0", "False"], ["-83.0", "False"]], "doc_hash": "f332b1fd85c17d2f32823aeacffb431123a04d89efe708740fae166e511b7739", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 135, "doc": {"premise": "That's why I didn't graduate college, but I never, I never read any of the books I was supposed to.", "hypothesis": "I didn't finish college.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Yes, I didn't finish college."}, "gen_args_1": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? Also, I didn't finish college."}, "gen_args_2": {"arg_0": "", "arg_1": " That's why I didn't graduate college, but I never, I never read any of the books I was supposed to., right? No, I didn't finish college."}}, "resps": [[["-108.0", "False"]], [["-110.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-110.0", "False"], ["-106.0", "False"]], "doc_hash": "6aa7c7cc25318774b7aad388cc7845466ab8d77675c94a0a0d8f601cdcd1e02a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 143, "doc": {"premise": "So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there.", "hypothesis": "Granny walked away from the house.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Yes, Granny walked away from the house."}, "gen_args_1": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? Also, Granny walked away from the house."}, "gen_args_2": {"arg_0": "", "arg_1": " So Granny got up, and she kind of walked down the steps off the porch and she was walking up towards the road and she then just stood there., right? No, Granny walked away from the house."}}, "resps": [[["-146.0", "False"]], [["-151.0", "False"]], [["-145.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-151.0", "False"], ["-145.0", "False"]], "doc_hash": "59b6a145077f649c64106b90be73f2c4bf43a043f15f0a1da512ae2c00bc2836", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 151, "doc": {"premise": "And then I heard him leave, so I'm still finishing what I had to do.", "hypothesis": "I'm doing the important jobs that I was assigned this morning.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Yes, I'm doing the important jobs that I was assigned this morning."}, "gen_args_1": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? Also, I'm doing the important jobs that I was assigned this morning."}, "gen_args_2": {"arg_0": "", "arg_1": " And then I heard him leave, so I'm still finishing what I had to do., right? No, I'm doing the important jobs that I was assigned this morning."}}, "resps": [[["-131.0", "False"]], [["-135.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-135.0", "False"], ["-131.0", "False"]], "doc_hash": "95e407bebe74f609ce8041ec3bac01d100aafc28a43e398394dce0f70538b0aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 159, "doc": {"premise": "And so when they told her she had to go home with this guy, she said, Go home with him?", "hypothesis": "They said she couldn't go anywhere yet", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Yes, They said she couldn't go anywhere yet"}, "gen_args_1": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? Also, They said she couldn't go anywhere yet"}, "gen_args_2": {"arg_0": "", "arg_1": " And so when they told her she had to go home with this guy, she said, Go home with him?, right? No, They said she couldn't go anywhere yet"}}, "resps": [[["-124.5", "False"]], [["-128.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-128.0", "False"], ["-122.0", "False"]], "doc_hash": "cb4f0a794af73b0828a953a8d8665ab792e78e48c440fdd49f8bbab31c2e5403", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07568481 0.00228548 0.92202971]"]}
{"doc_id": 167, "doc": {"premise": "I don't care if you don't know anything about it.", "hypothesis": "I'm not worried if you don't know anything about it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Yes, I'm not worried if you don't know anything about it."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? Also, I'm not worried if you don't know anything about it."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't care if you don't know anything about it., right? No, I'm not worried if you don't know anything about it."}}, "resps": [[["-72.0", "False"]], [["-76.0", "False"]], [["-71.0", "False"]]], "filtered_resps": [["-72.0", "False"], ["-76.0", "False"], ["-71.0", "False"]], "doc_hash": "ce975dc4adb14b0d260858837c19f304b5cbb0ce970216f649437e7e48c6378c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 175, "doc": {"premise": "They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington.", "hypothesis": "They told me to grab my bags.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Yes, They told me to grab my bags."}, "gen_args_1": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? Also, They told me to grab my bags."}, "gen_args_2": {"arg_0": "", "arg_1": " They asked a few questions and I answered them and they said, Get your baggage and leave there immediately, and come to the address you were supposed to when you arrived in Washington., right? No, They told me to grab my bags."}}, "resps": [[["-166.0", "False"]], [["-171.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-166.0", "False"], ["-171.0", "False"], ["-168.0", "False"]], "doc_hash": "87ae904c85bc840ca401c38c807f496d1146880c8b4929e099ea1ee9540abf11", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 183, "doc": {"premise": "Is there any reason why she didn't tell you?", "hypothesis": "I know there's no reason she wouldn't tell you.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Yes, I know there's no reason she wouldn't tell you."}, "gen_args_1": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? Also, I know there's no reason she wouldn't tell you."}, "gen_args_2": {"arg_0": "", "arg_1": " Is there any reason why she didn't tell you?, right? No, I know there's no reason she wouldn't tell you."}}, "resps": [[["-86.0", "False"]], [["-90.0", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-86.0", "False"], ["-90.0", "False"], ["-84.0", "False"]], "doc_hash": "18badcc147eb700be278e5a8dafe2bf01eeb9218479d49c3f5d9787efaa38855", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 191, "doc": {"premise": "No, it was just that one time in the morning, and she said that she was going to come back to the office.", "hypothesis": "She said she'd come back to the office with lunch.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Yes, She said she'd come back to the office with lunch."}, "gen_args_1": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? Also, She said she'd come back to the office with lunch."}, "gen_args_2": {"arg_0": "", "arg_1": " No, it was just that one time in the morning, and she said that she was going to come back to the office., right? No, She said she'd come back to the office with lunch."}}, "resps": [[["-124.0", "False"]], [["-131.0", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-124.0", "False"], ["-131.0", "False"], ["-125.5", "False"]], "doc_hash": "05b53a537f0d2161ec425fe7df026d2952b47a38d6252ed0463e0ed923d5ce40", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.16965403e-01 7.44976017e-04 1.82289621e-01]"]}
{"doc_id": 199, "doc": {"premise": "So he stayed in Augusta after that?", "hypothesis": "Did he stay in Augusta after the riot?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Yes, Did he stay in Augusta after the riot?"}, "gen_args_1": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? Also, Did he stay in Augusta after the riot?"}, "gen_args_2": {"arg_0": "", "arg_1": " So he stayed in Augusta after that?, right? No, Did he stay in Augusta after the riot?"}}, "resps": [[["-94.5", "False"]], [["-95.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-94.5", "False"], ["-95.5", "False"], ["-95.0", "False"]], "doc_hash": "af6f52adbfa2819ddd1fbf863e73bf37c8a39867ba48636b20a2b416c913bd92", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.50648039 0.18632372 0.30719589]"]}
{"doc_id": 207, "doc": {"premise": "And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast.", "hypothesis": "She kept talking to her coworkers about the guy running away.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Yes, She kept talking to her coworkers about the guy running away."}, "gen_args_1": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? Also, She kept talking to her coworkers about the guy running away."}, "gen_args_2": {"arg_0": "", "arg_1": " And so she sat back down, and, you know, they were still chatting, and they could still see this person, and this person was walking really, really fast., right? No, She kept talking to her coworkers about the guy running away."}}, "resps": [[["-176.0", "False"]], [["-178.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-178.0", "False"], ["-178.0", "False"]], "doc_hash": "f64627bf0a23507d9a7a522aeba316d8c01dfaeb58794f812989d2dab88f7863", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 215, "doc": {"premise": "I don't have enough information.", "hypothesis": "I need to gather more information about this thing.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I don't have enough information., right? Yes, I need to gather more information about this thing."}, "gen_args_1": {"arg_0": "", "arg_1": " I don't have enough information., right? Also, I need to gather more information about this thing."}, "gen_args_2": {"arg_0": "", "arg_1": " I don't have enough information., right? No, I need to gather more information about this thing."}}, "resps": [[["-71.0", "False"]], [["-74.5", "False"]], [["-72.0", "False"]]], "filtered_resps": [["-71.0", "False"], ["-74.5", "False"], ["-72.0", "False"]], "doc_hash": "186043b452ebc1975eb22f30307bcd25965b1c290938b79f386094583181e6c9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 223, "doc": {"premise": "I had to start training in course.", "hypothesis": "I had to learn how to complete the obstacle course.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I had to start training in course., right? Yes, I had to learn how to complete the obstacle course."}, "gen_args_1": {"arg_0": "", "arg_1": " I had to start training in course., right? Also, I had to learn how to complete the obstacle course."}, "gen_args_2": {"arg_0": "", "arg_1": " I had to start training in course., right? No, I had to learn how to complete the obstacle course."}}, "resps": [[["-92.0", "False"]], [["-93.5", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-92.0", "False"], ["-93.5", "False"], ["-91.5", "False"]], "doc_hash": "bee8af0092b71cb614145ae5f30e1b9d1c652bade49b000b4f5a387ede5532d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.34820743 0.07769558 0.57409699]"]}
{"doc_id": 231, "doc": {"premise": "They didn't want to stay captive.", "hypothesis": "They had been captured at some point but wanted to escape.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Yes, They had been captured at some point but wanted to escape."}, "gen_args_1": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? Also, They had been captured at some point but wanted to escape."}, "gen_args_2": {"arg_0": "", "arg_1": " They didn't want to stay captive., right? No, They had been captured at some point but wanted to escape."}}, "resps": [[["-97.5", "False"]], [["-100.5", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-97.5", "False"], ["-100.5", "False"], ["-98.5", "False"]], "doc_hash": "4152376ae6fa012eaf71768bc2fc602116a363582b3bb440af0fc44bb4339b2c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 239, "doc": {"premise": "Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down.", "hypothesis": "The altitude chamber has been discontinued.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Yes, The altitude chamber has been discontinued."}, "gen_args_1": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? Also, The altitude chamber has been discontinued."}, "gen_args_2": {"arg_0": "", "arg_1": " Physiological support differs from life support in that he handles the altitude chambers which run pilots up to 80 thousand feet in high altitude chambers, and brings him back down., right? No, The altitude chamber has been discontinued."}}, "resps": [[["-210.0", "False"]], [["-210.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-210.0", "False"], ["-210.0", "False"], ["-207.0", "False"]], "doc_hash": "24e0fd79116932547de2ce50ffb7dad4f52c490f227e2a5c6559e0942380dffd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 247, "doc": {"premise": "She's like, But you need to look here, look here, she's gives me like three different places to look in the computer.", "hypothesis": "She told me the folders would be on the desktop.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Yes, She told me the folders would be on the desktop."}, "gen_args_1": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? Also, She told me the folders would be on the desktop."}, "gen_args_2": {"arg_0": "", "arg_1": " She's like, But you need to look here, look here, she's gives me like three different places to look in the computer., right? No, She told me the folders would be on the desktop."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-161.0", "False"]], "doc_hash": "db90517766c7a1e25a94409c3a13e5a4b9f177b4c178be0247c67f0c2f7d8038", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 255, "doc": {"premise": "exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think", "hypothesis": "I think you have to devote 10 hours a day to be good at it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Yes, I think you have to devote 10 hours a day to be good at it."}, "gen_args_1": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? Also, I think you have to devote 10 hours a day to be good at it."}, "gen_args_2": {"arg_0": "", "arg_1": " exactly it's it's an active state it's not something that you can kind of you know be passively involved in and expect to do any good really i don't think, right? No, I think you have to devote 10 hours a day to be good at it."}}, "resps": [[["-176.0", "False"]], [["-182.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-182.0", "False"], ["-173.0", "False"]], "doc_hash": "7aee2511d6cb0ea0734adc52a62cea4381dfcd94f50ae65e48f43820119ab80a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.74202986e-02 1.17543168e-04 9.52462158e-01]"]}
{"doc_id": 263, "doc": {"premise": "and they can be very nice too after after they've been trained", "hypothesis": "When they undergo training they can be quite pleasant.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Yes, When they undergo training they can be quite pleasant."}, "gen_args_1": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? Also, When they undergo training they can be quite pleasant."}, "gen_args_2": {"arg_0": "", "arg_1": " and they can be very nice too after after they've been trained, right? No, When they undergo training they can be quite pleasant."}}, "resps": [[["-111.5", "False"]], [["-117.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-111.5", "False"], ["-117.5", "False"], ["-117.0", "False"]], "doc_hash": "d1ed8a0d0d43e16221361730663bcc1357f646350262e65e2446ddadcc45358f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.9934773  0.00246258 0.00406011]"]}
{"doc_id": 271, "doc": {"premise": "are you saying the teachers or the parents", "hypothesis": "Is it the teachers or the parents?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Yes, Is it the teachers or the parents?"}, "gen_args_1": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? Also, Is it the teachers or the parents?"}, "gen_args_2": {"arg_0": "", "arg_1": " are you saying the teachers or the parents, right? No, Is it the teachers or the parents?"}}, "resps": [[["-74.0", "False"]], [["-79.0", "False"]], [["-75.5", "False"]]], "filtered_resps": [["-74.0", "False"], ["-79.0", "False"], ["-75.5", "False"]], "doc_hash": "de9d39276b0d2d28a9971a5499ce35bdf187740839496fe5b358e728ca503d1e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81309532 0.00547859 0.18142609]"]}
{"doc_id": 279, "doc": {"premise": "care about how the national news affects the local area", "hypothesis": "Concerned about the local places being affected by national news.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Yes, Concerned about the local places being affected by national news."}, "gen_args_1": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? Also, Concerned about the local places being affected by national news."}, "gen_args_2": {"arg_0": "", "arg_1": " care about how the national news affects the local area, right? No, Concerned about the local places being affected by national news."}}, "resps": [[["-108.0", "False"]], [["-106.5", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-108.0", "False"], ["-106.5", "False"], ["-106.0", "False"]], "doc_hash": "6500c50a8fe1f224d8407463dd94b5ded352639a1e4be7a5d386acb43c6ce4a4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.07769558 0.34820743 0.57409699]"]}
{"doc_id": 287, "doc": {"premise": "yeah there there's something about having a place to live i don't know", "hypothesis": "It's nice to have a place to live.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Yes, It's nice to have a place to live."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? Also, It's nice to have a place to live."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah there there's something about having a place to live i don't know, right? No, It's nice to have a place to live."}}, "resps": [[["-97.0", "False"]], [["-104.0", "False"]], [["-99.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-104.0", "False"], ["-99.0", "False"]], "doc_hash": "f786ed51cf239dfc043d567c6ffa34ca4a1bd36394f3bcbbd617265becba5b1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 295, "doc": {"premise": "and uh i kind of kind of like the black eyed pea but i don't think it's a chain", "hypothesis": "I might check out the Black Eyed Pea later.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Yes, I might check out the Black Eyed Pea later."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? Also, I might check out the Black Eyed Pea later."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh i kind of kind of like the black eyed pea but i don't think it's a chain, right? No, I might check out the Black Eyed Pea later."}}, "resps": [[["-132.0", "False"]], [["-135.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-135.0", "False"], ["-131.0", "False"]], "doc_hash": "1400aefa654575c5c03eb779e8cd034e6fb89348541c72e36341fca504e2a6df", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 303, "doc": {"premise": "it's it's really bad it uh i", "hypothesis": "I have heard it is not good.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Yes, I have heard it is not good."}, "gen_args_1": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? Also, I have heard it is not good."}, "gen_args_2": {"arg_0": "", "arg_1": " it's it's really bad it uh i, right? No, I have heard it is not good."}}, "resps": [[["-89.5", "False"]], [["-98.5", "False"]], [["-91.5", "False"]]], "filtered_resps": [["-89.5", "False"], ["-98.5", "False"], ["-91.5", "False"]], "doc_hash": "da9b0e713f34d3f5072d2758786d8e0fcf98ee44f7233e319b29a1b922573e51", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80701347e-01 1.08687181e-04 1.19189966e-01]"]}
{"doc_id": 311, "doc": {"premise": "so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it", "hypothesis": "We have never been to the cottage.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Yes, We have never been to the cottage."}, "gen_args_1": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? Also, We have never been to the cottage."}, "gen_args_2": {"arg_0": "", "arg_1": " so um  we usually meet like at my uncle's cottage in the um at the lake and uh make a couple days of it, right? No, We have never been to the cottage."}}, "resps": [[["-158.0", "False"]], [["-164.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-164.0", "False"], ["-158.0", "False"]], "doc_hash": "d1a9cc32123b07076ddad671c5c19bcc09d1317998232de7464a9948492a76e2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 319, "doc": {"premise": "yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was", "hypothesis": "We didnt do anything for her birthday.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Yes, We didnt do anything for her birthday."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? Also, We didnt do anything for her birthday."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah and we just kind of we kept uh kind of uh it was a surprise birthday party for her was what it was, right? No, We didnt do anything for her birthday."}}, "resps": [[["-134.0", "False"]], [["-140.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-140.0", "False"], ["-132.0", "False"]], "doc_hash": "7b7aa9712168888ebe5e8014ee52f721ca16eabcd3b5cb92e0ce22ed627497a0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 327, "doc": {"premise": "course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know", "hypothesis": "People will work if they have opportunity.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Yes, People will work if they have opportunity."}, "gen_args_1": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? Also, People will work if they have opportunity."}, "gen_args_2": {"arg_0": "", "arg_1": " course that might up crime you know and uh people go in and steal your television and steal and sell it just because they can't they can't work anymore you know, right? No, People will work if they have opportunity."}}, "resps": [[["-201.0", "False"]], [["-206.0", "False"]], [["-201.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-206.0", "False"], ["-201.0", "False"]], "doc_hash": "35c1ac91cc3b3686521327e63650de95dffd9ffe85899c12d4cdcd2fb204ccdf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 335, "doc": {"premise": "but uh so you like different foods huh", "hypothesis": "You must enjoy trying different ethnic foods.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Yes, You must enjoy trying different ethnic foods."}, "gen_args_1": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? Also, You must enjoy trying different ethnic foods."}, "gen_args_2": {"arg_0": "", "arg_1": " but uh so you like different foods huh, right? No, You must enjoy trying different ethnic foods."}}, "resps": [[["-103.5", "False"]], [["-103.5", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-103.5", "False"], ["-103.5", "False"], ["-105.5", "False"]], "doc_hash": "65a0b085bf95a4317d7a43401b12c28c37d0152d4436e7573ba74200a11c77e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 343, "doc": {"premise": "well why don't you start because you've had more time to think about it if you don't mind", "hypothesis": "Why don't you go first.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Yes, Why don't you go first."}, "gen_args_1": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? Also, Why don't you go first."}, "gen_args_2": {"arg_0": "", "arg_1": " well why don't you start because you've had more time to think about it if you don't mind, right? No, Why don't you go first."}}, "resps": [[["-95.5", "False"]], [["-102.0", "False"]], [["-97.0", "False"]]], "filtered_resps": [["-95.5", "False"], ["-102.0", "False"], ["-97.0", "False"]], "doc_hash": "804327ee41d12c546be8e35f8a461a5bb770a67cdc97c45c588163e61e16b746", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.81657077 0.00122766 0.18220157]"]}
{"doc_id": 351, "doc": {"premise": "oh um no but they do have hay horse races  at the Oaklawn tracks", "hypothesis": "The hay horse races are fun.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Yes, The hay horse races are fun."}, "gen_args_1": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? Also, The hay horse races are fun."}, "gen_args_2": {"arg_0": "", "arg_1": " oh um no but they do have hay horse races  at the Oaklawn tracks, right? No, The hay horse races are fun."}}, "resps": [[["-137.0", "False"]], [["-139.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-139.0", "False"], ["-141.0", "False"]], "doc_hash": "4b8e1f84fbf5f2956d363cac3f69864d7f75a5d81a963a775ddf1d3b8fbd213a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 359, "doc": {"premise": "right they will go through the slot", "hypothesis": "They go in the trash.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " right they will go through the slot, right? Yes, They go in the trash."}, "gen_args_1": {"arg_0": "", "arg_1": " right they will go through the slot, right? Also, They go in the trash."}, "gen_args_2": {"arg_0": "", "arg_1": " right they will go through the slot, right? No, They go in the trash."}}, "resps": [[["-81.5", "False"]], [["-86.0", "False"]], [["-77.5", "False"]]], "filtered_resps": [["-81.5", "False"], ["-86.0", "False"], ["-77.5", "False"]], "doc_hash": "1029985a5492f28306b6ac81f30770a1320b4bde94ca3af42a62c571f651e523", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.79826169e-02 1.99768829e-04 9.81817614e-01]"]}
{"doc_id": 367, "doc": {"premise": "uh-huh it's funny and um i i guess i just like funny shows mostly", "hypothesis": "I like watching funny shows.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Yes, I like watching funny shows."}, "gen_args_1": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? Also, I like watching funny shows."}, "gen_args_2": {"arg_0": "", "arg_1": " uh-huh it's funny and um i i guess i just like funny shows mostly, right? No, I like watching funny shows."}}, "resps": [[["-102.5", "False"]], [["-111.5", "False"]], [["-105.0", "False"]]], "filtered_resps": [["-102.5", "False"], ["-111.5", "False"], ["-105.0", "False"]], "doc_hash": "ad39d6170277eed3e6d0a7136198a29eeef0cfe217b24b44f417e86dc5bf6ced", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.24036435e-01 1.14035155e-04 7.58495295e-02]"]}
{"doc_id": 375, "doc": {"premise": "do you do you wilderness camp", "hypothesis": "Did you attend the camp about wilderness?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Yes, Did you attend the camp about wilderness?"}, "gen_args_1": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? Also, Did you attend the camp about wilderness?"}, "gen_args_2": {"arg_0": "", "arg_1": " do you do you wilderness camp, right? No, Did you attend the camp about wilderness?"}}, "resps": [[["-99.0", "False"]], [["-100.0", "False"]], [["-98.5", "False"]]], "filtered_resps": [["-99.0", "False"], ["-100.0", "False"], ["-98.5", "False"]], "doc_hash": "fcf2b90d58854a1fa300ad0feda6a6bc2b40dddef1b929696ca19b44b804a14f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.33149896 0.12195165 0.54654939]"]}
{"doc_id": 383, "doc": {"premise": "and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i", "hypothesis": "When you own your own piece of land you have nothing to lose anymore.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Yes, When you own your own piece of land you have nothing to lose anymore."}, "gen_args_1": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? Also, When you own your own piece of land you have nothing to lose anymore."}, "gen_args_2": {"arg_0": "", "arg_1": " and i really hate to lose them but um that's one of the hazards i guess of uh having a a yard because i, right? No, When you own your own piece of land you have nothing to lose anymore."}}, "resps": [[["-176.0", "False"]], [["-180.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-180.0", "False"], ["-178.0", "False"]], "doc_hash": "473c1d6541235bcc0418542343cc24ddc5d56f30369681b7a12d30d80325a363", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 391, "doc": {"premise": "and uh that was twenty five hundred people when i joined and uh", "hypothesis": "I think when I joined there was at least a few people that I knew.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Yes, I think when I joined there was at least a few people that I knew."}, "gen_args_1": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? Also, I think when I joined there was at least a few people that I knew."}, "gen_args_2": {"arg_0": "", "arg_1": " and uh that was twenty five hundred people when i joined and uh, right? No, I think when I joined there was at least a few people that I knew."}}, "resps": [[["-126.5", "False"]], [["-131.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-131.0", "False"], ["-126.0", "False"]], "doc_hash": "f04cb6927c9f2b5057b61f3118353dd713f8e98347bd060feaee9a63e3de0d9d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37596384 0.00417658 0.61985958]"]}
{"doc_id": 399, "doc": {"premise": "i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and", "hypothesis": "Anderson beat out Reagan.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Yes, Anderson beat out Reagan."}, "gen_args_1": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? Also, Anderson beat out Reagan."}, "gen_args_2": {"arg_0": "", "arg_1": " i'm afraid that um i think his name was Anderson was the the gentleman who ran for uh on an independent ticket against Reagan and, right? No, Anderson beat out Reagan."}}, "resps": [[["-159.0", "False"]], [["-168.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-159.0", "False"], ["-168.0", "False"], ["-161.0", "False"]], "doc_hash": "31b530892d64b590eb0492e514a8a5af652d98658588af0ad96f8c743dbe7b5d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[8.80701347e-01 1.08687181e-04 1.19189966e-01]"]}
{"doc_id": 407, "doc": {"premise": "a few years ago i was a student there and spent um a semester studying abroad in London", "hypothesis": "London schools are the best.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Yes, London schools are the best."}, "gen_args_1": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? Also, London schools are the best."}, "gen_args_2": {"arg_0": "", "arg_1": " a few years ago i was a student there and spent um a semester studying abroad in London, right? No, London schools are the best."}}, "resps": [[["-116.5", "False"]], [["-120.5", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-116.5", "False"], ["-120.5", "False"], ["-118.5", "False"]], "doc_hash": "3e649f6ebb36a1ac1e05e1c3ea81dfdb8912a3029ab7da03c94784399a7728f7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 415, "doc": {"premise": "well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture", "hypothesis": "My VCR works perfectly.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Yes, My VCR works perfectly."}, "gen_args_1": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? Also, My VCR works perfectly."}, "gen_args_2": {"arg_0": "", "arg_1": " well i have a VCR and i've had to return it a couple of times because of the same part failure and uh it's still not getting a real good picture, right? No, My VCR works perfectly."}}, "resps": [[["-167.0", "False"]], [["-173.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-173.0", "False"], ["-165.0", "False"]], "doc_hash": "373a73f8677c998ddc2cefc4b12494ffbe39e1cd1d9d22d7bf57d69f3be3b96b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[1.19167711e-01 2.95387223e-04 8.80536902e-01]"]}
{"doc_id": 423, "doc": {"premise": "well oh well that's interesting do you uh did you take classes to learn how to do that", "hypothesis": "I bet you taught yourself how to do that.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Yes, I bet you taught yourself how to do that."}, "gen_args_1": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? Also, I bet you taught yourself how to do that."}, "gen_args_2": {"arg_0": "", "arg_1": " well oh well that's interesting do you uh did you take classes to learn how to do that, right? No, I bet you taught yourself how to do that."}}, "resps": [[["-115.5", "False"]], [["-117.5", "False"]], [["-112.5", "False"]]], "filtered_resps": [["-115.5", "False"], ["-117.5", "False"], ["-112.5", "False"]], "doc_hash": "23ea231cf64462bb06390801c25e7c9ce04a82b25300113bef5c710e0a01a98f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 431, "doc": {"premise": "do we know what we're going to say", "hypothesis": "What are we doing to say?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Yes, What are we doing to say?"}, "gen_args_1": {"arg_0": "", "arg_1": " do we know what we're going to say, right? Also, What are we doing to say?"}, "gen_args_2": {"arg_0": "", "arg_1": " do we know what we're going to say, right? No, What are we doing to say?"}}, "resps": [[["-72.0", "False"]], [["-72.5", "False"]], [["-70.0", "False"]]], "filtered_resps": [["-72.0", "False"], ["-72.5", "False"], ["-70.0", "False"]], "doc_hash": "ff062ea65d0f297785032d3218f3b1dadfa64ca39747d05f0e4f1a4470fa16d6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11116562 0.06742536 0.82140902]"]}
{"doc_id": 439, "doc": {"premise": "okay and do they have good lasagna", "hypothesis": "Their lasagna is excellent.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Yes, Their lasagna is excellent."}, "gen_args_1": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? Also, Their lasagna is excellent."}, "gen_args_2": {"arg_0": "", "arg_1": " okay and do they have good lasagna, right? No, Their lasagna is excellent."}}, "resps": [[["-74.5", "False"]], [["-84.0", "False"]], [["-78.5", "False"]]], "filtered_resps": [["-74.5", "False"], ["-84.0", "False"], ["-78.5", "False"]], "doc_hash": "4a4914caa553e484b5721a7149f0d76a23753b64ceaee642fbc7529346e7383c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81941612e-01 7.35001265e-05 1.79848880e-02]"]}
{"doc_id": 447, "doc": {"premise": "um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you", "hypothesis": "It's ok for a parent to give lots of gifts.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Yes, It's ok for a parent to give lots of gifts."}, "gen_args_1": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? Also, It's ok for a parent to give lots of gifts."}, "gen_args_2": {"arg_0": "", "arg_1": " um there's nothing wrong with a parent gifting everything she has to uh to uh to an individual like uh like like you, right? No, It's ok for a parent to give lots of gifts."}}, "resps": [[["-162.0", "False"]], [["-168.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-168.0", "False"], ["-163.0", "False"]], "doc_hash": "c52b7bf9948513ebf3284d8ab5b972ef53dc43d5e78eeffa50673fd257b09d27", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 455, "doc": {"premise": "expensive you can get a lot of money in that kind of stuff especially the good stuff", "hypothesis": "You can get paid a ton of money if you have the best fabrics.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Yes, You can get paid a ton of money if you have the best fabrics."}, "gen_args_1": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? Also, You can get paid a ton of money if you have the best fabrics."}, "gen_args_2": {"arg_0": "", "arg_1": " expensive you can get a lot of money in that kind of stuff especially the good stuff, right? No, You can get paid a ton of money if you have the best fabrics."}}, "resps": [[["-124.0", "False"]], [["-129.0", "False"]], [["-129.0", "False"]]], "filtered_resps": [["-124.0", "False"], ["-129.0", "False"], ["-129.0", "False"]], "doc_hash": "6ec43d76948cc0856619171cf457f78d70562a06b6e6cf3cdfb90a28974003ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 463, "doc": {"premise": "yeah we have between the spouse and myself we have six", "hypothesis": "My husband and I have six kids total.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Yes, My husband and I have six kids total."}, "gen_args_1": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? Also, My husband and I have six kids total."}, "gen_args_2": {"arg_0": "", "arg_1": " yeah we have between the spouse and myself we have six, right? No, My husband and I have six kids total."}}, "resps": [[["-94.5", "False"]], [["-101.5", "False"]], [["-97.0", "False"]]], "filtered_resps": [["-94.5", "False"], ["-101.5", "False"], ["-97.0", "False"]], "doc_hash": "3f9e41c726abcd46001898d7fbfa932a432b8e4c6c4b4fd7118c1c48b4bc9fd3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.23363694e-01 8.41998700e-04 7.57943075e-02]"]}
{"doc_id": 471, "doc": {"premise": "and uh sometimes it's nice to go out and have a salad", "hypothesis": "I never eat salad- gross!", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Yes, I never eat salad- gross!"}, "gen_args_1": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? Also, I never eat salad- gross!"}, "gen_args_2": {"arg_0": "", "arg_1": " and uh sometimes it's nice to go out and have a salad, right? No, I never eat salad- gross!"}}, "resps": [[["-100.0", "False"]], [["-103.5", "False"]], [["-97.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-103.5", "False"], ["-97.5", "False"]], "doc_hash": "4832516e0b32f1b061186f7bcd4342a639e0bfeb41d820eb779492a56d7468aa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07568481 0.00228548 0.92202971]"]}
{"doc_id": 479, "doc": {"premise": "wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it", "hypothesis": "We can go to dinner after the show.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Yes, We can go to dinner after the show."}, "gen_args_1": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? Also, We can go to dinner after the show."}, "gen_args_2": {"arg_0": "", "arg_1": " wow maybe i should go see it in a theatre and plan to go out to dinner afterwards so we could sit and talk about it, right? No, We can go to dinner after the show."}}, "resps": [[["-124.0", "False"]], [["-130.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-124.0", "False"], ["-130.0", "False"], ["-128.0", "False"]], "doc_hash": "bb78441c7dbb24b50074f7996b558b6b902d46ba7fb86931f2385464b933d1a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 487, "doc": {"premise": "it's kind of like a soap a nighttime soap opera type thing", "hypothesis": "It's like soap opera show.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Yes, It's like soap opera show."}, "gen_args_1": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? Also, It's like soap opera show."}, "gen_args_2": {"arg_0": "", "arg_1": " it's kind of like a soap a nighttime soap opera type thing, right? No, It's like soap opera show."}}, "resps": [[["-98.0", "False"]], [["-105.0", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-105.0", "False"], ["-101.0", "False"]], "doc_hash": "4b7588e94769ca82d8c22d63a2e161f031a0378942044c5bcbf951b3f613e603", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 8.67881295e-04 4.73847131e-02]"]}
{"doc_id": 495, "doc": {"premise": "the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know", "hypothesis": "The contracts have been very messy.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Yes, The contracts have been very messy."}, "gen_args_1": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? Also, The contracts have been very messy."}, "gen_args_2": {"arg_0": "", "arg_1": " the latest contract that was awarded Virginia sued or has got a lawsuit against uh Gratin to stop construction because it was unfairly obtained or something like that you know, right? No, The contracts have been very messy."}}, "resps": [[["-212.0", "False"]], [["-217.0", "False"]], [["-217.0", "False"]]], "filtered_resps": [["-212.0", "False"], ["-217.0", "False"], ["-217.0", "False"]], "doc_hash": "a60dd3f807b8ad6d36a1443f4fc15ffbde5cfdbd1879e396155411dacfff1182", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.98670329 0.00664835 0.00664835]"]}
{"doc_id": 503, "doc": {"premise": "These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness.", "hypothesis": "These molecular devices are mostly used to produce various poisons for protection.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Yes, These molecular devices are mostly used to produce various poisons for protection."}, "gen_args_1": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? Also, These molecular devices are mostly used to produce various poisons for protection."}, "gen_args_2": {"arg_0": "", "arg_1": " These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness., right? No, These molecular devices are mostly used to produce various poisons for protection."}}, "resps": [[["-221.0", "False"]], [["-219.0", "False"]], [["-220.0", "False"]]], "filtered_resps": [["-221.0", "False"], ["-219.0", "False"], ["-220.0", "False"]], "doc_hash": "5239f5b4ddc25a601a390abe95de8352527333a100e4fbc0f2b7d2389a1fff2d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 511, "doc": {"premise": "The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory.", "hypothesis": "Part of the text of the constitution was written in 1787.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Yes, Part of the text of the constitution was written in 1787."}, "gen_args_1": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? Also, Part of the text of the constitution was written in 1787."}, "gen_args_2": {"arg_0": "", "arg_1": " The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory., right? No, Part of the text of the constitution was written in 1787."}}, "resps": [[["-139.0", "False"]], [["-146.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-146.0", "False"], ["-141.0", "False"]], "doc_hash": "f99d095ca0dea6f814ba54e76c0168a6ba40e11dd2da94c85928a3ccd068611a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 519, "doc": {"premise": "For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?", "hypothesis": "Children do not usually learn to communicate until the age of six.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Yes, Children do not usually learn to communicate until the age of six."}, "gen_args_1": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? Also, Children do not usually learn to communicate until the age of six."}, "gen_args_2": {"arg_0": "", "arg_1": " For 4- and 5-year-olds, questions more often address narrative organization ( What happens next?, right? No, Children do not usually learn to communicate until the age of six."}}, "resps": [[["-158.0", "False"]], [["-156.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-158.0", "False"], ["-156.0", "False"], ["-159.0", "False"]], "doc_hash": "40c98de1fd8ec6ddbb03e5c0696906c43c80fcf3630cdc9977413470caea9c57", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.84379473 0.04201007]"]}
{"doc_id": 527, "doc": {"premise": "Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data.", "hypothesis": "These hypothetical worlds are used to forecast weather patterns.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Yes, These hypothetical worlds are used to forecast weather patterns."}, "gen_args_1": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? Also, These hypothetical worlds are used to forecast weather patterns."}, "gen_args_2": {"arg_0": "", "arg_1": " Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data., right? No, These hypothetical worlds are used to forecast weather patterns."}}, "resps": [[["-168.0", "False"]], [["-168.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-168.0", "False"], ["-169.0", "False"]], "doc_hash": "bc78f36d16829a5bf88d564f6007f9b354148607a05f07bbecb5e87540055b44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 535, "doc": {"premise": "No difference exists between younger and older classmates in achievement test scores.", "hypothesis": "Young and old classmates achieve same results in test scores.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Yes, Young and old classmates achieve same results in test scores."}, "gen_args_1": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? Also, Young and old classmates achieve same results in test scores."}, "gen_args_2": {"arg_0": "", "arg_1": " No difference exists between younger and older classmates in achievement test scores., right? No, Young and old classmates achieve same results in test scores."}}, "resps": [[["-117.0", "False"]], [["-121.0", "False"]], [["-119.0", "False"]]], "filtered_resps": [["-117.0", "False"], ["-121.0", "False"], ["-119.0", "False"]], "doc_hash": "664ba301414c728c078b648b05024446329a50deb858b1db7171dca676777bb0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 543, "doc": {"premise": "The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection.", "hypothesis": "Middle ear infection is the most common cause for toddlers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Yes, Middle ear infection is the most common cause for toddlers."}, "gen_args_1": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? Also, Middle ear infection is the most common cause for toddlers."}, "gen_args_2": {"arg_0": "", "arg_1": " The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection., right? No, Middle ear infection is the most common cause for toddlers."}}, "resps": [[["-113.5", "False"]], [["-120.0", "False"]], [["-118.5", "False"]]], "filtered_resps": [["-113.5", "False"], ["-120.0", "False"], ["-118.5", "False"]], "doc_hash": "879e9abad99d95df658cbbe22f06debaf32051b828a6aac6f6b675f24a845be2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.99182598 0.00149115 0.00668287]"]}
{"doc_id": 551, "doc": {"premise": "McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell.", "hypothesis": "McKim was humiliated because he finished third.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Yes, McKim was humiliated because he finished third."}, "gen_args_1": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? Also, McKim was humiliated because he finished third."}, "gen_args_2": {"arg_0": "", "arg_1": " McKim, much to his chagrin, not only lost but placed third behind Howard &amp; Cauldwell., right? No, McKim was humiliated because he finished third."}}, "resps": [[["-154.0", "False"]], [["-158.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-158.0", "False"], ["-159.0", "False"]], "doc_hash": "5997658d0e72f25d7486a6c4936f6f52227860a50df7c217865a868c78f43469", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.01786798 0.00657326]"]}
{"doc_id": 559, "doc": {"premise": "But consider bread and butter.", "hypothesis": "Think about bread and butter.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But consider bread and butter., right? Yes, Think about bread and butter."}, "gen_args_1": {"arg_0": "", "arg_1": " But consider bread and butter., right? Also, Think about bread and butter."}, "gen_args_2": {"arg_0": "", "arg_1": " But consider bread and butter., right? No, Think about bread and butter."}}, "resps": [[["-76.0", "False"]], [["-79.5", "False"]], [["-77.0", "False"]]], "filtered_resps": [["-76.0", "False"], ["-79.5", "False"], ["-77.0", "False"]], "doc_hash": "b5170deea103b33c34f78d06f87cc3614283b29a156b7556c1b386e6ea532da4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 567, "doc": {"premise": "We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance.", "hypothesis": "Everything that can be learned about the organization has already been made known.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Yes, Everything that can be learned about the organization has already been made known."}, "gen_args_1": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? Also, Everything that can be learned about the organization has already been made known."}, "gen_args_2": {"arg_0": "", "arg_1": " We have beginning mathematical models that reveal something about this hierarchical organizationa=aalthough the best current models are curiously limited despite their brilliance., right? No, Everything that can be learned about the organization has already been made known."}}, "resps": [[["-241.0", "False"]], [["-242.0", "False"]], [["-240.0", "False"]]], "filtered_resps": [["-241.0", "False"], ["-242.0", "False"], ["-240.0", "False"]], "doc_hash": "1b54566416c09578ac5af246066850836d7f446b85d90efa9062d1b6dd8da8d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 575, "doc": {"premise": "The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible.", "hypothesis": "The biosphere shrinks", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Yes, The biosphere shrinks"}, "gen_args_1": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? Also, The biosphere shrinks"}, "gen_args_2": {"arg_0": "", "arg_1": " The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible., right? No, The biosphere shrinks"}}, "resps": [[["-153.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "70c657037937634aaf75c6786568ee487ff8bb2ba6982ea9d172b2a789d8fc1a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 583, "doc": {"premise": "The relationship between rights and freedom is thus turned on its head.", "hypothesis": "Rights and freedom aren't connected at all.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Yes, Rights and freedom aren't connected at all."}, "gen_args_1": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? Also, Rights and freedom aren't connected at all."}, "gen_args_2": {"arg_0": "", "arg_1": " The relationship between rights and freedom is thus turned on its head., right? No, Rights and freedom aren't connected at all."}}, "resps": [[["-103.0", "False"]], [["-105.5", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-103.0", "False"], ["-105.5", "False"], ["-100.5", "False"]], "doc_hash": "2a7da883c56d604c390e06684ebe5e36fd2a605bf6d72f76812f214a4c316b4c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07538875 0.00618829 0.91842297]"]}
{"doc_id": 591, "doc": {"premise": "I begin life with an endowment of a hundred pears and a thousand apples.", "hypothesis": "I have more pears than apples.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Yes, I have more pears than apples."}, "gen_args_1": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? Also, I have more pears than apples."}, "gen_args_2": {"arg_0": "", "arg_1": " I begin life with an endowment of a hundred pears and a thousand apples., right? No, I have more pears than apples."}}, "resps": [[["-109.0", "False"]], [["-109.0", "False"]], [["-106.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-109.0", "False"], ["-106.0", "False"]], "doc_hash": "58ed83ddab27ff2dbc0ebf0a78919dcc98e749a8391f116dec7e8080c3cb2953", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 599, "doc": {"premise": "Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew.", "hypothesis": "There were roses on top of the hill.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Yes, There were roses on top of the hill."}, "gen_args_1": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? Also, There were roses on top of the hill."}, "gen_args_2": {"arg_0": "", "arg_1": " Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew., right? No, There were roses on top of the hill."}}, "resps": [[["-152.0", "False"]], [["-160.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-160.0", "False"], ["-155.0", "False"]], "doc_hash": "82759a8d5a3d22a826ca3afaa8332bf24d7b4157be14a481b1905b7f73e8ecad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52269826e-01 3.19450938e-04 4.74107229e-02]"]}
{"doc_id": 607, "doc": {"premise": "And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation.", "hypothesis": "There is a common assumption about our officials.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Yes, There is a common assumption about our officials."}, "gen_args_1": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? Also, There is a common assumption about our officials."}, "gen_args_2": {"arg_0": "", "arg_1": " And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation., right? No, There is a common assumption about our officials."}}, "resps": [[["-162.0", "False"]], [["-166.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-166.0", "False"], ["-165.0", "False"]], "doc_hash": "093a45433efc52743778cbfd04572d11038e117199af5d8514bd776935a51a65", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 615, "doc": {"premise": "While this is being done prayers are recited.", "hypothesis": "No one prays.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Yes, No one prays."}, "gen_args_1": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? Also, No one prays."}, "gen_args_2": {"arg_0": "", "arg_1": " While this is being done prayers are recited., right? No, No one prays."}}, "resps": [[["-90.0", "False"]], [["-94.0", "False"]], [["-86.5", "False"]]], "filtered_resps": [["-90.0", "False"], ["-94.0", "False"], ["-86.5", "False"]], "doc_hash": "423682c43e64eea6d074fdf22f4e1dda867d8a2137d6dbe06cc988157adfc31e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.92965023e-02 5.36584156e-04 9.70166914e-01]"]}
{"doc_id": 623, "doc": {"premise": "Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events.", "hypothesis": "Members of car clubs sell cars.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Yes, Members of car clubs sell cars."}, "gen_args_1": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? Also, Members of car clubs sell cars."}, "gen_args_2": {"arg_0": "", "arg_1": " Members of car clubs are referred to as  clubbers,  and they compete for trophies, ride in car caravans, and often participate in fund-raising events., right? No, Members of car clubs sell cars."}}, "resps": [[["-167.0", "False"]], [["-170.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-167.0", "False"], ["-170.0", "False"], ["-165.0", "False"]], "doc_hash": "2b1faac1a276c407fca6379feeb49049d610af545ef818d05a22c281d08effbb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 631, "doc": {"premise": "The same is true of the sense of nationhood.", "hypothesis": "The sense of nationhood depends on how well the economy is run.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Yes, The sense of nationhood depends on how well the economy is run."}, "gen_args_1": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? Also, The sense of nationhood depends on how well the economy is run."}, "gen_args_2": {"arg_0": "", "arg_1": " The same is true of the sense of nationhood., right? No, The sense of nationhood depends on how well the economy is run."}}, "resps": [[["-102.0", "False"]], [["-106.0", "False"]], [["-102.0", "False"]]], "filtered_resps": [["-102.0", "False"], ["-106.0", "False"], ["-102.0", "False"]], "doc_hash": "ea880621fe2fbe90fd52d13434bde62aa80f2ee3146be01e5669e98592bcdce7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 639, "doc": {"premise": "A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles.", "hypothesis": "Charles F. Lewis could not read.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Yes, Charles F. Lewis could not read."}, "gen_args_1": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? Also, Charles F. Lewis could not read."}, "gen_args_2": {"arg_0": "", "arg_1": " A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859-1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles., right? No, Charles F. Lewis could not read."}}, "resps": [[["-193.0", "False"]], [["-199.0", "False"]], [["-197.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-199.0", "False"], ["-197.0", "False"]], "doc_hash": "5bbd484bc9cb5a29084ca97fa6ea7197ef3007b6a16766bd35311c1d8b9702e1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 647, "doc": {"premise": "That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf.", "hypothesis": "Someone is talking to Vance.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Yes, Someone is talking to Vance."}, "gen_args_1": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? Also, Someone is talking to Vance."}, "gen_args_2": {"arg_0": "", "arg_1": " That can be our control tower,  he suggests to Vance, pointing to a corner by a bookshelf., right? No, Someone is talking to Vance."}}, "resps": [[["-151.0", "False"]], [["-152.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-152.0", "False"], ["-152.0", "False"]], "doc_hash": "53924f10ed4c73ccc3d0a1eb6de841d430b99031393c5855bd6113065b319e8a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 655, "doc": {"premise": "If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear.", "hypothesis": "The math for an exponential initial expansion is complex.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Yes, The math for an exponential initial expansion is complex."}, "gen_args_1": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? Also, The math for an exponential initial expansion is complex."}, "gen_args_2": {"arg_0": "", "arg_1": " If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear., right? No, The math for an exponential initial expansion is complex."}}, "resps": [[["-221.0", "False"]], [["-221.0", "False"]], [["-220.0", "False"]]], "filtered_resps": [["-221.0", "False"], ["-221.0", "False"], ["-220.0", "False"]], "doc_hash": "b3b1d8a069af168901dde9ea6f8462c9a3e59b34c636852a991ee6ac84d0d797", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 663, "doc": {"premise": "In turn, object must be on machine for minutes, then machine for minutes, and so on.", "hypothesis": "If it the object does not stay on the machine for minutes, it will explode.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Yes, If it the object does not stay on the machine for minutes, it will explode."}, "gen_args_1": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? Also, If it the object does not stay on the machine for minutes, it will explode."}, "gen_args_2": {"arg_0": "", "arg_1": " In turn, object must be on machine for minutes, then machine for minutes, and so on., right? No, If it the object does not stay on the machine for minutes, it will explode."}}, "resps": [[["-160.0", "False"]], [["-158.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-158.0", "False"], ["-159.0", "False"]], "doc_hash": "8c774c189cdfb16a500bf34cae2afdd035e03643a593b658c5e6ef3f018ecaa6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 671, "doc": {"premise": "The connection between the limited nation and unbounded equality has paradoxical overtones.", "hypothesis": "The nation is not reaching its full potential.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Yes, The nation is not reaching its full potential."}, "gen_args_1": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? Also, The nation is not reaching its full potential."}, "gen_args_2": {"arg_0": "", "arg_1": " The connection between the limited nation and unbounded equality has paradoxical overtones., right? No, The nation is not reaching its full potential."}}, "resps": [[["-141.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "19ace7ef067cfb84195f4550b8e3445e7585ad01cf4d44430f5ac102b1c9b7c5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 679, "doc": {"premise": "Limpiar means to clean and a limpia is similar to a barrida.", "hypothesis": "Limpiar means to dance.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Yes, Limpiar means to dance."}, "gen_args_1": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? Also, Limpiar means to dance."}, "gen_args_2": {"arg_0": "", "arg_1": " Limpiar means to clean and a limpia is similar to a barrida., right? No, Limpiar means to dance."}}, "resps": [[["-120.5", "False"]], [["-120.5", "False"]], [["-117.0", "False"]]], "filtered_resps": [["-120.5", "False"], ["-120.5", "False"], ["-117.0", "False"]], "doc_hash": "27ee94a7544274bf75fbea0c26f382b60c26fd9000be2ef2ee6c506cce1b789d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02847749 0.02847749 0.94304502]"]}
{"doc_id": 687, "doc": {"premise": "A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions.", "hypothesis": "The most important thing in our future discussions is the third feature.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Yes, The most important thing in our future discussions is the third feature."}, "gen_args_1": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? Also, The most important thing in our future discussions is the third feature."}, "gen_args_2": {"arg_0": "", "arg_1": " A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions., right? No, The most important thing in our future discussions is the third feature."}}, "resps": [[["-201.0", "False"]], [["-209.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-209.0", "False"], ["-203.0", "False"]], "doc_hash": "a4422382b87c251c0c2ba5dfb99a083ba466f3fbb1e35a8469f62405ac16fd15", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[8.80536902e-01 2.95387223e-04 1.19167711e-01]"]}
{"doc_id": 695, "doc": {"premise": "On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys.", "hypothesis": "On Christmas Day, children went to the North Pole to visit Santa.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Yes, On Christmas Day, children went to the North Pole to visit Santa."}, "gen_args_1": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? Also, On Christmas Day, children went to the North Pole to visit Santa."}, "gen_args_2": {"arg_0": "", "arg_1": " On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys., right? No, On Christmas Day, children went to the North Pole to visit Santa."}}, "resps": [[["-132.0", "False"]], [["-133.0", "False"]], [["-126.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-133.0", "False"], ["-126.0", "False"]], "doc_hash": "e612cc9643ed22a9b2cc8663b4e02b674882b067f4ff4080ffc4a4de78fdcfef", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 703, "doc": {"premise": "Could statistical averaging be the source of order in organisms?", "hypothesis": "Organisms are defined by chaos; there is not a hint of order in them.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Yes, Organisms are defined by chaos; there is not a hint of order in them."}, "gen_args_1": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? Also, Organisms are defined by chaos; there is not a hint of order in them."}, "gen_args_2": {"arg_0": "", "arg_1": " Could statistical averaging be the source of order in organisms?, right? No, Organisms are defined by chaos; there is not a hint of order in them."}}, "resps": [[["-144.0", "False"]], [["-147.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-147.0", "False"], ["-144.0", "False"]], "doc_hash": "fa97a12f92743a32ee4b9f2c9f679884c2ac29155ffd1f037f5ba7d42740f47e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 711, "doc": {"premise": "Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers.", "hypothesis": "Catarino Garza was a well known Texas Ranger.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Yes, Catarino Garza was a well known Texas Ranger."}, "gen_args_1": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? Also, Catarino Garza was a well known Texas Ranger."}, "gen_args_2": {"arg_0": "", "arg_1": " Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers., right? No, Catarino Garza was a well known Texas Ranger."}}, "resps": [[["-168.0", "False"]], [["-172.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-172.0", "False"], ["-170.0", "False"]], "doc_hash": "f484a1cf733fae0f1ceb4935b1d5660ebd83ee3f0816a7b8f1ead71718fb8c76", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 719, "doc": {"premise": "Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons.", "hypothesis": "Neurons operate independently and never need to connect with other neurons.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Yes, Neurons operate independently and never need to connect with other neurons."}, "gen_args_1": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? Also, Neurons operate independently and never need to connect with other neurons."}, "gen_args_2": {"arg_0": "", "arg_1": " Once established, neurons begin to take on unique functions by sending out branching  bers, which form elaborate connections with other neurons., right? No, Neurons operate independently and never need to connect with other neurons."}}, "resps": [[["-172.0", "False"]], [["-174.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-174.0", "False"], ["-167.0", "False"]], "doc_hash": "8b24fc4a0cc5d4ccbf63154535d84b019436da0e0d2837a82b39a42229ff074b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 727, "doc": {"premise": "7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3).", "hypothesis": "The low demand group averages below three hundred.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Yes, The low demand group averages below three hundred."}, "gen_args_1": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? Also, The low demand group averages below three hundred."}, "gen_args_2": {"arg_0": "", "arg_1": " 7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3)., right? No, The low demand group averages below three hundred."}}, "resps": [[["-200.0", "False"]], [["-199.0", "False"]], [["-199.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-199.0", "False"], ["-199.0", "False"]], "doc_hash": "c0906990ceb8f1ccb9aba3fa556373855ed2343abbff732e1f1ca569ac398456", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 735, "doc": {"premise": "La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale.", "hypothesis": "Katz narced on the drug trade.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Yes, Katz narced on the drug trade."}, "gen_args_1": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? Also, Katz narced on the drug trade."}, "gen_args_2": {"arg_0": "", "arg_1": " La Vida de un Bato Loco,  written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of cale., right? No, Katz narced on the drug trade."}}, "resps": [[["-233.0", "False"]], [["-232.0", "False"]], [["-235.0", "False"]]], "filtered_resps": [["-233.0", "False"], ["-232.0", "False"], ["-235.0", "False"]], "doc_hash": "91efbb6ec8e68cb4169a720c86f557b52183bdb16c741f02fe5d39ea3f453f9e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.70538451 0.03511903]"]}
{"doc_id": 743, "doc": {"premise": "That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades.", "hypothesis": "We are not happy with hollow walls and flimsy doors.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Yes, We are not happy with hollow walls and flimsy doors."}, "gen_args_1": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? Also, We are not happy with hollow walls and flimsy doors."}, "gen_args_2": {"arg_0": "", "arg_1": " That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades., right? No, We are not happy with hollow walls and flimsy doors."}}, "resps": [[["-131.0", "False"]], [["-137.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-137.0", "False"], ["-132.0", "False"]], "doc_hash": "0bf6111235cbf6718e8bf278c6a70ad34f9178f9797af266420c96c1309b6501", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72973621 0.00180884 0.26845495]"]}
{"doc_id": 751, "doc": {"premise": "Jeremy Pitt answered the laugh with an oath.", "hypothesis": "Jeremy Pitt swore to fight for his country and his queen.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Yes, Jeremy Pitt swore to fight for his country and his queen."}, "gen_args_1": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? Also, Jeremy Pitt swore to fight for his country and his queen."}, "gen_args_2": {"arg_0": "", "arg_1": " Jeremy Pitt answered the laugh with an oath., right? No, Jeremy Pitt swore to fight for his country and his queen."}}, "resps": [[["-123.5", "False"]], [["-127.5", "False"]], [["-123.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-127.5", "False"], ["-123.0", "False"]], "doc_hash": "db049ace6b0168cddb0d9910108317f12f1f2a7edc328a738f5f9ad50d1465f9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.37494794 0.00686741 0.61818465]"]}
{"doc_id": 759, "doc": {"premise": "You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed.", "hypothesis": "He believed the crime committed could have been genocide.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Yes, He believed the crime committed could have been genocide."}, "gen_args_1": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? Also, He believed the crime committed could have been genocide."}, "gen_args_2": {"arg_0": "", "arg_1": " You have the effrontery to upbraid me because I will not take your hands when I know how they are stained; when I know you for a murderer and worse?   He stared at her open-mouthed., right? No, He believed the crime committed could have been genocide."}}, "resps": [[["-228.0", "False"]], [["-228.0", "False"]], [["-227.0", "False"]]], "filtered_resps": [["-228.0", "False"], ["-228.0", "False"], ["-227.0", "False"]], "doc_hash": "1494bd960bc9f9aa0cca254a825972d3526b44eff7900659713d42a91f24bb2b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 767, "doc": {"premise": "But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent.", "hypothesis": "The officer was shocked senseless by the vomiting onto the deck.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Yes, The officer was shocked senseless by the vomiting onto the deck."}, "gen_args_1": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? Also, The officer was shocked senseless by the vomiting onto the deck."}, "gen_args_2": {"arg_0": "", "arg_1": " But... but... aboard this ship...?  The officer made a gesture of helplessness, and, surrendering to his bewilderment, fell abruptly silent., right? No, The officer was shocked senseless by the vomiting onto the deck."}}, "resps": [[["-204.0", "False"]], [["-206.0", "False"]], [["-203.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-206.0", "False"], ["-203.0", "False"]], "doc_hash": "2f9ff8f635d4a89a23a3d8cbbd401be19be136e9999e6e0a6d925c41ffbffa27", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.03511903 0.70538451]"]}
{"doc_id": 775, "doc": {"premise": "There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him.", "hypothesis": "Lord Julian's domain includes Port Royal, a trade city that is a hub of activity in the region.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Yes, Lord Julian's domain includes Port Royal, a trade city that is a hub of activity in the region."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? Also, Lord Julian's domain includes Port Royal, a trade city that is a hub of activity in the region."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a gallows waiting for this rascal in Port Royal.   Blood would have intervened at that, but Lord Julian forestalled him., right? No, Lord Julian's domain includes Port Royal, a trade city that is a hub of activity in the region."}}, "resps": [[["-234.0", "False"]], [["-234.0", "False"]], [["-236.0", "False"]]], "filtered_resps": [["-234.0", "False"], ["-234.0", "False"], ["-236.0", "False"]], "doc_hash": "f8715cc05fc845a3d93d3b986f4ceaba21eb129af43a2dc7510d9936b638a079", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 783, "doc": {"premise": "Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission.", "hypothesis": "He slept soundly at night knowing he had rejected the King's commission.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Yes, He slept soundly at night knowing he had rejected the King's commission."}, "gen_args_1": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? Also, He slept soundly at night knowing he had rejected the King's commission."}, "gen_args_2": {"arg_0": "", "arg_1": " Things had not sped at all well with him in the past fortnight since his acceptance of the King's commission., right? No, He slept soundly at night knowing he had rejected the King's commission."}}, "resps": [[["-165.0", "False"]], [["-168.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-165.0", "False"], ["-168.0", "False"], ["-165.0", "False"]], "doc_hash": "83323b49758aee229faf0eefa18d4269b40f7c6cddabb40ece066e4f29d95dd7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 791, "doc": {"premise": "I have sent for you, Captain Blood, because of certain news that has just reached me.", "hypothesis": "The news I received shocked me to the core.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Yes, The news I received shocked me to the core."}, "gen_args_1": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? Also, The news I received shocked me to the core."}, "gen_args_2": {"arg_0": "", "arg_1": " I have sent for you, Captain Blood, because of certain news that has just reached me., right? No, The news I received shocked me to the core."}}, "resps": [[["-124.5", "False"]], [["-131.0", "False"]], [["-128.0", "False"]]], "filtered_resps": [["-124.5", "False"], ["-131.0", "False"], ["-128.0", "False"]], "doc_hash": "9c118a27b6f9e482065ed40400fe395d9ab2d6d0ba6e3c1f3a95388ca8b646e8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 799, "doc": {"premise": "Well, well, maybe he'll not find me quite so easy to grasp as he imagines.", "hypothesis": "He thinks grabbing me will be really simple.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Yes, He thinks grabbing me will be really simple."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? Also, He thinks grabbing me will be really simple."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, well, maybe he'll not find me quite so easy to grasp as he imagines., right? No, He thinks grabbing me will be really simple."}}, "resps": [[["-137.0", "False"]], [["-141.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-141.0", "False"], ["-137.0", "False"]], "doc_hash": "3ddb940ab0e2229abd28d81c5d3a4dba10a87633c00ca47c619ef010aafbea30", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 807, "doc": {"premise": "Thoughtfully he stroked his golden beard.", "hypothesis": "He had a beard that was a gold color.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Yes, He had a beard that was a gold color."}, "gen_args_1": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? Also, He had a beard that was a gold color."}, "gen_args_2": {"arg_0": "", "arg_1": " Thoughtfully he stroked his golden beard., right? No, He had a beard that was a gold color."}}, "resps": [[["-101.0", "False"]], [["-105.0", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-101.0", "False"], ["-105.0", "False"], ["-101.0", "False"]], "doc_hash": "044db25bd4323df0cd7d5d7ec5d08cc9a8e2adfc415ff864f853aa51c42c852d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 815, "doc": {"premise": "What better way?  he demanded.", "hypothesis": "He was convinced that he had chosen the best way.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Yes, He was convinced that he had chosen the best way."}, "gen_args_1": {"arg_0": "", "arg_1": " What better way?  he demanded., right? Also, He was convinced that he had chosen the best way."}, "gen_args_2": {"arg_0": "", "arg_1": " What better way?  he demanded., right? No, He was convinced that he had chosen the best way."}}, "resps": [[["-105.5", "False"]], [["-110.5", "False"]], [["-107.0", "False"]]], "filtered_resps": [["-105.5", "False"], ["-110.5", "False"], ["-107.0", "False"]], "doc_hash": "3a9317e42277c538e5cdbae7d12a3dcf349d8190e7622511dd73028389da76dd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.81309532 0.00547859 0.18142609]"]}
{"doc_id": 823, "doc": {"premise": "Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis.", "hypothesis": "He spit on the ground in an effort to emphasize his point.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Yes, He spit on the ground in an effort to emphasize his point."}, "gen_args_1": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? Also, He spit on the ground in an effort to emphasize his point."}, "gen_args_2": {"arg_0": "", "arg_1": " Wolverstone squared himself defiantly before his captain   I'll see Colonel Bishop in hell or ever I lies to for him.  And he spat, presumably for purposes of emphasis., right? No, He spit on the ground in an effort to emphasize his point."}}, "resps": [[["-262.0", "False"]], [["-270.0", "False"]], [["-266.0", "False"]]], "filtered_resps": [["-262.0", "False"], ["-270.0", "False"], ["-266.0", "False"]], "doc_hash": "51629d6a32c873b6726568293724287e7db9457b760981b4a9154e82f4c475a1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 831, "doc": {"premise": "Your resolve delivered me from a horrible danger,  she admitted.", "hypothesis": "She did not want him to help her, though was grateful anyway.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Yes, She did not want him to help her, though was grateful anyway."}, "gen_args_1": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? Also, She did not want him to help her, though was grateful anyway."}, "gen_args_2": {"arg_0": "", "arg_1": " Your resolve delivered me from a horrible danger,  she admitted., right? No, She did not want him to help her, though was grateful anyway."}}, "resps": [[["-160.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "523ac26a6f3f5db4300ee26e0330bbb3062be6c3ff5742fe57289a74fce96e90", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 839, "doc": {"premise": "You're not very civil, sir, as I have already noticed.", "hypothesis": "They are having a conversation.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Yes, They are having a conversation."}, "gen_args_1": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? Also, They are having a conversation."}, "gen_args_2": {"arg_0": "", "arg_1": " You're not very civil, sir, as I have already noticed., right? No, They are having a conversation."}}, "resps": [[["-106.0", "False"]], [["-107.5", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-106.0", "False"], ["-107.5", "False"], ["-106.5", "False"]], "doc_hash": "1c37207f21bb462f2904a42d128fe18b49bdad8fb4793170e28de08704c5115c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.54654939 0.12195165 0.33149896]"]}
{"doc_id": 847, "doc": {"premise": "But Pitt, although he shared it, was prompt to obey.", "hypothesis": "Pitt is the name of a dog that is very obedient.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Yes, Pitt is the name of a dog that is very obedient."}, "gen_args_1": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? Also, Pitt is the name of a dog that is very obedient."}, "gen_args_2": {"arg_0": "", "arg_1": " But Pitt, although he shared it, was prompt to obey., right? No, Pitt is the name of a dog that is very obedient."}}, "resps": [[["-134.0", "False"]], [["-138.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-138.0", "False"], ["-136.0", "False"]], "doc_hash": "c9fcf88f5c2b38436ef9f965d4373580646ce3527b7b3f31069dac367f6c1b52", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 855, "doc": {"premise": "There's a thorn or two left on me.  And with a laugh Blood departed to his cabin.", "hypothesis": "Blood had been inside his cabin.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Yes, Blood had been inside his cabin."}, "gen_args_1": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? Also, Blood had been inside his cabin."}, "gen_args_2": {"arg_0": "", "arg_1": " There's a thorn or two left on me.  And with a laugh Blood departed to his cabin., right? No, Blood had been inside his cabin."}}, "resps": [[["-168.0", "False"]], [["-173.0", "False"]], [["-167.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-173.0", "False"], ["-167.0", "False"]], "doc_hash": "e0863afb00271ff2b43506bf68ad693a45be4367b2927db39707b2874ddac1f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26845495 0.00180884 0.72973621]"]}
{"doc_id": 863, "doc": {"premise": "We went about, and it's been a race ever since.", "hypothesis": "There was never any race to begin with.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Yes, There was never any race to begin with."}, "gen_args_1": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? Also, There was never any race to begin with."}, "gen_args_2": {"arg_0": "", "arg_1": " We went about, and it's been a race ever since., right? No, There was never any race to begin with."}}, "resps": [[["-105.0", "False"]], [["-107.5", "False"]], [["-101.5", "False"]]], "filtered_resps": [["-105.0", "False"], ["-107.5", "False"], ["-101.5", "False"]], "doc_hash": "e22a8623dd222c481c8cfd21bf6b27f79a5598be5b5f00a0cc07e319e64966b8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 871, "doc": {"premise": "In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone.", "hypothesis": "Miss Bishop went to the garden in order to contemplate her life.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Yes, Miss Bishop went to the garden in order to contemplate her life."}, "gen_args_1": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? Also, Miss Bishop went to the garden in order to contemplate her life."}, "gen_args_2": {"arg_0": "", "arg_1": " In that garden's main avenue, that was fringed with palm and sandalwood, he had caught sight of Miss Bishop alone., right? No, Miss Bishop went to the garden in order to contemplate her life."}}, "resps": [[["-182.0", "False"]], [["-186.0", "False"]], [["-188.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-186.0", "False"], ["-188.0", "False"]], "doc_hash": "116d5a1cd06af8d18c34d77ee4f50e6c34b95049eb6eb78bc7a62c6c54910446", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.01794253 0.00242826]"]}
{"doc_id": 879, "doc": {"premise": "And who the devil may you be?  he exploded at last.", "hypothesis": "He had suddenly asked a question as to who you may be.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Yes, He had suddenly asked a question as to who you may be."}, "gen_args_1": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? Also, He had suddenly asked a question as to who you may be."}, "gen_args_2": {"arg_0": "", "arg_1": " And who the devil may you be?  he exploded at last., right? No, He had suddenly asked a question as to who you may be."}}, "resps": [[["-137.0", "False"]], [["-142.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-142.0", "False"], ["-137.0", "False"]], "doc_hash": "d67828911f55e181e596599083068dbca88c816f2cd531bec7606022d314ef98", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 887, "doc": {"premise": "Steady, Old Wolf! Steady!  Captain Blood admonished him.", "hypothesis": "Let go! Captain Blood yelled to Old Wolf.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Yes, Let go! Captain Blood yelled to Old Wolf."}, "gen_args_1": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? Also, Let go! Captain Blood yelled to Old Wolf."}, "gen_args_2": {"arg_0": "", "arg_1": " Steady, Old Wolf! Steady!  Captain Blood admonished him., right? No, Let go! Captain Blood yelled to Old Wolf."}}, "resps": [[["-148.0", "False"]], [["-149.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-149.0", "False"], ["-147.0", "False"]], "doc_hash": "e455d2c6d54ac5807c83b3eeb201386062d1a3d1eb2d21db6b92b11b50cecb04", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 895, "doc": {"premise": "And that was practically the end of the matter.", "hypothesis": "The matter remains unresolved.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Yes, The matter remains unresolved."}, "gen_args_1": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? Also, The matter remains unresolved."}, "gen_args_2": {"arg_0": "", "arg_1": " And that was practically the end of the matter., right? No, The matter remains unresolved."}}, "resps": [[["-81.0", "False"]], [["-84.5", "False"]], [["-78.5", "False"]]], "filtered_resps": [["-81.0", "False"], ["-84.5", "False"], ["-78.5", "False"]], "doc_hash": "6a9ffa43db91e18d26df2f174595e21384fbd864fd23f58d73504c6a23ce9736", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.07568481 0.00228548 0.92202971]"]}
{"doc_id": 903, "doc": {"premise": "There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk.", "hypothesis": "The ship will sink unless the crew acts fast.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Yes, The ship will sink unless the crew acts fast."}, "gen_args_1": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? Also, The ship will sink unless the crew acts fast."}, "gen_args_2": {"arg_0": "", "arg_1": " There's no heaving to for such a matter as that unless you wants to make quite sure of our being sunk., right? No, The ship will sink unless the crew acts fast."}}, "resps": [[["-172.0", "False"]], [["-174.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-174.0", "False"], ["-176.0", "False"]], "doc_hash": "0e6c9fc5882ff0301be69f3dc8b84ca7d8a2cb25946e5f659f661a28b10f55d1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 911, "doc": {"premise": "He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow.", "hypothesis": "There was once a story about a dog and a delusive shadow.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Yes, There was once a story about a dog and a delusive shadow."}, "gen_args_1": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? Also, There was once a story about a dog and a delusive shadow."}, "gen_args_2": {"arg_0": "", "arg_1": " He beheld himself to be as the dog in the fable that had dropped the substance to snatch at a delusive shadow., right? No, There was once a story about a dog and a delusive shadow."}}, "resps": [[["-174.0", "False"]], [["-177.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-177.0", "False"], ["-177.0", "False"]], "doc_hash": "d76edabb8fce72ba86ebc0c17b3142589bb048ddce444d9fa771741d583635ae", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.909443  0.0452785 0.0452785]"]}
{"doc_id": 919, "doc": {"premise": "But it'll be about the Old Wolf that he wants to see you.", "hypothesis": "He wants to see you about the Old Wolf.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Yes, He wants to see you about the Old Wolf."}, "gen_args_1": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? Also, He wants to see you about the Old Wolf."}, "gen_args_2": {"arg_0": "", "arg_1": " But it'll be about the Old Wolf that he wants to see you., right? No, He wants to see you about the Old Wolf."}}, "resps": [[["-114.0", "False"]], [["-121.0", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-114.0", "False"], ["-121.0", "False"], ["-115.0", "False"]], "doc_hash": "fc9e3968667188426d798d91ea7f2612a3e5da18268c4dd02f7cdf944aa7f5dc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30571551e-01 6.66195022e-04 2.68762254e-01]"]}
{"doc_id": 927, "doc": {"premise": "England's,  she corrected him in reproof.", "hypothesis": "He was wrong and she said nothing.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Yes, He was wrong and she said nothing."}, "gen_args_1": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? Also, He was wrong and she said nothing."}, "gen_args_2": {"arg_0": "", "arg_1": " England's,  she corrected him in reproof., right? No, He was wrong and she said nothing."}}, "resps": [[["-122.0", "False"]], [["-128.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-122.0", "False"], ["-128.0", "False"], ["-119.5", "False"]], "doc_hash": "c4f254ee17a15a5eee0b20349ded54d40d5323827bea847f53293eeeb2f40c04", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58439188e-02 1.87998279e-04 9.23968083e-01]"]}
{"doc_id": 935, "doc": {"premise": "I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels.", "hypothesis": "Your lordship has chosen to act in a manner against my advice.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Yes, Your lordship has chosen to act in a manner against my advice."}, "gen_args_1": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? Also, Your lordship has chosen to act in a manner against my advice."}, "gen_args_2": {"arg_0": "", "arg_1": " I hope your lordship begins at last to perceive the folly of granting the King's commission to such a man as this against all my counsels., right? No, Your lordship has chosen to act in a manner against my advice."}}, "resps": [[["-173.0", "False"]], [["-180.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-180.0", "False"], ["-173.0", "False"]], "doc_hash": "7e471b243637c90af226262cf45b8b0d8ce4aed52fc51245d56abbd3f3b16622", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99772133e-01 4.55733195e-04 4.99772133e-01]"]}
{"doc_id": 943, "doc": {"premise": "If anything it increased his excitement.", "hypothesis": "It made him more excited than he had ever been.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Yes, It made him more excited than he had ever been."}, "gen_args_1": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? Also, It made him more excited than he had ever been."}, "gen_args_2": {"arg_0": "", "arg_1": " If anything it increased his excitement., right? No, It made him more excited than he had ever been."}}, "resps": [[["-93.0", "False"]], [["-101.5", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-93.0", "False"], ["-101.5", "False"], ["-93.0", "False"]], "doc_hash": "405129bea3a50902a6f90fbef1b92ce7932800c95419a9b919f198be08309e64", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99949138e-01 1.01723836e-04 4.99949138e-01]"]}
{"doc_id": 951, "doc": {"premise": "Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way.", "hypothesis": "A person who is shouting decides to fix someone else's mistake.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Yes, A person who is shouting decides to fix someone else's mistake."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? Also, A person who is shouting decides to fix someone else's mistake."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't you, by God! And what else do you call this? But as His Majesty's Deputy-Governor of Jamaica, I'll take leave to correct your mistake in my own way., right? No, A person who is shouting decides to fix someone else's mistake."}}, "resps": [[["-216.0", "False"]], [["-221.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-216.0", "False"], ["-221.0", "False"], ["-216.0", "False"]], "doc_hash": "62011efcd3f52707bb31b8078e38b86ee871fe98b11084e84cfdc913fb82d6d3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49832117 0.00335766 0.49832117]"]}
{"doc_id": 959, "doc": {"premise": "That girl, there.  He flung out a bare arm to point to her.", "hypothesis": "The girl had blonde hair.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Yes, The girl had blonde hair."}, "gen_args_1": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? Also, The girl had blonde hair."}, "gen_args_2": {"arg_0": "", "arg_1": " That girl, there.  He flung out a bare arm to point to her., right? No, The girl had blonde hair."}}, "resps": [[["-125.0", "False"]], [["-127.5", "False"]], [["-125.5", "False"]]], "filtered_resps": [["-125.0", "False"], ["-127.5", "False"], ["-125.5", "False"]], "doc_hash": "dec56c322c9112e371c9fe1ece8d742b668d3e18f9c7cef4879cf35180590b3e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.59220107 0.04861082 0.35918811]"]}
{"doc_id": 967, "doc": {"premise": "I'll not be bubbled by what Wolverstone has said.", "hypothesis": "I felt very bubbled by the words of Wolverstone.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Yes, I felt very bubbled by the words of Wolverstone."}, "gen_args_1": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? Also, I felt very bubbled by the words of Wolverstone."}, "gen_args_2": {"arg_0": "", "arg_1": " I'll not be bubbled by what Wolverstone has said., right? No, I felt very bubbled by the words of Wolverstone."}}, "resps": [[["-134.0", "False"]], [["-142.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-142.0", "False"], ["-134.0", "False"]], "doc_hash": "b61fc8f7017ddb4a3c94f67346f79770e8f3e0732f9d74379000d8920950b99a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.99916148e-01 1.67703185e-04 4.99916148e-01]"]}
{"doc_id": 975, "doc": {"premise": "Bid them take in sail, Jeremy,  he said quietly.", "hypothesis": "He spoke with a soft tone.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Yes, He spoke with a soft tone."}, "gen_args_1": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? Also, He spoke with a soft tone."}, "gen_args_2": {"arg_0": "", "arg_1": " Bid them take in sail, Jeremy,  he said quietly., right? No, He spoke with a soft tone."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-134.0", "False"]], "doc_hash": "1c230bbb75c39b0454d6d9f1de0b0a4c5780f6d4a22b3d5d451bfa95a2885755", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 983, "doc": {"premise": "He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it.", "hypothesis": "There was some foreign language in the pages before him.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Yes, There was some foreign language in the pages before him."}, "gen_args_1": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? Also, There was some foreign language in the pages before him."}, "gen_args_2": {"arg_0": "", "arg_1": " He sought comfort in a line on the open page before him:     levius fit patientia quicquid corrigere est nefas.   Sought it, but hardly found it., right? No, There was some foreign language in the pages before him."}}, "resps": [[["-258.0", "False"]], [["-260.0", "False"]], [["-258.0", "False"]]], "filtered_resps": [["-258.0", "False"], ["-260.0", "False"], ["-258.0", "False"]], "doc_hash": "797db4a30b0485cdb67a25b1d6b8ee5df014c0eeee71c4f8fc3fff28ec5e4d8b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 991, "doc": {"premise": "He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic.", "hypothesis": "He could see Captain Blood.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Yes, He could see Captain Blood."}, "gen_args_1": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? Also, He could see Captain Blood."}, "gen_args_2": {"arg_0": "", "arg_1": " He stopped short at sight of Captain Blood, and saluted him, as was his due, but the smile that lifted the officer's stiff mostachios was grimly sardonic., right? No, He could see Captain Blood."}}, "resps": [[["-199.0", "False"]], [["-202.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-202.0", "False"], ["-200.0", "False"]], "doc_hash": "901a184bb2278c7bf50e0d4d0faaa253ea84ba7d01a57537b7938dd6c4018b26", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 999, "doc": {"premise": "The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December.", "hypothesis": "In the fall and summer, the San Francisco Ballet is on break.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Yes, In the fall and summer, the San Francisco Ballet is on break."}, "gen_args_1": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? Also, In the fall and summer, the San Francisco Ballet is on break."}, "gen_args_2": {"arg_0": "", "arg_1": " The San Francisco Ballet has its main season at the Opera House in the spring, but also puts on performances during December., right? No, In the fall and summer, the San Francisco Ballet is on break."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "ae0390a3bc2b6e29316c097d9149e85747ef8babcf9b7628eac23eeedd6feb23", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1007, "doc": {"premise": "Hopes were raised, and also fizzled, over Bahamian citrus and pineapple.", "hypothesis": "The Bahamian citrus was not as great as everyone had hoped.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Yes, The Bahamian citrus was not as great as everyone had hoped."}, "gen_args_1": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? Also, The Bahamian citrus was not as great as everyone had hoped."}, "gen_args_2": {"arg_0": "", "arg_1": " Hopes were raised, and also fizzled, over Bahamian citrus and pineapple., right? No, The Bahamian citrus was not as great as everyone had hoped."}}, "resps": [[["-147.0", "False"]], [["-152.0", "False"]], [["-151.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-152.0", "False"], ["-151.0", "False"]], "doc_hash": "765cc9211e4c7a25bbba4e9232d19e62d9901732945fb11297a526c500dec691", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1015, "doc": {"premise": "There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society.", "hypothesis": "There is a language problem that might intimidate you.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Yes, There is a language problem that might intimidate you."}, "gen_args_1": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? Also, There is a language problem that might intimidate you."}, "gen_args_2": {"arg_0": "", "arg_1": " There the scene is less relaxed and the language problem might daunt you, but at least you'll be able to catch a glimpse of Chinese consumer society., right? No, There is a language problem that might intimidate you."}}, "resps": [[["-180.0", "False"]], [["-183.0", "False"]], [["-182.0", "False"]]], "filtered_resps": [["-180.0", "False"], ["-183.0", "False"], ["-182.0", "False"]], "doc_hash": "6fd68d9656f2dd02c98a5129a45e7bac135a5e78e2a43d03a6a807ee82ffc925", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1023, "doc": {"premise": "The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture.", "hypothesis": "Sant Pau does not have Romanesque lines.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Yes, Sant Pau does not have Romanesque lines."}, "gen_args_1": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? Also, Sant Pau does not have Romanesque lines."}, "gen_args_2": {"arg_0": "", "arg_1": " The simplicity of Sant Pau's Romanesque lines is an agreeable change from the extravagance of Barcelona's modernisme and the intricacies of Gothic architecture., right? No, Sant Pau does not have Romanesque lines."}}, "resps": [[["-155.0", "False"]], [["-155.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-155.0", "False"], ["-155.0", "False"], ["-149.0", "False"]], "doc_hash": "0e0f9311a26f4584324c3ca765705694eb84d9b01b16ae0c219ce98319903982", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1031, "doc": {"premise": "An extensive program of refurbishment is due to be finished by late 2001.", "hypothesis": "When the refurbishment program ends, it will have lasted five years.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Yes, When the refurbishment program ends, it will have lasted five years."}, "gen_args_1": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? Also, When the refurbishment program ends, it will have lasted five years."}, "gen_args_2": {"arg_0": "", "arg_1": " An extensive program of refurbishment is due to be finished by late 2001., right? No, When the refurbishment program ends, it will have lasted five years."}}, "resps": [[["-122.0", "False"]], [["-129.0", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-122.0", "False"], ["-129.0", "False"], ["-124.0", "False"]], "doc_hash": "b2782ecc671577328e593bc65aef651c62cb0ffacfc3dade65ffbb7c1d0ce75d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 1039, "doc": {"premise": "The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast.", "hypothesis": "The mountains make it hard to build harbors.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Yes, The mountains make it hard to build harbors."}, "gen_args_1": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? Also, The mountains make it hard to build harbors."}, "gen_args_2": {"arg_0": "", "arg_1": " The rugged mountains of the Serra de Tramuntana sweep down to the sea so steeply here that there are few points of access and only one harbor and port of any size along the coast., right? No, The mountains make it hard to build harbors."}}, "resps": [[["-181.0", "False"]], [["-185.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-185.0", "False"], ["-181.0", "False"]], "doc_hash": "31500e1efd1158b8e576e428bc85e6c32b6548726d28203981aed8c557e4034e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1047, "doc": {"premise": "Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle.", "hypothesis": "Umeda is not part of the entertainment district.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Yes, Umeda is not part of the entertainment district."}, "gen_args_1": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? Also, Umeda is not part of the entertainment district."}, "gen_args_2": {"arg_0": "", "arg_1": " Umeda marks the northern end of the business and entertainment district popularly known as Kita (meaning simply  North ), and is the very essence of modern Osaka's hustle and bustle., right? No, Umeda is not part of the entertainment district."}}, "resps": [[["-181.0", "False"]], [["-180.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-180.0", "False"], ["-173.0", "False"]], "doc_hash": "f8ca35bcccda4b9166ea04d542136cbef007c0276033e5c1a2cc26984a1d40c7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35044712e-04 9.10745952e-04 9.98754209e-01]"]}
{"doc_id": 1055, "doc": {"premise": "The third member of the Hindu  trinity  is Brahma, whose only task was to create the world.", "hypothesis": "Brahma is the most important part of the trinity.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Yes, Brahma is the most important part of the trinity."}, "gen_args_1": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? Also, Brahma is the most important part of the trinity."}, "gen_args_2": {"arg_0": "", "arg_1": " The third member of the Hindu  trinity  is Brahma, whose only task was to create the world., right? No, Brahma is the most important part of the trinity."}}, "resps": [[["-126.5", "False"]], [["-127.5", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-126.5", "False"], ["-127.5", "False"], ["-125.0", "False"]], "doc_hash": "701772454e565e972907016086a2f0791891e2273ec45075e6fd705547744873", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.17095278 0.06289001 0.76615721]"]}
{"doc_id": 1063, "doc": {"premise": "The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor.", "hypothesis": "You can touch some of the imperial armor.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Yes, You can touch some of the imperial armor."}, "gen_args_1": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? Also, You can touch some of the imperial armor."}, "gen_args_2": {"arg_0": "", "arg_1": " The massive courtyards and pavilions above Yongle's burial chambers have been restored, and they house some of the Ming Tombs' excavated treasures, including imperial armor., right? No, You can touch some of the imperial armor."}}, "resps": [[["-186.0", "False"]], [["-191.0", "False"]], [["-190.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-191.0", "False"], ["-190.0", "False"]], "doc_hash": "4e4369c35fe7f15f69e130d04bfa78dd767edb017df7185e7e19b284a61b1b29", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1071, "doc": {"premise": "Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott.", "hypothesis": "Hawthorne lived on Main Street.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Yes, Hawthorne lived on Main Street."}, "gen_args_1": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? Also, Hawthorne lived on Main Street."}, "gen_args_2": {"arg_0": "", "arg_1": " Louisa May Alcott and Nathaniel Hawthorne resided on Pinckney Street, while Beacon Street which Oliver Wendell Holmes dubbed  the sunny street that holds the sifted few  boasted historian William Prescott., right? No, Hawthorne lived on Main Street."}}, "resps": [[["-237.0", "False"]], [["-236.0", "False"]], [["-236.0", "False"]]], "filtered_resps": [["-237.0", "False"], ["-236.0", "False"], ["-236.0", "False"]], "doc_hash": "e8f5794bb7c1ad3bfd34f3236c86d91fa9129ed974450c76f702d96801ffb7cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1079, "doc": {"premise": "Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi.", "hypothesis": "Kuala Perlis was to the south.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Yes, Kuala Perlis was to the south."}, "gen_args_1": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? Also, Kuala Perlis was to the south."}, "gen_args_2": {"arg_0": "", "arg_1": " Kuala Perlis, south of the state capital, Kangar, is the departure point for the less than an hour's ferry journey to Langkawi., right? No, Kuala Perlis was to the south."}}, "resps": [[["-145.0", "False"]], [["-147.0", "False"]], [["-142.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-147.0", "False"], ["-142.0", "False"]], "doc_hash": "5657340a4b34bdfc95a925465469519fe9648db69d49036ae115862591b27561", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1087, "doc": {"premise": "May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them.", "hypothesis": "The pictures show what lovely things will happen to them.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Yes, The pictures show what lovely things will happen to them."}, "gen_args_1": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? Also, The pictures show what lovely things will happen to them."}, "gen_args_2": {"arg_0": "", "arg_1": " May such terror terrify those in thrall to earthly error, for the horror of these images tells what awaits them., right? No, The pictures show what lovely things will happen to them."}}, "resps": [[["-186.0", "False"]], [["-191.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-191.0", "False"], ["-183.0", "False"]], "doc_hash": "440cb115a9163025d19fca02b0e39d6fa10ebcc7d58064cf150d2eba1326bbca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.74107229e-02 3.19450938e-04 9.52269826e-01]"]}
{"doc_id": 1095, "doc": {"premise": "As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda.", "hypothesis": "The chimney is not an indicator that the village used to be part of a hacienda.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Yes, The chimney is not an indicator that the village used to be part of a hacienda."}, "gen_args_1": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? Also, The chimney is not an indicator that the village used to be part of a hacienda."}, "gen_args_2": {"arg_0": "", "arg_1": " As you pass through them you may see an old chimney breaking above the tree line, a sure sign that the village was once part of a hacienda., right? No, The chimney is not an indicator that the village used to be part of a hacienda."}}, "resps": [[["-168.0", "False"]], [["-170.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-170.0", "False"], ["-163.0", "False"]], "doc_hash": "5eddff5df41da914acaece3de3c5c5d20699afeddd91cdbeaf0706def72680e5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[6.68679417e-03 9.04959183e-04 9.92408247e-01]"]}
{"doc_id": 1103, "doc": {"premise": "The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors.", "hypothesis": "The acoustics make things loud.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Yes, The acoustics make things loud."}, "gen_args_1": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? Also, The acoustics make things loud."}, "gen_args_2": {"arg_0": "", "arg_1": " The acoustics inside the tomb are very precise, exaggerating the sound of your approaching fellow visitors., right? No, The acoustics make things loud."}}, "resps": [[["-149.0", "False"]], [["-152.0", "False"]], [["-147.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-152.0", "False"], ["-147.0", "False"]], "doc_hash": "c1ee78d3ae9ed240866b5c2fef0bfb2031112c25777579a8576dcb38cfad509e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1111, "doc": {"premise": "Don't fire unless fired upon!", "hypothesis": "Only shoot if someone near you has a gun and fires a shot at your head.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Yes, Only shoot if someone near you has a gun and fires a shot at your head."}, "gen_args_1": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? Also, Only shoot if someone near you has a gun and fires a shot at your head."}, "gen_args_2": {"arg_0": "", "arg_1": " Don't fire unless fired upon!, right? No, Only shoot if someone near you has a gun and fires a shot at your head."}}, "resps": [[["-112.0", "False"]], [["-116.0", "False"]], [["-109.5", "False"]]], "filtered_resps": [["-112.0", "False"], ["-116.0", "False"], ["-109.5", "False"]], "doc_hash": "28ebc4311d08c703fb4728ecaa18b988e9c81c015504ef6acdc4df57f973cdc8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07575293 0.00138746 0.92285961]"]}
{"doc_id": 1119, "doc": {"premise": "At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany.", "hypothesis": "Canada has never welcomed refugees.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Yes, Canada has never welcomed refugees."}, "gen_args_1": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? Also, Canada has never welcomed refugees."}, "gen_args_2": {"arg_0": "", "arg_1": " At the outbreak of war, Canada's reputation for welcoming immigrants and refugees from all over the world was tarnished by the blocking of Communists and Jews from Hitler's Germany., right? No, Canada has never welcomed refugees."}}, "resps": [[["-156.0", "False"]], [["-156.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-156.0", "False"], ["-152.0", "False"]], "doc_hash": "ae09906681c78d2caae5dc3d57951eba5aad0922005c8b05d680c77a600a5b0f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01766842 0.01766842 0.96466316]"]}
{"doc_id": 1127, "doc": {"premise": "Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth.", "hypothesis": "These structures were built by the greatest architect in the world.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Yes, These structures were built by the greatest architect in the world."}, "gen_args_1": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? Also, These structures were built by the greatest architect in the world."}, "gen_args_2": {"arg_0": "", "arg_1": " Flanking it, a modern octagonal church to the east and a chapel and hexagonal tower to the west represent the city's post-war rebirth., right? No, These structures were built by the greatest architect in the world."}}, "resps": [[["-178.0", "False"]], [["-179.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-178.0", "False"], ["-179.0", "False"], ["-175.0", "False"]], "doc_hash": "e2b4ebcf3b511580c191b1046e8b48b4480b8af520b9c274d23a734956ebdfa1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 1135, "doc": {"premise": "Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge.", "hypothesis": "The collection of clubs is dull and looks the same as all the others.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Yes, The collection of clubs is dull and looks the same as all the others."}, "gen_args_1": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? Also, The collection of clubs is dull and looks the same as all the others."}, "gen_args_2": {"arg_0": "", "arg_1": " Just a few blocks in back of the malecen are a growing collection of unique clubs with a more urban edge., right? No, The collection of clubs is dull and looks the same as all the others."}}, "resps": [[["-187.0", "False"]], [["-188.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-187.0", "False"], ["-188.0", "False"], ["-185.0", "False"]], "doc_hash": "ef98a4a49c10312445334c0e367b167193f398e42071016cb90cdbc19db27577", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.1141952  0.04201007 0.84379473]"]}
{"doc_id": 1143, "doc": {"premise": "On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony.", "hypothesis": "The Parque de Palapas is where people have barbecues all the time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Yes, The Parque de Palapas is where people have barbecues all the time."}, "gen_args_1": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? Also, The Parque de Palapas is where people have barbecues all the time."}, "gen_args_2": {"arg_0": "", "arg_1": " On weekends you can join the locals in the Parque de Palapas, where the strains of rock, salsa, and folk music can blend together into a bewildering cacophony., right? No, The Parque de Palapas is where people have barbecues all the time."}}, "resps": [[["-186.0", "False"]], [["-184.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-184.0", "False"], ["-185.0", "False"]], "doc_hash": "b465f28ba23bfac2ce163d54ace2f1050604c60d01c968d3eb4d1a25a3eba15d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.09003057 0.66524096 0.24472847]"]}
{"doc_id": 1151, "doc": {"premise": "Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests.", "hypothesis": "National unity is never the first priority.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Yes, National unity is never the first priority."}, "gen_args_1": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? Also, National unity is never the first priority."}, "gen_args_2": {"arg_0": "", "arg_1": " Henceforth, national unity always played second fiddle to ethnic, religious, and above all economic regional interests., right? No, National unity is never the first priority."}}, "resps": [[["-132.0", "False"]], [["-137.0", "False"]], [["-133.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-137.0", "False"], ["-133.0", "False"]], "doc_hash": "0b59856ea21f43f512ba17c7291c95780d8f4b952fed63fbabba1b496740c3cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1159, "doc": {"premise": "Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market.", "hypothesis": "The market sells lots of fruits and vegetables.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Yes, The market sells lots of fruits and vegetables."}, "gen_args_1": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? Also, The market sells lots of fruits and vegetables."}, "gen_args_2": {"arg_0": "", "arg_1": " Have a look at Passeig de Gracia to the east, especially the carrers Diputacie, Consell de Cent, Mallorca, and Valancia as far as the Mercat de la Concepcie market., right? No, The market sells lots of fruits and vegetables."}}, "resps": [[["-219.0", "False"]], [["-221.0", "False"]], [["-224.0", "False"]]], "filtered_resps": [["-219.0", "False"], ["-221.0", "False"], ["-224.0", "False"]], "doc_hash": "ee27839f5d005bbd50a99780a7159cb91f24f0ca5643527ded08654b0ba99ab4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.11849965 0.00589975]"]}
{"doc_id": 1167, "doc": {"premise": "The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay.", "hypothesis": "The visitors all stay far away from the cathedral.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Yes, The visitors all stay far away from the cathedral."}, "gen_args_1": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? Also, The visitors all stay far away from the cathedral."}, "gen_args_2": {"arg_0": "", "arg_1": " The area of greatest interest to visitors is the small old quarter that surrounds the cathedral, which sits on a small hill overlooking the bay., right? No, The visitors all stay far away from the cathedral."}}, "resps": [[["-156.0", "False"]], [["-158.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-158.0", "False"], ["-152.0", "False"]], "doc_hash": "9ce38afa828f968134d1fb3c4021b627181a4917ce77dd7f2e95f7d60935a9c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1175, "doc": {"premise": "Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy.", "hypothesis": "The snake would only eat pilgrims attempting to gain access to the temple.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Yes, The snake would only eat pilgrims attempting to gain access to the temple."}, "gen_args_1": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? Also, The snake would only eat pilgrims attempting to gain access to the temple."}, "gen_args_2": {"arg_0": "", "arg_1": " Pilgrims would buy honey cakes for this snake and leave them at the temple entrance for it to enjoy., right? No, The snake would only eat pilgrims attempting to gain access to the temple."}}, "resps": [[["-168.0", "False"]], [["-168.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-168.0", "False"], ["-162.0", "False"]], "doc_hash": "f7e33dddd7d7debebd03ce371dfbc4670bcdafb43ae93e309590e60ef0d01b33", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00246652 0.00246652 0.99506695]"]}
{"doc_id": 1183, "doc": {"premise": "Today the site is called the Temple of Heaven Park (Tiantan Gongyuan).", "hypothesis": "Temple of Heaven Park was named that in 2010.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Yes, Temple of Heaven Park was named that in 2010."}, "gen_args_1": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? Also, Temple of Heaven Park was named that in 2010."}, "gen_args_2": {"arg_0": "", "arg_1": " Today the site is called the Temple of Heaven Park (Tiantan Gongyuan)., right? No, Temple of Heaven Park was named that in 2010."}}, "resps": [[["-105.0", "False"]], [["-109.0", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-105.0", "False"], ["-109.0", "False"], ["-103.0", "False"]], "doc_hash": "7045a5b7c065f596374e95c0971e00f8f20e50b5c3766147d9b47e17cbf506c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11894324 0.00217852 0.87887824]"]}
{"doc_id": 1191, "doc": {"premise": "Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport.", "hypothesis": "Miramar has pretty homes.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Yes, Miramar has pretty homes."}, "gen_args_1": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? Also, Miramar has pretty homes."}, "gen_args_2": {"arg_0": "", "arg_1": " Miramar, a pleasant residential quarter with fine family homes, benefits from its position alongside the Isla Grande commuter airport., right? No, Miramar has pretty homes."}}, "resps": [[["-164.0", "False"]], [["-170.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-170.0", "False"], ["-168.0", "False"]], "doc_hash": "b08f4ce323a79fd4ab5cf417f8c950b3b66bb3d01b39e98964fe350f8aacb64e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 1199, "doc": {"premise": "The Great Depression hit California hard.", "hypothesis": "No one in California had jobs.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Yes, No one in California had jobs."}, "gen_args_1": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? Also, No one in California had jobs."}, "gen_args_2": {"arg_0": "", "arg_1": " The Great Depression hit California hard., right? No, No one in California had jobs."}}, "resps": [[["-82.0", "False"]], [["-84.0", "False"]], [["-79.5", "False"]]], "filtered_resps": [["-82.0", "False"], ["-84.0", "False"], ["-79.5", "False"]], "doc_hash": "768f77b291f9a7f8c9c20c6fca9746e63d250fa139d893d446f8be253bf5737a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07508731 0.01016196 0.91475073]"]}
{"doc_id": 1207, "doc": {"premise": "Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates.", "hypothesis": "People line up to eat in the garden.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Yes, People line up to eat in the garden."}, "gen_args_1": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? Also, People line up to eat in the garden."}, "gen_args_2": {"arg_0": "", "arg_1": " Still there is shade and a flower garden in the middle of the square where locals and visitors alike rendezvous for lunch or dinner dates., right? No, People line up to eat in the garden."}}, "resps": [[["-161.0", "False"]], [["-163.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-163.0", "False"], ["-165.0", "False"]], "doc_hash": "3f4257434345001b03f69f920d5d224d10207db6d5f8bcd848c69d2972cd0782", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.86681333 0.11731043 0.01587624]"]}
{"doc_id": 1215, "doc": {"premise": "s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion.", "hypothesis": "Charlottetown hosted leaders who were changing the maritime industry.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Yes, Charlottetown hosted leaders who were changing the maritime industry."}, "gen_args_1": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? Also, Charlottetown hosted leaders who were changing the maritime industry."}, "gen_args_2": {"arg_0": "", "arg_1": " s great historic moment came in 1864, when its capital, Charlottetown, hosted a meeting of Maritime leaders with delegates from Ontario and Quebec to chart the path to Canada's federal status as a united dominion., right? No, Charlottetown hosted leaders who were changing the maritime industry."}}, "resps": [[["-222.0", "False"]], [["-225.0", "False"]], [["-218.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-225.0", "False"], ["-218.0", "False"]], "doc_hash": "6b4e455da28baf34797a462f8a262e4efa7a035f9bfc273a50939ba0da5676cd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[1.79701181e-02 8.94679497e-04 9.81135202e-01]"]}
{"doc_id": 1223, "doc": {"premise": "Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site.", "hypothesis": "There's a square that has ten benches in it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Yes, There's a square that has ten benches in it."}, "gen_args_1": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? Also, There's a square that has ten benches in it."}, "gen_args_2": {"arg_0": "", "arg_1": " Next to the church is all that remains of Contra-Aquincum an excavated square with benches and a small display of tablets and reliefs found on the site., right? No, There's a square that has ten benches in it."}}, "resps": [[["-204.0", "False"]], [["-209.0", "False"]], [["-206.0", "False"]]], "filtered_resps": [["-204.0", "False"], ["-209.0", "False"], ["-206.0", "False"]], "doc_hash": "389c6c30b7234f0cefee57b9a828e414070d76ac2383893acb17073e73e9b78c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1231, "doc": {"premise": "Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar.", "hypothesis": "Chinatown is on the water.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Yes, Chinatown is on the water."}, "gen_args_1": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? Also, Chinatown is on the water."}, "gen_args_2": {"arg_0": "", "arg_1": " Back in town, a waterfront stroll takes you through Chinatown on Jalan Bandar., right? No, Chinatown is on the water."}}, "resps": [[["-126.0", "False"]], [["-132.0", "False"]], [["-126.5", "False"]]], "filtered_resps": [["-126.0", "False"], ["-132.0", "False"], ["-126.5", "False"]], "doc_hash": "9e202601982d7b1b16b44e8e6b16b7c8919bd8e3b94d5853140cd37d8702b853", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.6215004  0.00154055 0.37695905]"]}
{"doc_id": 1239, "doc": {"premise": "Without doubt, the initial lure of the city is its numerous historic buildings.", "hypothesis": "The city also has a university and a harbor that are interesting.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Yes, The city also has a university and a harbor that are interesting."}, "gen_args_1": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? Also, The city also has a university and a harbor that are interesting."}, "gen_args_2": {"arg_0": "", "arg_1": " Without doubt, the initial lure of the city is its numerous historic buildings., right? No, The city also has a university and a harbor that are interesting."}}, "resps": [[["-133.0", "False"]], [["-133.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-133.0", "False"], ["-135.0", "False"]], "doc_hash": "f023b1cd390765050b256d1653f5983e008c9d9ef18b1d384b495f941be28c62", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.46831053 0.06337894]"]}
{"doc_id": 1247, "doc": {"premise": "Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base.", "hypothesis": "Human resource systems were expanded beyond their previous state.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Yes, Human resource systems were expanded beyond their previous state."}, "gen_args_1": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? Also, Human resource systems were expanded beyond their previous state."}, "gen_args_2": {"arg_0": "", "arg_1": " Human resources systems were consolidated and new corporate structures were quickly defined to ensure continued support to the enlarged customer base., right? No, Human resource systems were expanded beyond their previous state."}}, "resps": [[["-163.0", "False"]], [["-169.0", "False"]], [["-163.0", "False"]]], "filtered_resps": [["-163.0", "False"], ["-169.0", "False"], ["-163.0", "False"]], "doc_hash": "94315aad4fb4d15990d006af27191bef15d8667974d776a63168076315c97532", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1255, "doc": {"premise": "Executives could also receive a rating of provisional or fail for each element.", "hypothesis": "Executives can't fail.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Yes, Executives can't fail."}, "gen_args_1": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? Also, Executives can't fail."}, "gen_args_2": {"arg_0": "", "arg_1": " Executives could also receive a rating of provisional or fail for each element., right? No, Executives can't fail."}}, "resps": [[["-130.0", "False"]], [["-130.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-130.0", "False"], ["-125.0", "False"]], "doc_hash": "508b242114a5609241f645b28139ed0140efaf525a8e922bd7f7f9558433129d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 1263, "doc": {"premise": "For example, in GGD, a design study was done as a separate job, culminating", "hypothesis": "A design study never occurred.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Yes, A design study never occurred."}, "gen_args_1": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? Also, A design study never occurred."}, "gen_args_2": {"arg_0": "", "arg_1": " For example, in GGD, a design study was done as a separate job, culminating, right? No, A design study never occurred."}}, "resps": [[["-138.0", "False"]], [["-144.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-144.0", "False"], ["-137.0", "False"]], "doc_hash": "e068d1b0aa63b8d4a7588d8c1251a4d1a2fb01da910af2029c0b9ce03a17e412", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.68762254e-01 6.66195022e-04 7.30571551e-01]"]}
{"doc_id": 1271, "doc": {"premise": "Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999.", "hypothesis": "Households have gotten a lot more wealthincome ratio.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Yes, Households have gotten a lot more wealthincome ratio."}, "gen_args_1": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? Also, Households have gotten a lot more wealthincome ratio."}, "gen_args_2": {"arg_0": "", "arg_1": " Since 1996, households' wealthincome ratio has increased rapidly-peaking at 6.4 in 1999., right? No, Households have gotten a lot more wealthincome ratio."}}, "resps": [[["-160.0", "False"]], [["-163.0", "False"]], [["-161.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-163.0", "False"], ["-161.0", "False"]], "doc_hash": "d1021c1da7845e75f05ae101f1af0d3a820bbeebd454afd0d463639564096fbc", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1279, "doc": {"premise": "19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler.", "hypothesis": "It took 13 months to retrofit the boiler for the submarine.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Yes, It took 13 months to retrofit the boiler for the submarine."}, "gen_args_1": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? Also, It took 13 months to retrofit the boiler for the submarine."}, "gen_args_2": {"arg_0": "", "arg_1": " 19 Assuming four months of work prior to contract award, a total elapsed time of 13 months would have been necessary to retrofit this 675 MWe boiler., right? No, It took 13 months to retrofit the boiler for the submarine."}}, "resps": [[["-185.0", "False"]], [["-189.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-185.0", "False"], ["-189.0", "False"], ["-186.0", "False"]], "doc_hash": "f0d3c17dc87b8a8b867762d5b15dc6ff0e7a8b33fac30e15b319874def4fdbd1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1287, "doc": {"premise": "The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before.", "hypothesis": "The technical cost effects are figured one way.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Yes, The technical cost effects are figured one way."}, "gen_args_1": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? Also, The technical cost effects are figured one way."}, "gen_args_2": {"arg_0": "", "arg_1": " The technical cost effects, due to the work being done by a party that may do it at a higher cost, are also calculated in the same way as before., right? No, The technical cost effects are figured one way."}}, "resps": [[["-179.0", "False"]], [["-183.0", "False"]], [["-178.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-183.0", "False"], ["-178.0", "False"]], "doc_hash": "3259a7302ef67adaff5e48b1ee439e274091e0ef4882c60afec2c155a3aee25f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1295, "doc": {"premise": ", the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3.", "hypothesis": "They had no idea how to estimate the benefits.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Yes, They had no idea how to estimate the benefits."}, "gen_args_1": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? Also, They had no idea how to estimate the benefits."}, "gen_args_2": {"arg_0": "", "arg_1": " , the Regional Haze RIA and the NOx SIP Call RIA), the low-end estimate of benefits assumed a threshold in PM health effects at 15 :g/m3., right? No, They had no idea how to estimate the benefits."}}, "resps": [[["-213.0", "False"]], [["-212.0", "False"]], [["-211.0", "False"]]], "filtered_resps": [["-213.0", "False"], ["-212.0", "False"], ["-211.0", "False"]], "doc_hash": "303a33f7598a39ac13491c977d36da6193cdf6cc0b2b1baab5e7a83ba25d1610", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 1303, "doc": {"premise": "49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage.", "hypothesis": "Skimmers can get ahead by paying what everyone else does.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Yes, Skimmers can get ahead by paying what everyone else does."}, "gen_args_1": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? Also, Skimmers can get ahead by paying what everyone else does."}, "gen_args_2": {"arg_0": "", "arg_1": " 49 A wage premium allows cream skimmers to obtain an efficiency/cost advantage simply by paying the prevailing wage., right? No, Skimmers can get ahead by paying what everyone else does."}}, "resps": [[["-172.0", "False"]], [["-182.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-182.0", "False"], ["-181.0", "False"]], "doc_hash": "8ecdd1fb5bf74f62a3af36447c0cff51e663c3571b71a125b20b45d31866cafa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.99831219e-01 4.53922671e-05 1.23388975e-04]"]}
{"doc_id": 1311, "doc": {"premise": "29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler.", "hypothesis": "It could never take less than 21 months.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Yes, It could never take less than 21 months."}, "gen_args_1": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? Also, It could never take less than 21 months."}, "gen_args_2": {"arg_0": "", "arg_1": " 29 Therefore, 21 months should be a reasonable, and in some cases a conservative estimate of the total time necessary to retrofit a single utility boiler., right? No, It could never take less than 21 months."}}, "resps": [[["-174.0", "False"]], [["-176.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-176.0", "False"], ["-174.0", "False"]], "doc_hash": "2c86ddd26815cf4ecfbabe4b8a9053f6d844eab67395ae54caa2cfaca62aa6ed", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1319, "doc": {"premise": "But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one.", "hypothesis": "Her work was focused on rich people.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Yes, Her work was focused on rich people."}, "gen_args_1": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? Also, Her work was focused on rich people."}, "gen_args_2": {"arg_0": "", "arg_1": " But her work on the bench affects the lives of the underprivileged, as Zelon puts it, one by one., right? No, Her work was focused on rich people."}}, "resps": [[["-164.0", "False"]], [["-166.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-166.0", "False"], ["-162.0", "False"]], "doc_hash": "770818e8300e4404eeff010f3b1e0f6fd982f8d2ab7a9a0dae4d6baa3321241f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1327, "doc": {"premise": "1) Increasing penetration of alternative modes of communication", "hypothesis": "Everyone just uses letters.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Yes, Everyone just uses letters."}, "gen_args_1": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? Also, Everyone just uses letters."}, "gen_args_2": {"arg_0": "", "arg_1": " 1) Increasing penetration of alternative modes of communication, right? No, Everyone just uses letters."}}, "resps": [[["-109.5", "False"]], [["-112.5", "False"]], [["-106.5", "False"]]], "filtered_resps": [["-109.5", "False"], ["-112.5", "False"], ["-106.5", "False"]], "doc_hash": "8588d7f2d80fa8b468f1043234cd001d4003da3be7485a797a0c2e40c0f2869c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1335, "doc": {"premise": "Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so.", "hypothesis": "The ED is leisurely and relaxed.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Yes, The ED is leisurely and relaxed."}, "gen_args_1": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? Also, The ED is leisurely and relaxed."}, "gen_args_2": {"arg_0": "", "arg_1": " Second, the ED is a fast-paced environment in which providers cannot easily find time to conduct brief alcohol interventions, even if they have the training, skills, and desire to do so., right? No, The ED is leisurely and relaxed."}}, "resps": [[["-173.0", "False"]], [["-173.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-173.0", "False"], ["-170.0", "False"]], "doc_hash": "30c0fbe64ed2d2223a8db6b481850c4b816adaae64fb0d0bd5a439ddcb36190c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1343, "doc": {"premise": "When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher.", "hypothesis": "When the travel voucher is used, the system freaks out and won't work.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Yes, When the travel voucher is used, the system freaks out and won't work."}, "gen_args_1": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? Also, When the travel voucher is used, the system freaks out and won't work."}, "gen_args_2": {"arg_0": "", "arg_1": " When the travel voucher is being processed, the automated system could compare the information on the actual charges processed by the charge card company with those claimed on the voucher., right? No, When the travel voucher is used, the system freaks out and won't work."}}, "resps": [[["-194.0", "False"]], [["-193.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-193.0", "False"], ["-192.0", "False"]], "doc_hash": "ccdba719e456b7d5f0141c9d9d5eef453a19d5f60cbea992664d46eef1f1ed6d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.09003057 0.24472847 0.66524096]"]}
{"doc_id": 1351, "doc": {"premise": "I would be pleased to respond to any questions that the Members of the Subcommittee may have.", "hypothesis": "I like to talk about my work so I would love to answer questions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Yes, I like to talk about my work so I would love to answer questions."}, "gen_args_1": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? Also, I like to talk about my work so I would love to answer questions."}, "gen_args_2": {"arg_0": "", "arg_1": " I would be pleased to respond to any questions that the Members of the Subcommittee may have., right? No, I like to talk about my work so I would love to answer questions."}}, "resps": [[["-109.5", "False"]], [["-112.0", "False"]], [["-112.0", "False"]]], "filtered_resps": [["-109.5", "False"], ["-112.0", "False"], ["-112.0", "False"]], "doc_hash": "3e11f50329a56e8555098e735c0bc71ed377c1c60a5a26b87a5864269d76a96a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.85898108 0.07050946 0.07050946]"]}
{"doc_id": 1359, "doc": {"premise": "Figure 3 shows the basic results for the two models.", "hypothesis": "Figure 3 shows how the models calculate the incomes.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Yes, Figure 3 shows how the models calculate the incomes."}, "gen_args_1": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? Also, Figure 3 shows how the models calculate the incomes."}, "gen_args_2": {"arg_0": "", "arg_1": " Figure 3 shows the basic results for the two models., right? No, Figure 3 shows how the models calculate the incomes."}}, "resps": [[["-108.5", "False"]], [["-109.0", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-108.5", "False"], ["-109.0", "False"], ["-109.0", "False"]], "doc_hash": "6b3cbac025f903e4afd72c2586ce5ea2651a5339edff34ac3e1563c98e57866e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.45186276 0.27406862 0.27406862]"]}
{"doc_id": 1367, "doc": {"premise": "C-R functions may also be estimated with or without explicit thresholds.", "hypothesis": "C-R functions can never be estimated.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Yes, C-R functions can never be estimated."}, "gen_args_1": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? Also, C-R functions can never be estimated."}, "gen_args_2": {"arg_0": "", "arg_1": " C-R functions may also be estimated with or without explicit thresholds., right? No, C-R functions can never be estimated."}}, "resps": [[["-123.5", "False"]], [["-121.5", "False"]], [["-116.5", "False"]]], "filtered_resps": [["-123.5", "False"], ["-121.5", "False"], ["-116.5", "False"]], "doc_hash": "eb3937c62afe24fd7c7c502bd49a7f9e277d6b5a7f742ab98529765e8761ac45", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.04959183e-04 6.68679417e-03 9.92408247e-01]"]}
{"doc_id": 1375, "doc": {"premise": "Dr. Gentilello recommends the development of an ED alcohol research center.", "hypothesis": "Dr. Gentilello believes that too much money is already devoted to research.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Yes, Dr. Gentilello believes that too much money is already devoted to research."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? Also, Dr. Gentilello believes that too much money is already devoted to research."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Gentilello recommends the development of an ED alcohol research center., right? No, Dr. Gentilello believes that too much money is already devoted to research."}}, "resps": [[["-146.0", "False"]], [["-146.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-146.0", "False"], ["-139.0", "False"]], "doc_hash": "c7e9546308b94af6ad73415c90029d0285e9ce36c32e8c586bea80cc2ce56d2a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[9.10221936e-04 9.10221936e-04 9.98179556e-01]"]}
{"doc_id": 1383, "doc": {"premise": "Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice.", "hypothesis": "If an attorney withdraws from a case they will be free from all obligation and liability.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Yes, If an attorney withdraws from a case they will be free from all obligation and liability."}, "gen_args_1": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? Also, If an attorney withdraws from a case they will be free from all obligation and liability."}, "gen_args_2": {"arg_0": "", "arg_1": " Even if withdrawal were allowed, this may not protect the attorney from ethical obligations to vigorously represent the client, or from claims of malpractice., right? No, If an attorney withdraws from a case they will be free from all obligation and liability."}}, "resps": [[["-172.0", "False"]], [["-175.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-175.0", "False"], ["-170.0", "False"]], "doc_hash": "cbb58add671f86ff67f2991260512230dedba37130301dd9175d3a83d331d46f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 1391, "doc": {"premise": "Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees.", "hypothesis": "It would be allot of work to monitor a group of people at all times.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Yes, It would be allot of work to monitor a group of people at all times."}, "gen_args_1": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? Also, It would be allot of work to monitor a group of people at all times."}, "gen_args_2": {"arg_0": "", "arg_1": " Requiring attorneys to monitor the movements of eligible aliens at all times of the year would impose monumental burdens on LSC grantees., right? No, It would be allot of work to monitor a group of people at all times."}}, "resps": [[["-174.0", "False"]], [["-179.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-179.0", "False"], ["-177.0", "False"]], "doc_hash": "c6363d34a1fa46c0ef5c4c69fbdf97f3d409476407991191645277927bea1e48", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1399, "doc": {"premise": "Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed.", "hypothesis": "The public are banned from commenting.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Yes, The public are banned from commenting."}, "gen_args_1": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? Also, The public are banned from commenting."}, "gen_args_2": {"arg_0": "", "arg_1": " Following public comment, the Title V operating permit is not made final until compliance testing on the control device is completed., right? No, The public are banned from commenting."}}, "resps": [[["-160.0", "False"]], [["-160.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-160.0", "False"], ["-158.0", "False"]], "doc_hash": "8305136016b67c785c4e05282556ec8e57d028914b155b0c89728f55fd2f2169", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1407, "doc": {"premise": "The Title V operating permit must also be made available for public comment.", "hypothesis": "Not everyone ants to allow public comments.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Yes, Not everyone ants to allow public comments."}, "gen_args_1": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? Also, Not everyone ants to allow public comments."}, "gen_args_2": {"arg_0": "", "arg_1": " The Title V operating permit must also be made available for public comment., right? No, Not everyone ants to allow public comments."}}, "resps": [[["-130.0", "False"]], [["-127.0", "False"]], [["-125.0", "False"]]], "filtered_resps": [["-130.0", "False"], ["-127.0", "False"], ["-125.0", "False"]], "doc_hash": "a3bb8fa5a3a3c749adf56e5ffe2aa41d76cc31a8a42ffc98c8cc83eef0f17c02", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.00589975 0.11849965 0.8756006 ]"]}
{"doc_id": 1415, "doc": {"premise": "and internal control in either of two 6", "hypothesis": "Some have internal controls.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Yes, Some have internal controls."}, "gen_args_1": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? Also, Some have internal controls."}, "gen_args_2": {"arg_0": "", "arg_1": " and internal control in either of two 6, right? No, Some have internal controls."}}, "resps": [[["-97.0", "False"]], [["-99.5", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-97.0", "False"], ["-99.5", "False"], ["-98.0", "False"]], "doc_hash": "d25afa315fbee0db6e3929fc92b2b863348b91f35bb4cfdb1bb561c0d4e3c1ad", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 1423, "doc": {"premise": "Managing Change in the Postal and Delivery Industries, Ed.", "hypothesis": "Change in the Postal and Delivery Industries happen organically and do not need to be managed.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Yes, Change in the Postal and Delivery Industries happen organically and do not need to be managed."}, "gen_args_1": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? Also, Change in the Postal and Delivery Industries happen organically and do not need to be managed."}, "gen_args_2": {"arg_0": "", "arg_1": " Managing Change in the Postal and Delivery Industries, Ed., right? No, Change in the Postal and Delivery Industries happen organically and do not need to be managed."}}, "resps": [[["-123.5", "False"]], [["-124.5", "False"]], [["-120.0", "False"]]], "filtered_resps": [["-123.5", "False"], ["-124.5", "False"], ["-120.0", "False"]], "doc_hash": "76ffda48517d0424841a87ae23c7cc749c1f7c5ff6b98da67d73fd91bb6e3d34", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02899952 0.01066833 0.96033216]"]}
{"doc_id": 1431, "doc": {"premise": "Additional time is usually needed to develop the action plan.", "hypothesis": "They can develop the plan faster than expected.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Yes, They can develop the plan faster than expected."}, "gen_args_1": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? Also, They can develop the plan faster than expected."}, "gen_args_2": {"arg_0": "", "arg_1": " Additional time is usually needed to develop the action plan., right? No, They can develop the plan faster than expected."}}, "resps": [[["-106.5", "False"]], [["-109.0", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-106.5", "False"], ["-109.0", "False"], ["-103.0", "False"]], "doc_hash": "3634e8960793be3c050bc3621f96d8be5e88294e2a0c903250a5751b07eea92a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.02924187 0.00240032 0.96835781]"]}
{"doc_id": 1439, "doc": {"premise": "They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies.", "hypothesis": "They did not include technological innovation.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Yes, They did not include technological innovation."}, "gen_args_1": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? Also, They did not include technological innovation."}, "gen_args_2": {"arg_0": "", "arg_1": " They include a stable federal budgetary future, technological innovation, and improvements in the operations and service provision of government agencies., right? No, They did not include technological innovation."}}, "resps": [[["-154.0", "False"]], [["-156.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-156.0", "False"], ["-148.0", "False"]], "doc_hash": "b97241d17114cf62c6c6361188370c00d91333005a1f30462edf451848762868", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47179601e-03 3.34521213e-04 9.97193683e-01]"]}
{"doc_id": 1447, "doc": {"premise": "The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses.", "hypothesis": "The plan does not need to contain a training program.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Yes, The plan does not need to contain a training program."}, "gen_args_1": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? Also, The plan does not need to contain a training program."}, "gen_args_2": {"arg_0": "", "arg_1": " The plan should also identify the acquisition method, key go/no-go points, a formal training plan, and a contingency plan to minimize losses., right? No, The plan does not need to contain a training program."}}, "resps": [[["-170.0", "False"]], [["-171.0", "False"]], [["-162.0", "False"]]], "filtered_resps": [["-170.0", "False"], ["-171.0", "False"], ["-162.0", "False"]], "doc_hash": "ef65fee9a6aafa72c848993d4d9cf32252d398474fa5b07b989de1ddddf05df6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.35308764e-04 1.23353201e-04 9.99541338e-01]"]}
{"doc_id": 1455, "doc": {"premise": "28 In some cases longer outages are needed.", "hypothesis": "It is never necessary to have outages.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Yes, It is never necessary to have outages."}, "gen_args_1": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? Also, It is never necessary to have outages."}, "gen_args_2": {"arg_0": "", "arg_1": " 28 In some cases longer outages are needed., right? No, It is never necessary to have outages."}}, "resps": [[["-109.0", "False"]], [["-113.5", "False"]], [["-103.0", "False"]]], "filtered_resps": [["-109.0", "False"], ["-113.5", "False"], ["-103.0", "False"]], "doc_hash": "c1b8913f72241fb85dcc425d720cb6c229ad6b62114646916af052aa97d9d972", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47255524e-03 2.74676076e-05 9.97499977e-01]"]}
{"doc_id": 1463, "doc": {"premise": "Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect.", "hypothesis": "There is a threshold in each study that determines the effect of air pollution.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Yes, There is a threshold in each study that determines the effect of air pollution."}, "gen_args_1": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? Also, There is a threshold in each study that determines the effect of air pollution."}, "gen_args_2": {"arg_0": "", "arg_1": " Air pollution levels below the threshold for each health effect studied are assumed not to cause the effect., right? No, There is a threshold in each study that determines the effect of air pollution."}}, "resps": [[["-141.0", "False"]], [["-142.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-142.0", "False"], ["-140.0", "False"]], "doc_hash": "5656c93ceba48ea4206bbfa1fa9242d8b6bd7e3c076c62e89d3d60afa10bb714", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 1471, "doc": {"premise": "In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup.", "hypothesis": "9a is the most important metric.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Yes, 9a is the most important metric."}, "gen_args_1": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? Also, 9a is the most important metric."}, "gen_args_2": {"arg_0": "", "arg_1": " In this case, the rate difference is 9a, which is equal to the cost difference of 6a inflated by the 50% markup., right? No, 9a is the most important metric."}}, "resps": [[["-149.0", "False"]], [["-151.0", "False"]], [["-149.0", "False"]]], "filtered_resps": [["-149.0", "False"], ["-151.0", "False"], ["-149.0", "False"]], "doc_hash": "add9a24559ae3dfca09922ffa8a2a7910720c13cc2944054f3d18c0c592530a4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1479, "doc": {"premise": "Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary.", "hypothesis": "Centrelink asks its customers to carefully enter details when declaring income.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Yes, Centrelink asks its customers to carefully enter details when declaring income."}, "gen_args_1": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? Also, Centrelink asks its customers to carefully enter details when declaring income."}, "gen_args_2": {"arg_0": "", "arg_1": " Also in Australia, Centrelink has determined that 65 percent of its preventable incorrect payments 13relate to incorrect declaration of income by the customer or beneficiary., right? No, Centrelink asks its customers to carefully enter details when declaring income."}}, "resps": [[["-215.0", "False"]], [["-215.0", "False"]], [["-216.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-215.0", "False"], ["-216.0", "False"]], "doc_hash": "fadd633ea268ddf987741efdbf03044317d6ec054dcba7d65e9c2d7e103316cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 1487, "doc": {"premise": "An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options.", "hypothesis": "The US does not allow aliens into any of its states.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Yes, The US does not allow aliens into any of its states."}, "gen_args_1": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? Also, The US does not allow aliens into any of its states."}, "gen_args_2": {"arg_0": "", "arg_1": " An interpretation that legal services recipients can represent aliens only during the times that they are physically present in the United States would present LSC providers with two options., right? No, The US does not allow aliens into any of its states."}}, "resps": [[["-223.0", "False"]], [["-223.0", "False"]], [["-221.0", "False"]]], "filtered_resps": [["-223.0", "False"], ["-223.0", "False"], ["-221.0", "False"]], "doc_hash": "ec5fe7f101ecfb4393aba27556b9c59db91faeea5bdcaaefe1c792ea262a4cdb", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.10650698 0.10650698 0.78698604]"]}
{"doc_id": 1495, "doc": {"premise": "The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization.", "hypothesis": "The Islamist movement was begun in the sixth century.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Yes, The Islamist movement was begun in the sixth century."}, "gen_args_1": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? Also, The Islamist movement was begun in the sixth century."}, "gen_args_2": {"arg_0": "", "arg_1": " The Islamist movement, born about 1940, is a product of the modern world, influenced by Marxist-Leninist concepts about revolutionary organization., right? No, The Islamist movement was begun in the sixth century."}}, "resps": [[["-156.0", "False"]], [["-157.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-156.0", "False"], ["-157.0", "False"], ["-150.0", "False"]], "doc_hash": "faabf85e1214f2a491780f9eeda51aa5c4f45ad31bc4a943bb8ddb9714f87b1c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[2.47037604e-03 9.08800555e-04 9.96620823e-01]"]}
{"doc_id": 1503, "doc": {"premise": "We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations.", "hypothesis": "We are 100% certain that Clarke never gave his paper to anyone.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Yes, We are 100% certain that Clarke never gave his paper to anyone."}, "gen_args_1": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? Also, We are 100% certain that Clarke never gave his paper to anyone."}, "gen_args_2": {"arg_0": "", "arg_1": " We have found no indication that the idea was briefed to the new administration or that Clarke passed his paper to them, although the same team of career officials spanned both administrations., right? No, We are 100% certain that Clarke never gave his paper to anyone."}}, "resps": [[["-207.0", "False"]], [["-209.0", "False"]], [["-204.0", "False"]]], "filtered_resps": [["-207.0", "False"], ["-209.0", "False"], ["-204.0", "False"]], "doc_hash": "e675a1ed2c7746c6f26dc43041ff63bcaea4cc8531774cb35abe6e661d4dfb8b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04712342 0.00637746 0.94649912]"]}
{"doc_id": 1511, "doc": {"premise": "Intelligence report, interrogation of KSM, July 30, 2003.", "hypothesis": "The interrogation revealed that KSM's favorite ice cream flavor was chocolate.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Yes, The interrogation revealed that KSM's favorite ice cream flavor was chocolate."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? Also, The interrogation revealed that KSM's favorite ice cream flavor was chocolate."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of KSM, July 30, 2003., right? No, The interrogation revealed that KSM's favorite ice cream flavor was chocolate."}}, "resps": [[["-126.5", "False"]], [["-129.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-126.5", "False"], ["-129.0", "False"], ["-127.5", "False"]], "doc_hash": "13d7e343ddb1dd5e63d86053827b3fabccb7cffeff7a5a658792f6af737e3c17", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.68967209 0.05661173 0.25371618]"]}
{"doc_id": 1519, "doc": {"premise": "The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done.", "hypothesis": "The director of the unit didn't want to get involved in directing what was done.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Yes, The director of the unit didn't want to get involved in directing what was done."}, "gen_args_1": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? Also, The director of the unit didn't want to get involved in directing what was done."}, "gen_args_2": {"arg_0": "", "arg_1": " The next level down, the director of the al Qaeda unit in CIA at the time recalled that he did not think it was his job to direct what should or should not be done., right? No, The director of the unit didn't want to get involved in directing what was done."}}, "resps": [[["-191.0", "False"]], [["-196.0", "False"]], [["-192.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-196.0", "False"], ["-192.0", "False"]], "doc_hash": "63c2ca36e57e2cae487cf29b0339c91bb3fcc2e5c1fb939a9dace7d0d10dc3d0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72747516 0.00490169 0.26762315]"]}
{"doc_id": 1527, "doc": {"premise": "Pickard recalls the alleged statement being made at a briefing on July 12.", "hypothesis": "Pickard couldn't remember anything they'd said.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Yes, Pickard couldn't remember anything they'd said."}, "gen_args_1": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? Also, Pickard couldn't remember anything they'd said."}, "gen_args_2": {"arg_0": "", "arg_1": " Pickard recalls the alleged statement being made at a briefing on July 12., right? No, Pickard couldn't remember anything they'd said."}}, "resps": [[["-138.0", "False"]], [["-136.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-136.0", "False"], ["-132.0", "False"]], "doc_hash": "ee8ee1378a9420474ae1dff5ef00b102e41e006432b2e68fafccbdc96c9b2c99", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00242826 0.01794253 0.97962921]"]}
{"doc_id": 1535, "doc": {"premise": "For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed.", "hypothesis": "The intercepts weren't handled correctly.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Yes, The intercepts weren't handled correctly."}, "gen_args_1": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? Also, The intercepts weren't handled correctly."}, "gen_args_2": {"arg_0": "", "arg_1": " For a brief summary of these routines and the reasons why the intercepts were not properly digested, see Graham Allison and Philip Zelikow, Essence of Decision, 2d ed., right? No, The intercepts weren't handled correctly."}}, "resps": [[["-175.0", "False"]], [["-179.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-179.0", "False"], ["-176.0", "False"]], "doc_hash": "3243402bc7df59cb148b27da809930eef21b50882a27fca8caa9f660c69713e6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1543, "doc": {"premise": "We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate.", "hypothesis": "We want to have a debate because we know these recommendations are important.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Yes, We want to have a debate because we know these recommendations are important."}, "gen_args_1": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? Also, We want to have a debate because we know these recommendations are important."}, "gen_args_2": {"arg_0": "", "arg_1": " We look forward to a national debate on the merits of what we have recommended, and we will participate vigorously in that debate., right? No, We want to have a debate because we know these recommendations are important."}}, "resps": [[["-138.0", "False"]], [["-143.0", "False"]], [["-140.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-143.0", "False"], ["-140.0", "False"]], "doc_hash": "b396927e53289ed3ff053903e8e33bf779353a58a839e4d5bcd301221d7647d8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 1551, "doc": {"premise": "After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24.", "hypothesis": "More than 100 Saudi national left the US.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Yes, More than 100 Saudi national left the US."}, "gen_args_1": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? Also, More than 100 Saudi national left the US."}, "gen_args_2": {"arg_0": "", "arg_1": " After the airspace reopened, nine chartered flights with 160 people, mostly Saudi nationals, departed from the United States between September 14 and 24., right? No, More than 100 Saudi national left the US."}}, "resps": [[["-168.0", "False"]], [["-171.0", "False"]], [["-169.0", "False"]]], "filtered_resps": [["-168.0", "False"], ["-171.0", "False"], ["-169.0", "False"]], "doc_hash": "46a558433f6073ec1cc4ecdaea2a26253a8a06a4e5ef474839e771164b764d35", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1559, "doc": {"premise": "It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious.", "hypothesis": "No one could find a connection between Khallad and Mihdhar.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Yes, No one could find a connection between Khallad and Mihdhar."}, "gen_args_1": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? Also, No one could find a connection between Khallad and Mihdhar."}, "gen_args_2": {"arg_0": "", "arg_1": " It also meant that there was a link between Khallad and Mihdhar, making Mihdhar seem even more suspicious., right? No, No one could find a connection between Khallad and Mihdhar."}}, "resps": [[["-144.0", "False"]], [["-144.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-144.0", "False"], ["-141.0", "False"]], "doc_hash": "49a85ece6c511bee0e4d410404639814f61ab001e8fa284fdc5425a313e6f976", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0452785 0.0452785 0.909443 ]"]}
{"doc_id": 1567, "doc": {"premise": "Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles.", "hypothesis": "They attempted to board the flight but Wail al Shehri was detained by security.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Yes, They attempted to board the flight but Wail al Shehri was detained by security."}, "gen_args_1": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? Also, They attempted to board the flight but Wail al Shehri was detained by security."}, "gen_args_2": {"arg_0": "", "arg_1": " Between 6:45 and 7:40, Atta and Omari, along with Satam al Suqami, Wail al Shehri, and Waleed al Shehri, checked in and boarded American Airlines Flight 11, bound for Los Angeles., right? No, They attempted to board the flight but Wail al Shehri was detained by security."}}, "resps": [[["-191.0", "False"]], [["-197.0", "False"]], [["-191.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-197.0", "False"], ["-191.0", "False"]], "doc_hash": "bf51abd02f3277c6139a1b5f0327f812414e67fcfde510e73d978b05dbca2bf6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49938108 0.00123784 0.49938108]"]}
{"doc_id": 1575, "doc": {"premise": "Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim.", "hypothesis": "All American newspapers have to sound pro-Muslim.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Yes, All American newspapers have to sound pro-Muslim."}, "gen_args_1": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? Also, All American newspapers have to sound pro-Muslim."}, "gen_args_2": {"arg_0": "", "arg_1": " Local newspapers and the few influential satellite broadcasters-like al Jazeera-often reinforce the jihadist theme that portrays the United States as anti-Muslim., right? No, All American newspapers have to sound pro-Muslim."}}, "resps": [[["-201.0", "False"]], [["-204.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-201.0", "False"], ["-204.0", "False"], ["-200.0", "False"]], "doc_hash": "134e3ccc9ac6b697a33d1de35f4f328528224d7076f1e60568161a8dce8365f1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 1583, "doc": {"premise": "As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process.", "hypothesis": "The Saudis refused to work with the US and instead pushed violence.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Yes, The Saudis refused to work with the US and instead pushed violence."}, "gen_args_1": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? Also, The Saudis refused to work with the US and instead pushed violence."}, "gen_args_2": {"arg_0": "", "arg_1": " As a result, neither the U.S. nor the Saudi people appreciated all the dimensions of the bilateral relationship, including the Saudi role in U.S. strategies to promote the Middle East peace process., right? No, The Saudis refused to work with the US and instead pushed violence."}}, "resps": [[["-191.0", "False"]], [["-193.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-191.0", "False"], ["-193.0", "False"], ["-189.0", "False"]], "doc_hash": "fb43d2ed8b5023f920b6c247c65698dfc10d5c682f8ecf72e41f089854e8bd1b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1591, "doc": {"premise": "There is no indication that Atta or Shehhi received any additional flight training in June.", "hypothesis": "There is evidence that Atta and Shehhi worked hard to become better pilots in June.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Yes, There is evidence that Atta and Shehhi worked hard to become better pilots in June."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? Also, There is evidence that Atta and Shehhi worked hard to become better pilots in June."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no indication that Atta or Shehhi received any additional flight training in June., right? No, There is evidence that Atta and Shehhi worked hard to become better pilots in June."}}, "resps": [[["-135.0", "False"]], [["-138.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-138.0", "False"], ["-132.0", "False"]], "doc_hash": "db55a91adaebccba7c70ab098cc52e3721a06f56b01ad8cb81b77b579a43a4c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04731416 0.00235563 0.95033021]"]}
{"doc_id": 1599, "doc": {"premise": "Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel.", "hypothesis": "Mihdhar did not stay at the hotel he indicated he would.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Yes, Mihdhar did not stay at the hotel he indicated he would."}, "gen_args_1": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? Also, Mihdhar did not stay at the hotel he indicated he would."}, "gen_args_2": {"arg_0": "", "arg_1": " Mihdhar gave his intended address as the Marriott Hotel, New York City, but instead spent one night at another New York hotel., right? No, Mihdhar did not stay at the hotel he indicated he would."}}, "resps": [[["-144.0", "False"]], [["-148.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-148.0", "False"], ["-144.0", "False"]], "doc_hash": "47870e9ed250e62087a822c961c6463d5e98778f4d8bf8b5f1f05c9c7c9c593e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1607, "doc": {"premise": "He believed that there was sufficient probable cause for a criminal warrant at that time.", "hypothesis": "There were reasons to be suspicious that a crime was being committed.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Yes, There were reasons to be suspicious that a crime was being committed."}, "gen_args_1": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? Also, There were reasons to be suspicious that a crime was being committed."}, "gen_args_2": {"arg_0": "", "arg_1": " He believed that there was sufficient probable cause for a criminal warrant at that time., right? No, There were reasons to be suspicious that a crime was being committed."}}, "resps": [[["-118.5", "False"]], [["-120.0", "False"]], [["-121.0", "False"]]], "filtered_resps": [["-118.5", "False"], ["-120.0", "False"], ["-121.0", "False"]], "doc_hash": "902d608639a0ab18757635dad52a674fcb50df830646e8722c94349a2e743e47", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.76615721 0.17095278 0.06289001]"]}
{"doc_id": 1615, "doc": {"premise": "The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups.", "hypothesis": "The US definitely did not give al Qaeda any money.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Yes, The US definitely did not give al Qaeda any money."}, "gen_args_1": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? Also, The US definitely did not give al Qaeda any money."}, "gen_args_2": {"arg_0": "", "arg_1": " The United States was not a primary source of al Qaeda funding, although some funds raised in the United States may have made their way to al Qaeda or its affiliated groups., right? No, The US definitely did not give al Qaeda any money."}}, "resps": [[["-141.0", "False"]], [["-143.0", "False"]], [["-141.0", "False"]]], "filtered_resps": [["-141.0", "False"], ["-143.0", "False"], ["-141.0", "False"]], "doc_hash": "4c2700ab5f7b0d1fa773251ec3d8e9d4f51ab2e85fc8957cd7a24e5855c2cce5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 1623, "doc": {"premise": "If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official.", "hypothesis": "Director of the DIA is the lowest position in relation to responsibilities.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Yes, Director of the DIA is the lowest position in relation to responsibilities."}, "gen_args_1": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? Also, Director of the DIA is the lowest position in relation to responsibilities."}, "gen_args_2": {"arg_0": "", "arg_1": " If defense intelligence is reorganized to elevate the responsibilities of the director of the DIA, then that person might be the appropriate official., right? No, Director of the DIA is the lowest position in relation to responsibilities."}}, "resps": [[["-171.0", "False"]], [["-171.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-171.0", "False"], ["-170.0", "False"]], "doc_hash": "f6ab3a64bfc7ff132ef435b3d2adaf59816fdf227f0813ae06132de9931ee9e4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1631, "doc": {"premise": "Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy.", "hypothesis": "The Mayor immediately evacuated the state on the recommendation of the OEM director.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Yes, The Mayor immediately evacuated the state on the recommendation of the OEM director."}, "gen_args_1": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? Also, The Mayor immediately evacuated the state on the recommendation of the OEM director."}, "gen_args_2": {"arg_0": "", "arg_1": " Mayor Giuliani, along with the Police and Fire commissioners and the OEM director, moved quickly north and established an emergency operations command post at the Police Academy., right? No, The Mayor immediately evacuated the state on the recommendation of the OEM director."}}, "resps": [[["-184.0", "False"]], [["-188.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-184.0", "False"], ["-188.0", "False"], ["-183.0", "False"]], "doc_hash": "78ae0b876ea3771fd820ff6dbbcfb537b3d67e3aa39874fd2f274ac832c1a1fa", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26762315 0.00490169 0.72747516]"]}
{"doc_id": 1639, "doc": {"premise": "Hard Put to Find Proof Bin Laden Directed Attacks.", "hypothesis": "It was tough to prove that Bin Laden was responsible.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Yes, It was tough to prove that Bin Laden was responsible."}, "gen_args_1": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? Also, It was tough to prove that Bin Laden was responsible."}, "gen_args_2": {"arg_0": "", "arg_1": " Hard Put to Find Proof Bin Laden Directed Attacks., right? No, It was tough to prove that Bin Laden was responsible."}}, "resps": [[["-115.0", "False"]], [["-120.0", "False"]], [["-118.0", "False"]]], "filtered_resps": [["-115.0", "False"], ["-120.0", "False"], ["-118.0", "False"]], "doc_hash": "e647c767cb54e9412244be79ac9cbb364ae12f2071869612e071d73ef9ae6694", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1647, "doc": {"premise": "The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment.", "hypothesis": "Philip Zelikow and his staff spent many hours preparing the report.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Yes, Philip Zelikow and his staff spent many hours preparing the report."}, "gen_args_1": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? Also, Philip Zelikow and his staff spent many hours preparing the report."}, "gen_args_2": {"arg_0": "", "arg_1": " The dedicated professional staff, headed by Philip Zelikow, has contributed innumerable hours to the completion of this report, setting aside other important endeavors to take on this all-consuming assignment., right? No, Philip Zelikow and his staff spent many hours preparing the report."}}, "resps": [[["-175.0", "False"]], [["-181.0", "False"]], [["-177.0", "False"]]], "filtered_resps": [["-175.0", "False"], ["-181.0", "False"], ["-177.0", "False"]], "doc_hash": "f7231df8a0d6e56d2a44d856c37697aa81bf450d5927e0c0bcd54f3161adfdab", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.87887824 0.00217852 0.11894324]"]}
{"doc_id": 1655, "doc": {"premise": "Intelligence report, interrogation of detainee, Dec. 2, 2001.", "hypothesis": "The intelligence report was written up on December 3, 2001.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Yes, The intelligence report was written up on December 3, 2001."}, "gen_args_1": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? Also, The intelligence report was written up on December 3, 2001."}, "gen_args_2": {"arg_0": "", "arg_1": " Intelligence report, interrogation of detainee, Dec. 2, 2001., right? No, The intelligence report was written up on December 3, 2001."}}, "resps": [[["-118.0", "False"]], [["-121.0", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-118.0", "False"], ["-121.0", "False"], ["-115.5", "False"]], "doc_hash": "01595bcf0255cb2028cf73d17f7012f26a6be12ff0312221c9c86660e2bbd563", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.07557276 0.00376255 0.92066469]"]}
{"doc_id": 1663, "doc": {"premise": "The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing.", "hypothesis": "Nobody had ever photographed anyone involved in the Cole bombing.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Yes, Nobody had ever photographed anyone involved in the Cole bombing."}, "gen_args_1": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? Also, Nobody had ever photographed anyone involved in the Cole bombing."}, "gen_args_2": {"arg_0": "", "arg_1": " The FBI agent obtained from a foreign government a photo of the person believed to have directed the Cole bombing., right? No, Nobody had ever photographed anyone involved in the Cole bombing."}}, "resps": [[["-148.0", "False"]], [["-150.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-148.0", "False"], ["-150.0", "False"], ["-146.0", "False"]], "doc_hash": "9044c1956a8e7f694e4b2e57299814a09e803388dd46af62cb035584744f4b01", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 1671, "doc": {"premise": "They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House.", "hypothesis": "They came right out and said what landmarks they were talking about.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Yes, They came right out and said what landmarks they were talking about."}, "gen_args_1": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? Also, They came right out and said what landmarks they were talking about."}, "gen_args_2": {"arg_0": "", "arg_1": " They discussed targets in coded language, pretending to be students discussing various fields of  architecture referred to the World Trade Center, arts the Pentagon,law the Capitol, and politics the White House., right? No, They came right out and said what landmarks they were talking about."}}, "resps": [[["-242.0", "False"]], [["-246.0", "False"]], [["-239.0", "False"]]], "filtered_resps": [["-242.0", "False"], ["-246.0", "False"], ["-239.0", "False"]], "doc_hash": "f147ec19b7475698285231c66aecc57d8ac9510e05f2a5b0a2f8e2b2064ef29b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[4.73847131e-02 8.67881295e-04 9.51747406e-01]"]}
{"doc_id": 1679, "doc": {"premise": "In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation.", "hypothesis": "Nawaf al Hazmi traveled to five different countries.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Yes, Nawaf al Hazmi traveled to five different countries."}, "gen_args_1": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? Also, Nawaf al Hazmi traveled to five different countries."}, "gen_args_2": {"arg_0": "", "arg_1": " In chapter 5 we described the Southeast Asia travels of Nawaf al Hazmi, Khalid al Mihdhar, and others in January 2000 on the first part of the planes operation., right? No, Nawaf al Hazmi traveled to five different countries."}}, "resps": [[["-186.0", "False"]], [["-187.0", "False"]], [["-186.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-187.0", "False"], ["-186.0", "False"]], "doc_hash": "bd39540b1c10e02f92b45797f9894dd67924b4256223897807f680b0663e6af9", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 1687, "doc": {"premise": "For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed.", "hypothesis": "The report contains great detail about the rescue efforts.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Yes, The report contains great detail about the rescue efforts."}, "gen_args_1": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? Also, The report contains great detail about the rescue efforts."}, "gen_args_2": {"arg_0": "", "arg_1": " For the rescue efforts, see FDNY report,Report from the Chief of Department, Anthony L. Fusco, in Manning, ed., right? No, The report contains great detail about the rescue efforts."}}, "resps": [[["-176.0", "False"]], [["-180.0", "False"]], [["-180.0", "False"]]], "filtered_resps": [["-176.0", "False"], ["-180.0", "False"], ["-180.0", "False"]], "doc_hash": "462d66d73990aecdd9315fd038dc9422c0c51666e97d97d7f9f973a68ebc3010", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 1695, "doc": {"premise": "NYPD recording, Special Operations Division radio channel, Sept. 11, 2001.", "hypothesis": "Recordings were made of some radio transmission in September.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Yes, Recordings were made of some radio transmission in September."}, "gen_args_1": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? Also, Recordings were made of some radio transmission in September."}, "gen_args_2": {"arg_0": "", "arg_1": " NYPD recording, Special Operations Division radio channel, Sept. 11, 2001., right? No, Recordings were made of some radio transmission in September."}}, "resps": [[["-135.0", "False"]], [["-140.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-140.0", "False"], ["-139.0", "False"]], "doc_hash": "4c088020f4f68bc90243d989f3a7cf2afd7575bdca09a94f09a810d816275069", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97555875 0.00657326 0.01786798]"]}
{"doc_id": 1703, "doc": {"premise": "When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office.", "hypothesis": "The New York Field Office took control over all the suspects in custody.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Yes, The New York Field Office took control over all the suspects in custody."}, "gen_args_1": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? Also, The New York Field Office took control over all the suspects in custody."}, "gen_args_2": {"arg_0": "", "arg_1": " When the attack was determined to be al Qaeda-related, responsibility shifted to the New York Field Office., right? No, The New York Field Office took control over all the suspects in custody."}}, "resps": [[["-143.0", "False"]], [["-144.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-144.0", "False"], ["-144.0", "False"]], "doc_hash": "51eca14a22008ed08ecb79f8489ae9b5bc4a37e8e1620a58c0750b1ea4c412f0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 1711, "doc": {"premise": "This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque.", "hypothesis": "These factions made up more than half of the modque's membership.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Yes, These factions made up more than half of the modque's membership."}, "gen_args_1": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? Also, These factions made up more than half of the modque's membership."}, "gen_args_2": {"arg_0": "", "arg_1": " This speculation is based, at least in part, on Thumairy's reported leadership of an extremist faction at the mosque., right? No, These factions made up more than half of the modque's membership."}}, "resps": [[["-182.0", "False"]], [["-181.0", "False"]], [["-183.0", "False"]]], "filtered_resps": [["-182.0", "False"], ["-181.0", "False"], ["-183.0", "False"]], "doc_hash": "40bf36855def0eff33159142533312049de9a59d6e8f23881de699bc268c3d81", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.24472847 0.66524096 0.09003057]"]}
{"doc_id": 1719, "doc": {"premise": "The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out.", "hypothesis": "Helocopters could not be flown near the roofs due to fires in the area.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Yes, Helocopters could not be flown near the roofs due to fires in the area."}, "gen_args_1": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? Also, Helocopters could not be flown near the roofs due to fires in the area."}, "gen_args_2": {"arg_0": "", "arg_1": " The operators were not given any information about the inability to conduct rooftop rescues and therefore could not advise callers that they had essentially been ruled out., right? No, Helocopters could not be flown near the roofs due to fires in the area."}}, "resps": [[["-208.0", "False"]], [["-207.0", "False"]], [["-207.0", "False"]]], "filtered_resps": [["-208.0", "False"], ["-207.0", "False"], ["-207.0", "False"]], "doc_hash": "b0d1a165a3b86c0d1ff5cbe809a0b4ca2036a904748aa469f9787ace3e694114", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.1553624 0.4223188 0.4223188]"]}
{"doc_id": 1727, "doc": {"premise": "This effort was going on before 9/11 and it continues on a vastly enlarged scale.", "hypothesis": "Since 9/11 funding for the effort has increased by 120%.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Yes, Since 9/11 funding for the effort has increased by 120%."}, "gen_args_1": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? Also, Since 9/11 funding for the effort has increased by 120%."}, "gen_args_2": {"arg_0": "", "arg_1": " This effort was going on before 9/11 and it continues on a vastly enlarged scale., right? No, Since 9/11 funding for the effort has increased by 120%."}}, "resps": [[["-133.0", "False"]], [["-136.0", "False"]], [["-134.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-136.0", "False"], ["-134.0", "False"]], "doc_hash": "e739af2dd16ea74ae375e6ddeb19538efb7ffb4fd7c9319377c5fd441327e30b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1735, "doc": {"premise": "The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed.", "hypothesis": "The embassy bombings killed fifteen people.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Yes, The embassy bombings killed fifteen people."}, "gen_args_1": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? Also, The embassy bombings killed fifteen people."}, "gen_args_2": {"arg_0": "", "arg_1": " The tragedy of the embassy bombings provided an opportunity for a full examination, across the government, of the national security threat that Bin Ladin posed., right? No, The embassy bombings killed fifteen people."}}, "resps": [[["-160.0", "False"]], [["-158.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-160.0", "False"], ["-158.0", "False"], ["-158.0", "False"]], "doc_hash": "6c6d23bf85537bbb327f469f086d78f7d8d8cdcb243c38e7e62376aac6ba652f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.06337894 0.46831053 0.46831053]"]}
{"doc_id": 1743, "doc": {"premise": "Your gift is important to the celebration of our 85th season.", "hypothesis": "Every gift we get is not as important as yours.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Yes, Every gift we get is not as important as yours."}, "gen_args_1": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? Also, Every gift we get is not as important as yours."}, "gen_args_2": {"arg_0": "", "arg_1": " Your gift is important to the celebration of our 85th season., right? No, Every gift we get is not as important as yours."}}, "resps": [[["-115.0", "False"]], [["-119.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-115.0", "False"], ["-119.5", "False"], ["-116.0", "False"]], "doc_hash": "13b614dbae7bb360013ff27ac8b0b35314e664261924a899828453a162a1aed3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72516924 0.0080559  0.26677486]"]}
{"doc_id": 1751, "doc": {"premise": "Most important is the fact that attending a performance at the IRT is not just a field trip.", "hypothesis": "In order to fully enjoy a performance at the IRT, you need to pay very hard attention and study the performance and its history beforehand.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Yes, In order to fully enjoy a performance at the IRT, you need to pay very hard attention and study the performance and its history beforehand."}, "gen_args_1": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? Also, In order to fully enjoy a performance at the IRT, you need to pay very hard attention and study the performance and its history beforehand."}, "gen_args_2": {"arg_0": "", "arg_1": " Most important is the fact that attending a performance at the IRT is not just a field trip., right? No, In order to fully enjoy a performance at the IRT, you need to pay very hard attention and study the performance and its history beforehand."}}, "resps": [[["-174.0", "False"]], [["-174.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-174.0", "False"], ["-174.0", "False"]], "doc_hash": "d37da4bb937d3e5b5a80e2ec370fc91160e3d306309c8bdff5435757be8c82b4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 1759, "doc": {"premise": "My hope is you were greatly blessed and encouraged by this issue.", "hypothesis": "I know this issue causes you despair, but look forward to your vacation.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Yes, I know this issue causes you despair, but look forward to your vacation."}, "gen_args_1": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? Also, I know this issue causes you despair, but look forward to your vacation."}, "gen_args_2": {"arg_0": "", "arg_1": " My hope is you were greatly blessed and encouraged by this issue., right? No, I know this issue causes you despair, but look forward to your vacation."}}, "resps": [[["-137.0", "False"]], [["-139.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-139.0", "False"], ["-139.0", "False"]], "doc_hash": "5d815f7dcd2c9347abec8d58707a817cd5fd72a18883902d833a5296f566eed6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1767, "doc": {"premise": "Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs.", "hypothesis": "Participants will be given prospects contact details and background information.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Yes, Participants will be given prospects contact details and background information."}, "gen_args_1": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? Also, Participants will be given prospects contact details and background information."}, "gen_args_2": {"arg_0": "", "arg_1": " Those participating will be provided prospects' names, addresses and telephone numbers, as well as background information on the school's needs., right? No, Participants will be given prospects contact details and background information."}}, "resps": [[["-139.0", "False"]], [["-147.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-139.0", "False"], ["-147.0", "False"], ["-143.0", "False"]], "doc_hash": "b764b76ee710e3a5a051255de68bdf0a3e69a943e7af614bafe6e8684c19eab5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81690393e-01 3.29320439e-04 1.79802867e-02]"]}
{"doc_id": 1775, "doc": {"premise": "Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live.", "hypothesis": "The biomes in our zoo were very expensive.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Yes, The biomes in our zoo were very expensive."}, "gen_args_1": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? Also, The biomes in our zoo were very expensive."}, "gen_args_2": {"arg_0": "", "arg_1": " Our Zoo was designed using the concept of biomes, which simulate the natural habitats in which animals live., right? No, The biomes in our zoo were very expensive."}}, "resps": [[["-135.0", "False"]], [["-137.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-137.0", "False"], ["-137.0", "False"]], "doc_hash": "a1d1ed60b94691b7d9fa1c3c277d9e68ae15000ab48a34492d31c8cf4704ffc0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 1783, "doc": {"premise": "However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget.", "hypothesis": "Our current budget doesn't permit us to maintain our present collections.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Yes, Our current budget doesn't permit us to maintain our present collections."}, "gen_args_1": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? Also, Our current budget doesn't permit us to maintain our present collections."}, "gen_args_2": {"arg_0": "", "arg_1": " However, dramatic increases in the costs of law books, journals, and database services mean that simply maintaining our present collections exceeds our budget., right? No, Our current budget doesn't permit us to maintain our present collections."}}, "resps": [[["-152.0", "False"]], [["-161.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-161.0", "False"], ["-152.0", "False"]], "doc_hash": "f209008255488e1e51718d9a7a20d19e60e6a42cdf448a3d0a89c895579dbfd7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[4.99969149e-01 6.17010948e-05 4.99969149e-01]"]}
{"doc_id": 1791, "doc": {"premise": "As a member of the law school's __, I know you are aware of our progress.", "hypothesis": "I am a member of the law school.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Yes, I am a member of the law school."}, "gen_args_1": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? Also, I am a member of the law school."}, "gen_args_2": {"arg_0": "", "arg_1": " As a member of the law school's __, I know you are aware of our progress., right? No, I am a member of the law school."}}, "resps": [[["-106.5", "False"]], [["-116.5", "False"]], [["-111.5", "False"]]], "filtered_resps": [["-106.5", "False"], ["-116.5", "False"], ["-111.5", "False"]], "doc_hash": "892cf4c8f66bd6de069281dd230b13a97ab46ef1daa1ad0583fb88325c4a4b20", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.93262357e-01 4.50940412e-05 6.69254912e-03]"]}
{"doc_id": 1799, "doc": {"premise": "It means everything to Becky, Stephanie, Marcus and Emily, and students like them.", "hypothesis": "Becky is a student.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Yes, Becky is a student."}, "gen_args_1": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? Also, Becky is a student."}, "gen_args_2": {"arg_0": "", "arg_1": " It means everything to Becky, Stephanie, Marcus and Emily, and students like them., right? No, Becky is a student."}}, "resps": [[["-121.0", "False"]], [["-127.5", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-127.5", "False"], ["-124.0", "False"]], "doc_hash": "7e8c047d0299c57ea44469ba15c3e9c98b2f887a11b3496e0453ba6dac6f641d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.95121186 0.00143009 0.04735805]"]}
{"doc_id": 1807, "doc": {"premise": "And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year.", "hypothesis": "The Civic Theater needs $1million this year.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Yes, The Civic Theater needs $1million this year."}, "gen_args_1": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? Also, The Civic Theater needs $1million this year."}, "gen_args_2": {"arg_0": "", "arg_1": " And, I hope that you will support the artistic and educational efforts of Civic Theatre again this year., right? No, The Civic Theater needs $1million this year."}}, "resps": [[["-137.0", "False"]], [["-140.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-137.0", "False"], ["-140.0", "False"], ["-139.0", "False"]], "doc_hash": "1331546682f2fbfc93d6b86f12972f1c7c2243a28ffcc1a41ddb43fad9e6006f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 1815, "doc": {"premise": "I believe just the opposite.", "hypothesis": "I don't think that's true.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I believe just the opposite., right? Yes, I don't think that's true."}, "gen_args_1": {"arg_0": "", "arg_1": " I believe just the opposite., right? Also, I don't think that's true."}, "gen_args_2": {"arg_0": "", "arg_1": " I believe just the opposite., right? No, I don't think that's true."}}, "resps": [[["-68.0", "False"]], [["-69.0", "False"]], [["-63.0", "False"]]], "filtered_resps": [["-68.0", "False"], ["-69.0", "False"], ["-63.0", "False"]], "doc_hash": "e195baa42347d64928e0a63c17f93062821cdb4490b83092497d53a7d505e688", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1823, "doc": {"premise": "Provide a professional atmosphere for many talented community actors to hone and perfect their skills.", "hypothesis": "Some actors use community theater to improve.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Yes, Some actors use community theater to improve."}, "gen_args_1": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? Also, Some actors use community theater to improve."}, "gen_args_2": {"arg_0": "", "arg_1": " Provide a professional atmosphere for many talented community actors to hone and perfect their skills., right? No, Some actors use community theater to improve."}}, "resps": [[["-138.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "724d91b0fd65671fc02dccdb09e3c73ff8b36cc63e86310daaee88f84a058695", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1831, "doc": {"premise": "We need resources to recruit and develop outstanding teachers.", "hypothesis": "We need better teachers.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Yes, We need better teachers."}, "gen_args_1": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? Also, We need better teachers."}, "gen_args_2": {"arg_0": "", "arg_1": " We need resources to recruit and develop outstanding teachers., right? No, We need better teachers."}}, "resps": [[["-85.0", "False"]], [["-89.0", "False"]], [["-83.5", "False"]]], "filtered_resps": [["-85.0", "False"], ["-89.0", "False"], ["-83.5", "False"]], "doc_hash": "4f508e3b2460c47b466d744d5a8e7989c2059d0b0cad45a5e07085eb31b9fd8c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.18181803 0.00333011 0.81485186]"]}
{"doc_id": 1839, "doc": {"premise": "I've got more than a job", "hypothesis": "I don't have a job or any hobby.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I've got more than a job, right? Yes, I don't have a job or any hobby."}, "gen_args_1": {"arg_0": "", "arg_1": " I've got more than a job, right? Also, I don't have a job or any hobby."}, "gen_args_2": {"arg_0": "", "arg_1": " I've got more than a job, right? No, I don't have a job or any hobby."}}, "resps": [[["-74.0", "False"]], [["-76.0", "False"]], [["-70.0", "False"]]], "filtered_resps": [["-74.0", "False"], ["-76.0", "False"], ["-70.0", "False"]], "doc_hash": "6d0135c968e30ee3c7c88d07bf6d1ca7bea7b01004ff8013e841dd3d1738e67a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01794253 0.00242826 0.97962921]"]}
{"doc_id": 1847, "doc": {"premise": "You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate.", "hypothesis": "It costs $800 to be a member for the next two years.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Yes, It costs $800 to be a member for the next two years."}, "gen_args_1": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? Also, It costs $800 to be a member for the next two years."}, "gen_args_2": {"arg_0": "", "arg_1": " You may also take advantage of our special 2-year membership offer for $30, a savings of almost 60% off our regular 2 year rate., right? No, It costs $800 to be a member for the next two years."}}, "resps": [[["-146.0", "False"]], [["-150.0", "False"]], [["-146.0", "False"]]], "filtered_resps": [["-146.0", "False"], ["-150.0", "False"], ["-146.0", "False"]], "doc_hash": "535f9c8886d53449eb0b8216c1343be50e48f203e79ad5d78bc505bee6d6693e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 1855, "doc": {"premise": "Will you add your dreams to ours?", "hypothesis": "Will you help us build the best school in the nation?", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Yes, Will you help us build the best school in the nation?"}, "gen_args_1": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? Also, Will you help us build the best school in the nation?"}, "gen_args_2": {"arg_0": "", "arg_1": " Will you add your dreams to ours?, right? No, Will you help us build the best school in the nation?"}}, "resps": [[["-98.0", "False"]], [["-99.5", "False"]], [["-101.0", "False"]]], "filtered_resps": [["-98.0", "False"], ["-99.5", "False"], ["-101.0", "False"]], "doc_hash": "5b4f51302592efd78e212e5d2915ad2db141ab609d2ab6a876fb92bb4a12ba0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.78559703 0.17529039 0.03911257]"]}
{"doc_id": 1863, "doc": {"premise": "Chairman of the Board of Trustees", "hypothesis": "The Board of Trustees has no Chairman.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Yes, The Board of Trustees has no Chairman."}, "gen_args_1": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? Also, The Board of Trustees has no Chairman."}, "gen_args_2": {"arg_0": "", "arg_1": " Chairman of the Board of Trustees, right? No, The Board of Trustees has no Chairman."}}, "resps": [[["-63.75", "False"]], [["-69.0", "False"]], [["-60.5", "False"]]], "filtered_resps": [["-63.75", "False"], ["-69.0", "False"], ["-60.5", "False"]], "doc_hash": "8e7e301f58fc451c04848f1f357a300b14d50f4331a1923febd67bbc60bfe700", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[3.73195774e-02 1.95835169e-04 9.62484587e-01]"]}
{"doc_id": 1871, "doc": {"premise": "Last year, you generously donated $-.", "hypothesis": "You donated money last year.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Yes, You donated money last year."}, "gen_args_1": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? Also, You donated money last year."}, "gen_args_2": {"arg_0": "", "arg_1": " Last year, you generously donated $-., right? No, You donated money last year."}}, "resps": [[["-89.0", "False"]], [["-93.5", "False"]], [["-93.0", "False"]]], "filtered_resps": [["-89.0", "False"], ["-93.5", "False"], ["-93.0", "False"]], "doc_hash": "0ec9ad75c21c2b320b2c85f67661326574c19017607773922bd7b70045e14223", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97141643 0.01079146 0.01779211]"]}
{"doc_id": 1879, "doc": {"premise": "I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support.", "hypothesis": "I am asking you to donate $100 to the IUPUI University Libraries.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Yes, I am asking you to donate $100 to the IUPUI University Libraries."}, "gen_args_1": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? Also, I am asking you to donate $100 to the IUPUI University Libraries."}, "gen_args_2": {"arg_0": "", "arg_1": " I am writing to thank you for your past gifts to the IUPUI University Libraries and to ask you to renew that support., right? No, I am asking you to donate $100 to the IUPUI University Libraries."}}, "resps": [[["-119.5", "False"]], [["-123.0", "False"]], [["-120.5", "False"]]], "filtered_resps": [["-119.5", "False"], ["-123.0", "False"], ["-120.5", "False"]], "doc_hash": "25934d2e0e5c841ac47582339a03d1ad83b8473e5e543f7bc5bab1db59eed75b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.71526828 0.02159923 0.26313249]"]}
{"doc_id": 1887, "doc": {"premise": "You are important to us and the I.U.", "hypothesis": "We and the I.U. consider you to be important because you are a prolific donor.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Yes, We and the I.U. consider you to be important because you are a prolific donor."}, "gen_args_1": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? Also, We and the I.U. consider you to be important because you are a prolific donor."}, "gen_args_2": {"arg_0": "", "arg_1": " You are important to us and the I.U., right? No, We and the I.U. consider you to be important because you are a prolific donor."}}, "resps": [[["-116.5", "False"]], [["-124.0", "False"]], [["-122.0", "False"]]], "filtered_resps": [["-116.5", "False"], ["-124.0", "False"], ["-122.0", "False"]], "doc_hash": "7cef0f70c0e69c6e700fa31595d5da2b5097fc53ba500615b284b6fa1eb0e50a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.95381573e-01 5.50529990e-04 4.06789698e-03]"]}
{"doc_id": 1895, "doc": {"premise": "Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you.", "hypothesis": "People give us money to keep our organization running.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Yes, People give us money to keep our organization running."}, "gen_args_1": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? Also, People give us money to keep our organization running."}, "gen_args_2": {"arg_0": "", "arg_1": " Civic's revenue comes from full houses, workshop and program tuitions, facility rental, foundations, corporate sponsors and individual contributions from supporters like you., right? No, People give us money to keep our organization running."}}, "resps": [[["-186.0", "False"]], [["-191.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-186.0", "False"], ["-191.0", "False"], ["-189.0", "False"]], "doc_hash": "9d06b5feafb65a25e550a16074e7f98688b12b8c9dc1012e6028d0ed7b187c16", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94649912 0.00637746 0.04712342]"]}
{"doc_id": 1903, "doc": {"premise": "We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself.", "hypothesis": "This is the last year we will be doing ticket sales.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Yes, This is the last year we will be doing ticket sales."}, "gen_args_1": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? Also, This is the last year we will be doing ticket sales."}, "gen_args_2": {"arg_0": "", "arg_1": " We recoup 58% of that money on ticket sales, leaving 32% to be garnered from donations and gifts from friends such as yourself., right? No, This is the last year we will be doing ticket sales."}}, "resps": [[["-169.0", "False"]], [["-169.0", "False"]], [["-168.0", "False"]]], "filtered_resps": [["-169.0", "False"], ["-169.0", "False"], ["-168.0", "False"]], "doc_hash": "9499fb18b052cc44ad1e06a30e2cf246ba585713a8e88992ef6cb8ebd9cf9093", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1911, "doc": {"premise": "This situation could also impact our ability to mount another festival next year.", "hypothesis": "We are guaranteed to have a festival for 10 years, no matter what.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Yes, We are guaranteed to have a festival for 10 years, no matter what."}, "gen_args_1": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? Also, We are guaranteed to have a festival for 10 years, no matter what."}, "gen_args_2": {"arg_0": "", "arg_1": " This situation could also impact our ability to mount another festival next year., right? No, We are guaranteed to have a festival for 10 years, no matter what."}}, "resps": [[["-134.0", "False"]], [["-135.0", "False"]], [["-130.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-135.0", "False"], ["-130.0", "False"]], "doc_hash": "d500bdf7fc6e063ae2831908bdaba3b19385b74447880acfcf916a354430e394", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01786798 0.00657326 0.97555875]"]}
{"doc_id": 1919, "doc": {"premise": "Very soon, a friend of the IRT will be calling you to take your pledge over the phone.", "hypothesis": "You need to donate $100 over the phone if you want to be a member.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Yes, You need to donate $100 over the phone if you want to be a member."}, "gen_args_1": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? Also, You need to donate $100 over the phone if you want to be a member."}, "gen_args_2": {"arg_0": "", "arg_1": " Very soon, a friend of the IRT will be calling you to take your pledge over the phone., right? No, You need to donate $100 over the phone if you want to be a member."}}, "resps": [[["-138.0", "False"]], [["-141.0", "False"]], [["-139.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-141.0", "False"], ["-139.0", "False"]], "doc_hash": "e93588685563a071788e02d1100f172079023a4838d3b1b9369067f3b84c0d54", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.70538451 0.03511903 0.25949646]"]}
{"doc_id": 1927, "doc": {"premise": "The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research.", "hypothesis": "Loren Field works at the city dump.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Yes, Loren Field works at the city dump."}, "gen_args_1": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? Also, Loren Field works at the city dump."}, "gen_args_2": {"arg_0": "", "arg_1": " The work by Loren I. Field, Ph.D., and his colleagues at the School was a cover story in a recent issue of Science - the preeminent journal recognizing benchmark research., right? No, Loren Field works at the city dump."}}, "resps": [[["-203.0", "False"]], [["-204.0", "False"]], [["-198.0", "False"]]], "filtered_resps": [["-203.0", "False"], ["-204.0", "False"], ["-198.0", "False"]], "doc_hash": "ea8c6062ff127ebfb44cd4c2083a7d45e439060a255068fd0068f0ef20e85b44", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00667641 0.00245611 0.99086747]"]}
{"doc_id": 1935, "doc": {"premise": "Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy.", "hypothesis": "Visitors will be able to see several shows in the Hilbert Conservatory every day.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Yes, Visitors will be able to see several shows in the Hilbert Conservatory every day."}, "gen_args_1": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? Also, Visitors will be able to see several shows in the Hilbert Conservatory every day."}, "gen_args_2": {"arg_0": "", "arg_1": " Visitors will have the opportunity to view changing shows in the Hilbert Conservatory  Butterflies Are Free, Wizard of Oz, Toyland, and Flights of Fantasy., right? No, Visitors will be able to see several shows in the Hilbert Conservatory every day."}}, "resps": [[["-181.0", "False"]], [["-191.0", "False"]], [["-181.0", "False"]]], "filtered_resps": [["-181.0", "False"], ["-191.0", "False"], ["-181.0", "False"]], "doc_hash": "354823b4e01d17c41b6e7569f3b74bd0617b305fec05cec61baaef712157038e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[4.99988650e-01 2.26994496e-05 4.99988650e-01]"]}
{"doc_id": 1943, "doc": {"premise": "Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters.", "hypothesis": "Members have a 25% discount .", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Yes, Members have a 25% discount ."}, "gen_args_1": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? Also, Members have a 25% discount ."}, "gen_args_2": {"arg_0": "", "arg_1": " Members receive discounts on Society products and publications available through regular catalogs and at the History Market gift shop located at our beautiful Society headquarters., right? No, Members have a 25% discount ."}}, "resps": [[["-171.0", "False"]], [["-180.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-180.0", "False"], ["-176.0", "False"]], "doc_hash": "716b5a65ff595362db97cbb9522a9f62738b0eb3e5106832be31855d9b70191b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[9.93185401e-01 1.22568816e-04 6.69203059e-03]"]}
{"doc_id": 1951, "doc": {"premise": "Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre.", "hypothesis": "IRT artists help kids in the schools.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Yes, IRT artists help kids in the schools."}, "gen_args_1": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? Also, IRT artists help kids in the schools."}, "gen_args_2": {"arg_0": "", "arg_1": " Outside of the Theatre, IRT artists go directly into the classroom to work with kids and introduce them more personally to the world of theatre., right? No, IRT artists help kids in the schools."}}, "resps": [[["-151.0", "False"]], [["-155.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-151.0", "False"], ["-155.0", "False"], ["-152.0", "False"]], "doc_hash": "0c3c289fd1ec016b65114aaecb99a36e937dcbf0712cec2495922b42ce1f0cd2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 1959, "doc": {"premise": "It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots.", "hypothesis": "The Center really wants to help the community.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Yes, The Center really wants to help the community."}, "gen_args_1": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? Also, The Center really wants to help the community."}, "gen_args_2": {"arg_0": "", "arg_1": " It is part of the Center's effort to serve the needs of communities directly by training those 'who are responsible for sustaining philanthropy at the grassroots., right? No, The Center really wants to help the community."}}, "resps": [[["-173.0", "False"]], [["-177.0", "False"]], [["-176.0", "False"]]], "filtered_resps": [["-173.0", "False"], ["-177.0", "False"], ["-176.0", "False"]], "doc_hash": "9fc0b4f335b6cab6f3665e84f9f3055a1ba190f9e0d2e8bfc675b727d453f840", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 1967, "doc": {"premise": "Your name or other inscription of your choice will be engraved on a plaque and.", "hypothesis": "Your name or message will be put on the plaque.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Yes, Your name or message will be put on the plaque."}, "gen_args_1": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? Also, Your name or message will be put on the plaque."}, "gen_args_2": {"arg_0": "", "arg_1": " Your name or other inscription of your choice will be engraved on a plaque and., right? No, Your name or message will be put on the plaque."}}, "resps": [[["-107.0", "False"]], [["-116.0", "False"]], [["-111.0", "False"]]], "filtered_resps": [["-107.0", "False"], ["-116.0", "False"], ["-111.0", "False"]], "doc_hash": "b8b47746f11d302c00cfbf11c52332691c697123992d4c4d9fb1037a832f8d54", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.81894794e-01 1.21175444e-04 1.79840305e-02]"]}
{"doc_id": 1975, "doc": {"premise": "P. S. A tribute donation to the IMA makes a wonderful holiday gift.", "hypothesis": "A donation in honor of someone would make a great gift for the holidays.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Yes, A donation in honor of someone would make a great gift for the holidays."}, "gen_args_1": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? Also, A donation in honor of someone would make a great gift for the holidays."}, "gen_args_2": {"arg_0": "", "arg_1": " P. S. A tribute donation to the IMA makes a wonderful holiday gift., right? No, A donation in honor of someone would make a great gift for the holidays."}}, "resps": [[["-125.0", "False"]], [["-128.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-125.0", "False"], ["-128.0", "False"], ["-132.0", "False"]], "doc_hash": "f03704982be2c546c7acd9eb257b6f728a523c189e91e5c88941a9c77a317897", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.51747406e-01 4.73847131e-02 8.67881295e-04]"]}
{"doc_id": 1983, "doc": {"premise": "The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it.", "hypothesis": "The Indianapolis Civic Theater has produced shows for over 80 years.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Yes, The Indianapolis Civic Theater has produced shows for over 80 years."}, "gen_args_1": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? Also, The Indianapolis Civic Theater has produced shows for over 80 years."}, "gen_args_2": {"arg_0": "", "arg_1": " The Indianapolis Civic Theatre has entertained her audiences with professionally-produced plays and musicals for 82 years while providing an arena for our city's exceptional talent, but that is certainly not the extent of it., right? No, The Indianapolis Civic Theater has produced shows for over 80 years."}}, "resps": [[["-193.0", "False"]], [["-197.0", "False"]], [["-195.0", "False"]]], "filtered_resps": [["-193.0", "False"], ["-197.0", "False"], ["-195.0", "False"]], "doc_hash": "7b23680c6cca31fc6489fa0c0ebc027b451d4153e45c71b5be9771db29b16b58", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.86681333 0.01587624 0.11731043]"]}
{"doc_id": 1991, "doc": {"premise": "Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment.", "hypothesis": "Your colleagues are being asked to follow your judgment.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Yes, Your colleagues are being asked to follow your judgment."}, "gen_args_1": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? Also, Your colleagues are being asked to follow your judgment."}, "gen_args_2": {"arg_0": "", "arg_1": " Also, you have the satisfaction of knowing that your colleagues are being urged to emulate your good judgment., right? No, Your colleagues are being asked to follow your judgment."}}, "resps": [[["-132.0", "False"]], [["-132.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-132.0", "False"], ["-132.0", "False"], ["-131.0", "False"]], "doc_hash": "858ef16e816c06e3226501ea50cd214e650434c5557724e6a35c85e2a07a48a1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 1999, "doc": {"premise": "There is one detail of Southern japes that has inverted its class associations.", "hypothesis": "Southern japes has a very clear and rigid class association.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Yes, Southern japes has a very clear and rigid class association."}, "gen_args_1": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? Also, Southern japes has a very clear and rigid class association."}, "gen_args_2": {"arg_0": "", "arg_1": " There is one detail of Southern japes that has inverted its class associations., right? No, Southern japes has a very clear and rigid class association."}}, "resps": [[["-145.0", "False"]], [["-148.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-145.0", "False"], ["-148.0", "False"], ["-143.0", "False"]], "doc_hash": "93cbf1dd0ec88208c6b6897da044c50fe2c57e8768974280d0edb63eb409c181", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11849965 0.00589975 0.8756006 ]"]}
{"doc_id": 2007, "doc": {"premise": "Run Silent, Run Deep, Run the Answer", "hypothesis": "Run while making noise.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Yes, Run while making noise."}, "gen_args_1": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? Also, Run while making noise."}, "gen_args_2": {"arg_0": "", "arg_1": " Run Silent, Run Deep, Run the Answer, right? No, Run while making noise."}}, "resps": [[["-91.0", "False"]], [["-89.5", "False"]], [["-87.0", "False"]]], "filtered_resps": [["-91.0", "False"], ["-89.5", "False"], ["-87.0", "False"]], "doc_hash": "6765ea5664175e3fe86bc506938a7dca8ba5385331dd2f18b0d15c2662b383a3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01664452 0.07459556 0.90875992]"]}
{"doc_id": 2015, "doc": {"premise": "With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux.", "hypothesis": "I was having trouble with Linux.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Yes, I was having trouble with Linux."}, "gen_args_1": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? Also, I was having trouble with Linux."}, "gen_args_2": {"arg_0": "", "arg_1": " With Microsoft Helpdesk assistance I figured out that my CD-ROM drive was probably connected to my sound card and not to the IDE port, and thus was foiling Linux., right? No, I was having trouble with Linux."}}, "resps": [[["-172.0", "False"]], [["-174.0", "False"]], [["-173.0", "False"]]], "filtered_resps": [["-172.0", "False"], ["-174.0", "False"], ["-173.0", "False"]], "doc_hash": "e6afac5a9e2d8b542f8536f764d5e2c55d0e338ccb4b22c48950f57f59da42b5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.66524096 0.09003057 0.24472847]"]}
{"doc_id": 2023, "doc": {"premise": "Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre.", "hypothesis": "Trip's conversations can be listened to.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Yes, Trip's conversations can be listened to."}, "gen_args_1": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? Also, Trip's conversations can be listened to."}, "gen_args_2": {"arg_0": "", "arg_1": " Sure, the Linda Tripp conversations do not make her sound like Simone de Beauvoir discussing her relationship with Jean-Paul Sartre., right? No, Trip's conversations can be listened to."}}, "resps": [[["-153.0", "False"]], [["-155.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-155.0", "False"], ["-155.0", "False"]], "doc_hash": "c7baf32ee264d1cdae4330d2de354655f5a3c144687d140fdf02c76e7e7d1858", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.78698604 0.10650698 0.10650698]"]}
{"doc_id": 2031, "doc": {"premise": "This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights.", "hypothesis": "Kennedy favors federal rights.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Yes, Kennedy favors federal rights."}, "gen_args_1": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? Also, Kennedy favors federal rights."}, "gen_args_2": {"arg_0": "", "arg_1": " This is the legal underpinning of Justice Anthony Kennedy's nostalgic embrace of states' rights., right? No, Kennedy favors federal rights."}}, "resps": [[["-123.5", "False"]], [["-123.0", "False"]], [["-119.5", "False"]]], "filtered_resps": [["-123.5", "False"], ["-123.0", "False"], ["-119.5", "False"]], "doc_hash": "11d88361e3951217bd1967ef18328f687d48d35efb746afd6b9c5ebf81db15cf", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.0174682 0.0288002 0.9537316]"]}
{"doc_id": 2039, "doc": {"premise": "Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee.", "hypothesis": "Bradley was from the east side of St Louis.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Yes, Bradley was from the east side of St Louis."}, "gen_args_1": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? Also, Bradley was from the east side of St Louis."}, "gen_args_2": {"arg_0": "", "arg_1": " Well, given that Bill Bradley grew up in St. Louis   wait, sorry, that would only be funny if Al Gore had grown up in Tennessee., right? No, Bradley was from the east side of St Louis."}}, "resps": [[["-162.0", "False"]], [["-161.0", "False"]], [["-159.0", "False"]]], "filtered_resps": [["-162.0", "False"], ["-161.0", "False"], ["-159.0", "False"]], "doc_hash": "a4924be1e6988102786bd7e89260fdf665a72a30c306aa938002b99fa945e4c8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.04201007 0.1141952  0.84379473]"]}
{"doc_id": 2047, "doc": {"premise": "Why doesn't this apply on the Web?", "hypothesis": "This currently does not apply on the Web.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Yes, This currently does not apply on the Web."}, "gen_args_1": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? Also, This currently does not apply on the Web."}, "gen_args_2": {"arg_0": "", "arg_1": " Why doesn't this apply on the Web?, right? No, This currently does not apply on the Web."}}, "resps": [[["-85.5", "False"]], [["-93.5", "False"]], [["-86.5", "False"]]], "filtered_resps": [["-85.5", "False"], ["-93.5", "False"], ["-86.5", "False"]], "doc_hash": "2a732b249ffd34cb473da30c97762cdb49c20fdc990488039dae571e9236873a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[7.30879336e-01 2.45182703e-04 2.68875482e-01]"]}
{"doc_id": 2055, "doc": {"premise": "You are not sure you've been clear about whose side you're on.", "hypothesis": "It's obvious who you support.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Yes, It's obvious who you support."}, "gen_args_1": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? Also, It's obvious who you support."}, "gen_args_2": {"arg_0": "", "arg_1": " You are not sure you've been clear about whose side you're on., right? No, It's obvious who you support."}}, "resps": [[["-102.0", "False"]], [["-104.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-102.0", "False"], ["-104.0", "False"], ["-100.5", "False"]], "doc_hash": "ffd3de30bf2430dfb804e7a437c2c3ddbf1980754bbaf80bda4190b7573315c7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.17803021 0.02409377 0.79787603]"]}
{"doc_id": 2063, "doc": {"premise": "One day, the technology that today creates a market for visionaries will be as mundane as light bulbs.", "hypothesis": "Technology is boring if you don't keep changing it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Yes, Technology is boring if you don't keep changing it."}, "gen_args_1": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? Also, Technology is boring if you don't keep changing it."}, "gen_args_2": {"arg_0": "", "arg_1": " One day, the technology that today creates a market for visionaries will be as mundane as light bulbs., right? No, Technology is boring if you don't keep changing it."}}, "resps": [[["-147.0", "False"]], [["-148.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-147.0", "False"], ["-148.0", "False"], ["-148.0", "False"]], "doc_hash": "37d66647a954d47cce8348e25bfc40833478feadb5cc543b61b91d4ff539bc4f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2071, "doc": {"premise": "The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat.", "hypothesis": "Some students might have cheated on their finals.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Yes, Some students might have cheated on their finals."}, "gen_args_1": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? Also, Some students might have cheated on their finals."}, "gen_args_2": {"arg_0": "", "arg_1": " The Scotsman reports that Edinburgh University is withholding exam results from 90 computer science students while the administration determines whether or not they used the Internet to cheat., right? No, Some students might have cheated on their finals."}}, "resps": [[["-157.0", "False"]], [["-158.0", "False"]], [["-157.0", "False"]]], "filtered_resps": [["-157.0", "False"], ["-158.0", "False"], ["-157.0", "False"]], "doc_hash": "463049b5388bca7c931985e87353df34fe095907cdc152d1d8c9e071bc165ac1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2079, "doc": {"premise": "One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?", "hypothesis": "Ames was arrested for selling classified information to the Soviets.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Yes, Ames was arrested for selling classified information to the Soviets."}, "gen_args_1": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? Also, Ames was arrested for selling classified information to the Soviets."}, "gen_args_2": {"arg_0": "", "arg_1": " One way to find the answer is to begin with a different  How much was Ames' information worth to the Soviets?, right? No, Ames was arrested for selling classified information to the Soviets."}}, "resps": [[["-153.0", "False"]], [["-154.0", "False"]], [["-155.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-154.0", "False"], ["-155.0", "False"]], "doc_hash": "c83629b776decd422ad9737ffd55021cb395718c44bdda87ad20757aa68be837", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.66524096 0.24472847 0.09003057]"]}
{"doc_id": 2087, "doc": {"premise": "Why is the consistent solution the right solution?", "hypothesis": "Why does the right solution so happen to be the most consistent?", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Yes, Why does the right solution so happen to be the most consistent?"}, "gen_args_1": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? Also, Why does the right solution so happen to be the most consistent?"}, "gen_args_2": {"arg_0": "", "arg_1": " Why is the consistent solution the right solution?, right? No, Why does the right solution so happen to be the most consistent?"}}, "resps": [[["-104.0", "False"]], [["-106.5", "False"]], [["-104.0", "False"]]], "filtered_resps": [["-104.0", "False"], ["-106.5", "False"], ["-104.0", "False"]], "doc_hash": "74be870aaa3442b975bbdc746b728a17b81cb8df096ea76fef53d76c6c1652b2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48028779 0.03942442 0.48028779]"]}
{"doc_id": 2095, "doc": {"premise": "She was a big-haired brunette with a fleshy face, full lips, and large teeth.", "hypothesis": "She liked to wear red lipstick and red clothes.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Yes, She liked to wear red lipstick and red clothes."}, "gen_args_1": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? Also, She liked to wear red lipstick and red clothes."}, "gen_args_2": {"arg_0": "", "arg_1": " She was a big-haired brunette with a fleshy face, full lips, and large teeth., right? No, She liked to wear red lipstick and red clothes."}}, "resps": [[["-129.0", "False"]], [["-128.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-129.0", "False"], ["-128.0", "False"], ["-131.0", "False"]], "doc_hash": "6144fe21ef5da40626a23ae3f98bb9e9a69696ca3b0f349d7aceafa09a335484", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.25949646 0.70538451 0.03511903]"]}
{"doc_id": 2103, "doc": {"premise": "Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner.", "hypothesis": "Gaddis and Pynchon are not as idiosyncratic as Morrison.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Yes, Gaddis and Pynchon are not as idiosyncratic as Morrison."}, "gen_args_1": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? Also, Gaddis and Pynchon are not as idiosyncratic as Morrison."}, "gen_args_2": {"arg_0": "", "arg_1": " Morrison certainly has earned the right to be as idiosyncratic as, say, William Gaddis, Thomas Pynchon, or William Faulkner., right? No, Gaddis and Pynchon are not as idiosyncratic as Morrison."}}, "resps": [[["-135.0", "False"]], [["-136.0", "False"]], [["-132.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-136.0", "False"], ["-132.0", "False"]], "doc_hash": "987e0700b6c3e79ea6c7730485bddb2c00be0bee8d5b719dd704715814f0881e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.04661262 0.01714783 0.93623955]"]}
{"doc_id": 2111, "doc": {"premise": "Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft.", "hypothesis": "Dickinson wrote poems.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Yes, Dickinson wrote poems."}, "gen_args_1": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? Also, Dickinson wrote poems."}, "gen_args_2": {"arg_0": "", "arg_1": " Look for Emily Dickinson's forthcoming poem, All I Really Need to Know in Poetry I Learned at Microsoft., right? No, Dickinson wrote poems."}}, "resps": [[["-134.0", "False"]], [["-140.0", "False"]], [["-138.0", "False"]]], "filtered_resps": [["-134.0", "False"], ["-140.0", "False"], ["-138.0", "False"]], "doc_hash": "447f33df22ab061f08f2e228e6e6aee3772c0707041abaccaccf8956d1c1a895", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.97962921 0.00242826 0.01794253]"]}
{"doc_id": 2119, "doc": {"premise": "Like Ross, Mehta struggles to express William Shawn's ineffable virtues.", "hypothesis": "Ross and Mehta have no problem expressing William Shawn's principles.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Yes, Ross and Mehta have no problem expressing William Shawn's principles."}, "gen_args_1": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? Also, Ross and Mehta have no problem expressing William Shawn's principles."}, "gen_args_2": {"arg_0": "", "arg_1": " Like Ross, Mehta struggles to express William Shawn's ineffable virtues., right? No, Ross and Mehta have no problem expressing William Shawn's principles."}}, "resps": [[["-152.0", "False"]], [["-154.0", "False"]], [["-150.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-154.0", "False"], ["-150.0", "False"]], "doc_hash": "a57dc010343287aee78ee3de0b3c26a8209d76de3cce7f5ee57ff958f32bb673", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.11731043 0.01587624 0.86681333]"]}
{"doc_id": 2127, "doc": {"premise": "The decent and sensitive thing to do is tell the president.", "hypothesis": "It would be humane to inform the president.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Yes, It would be humane to inform the president."}, "gen_args_1": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? Also, It would be humane to inform the president."}, "gen_args_2": {"arg_0": "", "arg_1": " The decent and sensitive thing to do is tell the president., right? No, It would be humane to inform the president."}}, "resps": [[["-102.0", "False"]], [["-108.5", "False"]], [["-105.5", "False"]]], "filtered_resps": [["-102.0", "False"], ["-108.5", "False"], ["-105.5", "False"]], "doc_hash": "adbc35cf7dc308c5b0fe38008cccaf9d56d5d5a350b61175a0f7e0ff82946d36", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96927324 0.00145724 0.02926952]"]}
{"doc_id": 2135, "doc": {"premise": "Why would human beings have Laibson-style preferences in the first place?", "hypothesis": "Laibson style preferences are the norm.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Yes, Laibson style preferences are the norm."}, "gen_args_1": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? Also, Laibson style preferences are the norm."}, "gen_args_2": {"arg_0": "", "arg_1": " Why would human beings have Laibson-style preferences in the first place?, right? No, Laibson style preferences are the norm."}}, "resps": [[["-110.5", "False"]], [["-115.5", "False"]], [["-109.0", "False"]]], "filtered_resps": [["-110.5", "False"], ["-115.5", "False"], ["-109.0", "False"]], "doc_hash": "cb548661e39b700798dd3b18ae0913879321f88f44ef224959f147a3934a474b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.18220157 0.00122766 0.81657077]"]}
{"doc_id": 2143, "doc": {"premise": "John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting.", "hypothesis": "John Horgan gave a glowing, five star review of Richard Dawkins' book.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Yes, John Horgan gave a glowing, five star review of Richard Dawkins' book."}, "gen_args_1": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? Also, John Horgan gave a glowing, five star review of Richard Dawkins' book."}, "gen_args_2": {"arg_0": "", "arg_1": " John Horgan's review of Richard Dawkins' Climbing Mount Impossible (The Mystery of Life) is interesting., right? No, John Horgan gave a glowing, five star review of Richard Dawkins' book."}}, "resps": [[["-142.0", "False"]], [["-149.0", "False"]], [["-144.0", "False"]]], "filtered_resps": [["-142.0", "False"], ["-149.0", "False"], ["-144.0", "False"]], "doc_hash": "ef04b6223e79657b4077892298a66ae1899d68f01d11e7671c4cb6043d89f7df", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[8.80090205e-01 8.02538386e-04 1.19107257e-01]"]}
{"doc_id": 2151, "doc": {"premise": "Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business.", "hypothesis": "Bruce apologizes very often.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Yes, Bruce apologizes very often."}, "gen_args_1": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? Also, Bruce apologizes very often."}, "gen_args_2": {"arg_0": "", "arg_1": " Lenny Bruce began his apologia this way--and I quote from bad memory--The continuation of crime, disease, suffering, and death is what keeps me, Albert Schweitzer, and J. Edgar Hoover in business., right? No, Bruce apologizes very often."}}, "resps": [[["-222.0", "False"]], [["-222.0", "False"]], [["-223.0", "False"]]], "filtered_resps": [["-222.0", "False"], ["-222.0", "False"], ["-223.0", "False"]], "doc_hash": "86a7c98a37ed93c3ef67670089f9215686fc3630371b818f1c901771b6fbedc6", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.4223188 0.1553624]"]}
{"doc_id": 2159, "doc": {"premise": "This man was born in Germany, is wealthy, educated, well-traveled...", "hypothesis": "This man was born in Arkansas and was poor, uneducated and never traveled.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Yes, This man was born in Arkansas and was poor, uneducated and never traveled."}, "gen_args_1": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? Also, This man was born in Arkansas and was poor, uneducated and never traveled."}, "gen_args_2": {"arg_0": "", "arg_1": " This man was born in Germany, is wealthy, educated, well-traveled..., right? No, This man was born in Arkansas and was poor, uneducated and never traveled."}}, "resps": [[["-122.5", "False"]], [["-123.5", "False"]], [["-115.0", "False"]]], "filtered_resps": [["-122.5", "False"], ["-123.5", "False"], ["-115.0", "False"]], "doc_hash": "1d2ef331e9faeed726c8c1354d7dd1ff51925241e5a64dce03d4ba77a55f9f9a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[5.52666249e-04 2.03314551e-04 9.99244019e-01]"]}
{"doc_id": 2167, "doc": {"premise": "This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious.", "hypothesis": "Most people dislike Forbes.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Yes, Most people dislike Forbes."}, "gen_args_1": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? Also, Most people dislike Forbes."}, "gen_args_2": {"arg_0": "", "arg_1": " This proposal initially drew some jeers from pundits whose contempt for Forbes is pretty obvious., right? No, Most people dislike Forbes."}}, "resps": [[["-133.0", "False"]], [["-137.0", "False"]], [["-136.0", "False"]]], "filtered_resps": [["-133.0", "False"], ["-137.0", "False"], ["-136.0", "False"]], "doc_hash": "7f7d53510cbf4968a304e9ae1fc635fddd3aa157452156172c605d42573830b8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.93623955 0.01714783 0.04661262]"]}
{"doc_id": 2175, "doc": {"premise": "My gender is interesting but really not the subject of the story here.", "hypothesis": "The interesting story regarding my gender is something I'll write about in the future.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Yes, The interesting story regarding my gender is something I'll write about in the future."}, "gen_args_1": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? Also, The interesting story regarding my gender is something I'll write about in the future."}, "gen_args_2": {"arg_0": "", "arg_1": " My gender is interesting but really not the subject of the story here., right? No, The interesting story regarding my gender is something I'll write about in the future."}}, "resps": [[["-135.0", "False"]], [["-135.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-135.0", "False"], ["-135.0", "False"], ["-135.0", "False"]], "doc_hash": "fb71041840a84d5b32c27d63157d66c1f0228ff90cf0707be06567a8872692b0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2183, "doc": {"premise": "The Boston Globe has published a hard-hitting four part series on Harvard University.", "hypothesis": "The Boston Globe has written about Harvard University.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Yes, The Boston Globe has written about Harvard University."}, "gen_args_1": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? Also, The Boston Globe has written about Harvard University."}, "gen_args_2": {"arg_0": "", "arg_1": " The Boston Globe has published a hard-hitting four part series on Harvard University., right? No, The Boston Globe has written about Harvard University."}}, "resps": [[["-101.5", "False"]], [["-107.0", "False"]], [["-100.5", "False"]]], "filtered_resps": [["-101.5", "False"], ["-107.0", "False"], ["-100.5", "False"]], "doc_hash": "631f2e8ffeea997918cf1fde42e93d384886daab70025525ba80d7ca43b1d1c4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26864615 0.0010979  0.73025595]"]}
{"doc_id": 2191, "doc": {"premise": "Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;", "hypothesis": "Irony is divided into subcategories.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Yes, Irony is divided into subcategories."}, "gen_args_1": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? Also, Irony is divided into subcategories."}, "gen_args_2": {"arg_0": "", "arg_1": " Search for condescension, sentimentality, irony (with separate options for intentional and unintentional), pandering, obscurantism, and puns;, right? No, Irony is divided into subcategories."}}, "resps": [[["-171.0", "False"]], [["-171.0", "False"]], [["-170.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-171.0", "False"], ["-170.0", "False"]], "doc_hash": "d6d8042e49ad5f6a41c292830f25aa6a09935187120122036a250f25e7584d93", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.21194156 0.21194156 0.57611688]"]}
{"doc_id": 2199, "doc": {"premise": "The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di.", "hypothesis": "Hillary Clinton is a perfect person.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Yes, Hillary Clinton is a perfect person."}, "gen_args_1": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? Also, Hillary Clinton is a perfect person."}, "gen_args_2": {"arg_0": "", "arg_1": " The very insinuation that Hillary Rodham Clinton could possibly have anything to learn from Princess Diana was intriguing enough to make me click on Margaret Carlson's Hillary and Di., right? No, Hillary Clinton is a perfect person."}}, "resps": [[["-177.0", "False"]], [["-182.0", "False"]], [["-179.0", "False"]]], "filtered_resps": [["-177.0", "False"], ["-182.0", "False"], ["-179.0", "False"]], "doc_hash": "f97643cf997b71536dc9c77d31cabe6a5293b7adef9f1773138533c0bbe7043e", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.8756006  0.00589975 0.11849965]"]}
{"doc_id": 2207, "doc": {"premise": "There is no need to apologize for our leadership role.", "hypothesis": "We owe no one any apologizes for our leadership in this matter.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Yes, We owe no one any apologizes for our leadership in this matter."}, "gen_args_1": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? Also, We owe no one any apologizes for our leadership in this matter."}, "gen_args_2": {"arg_0": "", "arg_1": " There is no need to apologize for our leadership role., right? No, We owe no one any apologizes for our leadership in this matter."}}, "resps": [[["-104.0", "False"]], [["-109.0", "False"]], [["-104.5", "False"]]], "filtered_resps": [["-104.0", "False"], ["-109.0", "False"], ["-104.5", "False"]], "doc_hash": "8c338d86dce94f0792130a7a9b49d0b63cc00392f9332faa4879e4ba31265eb4", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.61985958 0.00417658 0.37596384]"]}
{"doc_id": 2215, "doc": {"premise": "The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future.", "hypothesis": "In response, the New Yorker has published massive special issues about topics like Hollywood, race, and the future.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Yes, In response, the New Yorker has published massive special issues about topics like Hollywood, race, and the future."}, "gen_args_1": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? Also, In response, the New Yorker has published massive special issues about topics like Hollywood, race, and the future."}, "gen_args_2": {"arg_0": "", "arg_1": " The New Yorker has fought back with special issues--massive tomes about race or Hollywood or the future., right? No, In response, the New Yorker has published massive special issues about topics like Hollywood, race, and the future."}}, "resps": [[["-174.0", "False"]], [["-178.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-174.0", "False"], ["-178.0", "False"], ["-175.0", "False"]], "doc_hash": "821f4cf01c9856def66f91ffa87b55a0ad552f862163724666d78dea4e2a96a8", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2223, "doc": {"premise": "The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year.", "hypothesis": "Millions of people took a diet drug that made them lost 20 pounds each.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Yes, Millions of people took a diet drug that made them lost 20 pounds each."}, "gen_args_1": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? Also, Millions of people took a diet drug that made them lost 20 pounds each."}, "gen_args_2": {"arg_0": "", "arg_1": " The French findings were basically  Eighteen million prescriptions were filled for fen-phen in the United States last year., right? No, Millions of people took a diet drug that made them lost 20 pounds each."}}, "resps": [[["-183.0", "False"]], [["-186.0", "False"]], [["-185.0", "False"]]], "filtered_resps": [["-183.0", "False"], ["-186.0", "False"], ["-185.0", "False"]], "doc_hash": "048146ca9ada04e5ecb4df6b1e8f65e00d5a35ce7f7100993e2563eaf90f4b0c", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.84379473 0.04201007 0.1141952 ]"]}
{"doc_id": 2231, "doc": {"premise": "The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway.", "hypothesis": "The ABM Treaty involves missile defense.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Yes, The ABM Treaty involves missile defense."}, "gen_args_1": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? Also, The ABM Treaty involves missile defense."}, "gen_args_2": {"arg_0": "", "arg_1": " The State Department has asked Moscow to amend the ABM Treaty--which most missile defense proponents view as an outdated Cold War dinosaur anyway., right? No, The ABM Treaty involves missile defense."}}, "resps": [[["-161.0", "False"]], [["-162.0", "False"]], [["-160.0", "False"]]], "filtered_resps": [["-161.0", "False"], ["-162.0", "False"], ["-160.0", "False"]], "doc_hash": "4a0a1eeb8ad37c58a6b09be4be770427e8761b5279a9b75383e656fe65987af1", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2239, "doc": {"premise": "The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them.", "hypothesis": "Decter is 85 years old.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Yes, Decter is 85 years old."}, "gen_args_1": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? Also, Decter is 85 years old."}, "gen_args_2": {"arg_0": "", "arg_1": " The best thing that may be said of Podhoretz and Decter is that their biological clocks can't have many more minutes left on them., right? No, Decter is 85 years old."}}, "resps": [[["-152.0", "False"]], [["-153.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-152.0", "False"], ["-153.0", "False"], ["-152.0", "False"]], "doc_hash": "9fb2df57f4a9768929728b556f873189f4a0281789855b2d27c8d967a14e181a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2247, "doc": {"premise": "On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders.", "hypothesis": "The car and the fishing buoy were tiny, compared to the boulders.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Yes, The car and the fishing buoy were tiny, compared to the boulders."}, "gen_args_1": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? Also, The car and the fishing buoy were tiny, compared to the boulders."}, "gen_args_2": {"arg_0": "", "arg_1": " On the shingle at the back of the zawn lay a crumpled black car and a bright pink fishing buoy, small as toys against the boulders., right? No, The car and the fishing buoy were tiny, compared to the boulders."}}, "resps": [[["-194.0", "False"]], [["-197.0", "False"]], [["-194.0", "False"]]], "filtered_resps": [["-194.0", "False"], ["-197.0", "False"], ["-194.0", "False"]], "doc_hash": "d5f4a669f64eef4e5249d0d8bef01146c1322b73d79b049433a8ed877df8624f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2255, "doc": {"premise": "..,  but the second time the encounter is  he is caught in the middle between two friends.", "hypothesis": "The second time the encounter involves three people.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Yes, The second time the encounter involves three people."}, "gen_args_1": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? Also, The second time the encounter involves three people."}, "gen_args_2": {"arg_0": "", "arg_1": " ..,  but the second time the encounter is  he is caught in the middle between two friends., right? No, The second time the encounter involves three people."}}, "resps": [[["-153.0", "False"]], [["-155.0", "False"]], [["-153.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-155.0", "False"], ["-153.0", "False"]], "doc_hash": "aa97747561775a7c86a0eb8a818b8113e43ee32ba8827e0f60632494d59209ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.46831053 0.06337894 0.46831053]"]}
{"doc_id": 2263, "doc": {"premise": "The last sentence   We assume, of course, that you have not submitted this essay elsewhere.", "hypothesis": "We understand that you have previously published this essay in five newspapers.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Yes, We understand that you have previously published this essay in five newspapers."}, "gen_args_1": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? Also, We understand that you have previously published this essay in five newspapers."}, "gen_args_2": {"arg_0": "", "arg_1": " The last sentence   We assume, of course, that you have not submitted this essay elsewhere., right? No, We understand that you have previously published this essay in five newspapers."}}, "resps": [[["-143.0", "False"]], [["-144.0", "False"]], [["-143.0", "False"]]], "filtered_resps": [["-143.0", "False"], ["-144.0", "False"], ["-143.0", "False"]], "doc_hash": "174a7010ee0aea19b1f4340ef366e2c431ab5822ac8c8b94225e18180531ae6f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.4223188 0.1553624 0.4223188]"]}
{"doc_id": 2271, "doc": {"premise": "good brother -- this expression of common present usage is found in Julius Caesar (iv.", "hypothesis": "In Julius Caesar, the term good brother is used.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Yes, In Julius Caesar, the term good brother is used."}, "gen_args_1": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? Also, In Julius Caesar, the term good brother is used."}, "gen_args_2": {"arg_0": "", "arg_1": " good brother -- this expression of common present usage is found in Julius Caesar (iv., right? No, In Julius Caesar, the term good brother is used."}}, "resps": [[["-154.0", "False"]], [["-158.0", "False"]], [["-158.0", "False"]]], "filtered_resps": [["-154.0", "False"], ["-158.0", "False"], ["-158.0", "False"]], "doc_hash": "c52e5a455de8b99ffc4fcd699334756735c07113f765bbec18432784595dd206", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.96466316 0.01766842 0.01766842]"]}
{"doc_id": 2279, "doc": {"premise": "We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk.", "hypothesis": "We reluctantly ate what was given to us, even though we didn't like the looks of it.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Yes, We reluctantly ate what was given to us, even though we didn't like the looks of it."}, "gen_args_1": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? Also, We reluctantly ate what was given to us, even though we didn't like the looks of it."}, "gen_args_2": {"arg_0": "", "arg_1": " We were somewhat intimidated by the look of it, but we ate it--without enthusiasm, but with the stiff upper lip we had imbibed, so to speak, with our mothers' milk., right? No, We reluctantly ate what was given to us, even though we didn't like the looks of it."}}, "resps": [[["-199.0", "False"]], [["-203.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-199.0", "False"], ["-203.0", "False"], ["-200.0", "False"]], "doc_hash": "d2863007814ce93aaa07f49b6e8117e57691eec1149068310db337c831f4d255", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2287, "doc": {"premise": "According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations.", "hypothesis": "The ODNW has more than thirty percent more information.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Yes, The ODNW has more than thirty percent more information."}, "gen_args_1": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? Also, The ODNW has more than thirty percent more information."}, "gen_args_2": {"arg_0": "", "arg_1": " According to the blurbs, the former contains 2000 entries, the latter 2700; but the ODNW is more densely packed with information-- at least thirty per cent more, by my calculations., right? No, The ODNW has more than thirty percent more information."}}, "resps": [[["-188.0", "False"]], [["-189.0", "False"]], [["-189.0", "False"]]], "filtered_resps": [["-188.0", "False"], ["-189.0", "False"], ["-189.0", "False"]], "doc_hash": "37c9572828516243ccd55998244f4b3d5891becc8450de4250d96d854877672f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.57611688 0.21194156 0.21194156]"]}
{"doc_id": 2295, "doc": {"premise": "As for challenges, I am currently looking for a word that can be cut into two successively smaller forms.", "hypothesis": "I have found three words that can be cut into two successively smaller forms.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Yes, I have found three words that can be cut into two successively smaller forms."}, "gen_args_1": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? Also, I have found three words that can be cut into two successively smaller forms."}, "gen_args_2": {"arg_0": "", "arg_1": " As for challenges, I am currently looking for a word that can be cut into two successively smaller forms., right? No, I have found three words that can be cut into two successively smaller forms."}}, "resps": [[["-138.0", "False"]], [["-141.0", "False"]], [["-137.0", "False"]]], "filtered_resps": [["-138.0", "False"], ["-141.0", "False"], ["-137.0", "False"]], "doc_hash": "3216496b42728c5e67de963fec5d1484366bfdc53536ffaca3195783bd26c964", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2303, "doc": {"premise": "But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before.", "hypothesis": "The review does not cover some essential information from the dedication.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Yes, The review does not cover some essential information from the dedication."}, "gen_args_1": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? Also, The review does not cover some essential information from the dedication."}, "gen_args_2": {"arg_0": "", "arg_1": " But this gloss on the dedication is omitted in the review, leaving the reader no wiser than before., right? No, The review does not cover some essential information from the dedication."}}, "resps": [[["-153.0", "False"]], [["-156.0", "False"]], [["-152.0", "False"]]], "filtered_resps": [["-153.0", "False"], ["-156.0", "False"], ["-152.0", "False"]], "doc_hash": "453d797ea7df1d92e6c21f53db452d7c78854c550ac520e84016c03fbc293cbd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2311, "doc": {"premise": "But they have one private, hidden name which remains a family secret.", "hypothesis": "The secret name has been passed down through the family generation after generation.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Yes, The secret name has been passed down through the family generation after generation."}, "gen_args_1": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? Also, The secret name has been passed down through the family generation after generation."}, "gen_args_2": {"arg_0": "", "arg_1": " But they have one private, hidden name which remains a family secret., right? No, The secret name has been passed down through the family generation after generation."}}, "resps": [[["-121.0", "False"]], [["-127.5", "False"]], [["-124.0", "False"]]], "filtered_resps": [["-121.0", "False"], ["-127.5", "False"], ["-124.0", "False"]], "doc_hash": "ee2f49f7f88b671f8a02b2e59b8eed0e3805d7c4c808a50b85c5306b908f1be5", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95121186 0.00143009 0.04735805]"]}
{"doc_id": 2319, "doc": {"premise": "consistency is a form of ritualism.", "hypothesis": "Being consistent is like performing rituals.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Yes, Being consistent is like performing rituals."}, "gen_args_1": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? Also, Being consistent is like performing rituals."}, "gen_args_2": {"arg_0": "", "arg_1": " consistency is a form of ritualism., right? No, Being consistent is like performing rituals."}}, "resps": [[["-88.5", "False"]], [["-96.0", "False"]], [["-93.5", "False"]]], "filtered_resps": [["-88.5", "False"], ["-96.0", "False"], ["-93.5", "False"]], "doc_hash": "592cf46930dbc9636be8f42bddcf0a7849cfd2dc40a64cacda395f96a5191c53", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.92761743e-01 5.49081003e-04 6.68917601e-03]"]}
{"doc_id": 2327, "doc": {"premise": "said my wife, raising an eyebrow.", "hypothesis": "My wife squinted her eyes as she spoke.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Yes, My wife squinted her eyes as she spoke."}, "gen_args_1": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? Also, My wife squinted her eyes as she spoke."}, "gen_args_2": {"arg_0": "", "arg_1": " said my wife, raising an eyebrow., right? No, My wife squinted her eyes as she spoke."}}, "resps": [[["-93.5", "False"]], [["-96.5", "False"]], [["-95.0", "False"]]], "filtered_resps": [["-93.5", "False"], ["-96.5", "False"], ["-95.0", "False"]], "doc_hash": "f28e8f4b19b572223e32165e5ef0c15213b71d020ecbbf3eea5e3e0d99e8861b", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.78559703 0.03911257 0.17529039]"]}
{"doc_id": 2335, "doc": {"premise": "'  It is remarkable that this anomaly still persists, even in many modern sources.", "hypothesis": "This anomaly could be corrected, but the cost would be significant.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Yes, This anomaly could be corrected, but the cost would be significant."}, "gen_args_1": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? Also, This anomaly could be corrected, but the cost would be significant."}, "gen_args_2": {"arg_0": "", "arg_1": " '  It is remarkable that this anomaly still persists, even in many modern sources., right? No, This anomaly could be corrected, but the cost would be significant."}}, "resps": [[["-144.0", "False"]], [["-145.0", "False"]], [["-148.0", "False"]]], "filtered_resps": [["-144.0", "False"], ["-145.0", "False"], ["-148.0", "False"]], "doc_hash": "c382fde342cb863ad570df2754b962d958f274c8a0a48fa828694987a8bf4cdd", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.26538793 0.01321289]"]}
{"doc_id": 2343, "doc": {"premise": "They teach us to be resolute, relentless, and resourceful.", "hypothesis": "Being resolute, relentless, and resourceful are skills that can be taught.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Yes, Being resolute, relentless, and resourceful are skills that can be taught."}, "gen_args_1": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? Also, Being resolute, relentless, and resourceful are skills that can be taught."}, "gen_args_2": {"arg_0": "", "arg_1": " They teach us to be resolute, relentless, and resourceful., right? No, Being resolute, relentless, and resourceful are skills that can be taught."}}, "resps": [[["-100.0", "False"]], [["-105.0", "False"]], [["-102.5", "False"]]], "filtered_resps": [["-100.0", "False"], ["-105.0", "False"], ["-102.5", "False"]], "doc_hash": "8ef356ce5fa3f2ef8a7896e47e4aac13131605d7a2f914b41126f462621c12ee", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.91842297 0.00618829 0.07538875]"]}
{"doc_id": 2351, "doc": {"premise": "Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line.", "hypothesis": "This romantic Latin poem references a man and a woman in the first line.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Yes, This romantic Latin poem references a man and a woman in the first line."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? Also, This romantic Latin poem references a man and a woman in the first line."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, one has a romantic poem written in Latin in which the first line contains the words for man and woman on opposite ends of the line., right? No, This romantic Latin poem references a man and a woman in the first line."}}, "resps": [[["-164.0", "False"]], [["-168.0", "False"]], [["-165.0", "False"]]], "filtered_resps": [["-164.0", "False"], ["-168.0", "False"], ["-165.0", "False"]], "doc_hash": "f6e1ce98615ecd316432def50523a521dec5d6cba2095f046e136dadb4751bf3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.72139918 0.01321289 0.26538793]"]}
{"doc_id": 2359, "doc": {"premise": "Let it be remembered that they make no declarations.", "hypothesis": "They would like to voice an opinion, but are prevented from making any declarations at this time.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Yes, They would like to voice an opinion, but are prevented from making any declarations at this time."}, "gen_args_1": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? Also, They would like to voice an opinion, but are prevented from making any declarations at this time."}, "gen_args_2": {"arg_0": "", "arg_1": " Let it be remembered that they make no declarations., right? No, They would like to voice an opinion, but are prevented from making any declarations at this time."}}, "resps": [[["-131.0", "False"]], [["-134.0", "False"]], [["-131.0", "False"]]], "filtered_resps": [["-131.0", "False"], ["-134.0", "False"], ["-131.0", "False"]], "doc_hash": "df4ac707b52003ed03eb8ca85e23f2b3f83f1762500290faea5f069cfff49b36", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.48785555 0.0242889  0.48785555]"]}
{"doc_id": 2367, "doc": {"premise": "buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble'", "hypothesis": "Cats sometimes have five legs, so the people made a saying about it.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Yes, Cats sometimes have five legs, so the people made a saying about it."}, "gen_args_1": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? Also, Cats sometimes have five legs, so the people made a saying about it."}, "gen_args_2": {"arg_0": "", "arg_1": " buscarle la quinta pata al gato `to look for the cat's fifth leg' is very common with the meaning `to look for trouble', right? No, Cats sometimes have five legs, so the people made a saying about it."}}, "resps": [[["-171.0", "False"]], [["-172.0", "False"]], [["-175.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-172.0", "False"], ["-175.0", "False"]], "doc_hash": "9898008e597692bd14c23422169781af922268d0bd6c196c877ce536c1dea15d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.72139918 0.26538793 0.01321289]"]}
{"doc_id": 2375, "doc": {"premise": "It sweeps words in its passage, as well.", "hypothesis": "When passing, it sweeps nothing.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Yes, When passing, it sweeps nothing."}, "gen_args_1": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? Also, When passing, it sweeps nothing."}, "gen_args_2": {"arg_0": "", "arg_1": " It sweeps words in its passage, as well., right? No, When passing, it sweeps nothing."}}, "resps": [[["-116.5", "False"]], [["-119.5", "False"]], [["-115.5", "False"]]], "filtered_resps": [["-116.5", "False"], ["-119.5", "False"], ["-115.5", "False"]], "doc_hash": "76b847804cdb6962a2ffa6e5cb5c034cf25c3b5e751d93cbd0e33dcfc7f13874", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.26538793 0.01321289 0.72139918]"]}
{"doc_id": 2383, "doc": {"premise": "Many languages have this ambiguity.", "hypothesis": "This ambiguity is true about most languages.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Yes, This ambiguity is true about most languages."}, "gen_args_1": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? Also, This ambiguity is true about most languages."}, "gen_args_2": {"arg_0": "", "arg_1": " Many languages have this ambiguity., right? No, This ambiguity is true about most languages."}}, "resps": [[["-86.0", "False"]], [["-90.5", "False"]], [["-89.0", "False"]]], "filtered_resps": [["-86.0", "False"], ["-90.5", "False"], ["-89.0", "False"]], "doc_hash": "438e82f07b31de48cdedd3e8ec2ecca226a4c2d12454d5814b3cecf25028f8e7", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.94259941 0.01047133 0.04692926]"]}
{"doc_id": 2391, "doc": {"premise": "If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations.", "hypothesis": "The book is nonfiction.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Yes, The book is nonfiction."}, "gen_args_1": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? Also, The book is nonfiction."}, "gen_args_2": {"arg_0": "", "arg_1": " If enough people buy this book, it will soon need a second printing which, it is hoped, will include some of the foregoing (not these ) recommendations., right? No, The book is nonfiction."}}, "resps": [[["-171.0", "False"]], [["-171.0", "False"]], [["-171.0", "False"]]], "filtered_resps": [["-171.0", "False"], ["-171.0", "False"], ["-171.0", "False"]], "doc_hash": "62b9ca768b7d8c62988c28d7f2ef7c6d6ead12fec076ca4a5e90d473aeccabc2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.33333333 0.33333333 0.33333333]"]}
{"doc_id": 2399, "doc": {"premise": "The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort.", "hypothesis": "Soft and warm words from children allow us to not fear that computers that crash, bomb and abort.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Yes, Soft and warm words from children allow us to not fear that computers that crash, bomb and abort."}, "gen_args_1": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? Also, Soft and warm words from children allow us to not fear that computers that crash, bomb and abort."}, "gen_args_2": {"arg_0": "", "arg_1": " The soft, warm, children's words allow us to allay our fears about computers that crash and bomb and abort., right? No, Soft and warm words from children allow us to not fear that computers that crash, bomb and abort."}}, "resps": [[["-190.0", "False"]], [["-196.0", "False"]], [["-193.0", "False"]]], "filtered_resps": [["-190.0", "False"], ["-196.0", "False"], ["-193.0", "False"]], "doc_hash": "a3a27f87603265127d4b90da5450e566600bbe71b1c71fc52c4016746a87efc3", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.95033021 0.00235563 0.04731416]"]}
{"doc_id": 2407, "doc": {"premise": "RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of.", "hypothesis": "This South Midland expression means I'm hungry.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Yes, This South Midland expression means I'm hungry."}, "gen_args_1": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? Also, This South Midland expression means I'm hungry."}, "gen_args_2": {"arg_0": "", "arg_1": " RH-II labels this current expression to be of South Midland and southern U.S. origin and means  to be on the verge of., right? No, This South Midland expression means I'm hungry."}}, "resps": [[["-214.0", "False"]], [["-215.0", "False"]], [["-213.0", "False"]]], "filtered_resps": [["-214.0", "False"], ["-215.0", "False"], ["-213.0", "False"]], "doc_hash": "c5e5cac6dc33a5f9013f5875a4ccbcee892487be6a475d2fd60f11c88ac6183a", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2415, "doc": {"premise": "The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony.", "hypothesis": "The Greek word for competition has come to mean pain in English because of the agony that took place during the competitions.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Yes, The Greek word for competition has come to mean pain in English because of the agony that took place during the competitions."}, "gen_args_1": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? Also, The Greek word for competition has come to mean pain in English because of the agony that took place during the competitions."}, "gen_args_2": {"arg_0": "", "arg_1": " The stadium itself, and the kind of activity that took place there, were called agon , a Greek word which originally meant simply `competition,' but which has given us our word `agony., right? No, The Greek word for competition has come to mean pain in English because of the agony that took place during the competitions."}}, "resps": [[["-208.0", "False"]], [["-212.0", "False"]], [["-214.0", "False"]]], "filtered_resps": [["-208.0", "False"], ["-212.0", "False"], ["-214.0", "False"]], "doc_hash": "757357812884d2d10c66bc467f711360d27fa81001660354cb3b176913df5421", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.97962921 0.01794253 0.00242826]"]}
{"doc_id": 2423, "doc": {"premise": "In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk.", "hypothesis": "The correspondent for The Economist in Tokyo couldn't read the T-shirt he saw.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Yes, The correspondent for The Economist in Tokyo couldn't read the T-shirt he saw."}, "gen_args_1": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? Also, The correspondent for The Economist in Tokyo couldn't read the T-shirt he saw."}, "gen_args_2": {"arg_0": "", "arg_1": " In Tokyo, a correspondent for The Economist sighted a T-shirt   O D on Bourgeoisie Milk Boy Milk., right? No, The correspondent for The Economist in Tokyo couldn't read the T-shirt he saw."}}, "resps": [[["-215.0", "False"]], [["-215.0", "False"]], [["-210.0", "False"]]], "filtered_resps": [["-215.0", "False"], ["-215.0", "False"], ["-210.0", "False"]], "doc_hash": "eb35e50dfd24422dfdfd2c202509bd0a10887307ea640357f0d2589d87bc9d7f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00664835 0.00664835 0.98670329]"]}
{"doc_id": 2431, "doc": {"premise": "The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament.", "hypothesis": "The King James Bible contains only the Old Testament.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Yes, The King James Bible contains only the Old Testament."}, "gen_args_1": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? Also, The King James Bible contains only the Old Testament."}, "gen_args_2": {"arg_0": "", "arg_1": " The translators of the King James Bible were translating the Bible for a Christian audience; for them, the Bible consisted of the Old Testament and the New Testament., right? No, The King James Bible contains only the Old Testament."}}, "resps": [[["-118.5", "False"]], [["-124.5", "False"]], [["-116.0", "False"]]], "filtered_resps": [["-118.5", "False"], ["-124.5", "False"], ["-116.0", "False"]], "doc_hash": "d602593f533f76f66762b428c518bd6029d1da27d084c4a0ae8871c047c2c40f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[7.58439188e-02 1.87998279e-04 9.23968083e-01]"]}
{"doc_id": 2439, "doc": {"premise": "She pointed to a patch of equally depressing but bushier shrubbery.", "hypothesis": "She gestured toward another, bushier shrub.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Yes, She gestured toward another, bushier shrub."}, "gen_args_1": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? Also, She gestured toward another, bushier shrub."}, "gen_args_2": {"arg_0": "", "arg_1": " She pointed to a patch of equally depressing but bushier shrubbery., right? No, She gestured toward another, bushier shrub."}}, "resps": [[["-136.0", "False"]], [["-137.0", "False"]], [["-135.0", "False"]]], "filtered_resps": [["-136.0", "False"], ["-137.0", "False"], ["-135.0", "False"]], "doc_hash": "092fe6f881613d2af402670561032d00d37ef021ae797a8b38e097d0c4e2c4e0", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.24472847 0.09003057 0.66524096]"]}
{"doc_id": 2447, "doc": {"premise": "Words that do not fit cannot be returned.", "hypothesis": "Some words do not fit.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Yes, Some words do not fit."}, "gen_args_1": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? Also, Some words do not fit."}, "gen_args_2": {"arg_0": "", "arg_1": " Words that do not fit cannot be returned., right? No, Some words do not fit."}}, "resps": [[["-84.5", "False"]], [["-88.0", "False"]], [["-84.0", "False"]]], "filtered_resps": [["-84.5", "False"], ["-88.0", "False"], ["-84.0", "False"]], "doc_hash": "87b55e5ec71634a89f4571e8f3c886174ad7b38c8b7bfd8ae1e24febf811bf8d", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[0.37328494 0.01127223 0.61544283]"]}
{"doc_id": 2455, "doc": {"premise": "These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source.", "hypothesis": "No cables or wires care included in the trade for these boxes.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Yes, No cables or wires care included in the trade for these boxes."}, "gen_args_1": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? Also, No cables or wires care included in the trade for these boxes."}, "gen_args_2": {"arg_0": "", "arg_1": " These boxes come with wires (called  cables  in the trade because that sounds more impressive) that allow them to be connected to one another and into a power source., right? No, No cables or wires care included in the trade for these boxes."}}, "resps": [[["-200.0", "False"]], [["-204.0", "False"]], [["-200.0", "False"]]], "filtered_resps": [["-200.0", "False"], ["-204.0", "False"], ["-200.0", "False"]], "doc_hash": "d9eb3615f224b780b120884e3b061b037d100e8eae728180758273df6f26c3d2", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.49546264 0.00907471 0.49546264]"]}
{"doc_id": 2463, "doc": {"premise": "Dr. Richards never stops astonishing us.", "hypothesis": "We are continuously surprised by Dr. Richards.", "label": 0}, "target": 0, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Yes, We are continuously surprised by Dr. Richards."}, "gen_args_1": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? Also, We are continuously surprised by Dr. Richards."}, "gen_args_2": {"arg_0": "", "arg_1": " Dr. Richards never stops astonishing us., right? No, We are continuously surprised by Dr. Richards."}}, "resps": [[["-95.0", "False"]], [["-102.5", "False"]], [["-98.0", "False"]]], "filtered_resps": [["-95.0", "False"], ["-102.5", "False"], ["-98.0", "False"]], "doc_hash": "e72da53ae873fb71349ff4e56deb42552bc2bfa3631df9bd35e52f8a5c971c3f", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9", "brier_score": [0, "[9.52072524e-01 5.26576432e-04 4.74008998e-02]"]}
{"doc_id": 2471, "doc": {"premise": "Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World.", "hypothesis": "Webster's College is missing way more information than the other books.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Yes, Webster's College is missing way more information than the other books."}, "gen_args_1": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? Also, Webster's College is missing way more information than the other books."}, "gen_args_2": {"arg_0": "", "arg_1": " Thus, on average, Webster's Ninth New Collegiate and the Random House Webster's College contain at least fifteen per cent more information per entry than American Heritage and Webster's New World., right? No, Webster's College is missing way more information than the other books."}}, "resps": [[["-179.0", "False"]], [["-175.0", "False"]], [["-174.0", "False"]]], "filtered_resps": [["-179.0", "False"], ["-175.0", "False"], ["-174.0", "False"]], "doc_hash": "0e58ff52d6de649824f9f42cf86c099af81c88f000ff1ce62994d2bedebea119", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.00490169 0.26762315 0.72747516]"]}
{"doc_id": 2479, "doc": {"premise": "John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip.", "hypothesis": "John Burke ignores accounts.", "label": 2}, "target": 2, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Yes, John Burke ignores accounts."}, "gen_args_1": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? Also, John Burke ignores accounts."}, "gen_args_2": {"arg_0": "", "arg_1": " John Burke (Alabama) reviews and analyzes other contemporary accounts and finds that Boswell's is not only the most accurate but that he uses it to demonstrate Johnson's character, whereas others were merely retailing literary gossip., right? No, John Burke ignores accounts."}}, "resps": [[["-232.0", "False"]], [["-231.0", "False"]], [["-228.0", "False"]]], "filtered_resps": [["-232.0", "False"], ["-231.0", "False"], ["-228.0", "False"]], "doc_hash": "3964d35748ad9e9f69a46ea94bccc148e0a19df9ec3ee7d1d56488b6d18166ca", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35", "brier_score": [2, "[0.01714783 0.04661262 0.93623955]"]}
{"doc_id": 2487, "doc": {"premise": "While statement is better, answer gives the mental picture of completion.", "hypothesis": "Statement gives more details.", "label": 1}, "target": 1, "arguments": {"gen_args_0": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Yes, Statement gives more details."}, "gen_args_1": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? Also, Statement gives more details."}, "gen_args_2": {"arg_0": "", "arg_1": " While statement is better, answer gives the mental picture of completion., right? No, Statement gives more details."}}, "resps": [[["-127.0", "False"]], [["-125.0", "False"]], [["-127.5", "False"]]], "filtered_resps": [["-127.0", "False"], ["-125.0", "False"], ["-127.5", "False"]], "doc_hash": "877e435a31be307532c5631779ce3faa017319a3d42f85e42ddccd6fd9b7b116", "prompt_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "target_hash": "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b", "brier_score": [1, "[0.11116562 0.82140902 0.06742536]"]}
